{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d60c41ae-5ec6-434c-b42f-b7b16514a128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlxtend\n",
      "  Downloading mlxtend-0.21.0-py2.py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.9/dist-packages (from mlxtend) (1.4.3)\n",
      "Requirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.9/dist-packages (from mlxtend) (1.23.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.9/dist-packages (from mlxtend) (1.1.1)\n",
      "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.9/dist-packages (from mlxtend) (1.8.1)\n",
      "Requirement already satisfied: joblib>=0.13.2 in /usr/local/lib/python3.9/dist-packages (from mlxtend) (1.1.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from mlxtend) (63.1.0)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from mlxtend) (3.5.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.0.0->mlxtend) (1.4.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.0.0->mlxtend) (21.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.0.0->mlxtend) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.0.0->mlxtend) (9.2.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.0.0->mlxtend) (4.34.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.0.0->mlxtend) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.0.0->mlxtend) (3.0.9)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=0.24.2->mlxtend) (2022.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=1.0.2->mlxtend) (3.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.14.0)\n",
      "Installing collected packages: mlxtend\n",
      "Successfully installed mlxtend-0.21.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "addeba46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "import scipy.stats as stat\n",
    "import importlib\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "298c7238",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.read_csv(\"house_price_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "0a57d23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop(\"Id\",axis=1,inplace=True) ## reduntatnt\n",
    "output_col=df_train['SalePrice']\n",
    "df_train.drop('SalePrice',axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "22fc7cf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>...</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>13175</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9042</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GdPrv</td>\n",
       "      <td>Shed</td>\n",
       "      <td>2500</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0             60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1             20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2             60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3             70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4             60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "...          ...      ...          ...      ...    ...   ...      ...   \n",
       "1455          60       RL         62.0     7917   Pave   NaN      Reg   \n",
       "1456          20       RL         85.0    13175   Pave   NaN      Reg   \n",
       "1457          70       RL         66.0     9042   Pave   NaN      Reg   \n",
       "1458          20       RL         68.0     9717   Pave   NaN      Reg   \n",
       "1459          20       RL         75.0     9937   Pave   NaN      Reg   \n",
       "\n",
       "     LandContour Utilities LotConfig  ... ScreenPorch PoolArea PoolQC  Fence  \\\n",
       "0            Lvl    AllPub    Inside  ...           0        0    NaN    NaN   \n",
       "1            Lvl    AllPub       FR2  ...           0        0    NaN    NaN   \n",
       "2            Lvl    AllPub    Inside  ...           0        0    NaN    NaN   \n",
       "3            Lvl    AllPub    Corner  ...           0        0    NaN    NaN   \n",
       "4            Lvl    AllPub       FR2  ...           0        0    NaN    NaN   \n",
       "...          ...       ...       ...  ...         ...      ...    ...    ...   \n",
       "1455         Lvl    AllPub    Inside  ...           0        0    NaN    NaN   \n",
       "1456         Lvl    AllPub    Inside  ...           0        0    NaN  MnPrv   \n",
       "1457         Lvl    AllPub    Inside  ...           0        0    NaN  GdPrv   \n",
       "1458         Lvl    AllPub    Inside  ...           0        0    NaN    NaN   \n",
       "1459         Lvl    AllPub    Inside  ...           0        0    NaN    NaN   \n",
       "\n",
       "     MiscFeature MiscVal  MoSold  YrSold  SaleType  SaleCondition  \n",
       "0            NaN       0       2    2008        WD         Normal  \n",
       "1            NaN       0       5    2007        WD         Normal  \n",
       "2            NaN       0       9    2008        WD         Normal  \n",
       "3            NaN       0       2    2006        WD        Abnorml  \n",
       "4            NaN       0      12    2008        WD         Normal  \n",
       "...          ...     ...     ...     ...       ...            ...  \n",
       "1455         NaN       0       8    2007        WD         Normal  \n",
       "1456         NaN       0       2    2010        WD         Normal  \n",
       "1457        Shed    2500       5    2010        WD         Normal  \n",
       "1458         NaN       0       4    2010        WD         Normal  \n",
       "1459         NaN       0       6    2008        WD         Normal  \n",
       "\n",
       "[1460 rows x 79 columns]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "9d780948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1201.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1452.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>56.897260</td>\n",
       "      <td>70.049958</td>\n",
       "      <td>10516.828082</td>\n",
       "      <td>6.099315</td>\n",
       "      <td>5.575342</td>\n",
       "      <td>1971.267808</td>\n",
       "      <td>1984.865753</td>\n",
       "      <td>103.685262</td>\n",
       "      <td>443.639726</td>\n",
       "      <td>46.549315</td>\n",
       "      <td>...</td>\n",
       "      <td>472.980137</td>\n",
       "      <td>94.244521</td>\n",
       "      <td>46.660274</td>\n",
       "      <td>21.954110</td>\n",
       "      <td>3.409589</td>\n",
       "      <td>15.060959</td>\n",
       "      <td>2.758904</td>\n",
       "      <td>43.489041</td>\n",
       "      <td>6.321918</td>\n",
       "      <td>2007.815753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>42.300571</td>\n",
       "      <td>24.284752</td>\n",
       "      <td>9981.264932</td>\n",
       "      <td>1.382997</td>\n",
       "      <td>1.112799</td>\n",
       "      <td>30.202904</td>\n",
       "      <td>20.645407</td>\n",
       "      <td>181.066207</td>\n",
       "      <td>456.098091</td>\n",
       "      <td>161.319273</td>\n",
       "      <td>...</td>\n",
       "      <td>213.804841</td>\n",
       "      <td>125.338794</td>\n",
       "      <td>66.256028</td>\n",
       "      <td>61.119149</td>\n",
       "      <td>29.317331</td>\n",
       "      <td>55.757415</td>\n",
       "      <td>40.177307</td>\n",
       "      <td>496.123024</td>\n",
       "      <td>2.703626</td>\n",
       "      <td>1.328095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1300.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1872.000000</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2006.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>7553.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1954.000000</td>\n",
       "      <td>1967.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>334.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2007.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>9478.500000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1973.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>383.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2008.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>70.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>11601.500000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>712.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>576.000000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2009.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>190.000000</td>\n",
       "      <td>313.000000</td>\n",
       "      <td>215245.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>5644.000000</td>\n",
       "      <td>1474.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1418.000000</td>\n",
       "      <td>857.000000</td>\n",
       "      <td>547.000000</td>\n",
       "      <td>552.000000</td>\n",
       "      <td>508.000000</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>738.000000</td>\n",
       "      <td>15500.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        MSSubClass  LotFrontage        LotArea  OverallQual  OverallCond  \\\n",
       "count  1460.000000  1201.000000    1460.000000  1460.000000  1460.000000   \n",
       "mean     56.897260    70.049958   10516.828082     6.099315     5.575342   \n",
       "std      42.300571    24.284752    9981.264932     1.382997     1.112799   \n",
       "min      20.000000    21.000000    1300.000000     1.000000     1.000000   \n",
       "25%      20.000000    59.000000    7553.500000     5.000000     5.000000   \n",
       "50%      50.000000    69.000000    9478.500000     6.000000     5.000000   \n",
       "75%      70.000000    80.000000   11601.500000     7.000000     6.000000   \n",
       "max     190.000000   313.000000  215245.000000    10.000000     9.000000   \n",
       "\n",
       "         YearBuilt  YearRemodAdd   MasVnrArea   BsmtFinSF1   BsmtFinSF2  ...  \\\n",
       "count  1460.000000   1460.000000  1452.000000  1460.000000  1460.000000  ...   \n",
       "mean   1971.267808   1984.865753   103.685262   443.639726    46.549315  ...   \n",
       "std      30.202904     20.645407   181.066207   456.098091   161.319273  ...   \n",
       "min    1872.000000   1950.000000     0.000000     0.000000     0.000000  ...   \n",
       "25%    1954.000000   1967.000000     0.000000     0.000000     0.000000  ...   \n",
       "50%    1973.000000   1994.000000     0.000000   383.500000     0.000000  ...   \n",
       "75%    2000.000000   2004.000000   166.000000   712.250000     0.000000  ...   \n",
       "max    2010.000000   2010.000000  1600.000000  5644.000000  1474.000000  ...   \n",
       "\n",
       "        GarageArea   WoodDeckSF  OpenPorchSF  EnclosedPorch    3SsnPorch  \\\n",
       "count  1460.000000  1460.000000  1460.000000    1460.000000  1460.000000   \n",
       "mean    472.980137    94.244521    46.660274      21.954110     3.409589   \n",
       "std     213.804841   125.338794    66.256028      61.119149    29.317331   \n",
       "min       0.000000     0.000000     0.000000       0.000000     0.000000   \n",
       "25%     334.500000     0.000000     0.000000       0.000000     0.000000   \n",
       "50%     480.000000     0.000000    25.000000       0.000000     0.000000   \n",
       "75%     576.000000   168.000000    68.000000       0.000000     0.000000   \n",
       "max    1418.000000   857.000000   547.000000     552.000000   508.000000   \n",
       "\n",
       "       ScreenPorch     PoolArea       MiscVal       MoSold       YrSold  \n",
       "count  1460.000000  1460.000000   1460.000000  1460.000000  1460.000000  \n",
       "mean     15.060959     2.758904     43.489041     6.321918  2007.815753  \n",
       "std      55.757415    40.177307    496.123024     2.703626     1.328095  \n",
       "min       0.000000     0.000000      0.000000     1.000000  2006.000000  \n",
       "25%       0.000000     0.000000      0.000000     5.000000  2007.000000  \n",
       "50%       0.000000     0.000000      0.000000     6.000000  2008.000000  \n",
       "75%       0.000000     0.000000      0.000000     8.000000  2009.000000  \n",
       "max     480.000000   738.000000  15500.000000    12.000000  2010.000000  \n",
       "\n",
       "[8 rows x 36 columns]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "3c48be5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSSubClass         0\n",
       "MSZoning           0\n",
       "LotFrontage      259\n",
       "LotArea            0\n",
       "Street             0\n",
       "                ... \n",
       "MiscVal            0\n",
       "MoSold             0\n",
       "YrSold             0\n",
       "SaleType           0\n",
       "SaleCondition      0\n",
       "Length: 79, dtype: int64"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "598c821b-4254-4129-8cf9-0a9b4d50eb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns which have zero values in more than 50% rows are removed\n",
    "def column_with_most_reduntant_values(reduntant_value,df_train:pd.DataFrame,threshold:float):\n",
    "    reduntant_counts={}\n",
    "    columns_with_most_reduntant_counts=[]\n",
    "    for col in df_train.columns:\n",
    "        if df_train[col].dtypes=='int' or df_train[col].dtypes=='float':\n",
    "            for values in df_train[col]:\n",
    "                if values==reduntant_value:\n",
    "                    reduntant_counts[col]=1+reduntant_counts.get(col,0)\n",
    "    for col in reduntant_counts:\n",
    "        if reduntant_counts[col]>=(threshold*len(df_train)):\n",
    "            columns_with_most_reduntant_counts.append(col)\n",
    "    df_train.drop(columns_with_most_reduntant_counts,axis=1,inplace=True)\n",
    "        \n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "ac57fe70-5f53-4bdb-9607-238484acd4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_with_most_reduntant_values(reduntant_value=0,df_train=df_train,threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "4d518c35-78eb-49f2-a59e-1e8ec94ad72c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>...</th>\n",
       "      <th>GarageCond</th>\n",
       "      <th>PavedDrive</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>...</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>13175</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9042</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GdPrv</td>\n",
       "      <td>Shed</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0             60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1             20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2             60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3             70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4             60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "...          ...      ...          ...      ...    ...   ...      ...   \n",
       "1455          60       RL         62.0     7917   Pave   NaN      Reg   \n",
       "1456          20       RL         85.0    13175   Pave   NaN      Reg   \n",
       "1457          70       RL         66.0     9042   Pave   NaN      Reg   \n",
       "1458          20       RL         68.0     9717   Pave   NaN      Reg   \n",
       "1459          20       RL         75.0     9937   Pave   NaN      Reg   \n",
       "\n",
       "     LandContour Utilities LotConfig  ... GarageCond PavedDrive OpenPorchSF  \\\n",
       "0            Lvl    AllPub    Inside  ...         TA          Y          61   \n",
       "1            Lvl    AllPub       FR2  ...         TA          Y           0   \n",
       "2            Lvl    AllPub    Inside  ...         TA          Y          42   \n",
       "3            Lvl    AllPub    Corner  ...         TA          Y          35   \n",
       "4            Lvl    AllPub       FR2  ...         TA          Y          84   \n",
       "...          ...       ...       ...  ...        ...        ...         ...   \n",
       "1455         Lvl    AllPub    Inside  ...         TA          Y          40   \n",
       "1456         Lvl    AllPub    Inside  ...         TA          Y           0   \n",
       "1457         Lvl    AllPub    Inside  ...         TA          Y          60   \n",
       "1458         Lvl    AllPub    Inside  ...         TA          Y           0   \n",
       "1459         Lvl    AllPub    Inside  ...         TA          Y          68   \n",
       "\n",
       "     PoolQC  Fence MiscFeature  MoSold  YrSold  SaleType  SaleCondition  \n",
       "0       NaN    NaN         NaN       2    2008        WD         Normal  \n",
       "1       NaN    NaN         NaN       5    2007        WD         Normal  \n",
       "2       NaN    NaN         NaN       9    2008        WD         Normal  \n",
       "3       NaN    NaN         NaN       2    2006        WD        Abnorml  \n",
       "4       NaN    NaN         NaN      12    2008        WD         Normal  \n",
       "...     ...    ...         ...     ...     ...       ...            ...  \n",
       "1455    NaN    NaN         NaN       8    2007        WD         Normal  \n",
       "1456    NaN  MnPrv         NaN       2    2010        WD         Normal  \n",
       "1457    NaN  GdPrv        Shed       5    2010        WD         Normal  \n",
       "1458    NaN    NaN         NaN       4    2010        WD         Normal  \n",
       "1459    NaN    NaN         NaN       6    2008        WD         Normal  \n",
       "\n",
       "[1460 rows x 66 columns]"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "3aec5d13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Deleting columns which have more than 50% NULL values\n",
    "\n",
    "def column_with_most_reduntant_null_values(threshold,df_train:pd.DataFrame):\n",
    "    null_cols=[]\n",
    "    for col in df_train.columns:\n",
    "        if df_train[col].isnull().sum()>=(threshold*len(df_train)):\n",
    "            null_cols.append(col)\n",
    "    df_train.drop(null_cols,axis=1,inplace=True)\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "45e43969-8c4c-4da2-916c-9c31dbf3a687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(column_with_most_reduntant_null_values(threshold=0.5,X=df_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "390c6267-15fd-4ddf-b3fd-f3a91a12c080",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_with_most_reduntant_null_values(threshold=0.5,df_train=df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "1ed65a14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>...</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>GarageQual</th>\n",
       "      <th>GarageCond</th>\n",
       "      <th>PavedDrive</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>548</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>460</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>608</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>42</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>642</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>836</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>84</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>460</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>40</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>13175</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>500</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9042</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>252</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>60</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>240</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>276</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>68</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass MSZoning  LotFrontage  LotArea Street LotShape LandContour  \\\n",
       "0             60       RL         65.0     8450   Pave      Reg         Lvl   \n",
       "1             20       RL         80.0     9600   Pave      Reg         Lvl   \n",
       "2             60       RL         68.0    11250   Pave      IR1         Lvl   \n",
       "3             70       RL         60.0     9550   Pave      IR1         Lvl   \n",
       "4             60       RL         84.0    14260   Pave      IR1         Lvl   \n",
       "...          ...      ...          ...      ...    ...      ...         ...   \n",
       "1455          60       RL         62.0     7917   Pave      Reg         Lvl   \n",
       "1456          20       RL         85.0    13175   Pave      Reg         Lvl   \n",
       "1457          70       RL         66.0     9042   Pave      Reg         Lvl   \n",
       "1458          20       RL         68.0     9717   Pave      Reg         Lvl   \n",
       "1459          20       RL         75.0     9937   Pave      Reg         Lvl   \n",
       "\n",
       "     Utilities LotConfig LandSlope  ... GarageCars GarageArea GarageQual  \\\n",
       "0       AllPub    Inside       Gtl  ...          2        548         TA   \n",
       "1       AllPub       FR2       Gtl  ...          2        460         TA   \n",
       "2       AllPub    Inside       Gtl  ...          2        608         TA   \n",
       "3       AllPub    Corner       Gtl  ...          3        642         TA   \n",
       "4       AllPub       FR2       Gtl  ...          3        836         TA   \n",
       "...        ...       ...       ...  ...        ...        ...        ...   \n",
       "1455    AllPub    Inside       Gtl  ...          2        460         TA   \n",
       "1456    AllPub    Inside       Gtl  ...          2        500         TA   \n",
       "1457    AllPub    Inside       Gtl  ...          1        252         TA   \n",
       "1458    AllPub    Inside       Gtl  ...          1        240         TA   \n",
       "1459    AllPub    Inside       Gtl  ...          1        276         TA   \n",
       "\n",
       "     GarageCond PavedDrive  OpenPorchSF  MoSold  YrSold  SaleType  \\\n",
       "0            TA          Y           61       2    2008        WD   \n",
       "1            TA          Y            0       5    2007        WD   \n",
       "2            TA          Y           42       9    2008        WD   \n",
       "3            TA          Y           35       2    2006        WD   \n",
       "4            TA          Y           84      12    2008        WD   \n",
       "...         ...        ...          ...     ...     ...       ...   \n",
       "1455         TA          Y           40       8    2007        WD   \n",
       "1456         TA          Y            0       2    2010        WD   \n",
       "1457         TA          Y           60       5    2010        WD   \n",
       "1458         TA          Y            0       4    2010        WD   \n",
       "1459         TA          Y           68       6    2008        WD   \n",
       "\n",
       "     SaleCondition  \n",
       "0           Normal  \n",
       "1           Normal  \n",
       "2           Normal  \n",
       "3          Abnorml  \n",
       "4           Normal  \n",
       "...            ...  \n",
       "1455        Normal  \n",
       "1456        Normal  \n",
       "1457        Normal  \n",
       "1458        Normal  \n",
       "1459        Normal  \n",
       "\n",
       "[1460 rows x 62 columns]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "f731ac41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for cols in df_train.columns:\n",
    "    if df_train[cols].dtype==\"int64\":\n",
    "        # print(cols,i)\n",
    "        i+=1\n",
    "    elif df_train[cols].dtype==\"object\":\n",
    "#         print(cols,i)\n",
    "        i+=1\n",
    "#     elif df_train[cols].dtype==\"float64\":\n",
    "#         print(cols,i)\n",
    "# #         i+=1\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "b7285ad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>...</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>GarageQual</th>\n",
       "      <th>GarageCond</th>\n",
       "      <th>PavedDrive</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>548</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>460</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>608</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>42</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>642</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>836</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>84</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>460</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>40</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>13175</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>500</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9042</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>252</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>60</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>240</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>276</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>68</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass MSZoning  LotFrontage  LotArea Street LotShape LandContour  \\\n",
       "0             60       RL         65.0     8450   Pave      Reg         Lvl   \n",
       "1             20       RL         80.0     9600   Pave      Reg         Lvl   \n",
       "2             60       RL         68.0    11250   Pave      IR1         Lvl   \n",
       "3             70       RL         60.0     9550   Pave      IR1         Lvl   \n",
       "4             60       RL         84.0    14260   Pave      IR1         Lvl   \n",
       "...          ...      ...          ...      ...    ...      ...         ...   \n",
       "1455          60       RL         62.0     7917   Pave      Reg         Lvl   \n",
       "1456          20       RL         85.0    13175   Pave      Reg         Lvl   \n",
       "1457          70       RL         66.0     9042   Pave      Reg         Lvl   \n",
       "1458          20       RL         68.0     9717   Pave      Reg         Lvl   \n",
       "1459          20       RL         75.0     9937   Pave      Reg         Lvl   \n",
       "\n",
       "     Utilities LotConfig LandSlope  ... GarageCars GarageArea GarageQual  \\\n",
       "0       AllPub    Inside       Gtl  ...          2        548         TA   \n",
       "1       AllPub       FR2       Gtl  ...          2        460         TA   \n",
       "2       AllPub    Inside       Gtl  ...          2        608         TA   \n",
       "3       AllPub    Corner       Gtl  ...          3        642         TA   \n",
       "4       AllPub       FR2       Gtl  ...          3        836         TA   \n",
       "...        ...       ...       ...  ...        ...        ...        ...   \n",
       "1455    AllPub    Inside       Gtl  ...          2        460         TA   \n",
       "1456    AllPub    Inside       Gtl  ...          2        500         TA   \n",
       "1457    AllPub    Inside       Gtl  ...          1        252         TA   \n",
       "1458    AllPub    Inside       Gtl  ...          1        240         TA   \n",
       "1459    AllPub    Inside       Gtl  ...          1        276         TA   \n",
       "\n",
       "     GarageCond PavedDrive  OpenPorchSF  MoSold  YrSold  SaleType  \\\n",
       "0            TA          Y           61       2    2008        WD   \n",
       "1            TA          Y            0       5    2007        WD   \n",
       "2            TA          Y           42       9    2008        WD   \n",
       "3            TA          Y           35       2    2006        WD   \n",
       "4            TA          Y           84      12    2008        WD   \n",
       "...         ...        ...          ...     ...     ...       ...   \n",
       "1455         TA          Y           40       8    2007        WD   \n",
       "1456         TA          Y            0       2    2010        WD   \n",
       "1457         TA          Y           60       5    2010        WD   \n",
       "1458         TA          Y            0       4    2010        WD   \n",
       "1459         TA          Y           68       6    2008        WD   \n",
       "\n",
       "     SaleCondition  \n",
       "0           Normal  \n",
       "1           Normal  \n",
       "2           Normal  \n",
       "3          Abnorml  \n",
       "4           Normal  \n",
       "...            ...  \n",
       "1455        Normal  \n",
       "1456        Normal  \n",
       "1457        Normal  \n",
       "1458        Normal  \n",
       "1459        Normal  \n",
       "\n",
       "[1460 rows x 62 columns]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "9928a0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling Null Values\n",
    "\n",
    "def fill_null_values(for_numerical_cols:str,for_categorical_cols:str,df_train):\n",
    "    for cols in df_train.columns:\n",
    "        if df_train[cols].dtype==\"int64\" or df_train[cols].dtype==\"float64\":\n",
    "            if for_numerical_cols==\"median\":\n",
    "                median_=df_train[cols].median()\n",
    "                df_train[cols].fillna(median_,inplace=True)\n",
    "        elif df_train[cols].dtype==\"object\":\n",
    "            if for_categorical_cols==\"most_frequent\":\n",
    "                d=list(df_train[cols].value_counts().index) # most frequent\n",
    "                df_train[cols].fillna(d[0],inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "9c256fcd-de29-4a4b-b910-5326262601cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_null_values(for_numerical_cols=\"median\",for_categorical_cols=\"most_frequent\",df_train=df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "13f5495b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_train.columns:\n",
    "    if df_train[col].isnull().sum()>(0):\n",
    "\n",
    "        print(col,df[col].isnull().sum(),df_train[col].dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "e468feff-0a9c-4f0e-a7df-f8f66655fcb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>...</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>GarageQual</th>\n",
       "      <th>GarageCond</th>\n",
       "      <th>PavedDrive</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>548</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>460</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>608</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>42</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>642</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>836</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>84</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>460</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>40</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>13175</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>500</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9042</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>252</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>60</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>240</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>276</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>68</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass MSZoning  LotFrontage  LotArea Street LotShape LandContour  \\\n",
       "0             60       RL         65.0     8450   Pave      Reg         Lvl   \n",
       "1             20       RL         80.0     9600   Pave      Reg         Lvl   \n",
       "2             60       RL         68.0    11250   Pave      IR1         Lvl   \n",
       "3             70       RL         60.0     9550   Pave      IR1         Lvl   \n",
       "4             60       RL         84.0    14260   Pave      IR1         Lvl   \n",
       "...          ...      ...          ...      ...    ...      ...         ...   \n",
       "1455          60       RL         62.0     7917   Pave      Reg         Lvl   \n",
       "1456          20       RL         85.0    13175   Pave      Reg         Lvl   \n",
       "1457          70       RL         66.0     9042   Pave      Reg         Lvl   \n",
       "1458          20       RL         68.0     9717   Pave      Reg         Lvl   \n",
       "1459          20       RL         75.0     9937   Pave      Reg         Lvl   \n",
       "\n",
       "     Utilities LotConfig LandSlope  ... GarageCars GarageArea GarageQual  \\\n",
       "0       AllPub    Inside       Gtl  ...          2        548         TA   \n",
       "1       AllPub       FR2       Gtl  ...          2        460         TA   \n",
       "2       AllPub    Inside       Gtl  ...          2        608         TA   \n",
       "3       AllPub    Corner       Gtl  ...          3        642         TA   \n",
       "4       AllPub       FR2       Gtl  ...          3        836         TA   \n",
       "...        ...       ...       ...  ...        ...        ...        ...   \n",
       "1455    AllPub    Inside       Gtl  ...          2        460         TA   \n",
       "1456    AllPub    Inside       Gtl  ...          2        500         TA   \n",
       "1457    AllPub    Inside       Gtl  ...          1        252         TA   \n",
       "1458    AllPub    Inside       Gtl  ...          1        240         TA   \n",
       "1459    AllPub    Inside       Gtl  ...          1        276         TA   \n",
       "\n",
       "     GarageCond PavedDrive  OpenPorchSF  MoSold  YrSold  SaleType  \\\n",
       "0            TA          Y           61       2    2008        WD   \n",
       "1            TA          Y            0       5    2007        WD   \n",
       "2            TA          Y           42       9    2008        WD   \n",
       "3            TA          Y           35       2    2006        WD   \n",
       "4            TA          Y           84      12    2008        WD   \n",
       "...         ...        ...          ...     ...     ...       ...   \n",
       "1455         TA          Y           40       8    2007        WD   \n",
       "1456         TA          Y            0       2    2010        WD   \n",
       "1457         TA          Y           60       5    2010        WD   \n",
       "1458         TA          Y            0       4    2010        WD   \n",
       "1459         TA          Y           68       6    2008        WD   \n",
       "\n",
       "     SaleCondition  \n",
       "0           Normal  \n",
       "1           Normal  \n",
       "2           Normal  \n",
       "3          Abnorml  \n",
       "4           Normal  \n",
       "...            ...  \n",
       "1455        Normal  \n",
       "1456        Normal  \n",
       "1457        Normal  \n",
       "1458        Normal  \n",
       "1459        Normal  \n",
       "\n",
       "[1460 rows x 62 columns]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "fcb707f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_cols=list(df_train.select_dtypes(include= np.number).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "8c5627c5-6f9f-4e18-ae8d-48d91f242201",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols=list(df_train.select_dtypes(exclude= np.number).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "e527d259",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MSZoning',\n",
       " 'Street',\n",
       " 'LotShape',\n",
       " 'LandContour',\n",
       " 'Utilities',\n",
       " 'LotConfig',\n",
       " 'LandSlope',\n",
       " 'Neighborhood',\n",
       " 'Condition1',\n",
       " 'Condition2',\n",
       " 'BldgType',\n",
       " 'HouseStyle',\n",
       " 'RoofStyle',\n",
       " 'RoofMatl',\n",
       " 'Exterior1st',\n",
       " 'Exterior2nd',\n",
       " 'MasVnrType',\n",
       " 'ExterQual',\n",
       " 'ExterCond',\n",
       " 'Foundation',\n",
       " 'BsmtQual',\n",
       " 'BsmtCond',\n",
       " 'BsmtExposure',\n",
       " 'BsmtFinType1',\n",
       " 'BsmtFinType2',\n",
       " 'Heating',\n",
       " 'HeatingQC',\n",
       " 'CentralAir',\n",
       " 'Electrical',\n",
       " 'KitchenQual',\n",
       " 'Functional',\n",
       " 'FireplaceQu',\n",
       " 'GarageType',\n",
       " 'GarageFinish',\n",
       " 'GarageQual',\n",
       " 'GarageCond',\n",
       " 'PavedDrive',\n",
       " 'SaleType',\n",
       " 'SaleCondition']"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "938be803-6549-4586-a0d1-212fac08104c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"MSZoning\"].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "9205dbe5-2bb3-468d-8e02-35b5ce90833d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(nrows = 6, ncols = 4)    # axes is 2d array (3x3)\n",
    "# axes = axes.flatten()         # Convert axes to 1d array of length 9\n",
    "# fig.set_size_inches(40, 40)\n",
    "\n",
    "# for ax, col in zip(axes, continuous_cols):\n",
    "#     print()\n",
    "#     sns.distplot(df_train[col], ax = ax,kde=True)\n",
    "#     ax.set_title(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "dbbdbcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(nrows = 6, ncols = 4)#   skew axes is 2d array (3x3)\n",
    "# axes = axes.flatten()         # Convert axes to 1d array of length 9\n",
    "# fig.set_size_inches(40, 40)\n",
    "\n",
    "# for ax, col in zip(axes, continuous_cols):\n",
    "#     # print()\n",
    "#     sns.boxplot(df_train[col], ax = ax)\n",
    "#     ax.set_title(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "9192f5ff-e384-4144-bbce-641ed883309f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(20,15))\n",
    "# sns.heatmap(df_train.loc[:,continuous_cols].corr(method='spearman'),annot=True,cmap=\"RdYlGn\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "71b4cde3-7bbd-4799-8b58-a4fb0efb5534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.set(rc={'figure.figsize':(40,40)})\n",
    "# cData_attr = df_train.loc[:,continuous_cols]\n",
    "# sns.pairplot(cData_attr, diag_kind='kde')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "26eaf9a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>...</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>706</td>\n",
       "      <td>150</td>\n",
       "      <td>856</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>2</td>\n",
       "      <td>548</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>978</td>\n",
       "      <td>284</td>\n",
       "      <td>1262</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>2</td>\n",
       "      <td>460</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>486</td>\n",
       "      <td>434</td>\n",
       "      <td>920</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>2</td>\n",
       "      <td>608</td>\n",
       "      <td>42</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>216</td>\n",
       "      <td>540</td>\n",
       "      <td>756</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>3</td>\n",
       "      <td>642</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>655</td>\n",
       "      <td>490</td>\n",
       "      <td>1145</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>836</td>\n",
       "      <td>84</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>60</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1999</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>953</td>\n",
       "      <td>953</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>2</td>\n",
       "      <td>460</td>\n",
       "      <td>40</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>20</td>\n",
       "      <td>85.0</td>\n",
       "      <td>13175</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1978</td>\n",
       "      <td>1988</td>\n",
       "      <td>790</td>\n",
       "      <td>589</td>\n",
       "      <td>1542</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1978.0</td>\n",
       "      <td>2</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>70</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9042</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>1941</td>\n",
       "      <td>2006</td>\n",
       "      <td>275</td>\n",
       "      <td>877</td>\n",
       "      <td>1152</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1941.0</td>\n",
       "      <td>1</td>\n",
       "      <td>252</td>\n",
       "      <td>60</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>20</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1950</td>\n",
       "      <td>1996</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>1078</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>1</td>\n",
       "      <td>240</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>20</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1965</td>\n",
       "      <td>1965</td>\n",
       "      <td>830</td>\n",
       "      <td>136</td>\n",
       "      <td>1256</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1965.0</td>\n",
       "      <td>1</td>\n",
       "      <td>276</td>\n",
       "      <td>68</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0             60         65.0     8450            7            5       2003   \n",
       "1             20         80.0     9600            6            8       1976   \n",
       "2             60         68.0    11250            7            5       2001   \n",
       "3             70         60.0     9550            7            5       1915   \n",
       "4             60         84.0    14260            8            5       2000   \n",
       "...          ...          ...      ...          ...          ...        ...   \n",
       "1455          60         62.0     7917            6            5       1999   \n",
       "1456          20         85.0    13175            6            6       1978   \n",
       "1457          70         66.0     9042            7            9       1941   \n",
       "1458          20         68.0     9717            5            6       1950   \n",
       "1459          20         75.0     9937            5            6       1965   \n",
       "\n",
       "      YearRemodAdd  BsmtFinSF1  BsmtUnfSF  TotalBsmtSF  ...  BedroomAbvGr  \\\n",
       "0             2003         706        150          856  ...             3   \n",
       "1             1976         978        284         1262  ...             3   \n",
       "2             2002         486        434          920  ...             3   \n",
       "3             1970         216        540          756  ...             3   \n",
       "4             2000         655        490         1145  ...             4   \n",
       "...            ...         ...        ...          ...  ...           ...   \n",
       "1455          2000           0        953          953  ...             3   \n",
       "1456          1988         790        589         1542  ...             3   \n",
       "1457          2006         275        877         1152  ...             4   \n",
       "1458          1996          49          0         1078  ...             2   \n",
       "1459          1965         830        136         1256  ...             3   \n",
       "\n",
       "      KitchenAbvGr  TotRmsAbvGrd  Fireplaces  GarageYrBlt  GarageCars  \\\n",
       "0                1             8           0       2003.0           2   \n",
       "1                1             6           1       1976.0           2   \n",
       "2                1             6           1       2001.0           2   \n",
       "3                1             7           1       1998.0           3   \n",
       "4                1             9           1       2000.0           3   \n",
       "...            ...           ...         ...          ...         ...   \n",
       "1455             1             7           1       1999.0           2   \n",
       "1456             1             7           2       1978.0           2   \n",
       "1457             1             9           2       1941.0           1   \n",
       "1458             1             5           0       1950.0           1   \n",
       "1459             1             6           0       1965.0           1   \n",
       "\n",
       "      GarageArea  OpenPorchSF  MoSold  YrSold  \n",
       "0            548           61       2    2008  \n",
       "1            460            0       5    2007  \n",
       "2            608           42       9    2008  \n",
       "3            642           35       2    2006  \n",
       "4            836           84      12    2008  \n",
       "...          ...          ...     ...     ...  \n",
       "1455         460           40       8    2007  \n",
       "1456         500            0       2    2010  \n",
       "1457         252           60       5    2010  \n",
       "1458         240            0       4    2010  \n",
       "1459         276           68       6    2008  \n",
       "\n",
       "[1460 rows x 23 columns]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.loc[:,continuous_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "03f87857-2de4-4520-ab1b-b00cc28803ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MSSubClass',\n",
       " 'LotFrontage',\n",
       " 'LotArea',\n",
       " 'OverallQual',\n",
       " 'OverallCond',\n",
       " 'YearBuilt',\n",
       " 'YearRemodAdd',\n",
       " 'BsmtFinSF1',\n",
       " 'BsmtUnfSF',\n",
       " 'TotalBsmtSF',\n",
       " '1stFlrSF',\n",
       " 'GrLivArea',\n",
       " 'FullBath',\n",
       " 'BedroomAbvGr',\n",
       " 'KitchenAbvGr',\n",
       " 'TotRmsAbvGrd',\n",
       " 'Fireplaces',\n",
       " 'GarageYrBlt',\n",
       " 'GarageCars',\n",
       " 'GarageArea',\n",
       " 'OpenPorchSF',\n",
       " 'MoSold',\n",
       " 'YrSold']"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "continuous_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "4d88b603-83e1-4bfd-89e4-a1301aeed7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train=pd.concat([output_col,df_train],axis=1) # since rows will be deleted here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "a6a01c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for col in continuous_cols:\n",
    "#     q1=df_train[col].quantile(0.25)\n",
    "#     q3=df_train[col].quantile(0.75)\n",
    "#     iqr=q3-q1\n",
    "#     l=q1-1.5*iqr\n",
    "#     h=q3+1.5*iqr\n",
    "#     print(\"[\",l,\",\",h,\"]\")\n",
    "#     df_train = df_train[(df_train[col] <= h)]# & (df_train[col] >=l)] \n",
    "#     df_train =df_train[(df_train[col] >=l)] \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "1106dbc8-8495-4c6c-9a79-8f5388f4b1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_col=df_train['SalePrice']\n",
    "# df_train.drop(\"SalePrice\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "d2cc9e77-caf8-4f99-b317-ab717acdba09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>...</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>GarageQual</th>\n",
       "      <th>GarageCond</th>\n",
       "      <th>PavedDrive</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>548</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>460</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>608</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>42</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>642</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>836</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>84</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>460</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>40</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>13175</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>500</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9042</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>252</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>60</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>240</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>276</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>68</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass MSZoning  LotFrontage  LotArea Street LotShape LandContour  \\\n",
       "0             60       RL         65.0     8450   Pave      Reg         Lvl   \n",
       "1             20       RL         80.0     9600   Pave      Reg         Lvl   \n",
       "2             60       RL         68.0    11250   Pave      IR1         Lvl   \n",
       "3             70       RL         60.0     9550   Pave      IR1         Lvl   \n",
       "4             60       RL         84.0    14260   Pave      IR1         Lvl   \n",
       "...          ...      ...          ...      ...    ...      ...         ...   \n",
       "1455          60       RL         62.0     7917   Pave      Reg         Lvl   \n",
       "1456          20       RL         85.0    13175   Pave      Reg         Lvl   \n",
       "1457          70       RL         66.0     9042   Pave      Reg         Lvl   \n",
       "1458          20       RL         68.0     9717   Pave      Reg         Lvl   \n",
       "1459          20       RL         75.0     9937   Pave      Reg         Lvl   \n",
       "\n",
       "     Utilities LotConfig LandSlope  ... GarageCars GarageArea GarageQual  \\\n",
       "0       AllPub    Inside       Gtl  ...          2        548         TA   \n",
       "1       AllPub       FR2       Gtl  ...          2        460         TA   \n",
       "2       AllPub    Inside       Gtl  ...          2        608         TA   \n",
       "3       AllPub    Corner       Gtl  ...          3        642         TA   \n",
       "4       AllPub       FR2       Gtl  ...          3        836         TA   \n",
       "...        ...       ...       ...  ...        ...        ...        ...   \n",
       "1455    AllPub    Inside       Gtl  ...          2        460         TA   \n",
       "1456    AllPub    Inside       Gtl  ...          2        500         TA   \n",
       "1457    AllPub    Inside       Gtl  ...          1        252         TA   \n",
       "1458    AllPub    Inside       Gtl  ...          1        240         TA   \n",
       "1459    AllPub    Inside       Gtl  ...          1        276         TA   \n",
       "\n",
       "     GarageCond PavedDrive  OpenPorchSF  MoSold  YrSold  SaleType  \\\n",
       "0            TA          Y           61       2    2008        WD   \n",
       "1            TA          Y            0       5    2007        WD   \n",
       "2            TA          Y           42       9    2008        WD   \n",
       "3            TA          Y           35       2    2006        WD   \n",
       "4            TA          Y           84      12    2008        WD   \n",
       "...         ...        ...          ...     ...     ...       ...   \n",
       "1455         TA          Y           40       8    2007        WD   \n",
       "1456         TA          Y            0       2    2010        WD   \n",
       "1457         TA          Y           60       5    2010        WD   \n",
       "1458         TA          Y            0       4    2010        WD   \n",
       "1459         TA          Y           68       6    2008        WD   \n",
       "\n",
       "     SaleCondition  \n",
       "0           Normal  \n",
       "1           Normal  \n",
       "2           Normal  \n",
       "3          Abnorml  \n",
       "4           Normal  \n",
       "...            ...  \n",
       "1455        Normal  \n",
       "1456        Normal  \n",
       "1457        Normal  \n",
       "1458        Normal  \n",
       "1459        Normal  \n",
       "\n",
       "[1460 rows x 62 columns]"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "4cef4726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MSZoning',\n",
       " 'Street',\n",
       " 'LotShape',\n",
       " 'LandContour',\n",
       " 'Utilities',\n",
       " 'LotConfig',\n",
       " 'LandSlope',\n",
       " 'Neighborhood',\n",
       " 'Condition1',\n",
       " 'Condition2',\n",
       " 'BldgType',\n",
       " 'HouseStyle',\n",
       " 'RoofStyle',\n",
       " 'RoofMatl',\n",
       " 'Exterior1st',\n",
       " 'Exterior2nd',\n",
       " 'MasVnrType',\n",
       " 'ExterQual',\n",
       " 'ExterCond',\n",
       " 'Foundation',\n",
       " 'BsmtQual',\n",
       " 'BsmtCond',\n",
       " 'BsmtExposure',\n",
       " 'BsmtFinType1',\n",
       " 'BsmtFinType2',\n",
       " 'Heating',\n",
       " 'HeatingQC',\n",
       " 'CentralAir',\n",
       " 'Electrical',\n",
       " 'KitchenQual',\n",
       " 'Functional',\n",
       " 'FireplaceQu',\n",
       " 'GarageType',\n",
       " 'GarageFinish',\n",
       " 'GarageQual',\n",
       " 'GarageCond',\n",
       " 'PavedDrive',\n",
       " 'SaleType',\n",
       " 'SaleCondition']"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "f97b5f6b-648a-43cb-8849-0fec976df2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def encoding_categorical_cols(df_train:pd.DataFrame,categorical_columns:list,strategy:str):\n",
    "    df_categorical=pd.DataFrame(df_train.loc[:,categorical_columns])\n",
    "    if strategy==\"labelencoder\":\n",
    "        for col in list(df_categorical.columns):\n",
    "            cat=[]\n",
    "            d={}\n",
    "\n",
    "            cat.append([df_categorical[col].value_counts().index,len(df_categorical[col].value_counts().index)])\n",
    "\n",
    "            for j in range(int(cat[0][1])):\n",
    "                d[str(cat[0][0][j])]=j\n",
    "            df_categorical[col]=df_categorical[col].map(d)\n",
    "        df_train.drop(categorical_columns,axis=1,inplace=True)\n",
    "        \n",
    "        df_train=pd.concat([df_train,df_categorical],axis=1)\n",
    "        \n",
    "    if strategy==\"onehotencoder\":\n",
    "        one_hot_encoded=pd.get_dummies(df_categorical)\n",
    "        # print(one_hot_encoded)\n",
    "        df_train.drop(categorical_columns,axis=1,inplace=True)\n",
    "        df_train=pd.concat([df_train,one_hot_encoded],axis=1)\n",
    "    return df_train\n",
    "        \n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69450bb9-5dc9-43c6-9940-1cadcdcf8848",
   "metadata": {},
   "source": [
    "One hot encoding since hyperparameter tuning does not have its effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "b7d27212-4bf2-45ac-bce7-50ade37f1709",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=encoding_categorical_cols(df_train=df_train,categorical_columns=categorical_cols,strategy=\"onehotencoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "c3780d5c-cb7c-4836-b97b-8fd4dc8e051e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>...</th>\n",
       "      <th>KitchenQual</th>\n",
       "      <th>Functional</th>\n",
       "      <th>FireplaceQu</th>\n",
       "      <th>GarageType</th>\n",
       "      <th>GarageFinish</th>\n",
       "      <th>GarageQual</th>\n",
       "      <th>GarageCond</th>\n",
       "      <th>PavedDrive</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>706</td>\n",
       "      <td>150</td>\n",
       "      <td>856</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>978</td>\n",
       "      <td>284</td>\n",
       "      <td>1262</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>486</td>\n",
       "      <td>434</td>\n",
       "      <td>920</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>216</td>\n",
       "      <td>540</td>\n",
       "      <td>756</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>655</td>\n",
       "      <td>490</td>\n",
       "      <td>1145</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>60</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1999</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>953</td>\n",
       "      <td>953</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>20</td>\n",
       "      <td>85.0</td>\n",
       "      <td>13175</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1978</td>\n",
       "      <td>1988</td>\n",
       "      <td>790</td>\n",
       "      <td>589</td>\n",
       "      <td>1542</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>70</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9042</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>1941</td>\n",
       "      <td>2006</td>\n",
       "      <td>275</td>\n",
       "      <td>877</td>\n",
       "      <td>1152</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>20</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1950</td>\n",
       "      <td>1996</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>1078</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>20</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1965</td>\n",
       "      <td>1965</td>\n",
       "      <td>830</td>\n",
       "      <td>136</td>\n",
       "      <td>1256</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0             60         65.0     8450            7            5       2003   \n",
       "1             20         80.0     9600            6            8       1976   \n",
       "2             60         68.0    11250            7            5       2001   \n",
       "3             70         60.0     9550            7            5       1915   \n",
       "4             60         84.0    14260            8            5       2000   \n",
       "...          ...          ...      ...          ...          ...        ...   \n",
       "1455          60         62.0     7917            6            5       1999   \n",
       "1456          20         85.0    13175            6            6       1978   \n",
       "1457          70         66.0     9042            7            9       1941   \n",
       "1458          20         68.0     9717            5            6       1950   \n",
       "1459          20         75.0     9937            5            6       1965   \n",
       "\n",
       "      YearRemodAdd  BsmtFinSF1  BsmtUnfSF  TotalBsmtSF  ...  KitchenQual  \\\n",
       "0             2003         706        150          856  ...            1   \n",
       "1             1976         978        284         1262  ...            0   \n",
       "2             2002         486        434          920  ...            1   \n",
       "3             1970         216        540          756  ...            1   \n",
       "4             2000         655        490         1145  ...            1   \n",
       "...            ...         ...        ...          ...  ...          ...   \n",
       "1455          2000           0        953          953  ...            0   \n",
       "1456          1988         790        589         1542  ...            0   \n",
       "1457          2006         275        877         1152  ...            1   \n",
       "1458          1996          49          0         1078  ...            1   \n",
       "1459          1965         830        136         1256  ...            0   \n",
       "\n",
       "      Functional  FireplaceQu  GarageType  GarageFinish  GarageQual  \\\n",
       "0              0            0           0             1           0   \n",
       "1              0            1           0             1           0   \n",
       "2              0            1           0             1           0   \n",
       "3              0            0           1             0           0   \n",
       "4              0            1           0             1           0   \n",
       "...          ...          ...         ...           ...         ...   \n",
       "1455           0            1           0             1           0   \n",
       "1456           2            1           0             0           0   \n",
       "1457           0            0           0             1           0   \n",
       "1458           0            0           0             0           0   \n",
       "1459           0            0           0             2           0   \n",
       "\n",
       "      GarageCond  PavedDrive  SaleType  SaleCondition  \n",
       "0              0           0         0              0  \n",
       "1              0           0         0              0  \n",
       "2              0           0         0              0  \n",
       "3              0           0         0              2  \n",
       "4              0           0         0              0  \n",
       "...          ...         ...       ...            ...  \n",
       "1455           0           0         0              0  \n",
       "1456           0           0         0              0  \n",
       "1457           0           0         0              0  \n",
       "1458           0           0         0              0  \n",
       "1459           0           0         0              0  \n",
       "\n",
       "[1460 rows x 62 columns]"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "792d9fa3-dc99-4342-8826-206eeb185ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSZoning\n",
      "Street\n",
      "LotShape\n",
      "LandContour\n",
      "Utilities\n",
      "LotConfig\n",
      "LandSlope\n",
      "Neighborhood\n",
      "Condition1\n",
      "Condition2\n",
      "BldgType\n",
      "HouseStyle\n",
      "RoofStyle\n",
      "RoofMatl\n",
      "Exterior1st\n",
      "Exterior2nd\n",
      "MasVnrType\n",
      "ExterQual\n",
      "ExterCond\n",
      "Foundation\n",
      "BsmtQual\n",
      "BsmtCond\n",
      "BsmtExposure\n",
      "BsmtFinType1\n",
      "BsmtFinType2\n",
      "Heating\n",
      "HeatingQC\n",
      "CentralAir\n",
      "Electrical\n",
      "KitchenQual\n",
      "Functional\n",
      "FireplaceQu\n",
      "GarageType\n",
      "GarageFinish\n",
      "GarageQual\n",
      "GarageCond\n",
      "PavedDrive\n",
      "SaleType\n",
      "SaleCondition\n"
     ]
    }
   ],
   "source": [
    "for col in categorical_cols:\n",
    "    if col in set(df_train.columns):\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "e63bcfff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>...</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>56.897260</td>\n",
       "      <td>69.863699</td>\n",
       "      <td>10516.828082</td>\n",
       "      <td>6.099315</td>\n",
       "      <td>5.575342</td>\n",
       "      <td>1971.267808</td>\n",
       "      <td>1984.865753</td>\n",
       "      <td>443.639726</td>\n",
       "      <td>567.240411</td>\n",
       "      <td>1057.429452</td>\n",
       "      <td>...</td>\n",
       "      <td>2.866438</td>\n",
       "      <td>1.046575</td>\n",
       "      <td>6.517808</td>\n",
       "      <td>0.613014</td>\n",
       "      <td>1978.589041</td>\n",
       "      <td>1.767123</td>\n",
       "      <td>472.980137</td>\n",
       "      <td>46.660274</td>\n",
       "      <td>6.321918</td>\n",
       "      <td>2007.815753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>42.300571</td>\n",
       "      <td>22.027677</td>\n",
       "      <td>9981.264932</td>\n",
       "      <td>1.382997</td>\n",
       "      <td>1.112799</td>\n",
       "      <td>30.202904</td>\n",
       "      <td>20.645407</td>\n",
       "      <td>456.098091</td>\n",
       "      <td>441.866955</td>\n",
       "      <td>438.705324</td>\n",
       "      <td>...</td>\n",
       "      <td>0.815778</td>\n",
       "      <td>0.220338</td>\n",
       "      <td>1.625393</td>\n",
       "      <td>0.644666</td>\n",
       "      <td>23.997022</td>\n",
       "      <td>0.747315</td>\n",
       "      <td>213.804841</td>\n",
       "      <td>66.256028</td>\n",
       "      <td>2.703626</td>\n",
       "      <td>1.328095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1300.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1872.000000</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1900.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2006.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>7553.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1954.000000</td>\n",
       "      <td>1967.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>223.000000</td>\n",
       "      <td>795.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1962.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>334.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2007.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>9478.500000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1973.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>383.500000</td>\n",
       "      <td>477.500000</td>\n",
       "      <td>991.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1980.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2008.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>70.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>11601.500000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>712.250000</td>\n",
       "      <td>808.000000</td>\n",
       "      <td>1298.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2001.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>576.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2009.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>190.000000</td>\n",
       "      <td>313.000000</td>\n",
       "      <td>215245.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>5644.000000</td>\n",
       "      <td>2336.000000</td>\n",
       "      <td>6110.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1418.000000</td>\n",
       "      <td>547.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        MSSubClass  LotFrontage        LotArea  OverallQual  OverallCond  \\\n",
       "count  1460.000000  1460.000000    1460.000000  1460.000000  1460.000000   \n",
       "mean     56.897260    69.863699   10516.828082     6.099315     5.575342   \n",
       "std      42.300571    22.027677    9981.264932     1.382997     1.112799   \n",
       "min      20.000000    21.000000    1300.000000     1.000000     1.000000   \n",
       "25%      20.000000    60.000000    7553.500000     5.000000     5.000000   \n",
       "50%      50.000000    69.000000    9478.500000     6.000000     5.000000   \n",
       "75%      70.000000    79.000000   11601.500000     7.000000     6.000000   \n",
       "max     190.000000   313.000000  215245.000000    10.000000     9.000000   \n",
       "\n",
       "         YearBuilt  YearRemodAdd   BsmtFinSF1    BsmtUnfSF  TotalBsmtSF  ...  \\\n",
       "count  1460.000000   1460.000000  1460.000000  1460.000000  1460.000000  ...   \n",
       "mean   1971.267808   1984.865753   443.639726   567.240411  1057.429452  ...   \n",
       "std      30.202904     20.645407   456.098091   441.866955   438.705324  ...   \n",
       "min    1872.000000   1950.000000     0.000000     0.000000     0.000000  ...   \n",
       "25%    1954.000000   1967.000000     0.000000   223.000000   795.750000  ...   \n",
       "50%    1973.000000   1994.000000   383.500000   477.500000   991.500000  ...   \n",
       "75%    2000.000000   2004.000000   712.250000   808.000000  1298.250000  ...   \n",
       "max    2010.000000   2010.000000  5644.000000  2336.000000  6110.000000  ...   \n",
       "\n",
       "       BedroomAbvGr  KitchenAbvGr  TotRmsAbvGrd   Fireplaces  GarageYrBlt  \\\n",
       "count   1460.000000   1460.000000   1460.000000  1460.000000  1460.000000   \n",
       "mean       2.866438      1.046575      6.517808     0.613014  1978.589041   \n",
       "std        0.815778      0.220338      1.625393     0.644666    23.997022   \n",
       "min        0.000000      0.000000      2.000000     0.000000  1900.000000   \n",
       "25%        2.000000      1.000000      5.000000     0.000000  1962.000000   \n",
       "50%        3.000000      1.000000      6.000000     1.000000  1980.000000   \n",
       "75%        3.000000      1.000000      7.000000     1.000000  2001.000000   \n",
       "max        8.000000      3.000000     14.000000     3.000000  2010.000000   \n",
       "\n",
       "        GarageCars   GarageArea  OpenPorchSF       MoSold       YrSold  \n",
       "count  1460.000000  1460.000000  1460.000000  1460.000000  1460.000000  \n",
       "mean      1.767123   472.980137    46.660274     6.321918  2007.815753  \n",
       "std       0.747315   213.804841    66.256028     2.703626     1.328095  \n",
       "min       0.000000     0.000000     0.000000     1.000000  2006.000000  \n",
       "25%       1.000000   334.500000     0.000000     5.000000  2007.000000  \n",
       "50%       2.000000   480.000000    25.000000     6.000000  2008.000000  \n",
       "75%       2.000000   576.000000    68.000000     8.000000  2009.000000  \n",
       "max       4.000000  1418.000000   547.000000    12.000000  2010.000000  \n",
       "\n",
       "[8 rows x 23 columns]"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.loc[:,continuous_cols].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "4b450e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "### SCALING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "152a28be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>...</th>\n",
       "      <th>KitchenQual</th>\n",
       "      <th>Functional</th>\n",
       "      <th>FireplaceQu</th>\n",
       "      <th>GarageType</th>\n",
       "      <th>GarageFinish</th>\n",
       "      <th>GarageQual</th>\n",
       "      <th>GarageCond</th>\n",
       "      <th>PavedDrive</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.150685</td>\n",
       "      <td>0.033420</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.949275</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.125089</td>\n",
       "      <td>0.064212</td>\n",
       "      <td>0.140098</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.202055</td>\n",
       "      <td>0.038795</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.753623</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.173281</td>\n",
       "      <td>0.121575</td>\n",
       "      <td>0.206547</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.160959</td>\n",
       "      <td>0.046507</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.086109</td>\n",
       "      <td>0.185788</td>\n",
       "      <td>0.150573</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.133562</td>\n",
       "      <td>0.038561</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.311594</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.038271</td>\n",
       "      <td>0.231164</td>\n",
       "      <td>0.123732</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.215753</td>\n",
       "      <td>0.060576</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.927536</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.116052</td>\n",
       "      <td>0.209760</td>\n",
       "      <td>0.187398</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.140411</td>\n",
       "      <td>0.030929</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.920290</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.407962</td>\n",
       "      <td>0.155974</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.219178</td>\n",
       "      <td>0.055505</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.768116</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.139972</td>\n",
       "      <td>0.252140</td>\n",
       "      <td>0.252373</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.154110</td>\n",
       "      <td>0.036187</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.048724</td>\n",
       "      <td>0.375428</td>\n",
       "      <td>0.188543</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160959</td>\n",
       "      <td>0.039342</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.008682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.176432</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.184932</td>\n",
       "      <td>0.040370</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.673913</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.058219</td>\n",
       "      <td>0.205565</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass  LotFrontage   LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0       0.235294     0.150685  0.033420     0.666667        0.500   0.949275   \n",
       "1       0.000000     0.202055  0.038795     0.555556        0.875   0.753623   \n",
       "2       0.235294     0.160959  0.046507     0.666667        0.500   0.934783   \n",
       "3       0.294118     0.133562  0.038561     0.666667        0.500   0.311594   \n",
       "4       0.235294     0.215753  0.060576     0.777778        0.500   0.927536   \n",
       "...          ...          ...       ...          ...          ...        ...   \n",
       "1455    0.235294     0.140411  0.030929     0.555556        0.500   0.920290   \n",
       "1456    0.000000     0.219178  0.055505     0.555556        0.625   0.768116   \n",
       "1457    0.294118     0.154110  0.036187     0.666667        1.000   0.500000   \n",
       "1458    0.000000     0.160959  0.039342     0.444444        0.625   0.565217   \n",
       "1459    0.000000     0.184932  0.040370     0.444444        0.625   0.673913   \n",
       "\n",
       "      YearRemodAdd  BsmtFinSF1  BsmtUnfSF  TotalBsmtSF  ...  KitchenQual  \\\n",
       "0         0.883333    0.125089   0.064212     0.140098  ...     0.333333   \n",
       "1         0.433333    0.173281   0.121575     0.206547  ...     0.000000   \n",
       "2         0.866667    0.086109   0.185788     0.150573  ...     0.333333   \n",
       "3         0.333333    0.038271   0.231164     0.123732  ...     0.333333   \n",
       "4         0.833333    0.116052   0.209760     0.187398  ...     0.333333   \n",
       "...            ...         ...        ...          ...  ...          ...   \n",
       "1455      0.833333    0.000000   0.407962     0.155974  ...     0.000000   \n",
       "1456      0.633333    0.139972   0.252140     0.252373  ...     0.000000   \n",
       "1457      0.933333    0.048724   0.375428     0.188543  ...     0.333333   \n",
       "1458      0.766667    0.008682   0.000000     0.176432  ...     0.333333   \n",
       "1459      0.250000    0.147059   0.058219     0.205565  ...     0.000000   \n",
       "\n",
       "      Functional  FireplaceQu  GarageType  GarageFinish  GarageQual  \\\n",
       "0       0.000000         0.00         0.0           0.5         0.0   \n",
       "1       0.000000         0.25         0.0           0.5         0.0   \n",
       "2       0.000000         0.25         0.0           0.5         0.0   \n",
       "3       0.000000         0.00         0.2           0.0         0.0   \n",
       "4       0.000000         0.25         0.0           0.5         0.0   \n",
       "...          ...          ...         ...           ...         ...   \n",
       "1455    0.000000         0.25         0.0           0.5         0.0   \n",
       "1456    0.333333         0.25         0.0           0.0         0.0   \n",
       "1457    0.000000         0.00         0.0           0.5         0.0   \n",
       "1458    0.000000         0.00         0.0           0.0         0.0   \n",
       "1459    0.000000         0.00         0.0           1.0         0.0   \n",
       "\n",
       "      GarageCond  PavedDrive  SaleType  SaleCondition  \n",
       "0            0.0         0.0       0.0            0.0  \n",
       "1            0.0         0.0       0.0            0.0  \n",
       "2            0.0         0.0       0.0            0.0  \n",
       "3            0.0         0.0       0.0            0.4  \n",
       "4            0.0         0.0       0.0            0.0  \n",
       "...          ...         ...       ...            ...  \n",
       "1455         0.0         0.0       0.0            0.0  \n",
       "1456         0.0         0.0       0.0            0.0  \n",
       "1457         0.0         0.0       0.0            0.0  \n",
       "1458         0.0         0.0       0.0            0.0  \n",
       "1459         0.0         0.0       0.0            0.0  \n",
       "\n",
       "[1460 rows x 62 columns]"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler=scaler=MinMaxScaler()\n",
    "df_train=pd.DataFrame(scaler.fit_transform(df_train),columns=df_train.columns,)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "2b0069d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "589aafd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df_train\n",
    "Y=output_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "8abd68cd-17bb-4328-9838-79ab0285d8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=None,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "e5515b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies={}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3769e1-d00c-408f-a521-352e89b372a9",
   "metadata": {},
   "source": [
    "Atlast we will be doing manual hyperparameter tuning. Firstly we wiil do Random SearchCV since it gives us a region in the form of parameters where our accuracy could we very high,this reduces our search space. Then using those parameters we will use Grid Search CV to get best result using combinations of those parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "5f0ee5eb-4e09-49ca-9fb2-545ebb438eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_tuning(algo:str,param_grid:dict,n_iter:int,cv:int,verbose:int,random_state:int,X_train,Y_train,X_test,Y_test,evaluation_metric:str):\n",
    "    model=eval(algo)\n",
    "    evaluation_metric=eval(evaluation_metric)\n",
    "    \n",
    "    model_random_cv=RandomizedSearchCV(estimator=model,param_distributions=param_grid,n_iter=n_iter,cv=cv,verbose=verbose,random_state=random_state,n_jobs=-1)\n",
    "    model_random_cv.fit(X_train,Y_train)\n",
    "    best_params_=model_random_cv.best_params_\n",
    "    print(f\"{model} RandomCV Best Params :\",best_params_)\n",
    "    best_random_grid=model_random_cv.best_estimator_\n",
    "    y_pred=best_random_grid.predict(X_test)\n",
    "    \n",
    "    score=evaluation_metric(Y_test,y_pred)\n",
    "    print(f\"{model} RandomCV Score:\",score)\n",
    "    \n",
    "    \n",
    "    \n",
    "    param_grid=defaultdict(list)\n",
    "    for val in best_params_:\n",
    "        param_grid[val].append(best_params_[val])\n",
    "    \n",
    "    \n",
    "    model_for_gcv=eval(algo)\n",
    "    \n",
    "    grid_search=GridSearchCV(estimator=model_for_gcv,param_grid=param_grid,cv=cv,n_jobs=-1,verbose=verbose)\n",
    "    grid_search.fit(X_train,Y_train)\n",
    "    best_grid2=grid_search.best_estimator_\n",
    "    y_pred2=best_grid2.predict(X_test)\n",
    "    score_1=evaluation_metric(Y_test,y_pred2)\n",
    "    print(\"Final score is \",score_1)\n",
    "    accuracies[algo]=score_1\n",
    "    \n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "47b9754b-2b44-4cc1-9385-a395d0fb69c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## On Linear Regresion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "f1ea0622-0cc8-4bad-b256-f0b1121e0def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_intercept': ['True', 'False'], 'positive': ['False', 'True'], 'copy_X': ['True', 'False']}\n"
     ]
    }
   ],
   "source": [
    "# On Linear Regresion\n",
    "fit_intercept = [\"True\",\"False\"]\n",
    "copy_X =[\"True\",\"False\"] \n",
    "positive=[\"False\",\"True\"]\n",
    "\n",
    "random_grid = {'fit_intercept': fit_intercept,\n",
    "               'positive': positive,\n",
    "               'copy_X': copy_X}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "d5cfe0cb-0fbc-40a1-bd3b-b821b461a89d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "LinearRegression() RandomCV Best Params : {'positive': 'False', 'fit_intercept': 'True', 'copy_X': 'True'}\n",
      "LinearRegression() RandomCV Score: 0.7518561285635769\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Final score is  0.7518561285635769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_search.py:306: UserWarning: The total space of parameters 8 is smaller than n_iter=100. Running 8 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "hyperparameter_tuning(algo=\"LinearRegression()\",param_grid=random_grid,n_iter=100,cv=5,verbose=3,random_state=42,X_train=X_train,Y_train=Y_train,X_test=X_test,Y_test=Y_test,evaluation_metric=\"r2_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c805e5f3-e34a-48b1-b86b-daba1a972a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# lr=LinearRegression()\n",
    "# lr_random_cv=RandomizedSearchCV(estimator=lr,param_distributions=random_grid,n_iter=100,cv=5,verbose=0,random_state=100,n_jobs=-1)\n",
    "# lr_random_cv.fit(X_train,Y_train)\n",
    "# best_params_=lr_random_cv.best_params_\n",
    "# print(\"RandomCV Best Params :\",best_params_)\n",
    "# best_random_grid=lr_random_cv.best_estimator_\n",
    "# y_pred1=best_random_grid.predict(X_test)\n",
    "# score_1=r2_score(Y_test,y_pred1)\n",
    "# print(\"RandomCV Score: \",score_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85027760-9f10-4df8-be13-4a78a2a18bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid2=defaultdict(list)\n",
    "# for val in best_params_:\n",
    "#     param_grid2[val].append(best_params_[val])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbb90f3-fcea-474f-87e4-b7d5918d5aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr=LinearRegression()\n",
    "# grid_search=GridSearchCV(estimator=lr,param_grid=param_grid2,cv=5,n_jobs=-1,verbose=3)\n",
    "# grid_search.fit(X_train,Y_train)\n",
    "# print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd7f593-bc3e-4619-96f2-8229cbdd5283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_grid2=grid_search.best_estimator_\n",
    "# y_pred2=best_grid2.predict(X_test)\n",
    "# score_1=r2_score(Y_test,y_pred2)\n",
    "# print(score_1)\n",
    "# accuracies[\"LinearRegression\"]=score_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "4b4922a9-cfe9-434a-92bb-4124854a98d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e20558-17b5-49db-a12a-4523458f2624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['sqrt', 'log2'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190, 200, 210, 220, 230, 240, 250, 260, 270, 280, 290, 300, 310, 320, 330, 340, 350, 360, 370, 380, 390, 400, 410, 420, 430, 440, 450, 460, 470, 480, 490, 500, 510, 520, 530, 540, 550, 560, 570, 580, 590, 600, 610, 620, 630, 640, 650, 660, 670, 680, 690, 700, 710, 720, 730, 740, 750, 760, 770, 780, 790, 800, 810, 820, 830, 840, 850, 860, 870, 880, 890, 900, 910, 920, 930, 940, 950, 960, 970, 980, 990, 1000], 'min_samples_split': [2, 7, 12, 17, 22, 27, 32, 37, 42, 47, 52, 57, 62, 67, 72, 77, 82, 87, 92, 97, 102, 107, 112, 117, 122, 127, 132, 137, 142, 147, 152, 157, 162, 168, 173, 178, 183, 188, 193, 198, 203, 208, 213, 218, 223, 228, 233, 238, 243, 248, 253, 258, 263, 268, 273, 278, 283, 288, 293, 298, 303, 308, 313, 318, 323, 328, 334, 339, 344, 349, 354, 359, 364, 369, 374, 379, 384, 389, 394, 399, 404, 409, 414, 419, 424, 429, 434, 439, 444, 449, 454, 459, 464, 469, 474, 479, 484, 489, 494, 500], 'min_samples_leaf': [2, 7, 12, 17, 22, 27, 32, 37, 42, 47, 52, 57, 62, 67, 72, 77, 82, 87, 92, 97, 102, 107, 112, 117, 122, 127, 132, 137, 142, 147, 152, 157, 162, 168, 173, 178, 183, 188, 193, 198, 203, 208, 213, 218, 223, 228, 233, 238, 243, 248, 253, 258, 263, 268, 273, 278, 283, 288, 293, 298, 303, 308, 313, 318, 323, 328, 334, 339, 344, 349, 354, 359, 364, 369, 374, 379, 384, 389, 394, 399, 404, 409, 414, 419, 424, 429, 434, 439, 444, 449, 454, 459, 464, 469, 474, 479, 484, 489, 494, 500], 'criterion': ['squared_error', 'absolute_error', 'friedman_mse', 'poisson']}\n"
     ]
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['sqrt','log2']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 1000,10)]\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2,3,4, 5, 10,14]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4,6,8]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "              'criterion':['squared_error','absolute_error','friedman_mse','poisson']}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681322cd-1ddc-43ff-b400-6fb7e3d1d161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "RandomForestRegressor() RandomCV Best Params : {'n_estimators': 600, 'min_samples_split': 47, 'min_samples_leaf': 77, 'max_features': 'log2', 'max_depth': 670, 'criterion': 'squared_error'}\n",
      "RandomForestRegressor() RandomCV Score: 0.66952666471689\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Final score is  0.6663155322785399\n"
     ]
    }
   ],
   "source": [
    "hyperparameter_tuning(algo=\"RandomForestRegressor()\",param_grid=random_grid,n_iter=10,cv=5,verbose=3,random_state=42,X_train=X_train,Y_train=Y_train,X_test=X_test,Y_test=Y_test,evaluation_metric=\"r2_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "98c058e1-c70b-4ed4-a115-75fb89d19041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "23ba846f-adbc-4f0c-83e5-adb53edcc0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernel': ['linear', 'poly', 'sigmoid', 'poly'], 'degree': [1, 23, 45, 67, 89, 111, 133, 155, 177, 200], 'max_iter': [100], 'tol': [0.01], 'gamma': ['scale', 'auto']}\n"
     ]
    }
   ],
   "source": [
    "kernel = [\"linear\", \"poly\", \"sigmoid\",\"poly\"]\n",
    "degree = [int(x) for x in np.linspace(start = 1, stop = 200, num = 10)]\n",
    "gamma= [\"scale\", \"auto\"]\n",
    "\n",
    "tol=[1e-2]\n",
    "max_iter=[100]\n",
    "\n",
    "\n",
    "random_grid = {'kernel': kernel,\n",
    "               'degree':degree,\n",
    "               'max_iter':max_iter,\n",
    "               'tol':tol,\n",
    "               'gamma':gamma\n",
    "               \n",
    "               \n",
    "               }\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "99f2387a-c7b7-4cc0-a6ba-373a48f4b23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR() RandomCV Best Params : {'tol': 0.01, 'max_iter': 100, 'kernel': 'poly', 'gamma': 'auto', 'degree': 67}\n",
      "SVR() RandomCV Score: -0.10726984424962471\n",
      "Final score is  -0.10726984424962471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END criterion=poisson, max_depth=290, max_features=sqrt, min_samples_leaf=414, min_samples_split=434, n_estimators=1600;, score=-0.004 total time=   1.5s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=840, max_features=log2, min_samples_leaf=278, min_samples_split=17, n_estimators=1400;, score=0.265 total time=   1.5s\n",
      "[CV 1/5] END criterion=absolute_error, max_depth=60, max_features=sqrt, min_samples_leaf=409, min_samples_split=394, n_estimators=1800;, score=-0.047 total time=   2.1s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=670, max_features=log2, min_samples_leaf=77, min_samples_split=47, n_estimators=600;, score=0.626 total time=   0.7s\n",
      "[CV 1/5] END criterion=absolute_error, max_depth=340, max_features=log2, min_samples_leaf=178, min_samples_split=419, n_estimators=200;, score=0.316 total time=   0.5s\n",
      "[CV 2/5] END criterion=absolute_error, max_depth=590, max_features=sqrt, min_samples_leaf=162, min_samples_split=243, n_estimators=800;, score=0.367 total time=   2.6s\n",
      "[CV 5/5] END criterion=poisson, max_depth=840, max_features=log2, min_samples_leaf=188, min_samples_split=193, n_estimators=800;, score=0.424 total time=   0.9s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=670, max_features=log2, min_samples_leaf=77, min_samples_split=47, n_estimators=600;, score=0.578 total time=   0.7s\n",
      "[CV 1/5] END copy_X=True, fit_intercept=True, positive=False;, score=0.441 total time=   0.0s\n",
      "[CV 4/5] END copy_X=True, fit_intercept=True, positive=False;, score=0.847 total time=   0.0s\n",
      "[CV 5/5] END copy_X=True, fit_intercept=True, positive=True;, score=0.873 total time=   0.0s\n",
      "[CV 5/5] END copy_X=True, fit_intercept=False, positive=False;, score=0.873 total time=   0.0s\n",
      "[CV 1/5] END copy_X=True, fit_intercept=False, positive=True;, score=0.441 total time=   0.0s\n",
      "[CV 2/5] END copy_X=False, fit_intercept=True, positive=True;, score=0.839 total time=   0.0s\n",
      "[CV 3/5] END copy_X=False, fit_intercept=True, positive=True;, score=0.815 total time=   0.0s\n",
      "[CV 3/5] END copy_X=False, fit_intercept=False, positive=True;, score=0.815 total time=   0.0s\n",
      "[CV 1/5] END copy_X=True, fit_intercept=True, positive=False;, score=0.441 total time=   0.0s\n",
      "[CV 1/5] END criterion=poisson, max_depth=290, max_features=sqrt, min_samples_leaf=414, min_samples_split=434, n_estimators=1600;, score=-0.000 total time=   1.6s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=840, max_features=log2, min_samples_leaf=278, min_samples_split=17, n_estimators=1400;, score=0.289 total time=   1.5s\n",
      "[CV 3/5] END criterion=absolute_error, max_depth=60, max_features=sqrt, min_samples_leaf=409, min_samples_split=394, n_estimators=1800;, score=-0.102 total time=   2.1s\n",
      "[CV 1/5] END criterion=absolute_error, max_depth=790, max_features=log2, min_samples_leaf=444, min_samples_split=464, n_estimators=400;, score=-0.048 total time=   0.6s\n",
      "[CV 5/5] END criterion=absolute_error, max_depth=790, max_features=log2, min_samples_leaf=444, min_samples_split=464, n_estimators=400;, score=-0.029 total time=   0.5s\n",
      "[CV 1/5] END criterion=absolute_error, max_depth=590, max_features=sqrt, min_samples_leaf=162, min_samples_split=243, n_estimators=800;, score=0.377 total time=   2.6s\n",
      "[CV 4/5] END criterion=poisson, max_depth=840, max_features=log2, min_samples_leaf=188, min_samples_split=193, n_estimators=800;, score=0.484 total time=   0.9s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=250, max_features=log2, min_samples_leaf=409, min_samples_split=253, n_estimators=1200;, score=-0.007 total time=   1.1s\n",
      "[CV 2/5] END copy_X=True, fit_intercept=True, positive=True;, score=0.839 total time=   0.0s\n",
      "[CV 3/5] END copy_X=True, fit_intercept=False, positive=False;, score=0.815 total time=   0.0s\n",
      "[CV 4/5] END copy_X=True, fit_intercept=False, positive=False;, score=0.847 total time=   0.0s\n",
      "[CV 5/5] END copy_X=False, fit_intercept=True, positive=False;, score=0.873 total time=   0.0s\n",
      "[CV 1/5] END copy_X=False, fit_intercept=True, positive=True;, score=0.441 total time=   0.0s\n",
      "[CV 2/5] END copy_X=False, fit_intercept=False, positive=True;, score=0.839 total time=   0.0s\n",
      "[CV 5/5] END copy_X=False, fit_intercept=False, positive=True;, score=0.873 total time=   0.0s\n",
      "[CV 5/5] END copy_X=True, fit_intercept=True, positive=False;, score=0.873 total time=   0.0s\n",
      "[CV 2/5] END criterion=poisson, max_depth=290, max_features=sqrt, min_samples_leaf=414, min_samples_split=434, n_estimators=1600;, score=-0.003 total time=   1.8s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=850, max_features=sqrt, min_samples_leaf=414, min_samples_split=142, n_estimators=600;, score=-0.000 total time=   0.6s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=850, max_features=sqrt, min_samples_leaf=414, min_samples_split=142, n_estimators=600;, score=-0.004 total time=   0.6s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=850, max_features=sqrt, min_samples_leaf=414, min_samples_split=142, n_estimators=600;, score=-0.007 total time=   0.6s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=670, max_features=log2, min_samples_leaf=77, min_samples_split=47, n_estimators=600;, score=0.580 total time=   0.7s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=670, max_features=log2, min_samples_leaf=77, min_samples_split=47, n_estimators=600;, score=0.592 total time=   0.7s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=670, max_features=log2, min_samples_leaf=77, min_samples_split=47, n_estimators=600;, score=0.608 total time=   0.7s\n",
      "[CV 4/5] END criterion=absolute_error, max_depth=790, max_features=log2, min_samples_leaf=444, min_samples_split=464, n_estimators=400;, score=-0.031 total time=   0.5s\n",
      "[CV 5/5] END criterion=absolute_error, max_depth=340, max_features=log2, min_samples_leaf=178, min_samples_split=419, n_estimators=200;, score=0.343 total time=   0.5s\n",
      "[CV 1/5] END criterion=poisson, max_depth=840, max_features=log2, min_samples_leaf=188, min_samples_split=193, n_estimators=800;, score=0.390 total time=   0.9s\n",
      "[CV 2/5] END criterion=poisson, max_depth=840, max_features=log2, min_samples_leaf=188, min_samples_split=193, n_estimators=800;, score=0.387 total time=   0.9s\n",
      "[CV 3/5] END criterion=poisson, max_depth=840, max_features=log2, min_samples_leaf=188, min_samples_split=193, n_estimators=800;, score=0.413 total time=   0.9s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=250, max_features=log2, min_samples_leaf=409, min_samples_split=253, n_estimators=1200;, score=-0.004 total time=   1.1s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=670, max_features=log2, min_samples_leaf=77, min_samples_split=47, n_estimators=600;, score=0.627 total time=   0.7s\n",
      "[CV 1/5] END copy_X=True, fit_intercept=True, positive=True;, score=0.441 total time=   0.0s\n",
      "[CV 2/5] END copy_X=True, fit_intercept=False, positive=False;, score=0.839 total time=   0.0s\n",
      "[CV 3/5] END copy_X=False, fit_intercept=True, positive=False;, score=0.815 total time=   0.0s\n",
      "[CV 4/5] END copy_X=False, fit_intercept=True, positive=False;, score=0.847 total time=   0.0s\n",
      "[CV 3/5] END copy_X=False, fit_intercept=False, positive=False;, score=0.815 total time=   0.0s\n",
      "[CV 4/5] END copy_X=False, fit_intercept=False, positive=False;, score=0.847 total time=   0.0s\n",
      "[CV 3/5] END copy_X=True, fit_intercept=True, positive=False;, score=0.815 total time=   0.0s\n",
      "[CV 3/5] END criterion=poisson, max_depth=290, max_features=sqrt, min_samples_leaf=414, min_samples_split=434, n_estimators=1600;, score=-0.005 total time=   1.6s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=840, max_features=log2, min_samples_leaf=278, min_samples_split=17, n_estimators=1400;, score=0.336 total time=   1.7s\n",
      "[CV 4/5] END criterion=absolute_error, max_depth=60, max_features=sqrt, min_samples_leaf=409, min_samples_split=394, n_estimators=1800;, score=-0.031 total time=   2.1s\n",
      "[CV 2/5] END criterion=absolute_error, max_depth=790, max_features=log2, min_samples_leaf=444, min_samples_split=464, n_estimators=400;, score=-0.068 total time=   0.5s\n",
      "[CV 2/5] END criterion=absolute_error, max_depth=340, max_features=log2, min_samples_leaf=178, min_samples_split=419, n_estimators=200;, score=0.306 total time=   0.5s\n",
      "[CV 3/5] END criterion=absolute_error, max_depth=590, max_features=sqrt, min_samples_leaf=162, min_samples_split=243, n_estimators=800;, score=0.376 total time=   2.7s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=250, max_features=log2, min_samples_leaf=409, min_samples_split=253, n_estimators=1200;, score=-0.005 total time=   1.2s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=670, max_features=log2, min_samples_leaf=77, min_samples_split=47, n_estimators=600;, score=0.714 total time=   0.9s\n",
      "[CV 3/5] END copy_X=True, fit_intercept=True, positive=False;, score=0.815 total time=   0.0s\n",
      "[CV 4/5] END copy_X=True, fit_intercept=True, positive=True;, score=0.847 total time=   0.0s\n",
      "[CV 2/5] END copy_X=True, fit_intercept=False, positive=True;, score=0.839 total time=   0.0s\n",
      "[CV 3/5] END copy_X=True, fit_intercept=False, positive=True;, score=0.815 total time=   0.0s\n",
      "[CV 4/5] END copy_X=False, fit_intercept=True, positive=True;, score=0.847 total time=   0.0s\n",
      "[CV 5/5] END copy_X=False, fit_intercept=True, positive=True;, score=0.873 total time=   0.0s\n",
      "[CV 4/5] END copy_X=False, fit_intercept=False, positive=True;, score=0.847 total time=   0.0s\n",
      "[CV 2/5] END copy_X=True, fit_intercept=True, positive=False;, score=0.839 total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=840, max_features=log2, min_samples_leaf=278, min_samples_split=17, n_estimators=1400;, score=0.270 total time=   1.7s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=850, max_features=sqrt, min_samples_leaf=414, min_samples_split=142, n_estimators=600;, score=-0.003 total time=   0.6s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=850, max_features=sqrt, min_samples_leaf=414, min_samples_split=142, n_estimators=600;, score=-0.004 total time=   0.6s\n",
      "[CV 2/5] END criterion=absolute_error, max_depth=60, max_features=sqrt, min_samples_leaf=409, min_samples_split=394, n_estimators=1800;, score=-0.068 total time=   2.1s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=670, max_features=log2, min_samples_leaf=77, min_samples_split=47, n_estimators=600;, score=0.720 total time=   0.9s\n",
      "[CV 4/5] END criterion=absolute_error, max_depth=340, max_features=log2, min_samples_leaf=178, min_samples_split=419, n_estimators=200;, score=0.398 total time=   0.5s\n",
      "[CV 5/5] END criterion=absolute_error, max_depth=590, max_features=sqrt, min_samples_leaf=162, min_samples_split=243, n_estimators=800;, score=0.425 total time=   2.5s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=250, max_features=log2, min_samples_leaf=409, min_samples_split=253, n_estimators=1200;, score=-0.003 total time=   1.1s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=670, max_features=log2, min_samples_leaf=77, min_samples_split=47, n_estimators=600;, score=0.613 total time=   0.7s\n",
      "[CV 2/5] END copy_X=True, fit_intercept=True, positive=False;, score=0.839 total time=   0.0s\n",
      "[CV 3/5] END copy_X=True, fit_intercept=True, positive=True;, score=0.815 total time=   0.0s\n",
      "[CV 1/5] END copy_X=False, fit_intercept=True, positive=False;, score=0.441 total time=   0.0s\n",
      "[CV 2/5] END copy_X=False, fit_intercept=True, positive=False;, score=0.839 total time=   0.0s\n",
      "[CV 1/5] END copy_X=False, fit_intercept=False, positive=False;, score=0.441 total time=   0.0s\n",
      "[CV 2/5] END copy_X=False, fit_intercept=False, positive=False;, score=0.839 total time=   0.0s\n",
      "[CV 5/5] END criterion=poisson, max_depth=290, max_features=sqrt, min_samples_leaf=414, min_samples_split=434, n_estimators=1600;, score=-0.007 total time=   1.6s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=840, max_features=log2, min_samples_leaf=278, min_samples_split=17, n_estimators=1400;, score=0.307 total time=   1.8s\n",
      "[CV 5/5] END criterion=absolute_error, max_depth=60, max_features=sqrt, min_samples_leaf=409, min_samples_split=394, n_estimators=1800;, score=-0.029 total time=   2.1s\n",
      "[CV 3/5] END criterion=absolute_error, max_depth=790, max_features=log2, min_samples_leaf=444, min_samples_split=464, n_estimators=400;, score=-0.103 total time=   0.5s\n",
      "[CV 3/5] END criterion=absolute_error, max_depth=340, max_features=log2, min_samples_leaf=178, min_samples_split=419, n_estimators=200;, score=0.294 total time=   0.5s\n",
      "[CV 4/5] END criterion=absolute_error, max_depth=590, max_features=sqrt, min_samples_leaf=162, min_samples_split=243, n_estimators=800;, score=0.480 total time=   2.5s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=250, max_features=log2, min_samples_leaf=409, min_samples_split=253, n_estimators=1200;, score=-0.000 total time=   1.1s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=670, max_features=log2, min_samples_leaf=77, min_samples_split=47, n_estimators=600;, score=0.597 total time=   0.9s\n",
      "[CV 5/5] END copy_X=True, fit_intercept=True, positive=False;, score=0.873 total time=   0.0s\n",
      "[CV 1/5] END copy_X=True, fit_intercept=False, positive=False;, score=0.441 total time=   0.0s\n",
      "[CV 4/5] END copy_X=True, fit_intercept=False, positive=True;, score=0.847 total time=   0.0s\n",
      "[CV 5/5] END copy_X=True, fit_intercept=False, positive=True;, score=0.873 total time=   0.0s\n",
      "[CV 5/5] END copy_X=False, fit_intercept=False, positive=False;, score=0.873 total time=   0.0s\n",
      "[CV 1/5] END copy_X=False, fit_intercept=False, positive=True;, score=0.441 total time=   0.0s\n",
      "[CV 4/5] END copy_X=True, fit_intercept=True, positive=False;, score=0.847 total time=   0.0s\n"
     ]
    }
   ],
   "source": [
    "hyperparameter_tuning(algo=\"SVR()\",param_grid=random_grid,n_iter=10,cv=5,verbose=0,random_state=42,X_train=X_train,Y_train=Y_train,X_test=X_test,Y_test=Y_test,evaluation_metric=\"r2_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "e5a3a6ab-2022-40ad-8a12-79338312ea1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# svr=SVR()\n",
    "# svr_random_cv=RandomizedSearchCV(estimator=svr,param_distributions=random_grid,n_iter=100,cv=5,verbose=0,random_state=100,n_jobs=-1)\n",
    "# svr_random_cv.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "31599b8b-392b-48e2-a14a-20d76fc1d82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# best_params_=svr_random_cv.best_params_\n",
    "# print(\"RandomCV Best Params :\",best_params_)\n",
    "# best_random_grid=svr_random_cv.best_estimator_\n",
    "# y_pred3=best_random_grid.predict(X_test)\n",
    "# score_3=r2_score(Y_test,y_pred3)\n",
    "# print(\"RandomCV Score: \",score_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "7984d94e-b454-4d0c-8e99-09520b49868b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid3=defaultdict(list)\n",
    "# for val in best_params_:\n",
    "#     param_grid3[val].append(best_params_[val])\n",
    "# print(param_grid3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "9a6de630-558d-42db-abeb-cc2f4ddf4c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# svr=SVR()\n",
    "# grid_search_svr=GridSearchCV(estimator=svr,param_grid=param_grid3,cv=5,n_jobs=-1,verbose=3)\n",
    "# grid_search_svr.fit(X_train,Y_train)\n",
    "# print(grid_search_svr.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "c12ceac2-7135-4413-992b-cf5ee1a3c520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_grid2=grid_search_svr.best_estimator_\n",
    "# y_pred3=best_grid2.predict(X_test)\n",
    "# score_3=r2_score(Y_test,y_pred3)\n",
    "# print(score_3)\n",
    "# accuracies[\"SVR\"]=score_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "54ce9b9e-23a7-4be8-857d-86f034efa2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 KNN Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "4aa457e1-0391-4560-90ea-dca061d05c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'weights': ['uniform', 'distance'], 'n_neighbors': [5, 12, 19, 26, 33, 40, 47, 54, 61, 68, 75, 82, 89, 96, 103, 110, 117, 124, 131, 138, 145, 152, 159, 166, 173, 181, 188, 195, 202, 209, 216, 223, 230, 237, 244, 251, 258, 265, 272, 279, 286, 293, 300, 307, 314, 321, 328, 335, 342, 350], 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], 'leaf_size': [5, 6, 8, 10, 11, 13, 15, 16, 18, 20], 'p': [1, 2]}\n"
     ]
    }
   ],
   "source": [
    "weights=[\"uniform\", \"distance\"]\n",
    "n_neighbors = [int(x) for x in np.linspace(start = 5, stop = 350, num = 50)]\n",
    "algorithm= [\"auto\", \"ball_tree\",\"kd_tree\",\"brute\"]\n",
    "leaf_size=[int(x) for x in np.linspace(start = 5, stop = 20, num = 10)]\n",
    "p = [1,2]\n",
    "\n",
    "\n",
    "random_grid = {'weights': weights,\n",
    "               'n_neighbors': n_neighbors,\n",
    "               'algorithm': algorithm,\n",
    "               'leaf_size':leaf_size,\n",
    "               'p':p\n",
    "               }\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "b88b6711-3867-4aff-92ec-ce861183e3ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "KNeighborsRegressor() RandomCV Best Params : {'weights': 'distance', 'p': 2, 'n_neighbors': 5, 'leaf_size': 18, 'algorithm': 'brute'}\n",
      "KNeighborsRegressor() RandomCV Score: 0.7073273687494936\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Final score is  0.7073273687494936\n"
     ]
    }
   ],
   "source": [
    "hyperparameter_tuning(algo=\"KNeighborsRegressor()\",param_grid=random_grid,n_iter=10,cv=5,verbose=2,random_state=42,X_train=X_train,Y_train=Y_train,X_test=X_test,Y_test=Y_test,evaluation_metric=\"r2_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "36af1563-e691-49d1-9f98-cccc6ddba236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=KNeighborsRegressor()\n",
    "# knn_random_cv=RandomizedSearchCV(estimator=model,param_distributions=random_grid,n_iter=100,cv=5,verbose=1,random_state=100,n_jobs=-1)\n",
    "# knn_random_cv.fit(X_train,Y_train)\n",
    "# best_params_=knn_random_cv.best_params_\n",
    "# print(\"RandomCV Best Params :\",best_params_)\n",
    "# best_random_grid=knn_random_cv.best_estimator_\n",
    "# y_pred4=best_random_grid.predict(X_test)\n",
    "# score_4=r2_score(Y_test,y_pred4)\n",
    "# print(\"RandomCV Score: \",score_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "723f749c-ae27-4753-8a7d-a63a9d0fb3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid4=defaultdict(list)\n",
    "# for val in best_params_:\n",
    "#     param_grid4[val].append(best_params_[val])\n",
    "# print(param_grid4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "ed56a0b4-ea4b-4a71-a57f-8706465ab897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=KNeighborsRegressor()\n",
    "# grid_search=GridSearchCV(estimator=model,param_grid=param_grid4,cv=5,n_jobs=-1,verbose=3)\n",
    "# grid_search.fit(X_train,Y_train)\n",
    "# print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "ca600f00-e26a-4ac7-afa5-792a45ac3f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_grid2=grid_search.best_estimator_\n",
    "# final=best_grid2.predict(X_test)\n",
    "# score_final4=r2_score(Y_test,final)\n",
    "# print(score_final4)\n",
    "# accuracies[\"KNeighborsRegressor\"]=score_final4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "a8fea44b-4eeb-4bc3-989d-2c2f6826d88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5 DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "f1e5d7bf-71e3-4a7c-bce8-e8c924f7a515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'splitter': ['best', 'random'], 'ccp_alpha': [1, 0], 'max_features': ['sqrt', 'log2'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190, 200, 210, 220, 230, 240, 250, 260, 270, 280, 290, 300, 310, 320, 330, 340, 350, 360, 370, 380, 390, 400, 410, 420, 430, 440, 450, 460, 470, 480, 490, 500, 510, 520, 530, 540, 550, 560, 570, 580, 590, 600, 610, 620, 630, 640, 650, 660, 670, 680, 690, 700, 710, 720, 730, 740, 750, 760, 770, 780, 790, 800, 810, 820, 830, 840, 850, 860, 870, 880, 890, 900, 910, 920, 930, 940, 950, 960, 970, 980, 990, 1000], 'min_samples_split': [2, 3, 4, 5, 10, 14], 'min_samples_leaf': [1, 2, 4, 6, 8], 'criterion': ['squared_error', 'absolute_error', 'friedman_mse', 'poisson']}\n"
     ]
    }
   ],
   "source": [
    "splitter=[\"best\", \"random\"]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['sqrt','log2']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 1000,100)]\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2,3,4, 5, 10,14]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1,2, 4,6,8]\n",
    "# Create the random grid\n",
    "random_grid = {'splitter':splitter,\n",
    "               'ccp_alpha':[1,0],\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "              'criterion':['squared_error','absolute_error','friedman_mse','poisson']}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "8eab1272-c8ff-4111-b5a4-16e9edb41fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "DecisionTreeRegressor() RandomCV Best Params : {'splitter': 'best', 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 300, 'criterion': 'poisson', 'ccp_alpha': 0}\n",
      "DecisionTreeRegressor() RandomCV Score: 0.7533754964571078\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Final score is  0.6699070971484998\n"
     ]
    }
   ],
   "source": [
    "hyperparameter_tuning(algo=\"DecisionTreeRegressor()\",param_grid=random_grid,n_iter=10,cv=5,verbose=2,random_state=42,X_train=X_train,Y_train=Y_train,X_test=X_test,Y_test=Y_test,evaluation_metric=\"r2_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "4152fecd-e5cb-44b1-8cef-76544e83c7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dt=DecisionTreeRegressor()\n",
    "# dt_random_cv=RandomizedSearchCV(estimator=dt,param_distributions=random_grid,n_iter=100,cv=5,verbose=0,random_state=100,n_jobs=-1)\n",
    "# dt_random_cv.fit(X_train,Y_train)\n",
    "\n",
    "# best_params_=dt_random_cv.best_params_\n",
    "# print(\"RandomCV Best Params :\",best_params_)\n",
    "# best_random_grid=dt_random_cv.best_estimator_\n",
    "# y_pred5=best_random_grid.predict(X_test)\n",
    "# score_5=r2_score(Y_test,y_pred5)\n",
    "# print(\"RandomCV Score: \",score_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "d3ef23e3-a882-486b-9ce6-626a6695c674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid5=defaultdict(list)\n",
    "# for val in best_params_:\n",
    "#     param_grid5[val].append(best_params_[val])\n",
    "# print(param_grid5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "8f5b1961-7341-4f46-a938-778d752a10db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=DecisionTreeRegressor()\n",
    "# grid_search=GridSearchCV(estimator=model,param_grid=param_grid5,cv=5,n_jobs=-1,verbose=3)\n",
    "# grid_search.fit(X_train,Y_train)\n",
    "# print(grid_search.best_estimator_)\n",
    "# best_grid2=grid_search.best_estimator_\n",
    "# final5=best_grid2.predict(X_test)\n",
    "# score_final5=r2_score(Y_test,final5)\n",
    "# print(score_final5)\n",
    "# accuracies[\"DecisionTreeRegressor\"]=score_final5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "9786a182-4bd1-47c6-b3a3-39abe0b6f7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 6 SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "eb3b9860-4ce6-4527-b5b8-3012f8e51e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': ['squared_error', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'], 'penalty': ['l2', 'l1', 'elasticnet', 'None'], 'alpha': [0.0, 2.0408163265306123e-05, 4.0816326530612245e-05, 6.122448979591836e-05, 8.163265306122449e-05, 0.00010204081632653062, 0.00012244897959183673, 0.00014285714285714287, 0.00016326530612244898, 0.0001836734693877551, 0.00020408163265306123, 0.00022448979591836734, 0.00024489795918367346, 0.0002653061224489796, 0.00028571428571428574, 0.0003061224489795918, 0.00032653061224489796, 0.0003469387755102041, 0.0003673469387755102, 0.0003877551020408163, 0.00040816326530612246, 0.00042857142857142855, 0.0004489795918367347, 0.00046938775510204083, 0.0004897959183673469, 0.0005102040816326531, 0.0005306122448979592, 0.0005510204081632653, 0.0005714285714285715, 0.0005918367346938776, 0.0006122448979591836, 0.0006326530612244898, 0.0006530612244897959, 0.000673469387755102, 0.0006938775510204082, 0.0007142857142857143, 0.0007346938775510204, 0.0007551020408163266, 0.0007755102040816326, 0.0007959183673469387, 0.0008163265306122449, 0.000836734693877551, 0.0008571428571428571, 0.0008775510204081633, 0.0008979591836734694, 0.0009183673469387755, 0.0009387755102040817, 0.0009591836734693877, 0.0009795918367346938, 0.001], 'l1_ratio': [0.0, 0.01020408163265306, 0.02040816326530612, 0.030612244897959183, 0.04081632653061224, 0.0510204081632653, 0.061224489795918366, 0.07142857142857142, 0.08163265306122448, 0.09183673469387754, 0.1020408163265306, 0.11224489795918366, 0.12244897959183673, 0.13265306122448978, 0.14285714285714285, 0.1530612244897959, 0.16326530612244897, 0.17346938775510204, 0.18367346938775508, 0.19387755102040816, 0.2040816326530612, 0.21428571428571427, 0.22448979591836732, 0.2346938775510204, 0.24489795918367346, 0.25510204081632654, 0.26530612244897955, 0.2755102040816326, 0.2857142857142857, 0.29591836734693877, 0.3061224489795918, 0.31632653061224486, 0.32653061224489793, 0.336734693877551, 0.3469387755102041, 0.3571428571428571, 0.36734693877551017, 0.37755102040816324, 0.3877551020408163, 0.39795918367346933, 0.4081632653061224, 0.4183673469387755, 0.42857142857142855, 0.4387755102040816, 0.44897959183673464, 0.4591836734693877, 0.4693877551020408, 0.47959183673469385, 0.4897959183673469, 0.5], 'max_iter': [8000, 8121, 8242, 8363, 8484, 8606, 8727, 8848, 8969, 9090, 9212, 9333, 9454, 9575, 9696, 9818, 9939, 10060, 10181, 10303, 10424, 10545, 10666, 10787, 10909, 11030, 11151, 11272, 11393, 11515, 11636, 11757, 11878, 12000, 12121, 12242, 12363, 12484, 12606, 12727, 12848, 12969, 13090, 13212, 13333, 13454, 13575, 13696, 13818, 13939, 14060, 14181, 14303, 14424, 14545, 14666, 14787, 14909, 15030, 15151, 15272, 15393, 15515, 15636, 15757, 15878, 16000, 16121, 16242, 16363, 16484, 16606, 16727, 16848, 16969, 17090, 17212, 17333, 17454, 17575, 17696, 17818, 17939, 18060, 18181, 18303, 18424, 18545, 18666, 18787, 18909, 19030, 19151, 19272, 19393, 19515, 19636, 19757, 19878, 20000], 'tol': [0.01, 0.009909090909090909, 0.009818181818181818, 0.009727272727272727, 0.009636363636363637, 0.009545454545454546, 0.009454545454545455, 0.009363636363636364, 0.009272727272727273, 0.009181818181818182, 0.00909090909090909, 0.009000000000000001, 0.00890909090909091, 0.008818181818181819, 0.008727272727272728, 0.008636363636363636, 0.008545454545454545, 0.008454545454545454, 0.008363636363636363, 0.008272727272727272, 0.008181818181818182, 0.008090909090909091, 0.008, 0.007909090909090909, 0.007818181818181818, 0.007727272727272727, 0.0076363636363636364, 0.007545454545454545, 0.007454545454545455, 0.007363636363636364, 0.007272727272727273, 0.007181818181818182, 0.00709090909090909, 0.007, 0.006909090909090909, 0.006818181818181819, 0.006727272727272728, 0.006636363636363636, 0.006545454545454545, 0.006454545454545454, 0.006363636363636363, 0.006272727272727273, 0.0061818181818181816, 0.00609090909090909, 0.006, 0.005909090909090909, 0.005818181818181818, 0.005727272727272727, 0.005636363636363636, 0.005545454545454545, 0.005454545454545454, 0.005363636363636364, 0.005272727272727273, 0.0051818181818181815, 0.00509090909090909, 0.005, 0.004909090909090909, 0.004818181818181818, 0.004727272727272727, 0.004636363636363636, 0.004545454545454545, 0.004454545454545454, 0.004363636363636363, 0.004272727272727273, 0.0041818181818181815, 0.00409090909090909, 0.004, 0.003909090909090909, 0.003818181818181818, 0.0037272727272727266, 0.0036363636363636364, 0.003545454545454545, 0.003454545454545454, 0.003363636363636363, 0.0032727272727272726, 0.0031818181818181815, 0.0030909090909090903, 0.002999999999999999, 0.002909090909090909, 0.0028181818181818178, 0.0027272727272727266, 0.0026363636363636363, 0.002545454545454545, 0.002454545454545454, 0.002363636363636363, 0.0022727272727272726, 0.0021818181818181806, 0.002090909090909091, 0.002, 0.001909090909090909, 0.0018181818181818177, 0.0017272727272727266, 0.0016363636363636355, 0.0015454545454545443, 0.0014545454545454532, 0.0013636363636363637, 0.0012727272727272726, 0.0011818181818181814, 0.0010909090909090903, 0.001], 'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'], 'eta0': [0.1, 0.0994949494949495, 0.09898989898989899, 0.0984848484848485, 0.09797979797979799, 0.09747474747474748, 0.09696969696969697, 0.09646464646464648, 0.09595959595959597, 0.09545454545454546, 0.09494949494949495, 0.09444444444444446, 0.09393939393939395, 0.09343434343434344, 0.09292929292929293, 0.09242424242424244, 0.09191919191919193, 0.09141414141414142, 0.09090909090909091, 0.0904040404040404, 0.08989898989898991, 0.0893939393939394, 0.08888888888888889, 0.08838383838383838, 0.08787878787878789, 0.08737373737373738, 0.08686868686868687, 0.08636363636363636, 0.08585858585858586, 0.08535353535353536, 0.08484848484848485, 0.08434343434343435, 0.08383838383838385, 0.08333333333333334, 0.08282828282828283, 0.08232323232323233, 0.08181818181818182, 0.08131313131313132, 0.08080808080808081, 0.0803030303030303, 0.07979797979797981, 0.0792929292929293, 0.0787878787878788, 0.07828282828282829, 0.07777777777777778, 0.07727272727272727, 0.07676767676767678, 0.07626262626262627, 0.07575757575757576, 0.07525252525252527, 0.07474747474747476, 0.07424242424242425, 0.07373737373737374, 0.07323232323232323, 0.07272727272727274, 0.07222222222222223, 0.07171717171717172, 0.07121212121212121, 0.07070707070707072, 0.07020202020202021, 0.0696969696969697, 0.0691919191919192, 0.06868686868686869, 0.06818181818181819, 0.06767676767676768, 0.06717171717171717, 0.06666666666666668, 0.06616161616161617, 0.06565656565656566, 0.06515151515151515, 0.06464646464646465, 0.06414141414141414, 0.06363636363636364, 0.06313131313131314, 0.06262626262626264, 0.062121212121212126, 0.061616161616161624, 0.061111111111111116, 0.060606060606060615, 0.060101010101010106, 0.059595959595959605, 0.0590909090909091, 0.05858585858585859, 0.05808080808080809, 0.05757575757575758, 0.05707070707070708, 0.05656565656565657, 0.05606060606060607, 0.05555555555555556, 0.05505050505050506, 0.05454545454545455, 0.05404040404040405, 0.05353535353535354, 0.05303030303030304, 0.05252525252525253, 0.05202020202020203, 0.05151515151515152, 0.05101010101010101, 0.05050505050505051, 0.05], 'validation_fraction': [0.1, 0.1163265306122449, 0.1326530612244898, 0.1489795918367347, 0.1653061224489796, 0.1816326530612245, 0.1979591836734694, 0.2142857142857143, 0.2306122448979592, 0.2469387755102041, 0.263265306122449, 0.2795918367346939, 0.29591836734693877, 0.3122448979591837, 0.3285714285714286, 0.3448979591836735, 0.36122448979591837, 0.37755102040816324, 0.3938775510204082, 0.4102040816326531, 0.42653061224489797, 0.44285714285714284, 0.4591836734693878, 0.4755102040816327, 0.49183673469387756, 0.5081632653061224, 0.5244897959183674, 0.5408163265306123, 0.5571428571428572, 0.573469387755102, 0.589795918367347, 0.6061224489795919, 0.6224489795918368, 0.6387755102040816, 0.6551020408163265, 0.6714285714285715, 0.6877551020408164, 0.7040816326530612, 0.7204081632653062, 0.7367346938775511, 0.753061224489796, 0.7693877551020408, 0.7857142857142857, 0.8020408163265307, 0.8183673469387756, 0.8346938775510204, 0.8510204081632654, 0.8673469387755103, 0.8836734693877552, 0.9], 'n_iter_no_change': [1, 2, 4, 6, 8, 5, 10]}\n"
     ]
    }
   ],
   "source": [
    "loss = ['squared_error','huber','epsilon_insensitive','squared_epsilon_insensitive']\n",
    "penalty=['l2','l1','elasticnet','None']\n",
    "alpha = [float(x) for x in np.linspace(0, 0.001,50)]\n",
    "l1_ratio=[float(x) for x in np.linspace(0, 0.5,50)]\n",
    "max_iter=[int(x) for x in np.linspace(8000, 20000,100)]\n",
    "tol=[float(x) for x in np.linspace(0.01, 0.001,100)]\n",
    "learning_rate=['constant','optimal','invscaling','adaptive']\n",
    "eta0=[float(x) for x in np.linspace(0.1, 0.05,100)]\n",
    "early_stopping = ['True','False']\n",
    "validation_fraction=[float(x) for x in np.linspace(0.1, 0.9,50)]\n",
    "n_iter_no_change = [1,2, 4,6,8,5,10]\n",
    "average=['bool','int']\n",
    "random_grid = {\n",
    "               'loss': loss,\n",
    "               'penalty': penalty,\n",
    "               'alpha': alpha,\n",
    "               'l1_ratio': l1_ratio,\n",
    "              'max_iter':max_iter,\n",
    "               'tol':tol,\n",
    "                'learning_rate':learning_rate,\n",
    "                'eta0':eta0,\n",
    "               \n",
    "                'validation_fraction':validation_fraction,\n",
    "                'n_iter_no_change':n_iter_no_change\n",
    "                }\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "e64b77a0-63ee-4ac6-86f1-4a8b4203b97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END copy_X=True, fit_intercept=True, positive=False;, score=-1491335583445575312343040.000 total time=   0.1s\n",
      "[CV 4/5] END copy_X=True, fit_intercept=True, positive=True;, score=0.722 total time=   0.1s\n",
      "[CV 5/5] END copy_X=True, fit_intercept=False, positive=False;, score=0.772 total time=   0.1s\n",
      "[CV 1/5] END copy_X=False, fit_intercept=True, positive=False;, score=0.686 total time=   0.1s\n",
      "[CV 2/5] END copy_X=False, fit_intercept=True, positive=True;, score=0.559 total time=   0.1s\n",
      "[CV 3/5] END copy_X=False, fit_intercept=False, positive=False;, score=-1491335583445575312343040.000 total time=   0.1s\n",
      "[CV 4/5] END copy_X=False, fit_intercept=False, positive=True;, score=0.722 total time=   0.1s\n",
      "[CV 5/5] END copy_X=True, fit_intercept=True, positive=False;, score=0.772 total time=   0.1s\n",
      "[CV 4/5] END criterion=poisson, max_depth=1000, max_features=sqrt, min_samples_leaf=8, min_samples_split=3, n_estimators=1000;, score=0.786 total time=   1.8s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=670, max_features=sqrt, min_samples_leaf=6, min_samples_split=3, n_estimators=1200;, score=0.797 total time=   2.1s\n",
      "[CV 1/5] END criterion=absolute_error, max_depth=1000, max_features=log2, min_samples_leaf=8, min_samples_split=4, n_estimators=1000;, score=0.728 total time=   5.8s\n",
      "[CV 2/5] END criterion=absolute_error, max_depth=890, max_features=log2, min_samples_leaf=6, min_samples_split=2, n_estimators=1000;, score=0.692 total time=   6.1s\n",
      "[CV 5/5] END criterion=poisson, max_depth=670, max_features=log2, min_samples_leaf=6, min_samples_split=5, n_estimators=1800;, score=0.806 total time=   2.6s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=890, max_features=sqrt, min_samples_leaf=1, min_samples_split=14, n_estimators=200;, score=0.862 total time=   0.4s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=890, max_features=sqrt, min_samples_leaf=1, min_samples_split=14, n_estimators=200;, score=0.781 total time=   0.4s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=890, max_features=sqrt, min_samples_leaf=1, min_samples_split=14, n_estimators=200;, score=0.816 total time=   0.4s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=890, max_features=sqrt, min_samples_leaf=1, min_samples_split=14, n_estimators=200;, score=0.813 total time=   0.4s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=890, max_features=sqrt, min_samples_leaf=1, min_samples_split=14, n_estimators=200;, score=0.857 total time=   0.4s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=890, max_features=sqrt, min_samples_leaf=1, min_samples_split=14, n_estimators=200;, score=0.859 total time=   0.4s\n",
      "[CV] END algorithm=brute, leaf_size=15, n_neighbors=124, p=2, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, leaf_size=18, n_neighbors=5, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=15, n_neighbors=335, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, leaf_size=15, n_neighbors=335, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, leaf_size=18, n_neighbors=307, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=ball_tree, leaf_size=18, n_neighbors=307, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=ball_tree, leaf_size=13, n_neighbors=166, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=ball_tree, leaf_size=13, n_neighbors=166, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=kd_tree, leaf_size=18, n_neighbors=237, p=2, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, leaf_size=18, n_neighbors=5, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=absolute_error, max_depth=320, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=squared_error, max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=squared_error, max_depth=530, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=squared_error, max_depth=530, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=poisson, max_depth=100, max_features=log2, min_samples_leaf=8, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END ccp_alpha=0, criterion=poisson, max_depth=300, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=poisson, max_depth=680, max_features=log2, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END ccp_alpha=0, criterion=absolute_error, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=14, splitter=random; total time=   0.0s\n",
      "[CV] END ccp_alpha=0, criterion=poisson, max_depth=300, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END alpha=0.0005510204081632653, eta0=0.05555555555555556, l1_ratio=0.09183673469387754, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=14303, n_iter_no_change=8, penalty=l1, tol=0.004636363636363636, validation_fraction=0.7040816326530612; total time=  20.6s\n",
      "[CV] END alpha=6.122448979591836e-05, eta0=0.08535353535353536, l1_ratio=0.4387755102040816, learning_rate=constant, loss=huber, max_iter=19878, n_iter_no_change=1, penalty=l2, tol=0.008272727272727272, validation_fraction=0.49183673469387756; total time=   5.7s\n",
      "[CV] END alpha=0.00032653061224489796, eta0=0.05101010101010101, l1_ratio=0.22448979591836732, learning_rate=adaptive, loss=squared_error, max_iter=9454, n_iter_no_change=2, penalty=elasticnet, tol=0.008090909090909091, validation_fraction=0.1; total time=   0.0s\n",
      "[CV] END alpha=0.00032653061224489796, eta0=0.05101010101010101, l1_ratio=0.22448979591836732, learning_rate=adaptive, loss=squared_error, max_iter=9454, n_iter_no_change=2, penalty=elasticnet, tol=0.008090909090909091, validation_fraction=0.1; total time=   0.0s\n",
      "[CV] END alpha=0.00032653061224489796, eta0=0.05101010101010101, l1_ratio=0.22448979591836732, learning_rate=adaptive, loss=squared_error, max_iter=9454, n_iter_no_change=2, penalty=elasticnet, tol=0.008090909090909091, validation_fraction=0.1; total time=   0.0s\n",
      "[CV] END alpha=0.00032653061224489796, eta0=0.05101010101010101, l1_ratio=0.22448979591836732, learning_rate=adaptive, loss=squared_error, max_iter=9454, n_iter_no_change=2, penalty=elasticnet, tol=0.008090909090909091, validation_fraction=0.1; total time=   0.0s\n",
      "[CV] END alpha=0.00032653061224489796, eta0=0.05101010101010101, l1_ratio=0.22448979591836732, learning_rate=adaptive, loss=squared_error, max_iter=9454, n_iter_no_change=2, penalty=elasticnet, tol=0.008090909090909091, validation_fraction=0.1; total time=   0.0s\n",
      "[CV] END alpha=0.0008775510204081633, eta0=0.07121212121212121, l1_ratio=0.26530612244897955, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=12242, n_iter_no_change=8, penalty=elasticnet, tol=0.00509090909090909, validation_fraction=0.8020408163265307; total time=   0.4s\n",
      "[CV] END alpha=0.0008775510204081633, eta0=0.07121212121212121, l1_ratio=0.26530612244897955, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=12242, n_iter_no_change=8, penalty=elasticnet, tol=0.00509090909090909, validation_fraction=0.8020408163265307; total time=   0.3s\n",
      "[CV] END alpha=0.0008775510204081633, eta0=0.07121212121212121, l1_ratio=0.26530612244897955, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=12242, n_iter_no_change=8, penalty=elasticnet, tol=0.00509090909090909, validation_fraction=0.8020408163265307; total time=   0.3s\n",
      "[CV] END alpha=0.0008775510204081633, eta0=0.07121212121212121, l1_ratio=0.26530612244897955, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=12242, n_iter_no_change=8, penalty=elasticnet, tol=0.00509090909090909, validation_fraction=0.8020408163265307; total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDRegressor() RandomCV Best Params : {'validation_fraction': 0.3938775510204082, 'tol': 0.007727272727272727, 'penalty': 'l2', 'n_iter_no_change': 2, 'max_iter': 13333, 'loss': 'squared_epsilon_insensitive', 'learning_rate': 'invscaling', 'l1_ratio': 0.08163265306122448, 'eta0': 0.05555555555555556, 'alpha': 0.0009183673469387755}\n",
      "SGDRegressor() RandomCV Score: 0.7984591576471831\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Final score is  0.7848215372436905\n"
     ]
    }
   ],
   "source": [
    "hyperparameter_tuning(algo=\"SGDRegressor()\",param_grid=random_grid,n_iter=10,cv=5,verbose=2,random_state=42,X_train=X_train,Y_train=Y_train,X_test=X_test,Y_test=Y_test,evaluation_metric=\"r2_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "37e2e660-67b1-442d-a83b-aefd51711b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sgd=SGDRegressor()\n",
    "# sgd_random_cv=RandomizedSearchCV(estimator=sgd,param_distributions=random_grid,n_iter=100,cv=5,verbose=0,random_state=100,n_jobs=-1)\n",
    "# sgd_random_cv.fit(X_train,Y_train)\n",
    "\n",
    "# best_params_=sgd_random_cv.best_params_\n",
    "# print(\"RandomCV Best Params :\",best_params_)\n",
    "# best_random_grid=sgd_random_cv.best_estimator_\n",
    "# y_pred6=best_random_grid.predict(X_test)\n",
    "# score_6=r2_score(Y_test,y_pred6)\n",
    "# print(\"RandomCV Score: \",score_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "6cf817db-1727-479e-ba86-5de2b6ffeca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid6=defaultdict(list)\n",
    "# for val in best_params_:\n",
    "#     param_grid6[val].append(best_params_[val])\n",
    "# print(param_grid6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "6a24ac32-6482-4ca4-9d32-63087706a0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=SGDRegressor()\n",
    "# grid_search=GridSearchCV(estimator=model,param_grid=param_grid6,cv=5,n_jobs=-1,verbose=3)\n",
    "# grid_search.fit(X_train,Y_train)\n",
    "# print(grid_search.best_estimator_)\n",
    "# best_grid2=grid_search.best_estimator_\n",
    "# final6=best_grid2.predict(X_test)\n",
    "# score_final6=r2_score(Y_test,final6)\n",
    "# print(score_final6)\n",
    "# accuracies[\"SGDRegressor\"]=score_final6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "98cb9a98-292f-4f59-bd1f-79729779c474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LinearRegression()': -1.3643518980430038e+23,\n",
       " 'RandomForestRegressor()': 0.8201522653525275,\n",
       " 'SVR()': -7.943707625401863e-05,\n",
       " 'KNeighborsRegressor()': 0.7073273687494936,\n",
       " 'DecisionTreeRegressor()': 0.6699070971484998,\n",
       " 'SGDRegressor()': 0.7848215372436905}"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "2141aa06-dd6d-4ac4-9719-08bdaa5468ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7 ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "32abb30c-1645-4fe7-9eb9-d0d4acc83f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'copy_X': ['True', 'False'], 'alpha': [0.0, 0.001002004008016032, 0.002004008016032064, 0.0030060120240480957, 0.004008016032064128, 0.00501002004008016, 0.0060120240480961915, 0.007014028056112224, 0.008016032064128256, 0.009018036072144287, 0.01002004008016032, 0.011022044088176352, 0.012024048096192383, 0.013026052104208416, 0.014028056112224447, 0.01503006012024048, 0.01603206412825651, 0.017034068136272545, 0.018036072144288574, 0.019038076152304607, 0.02004008016032064, 0.02104208416833667, 0.022044088176352703, 0.023046092184368736, 0.024048096192384766, 0.0250501002004008, 0.026052104208416832, 0.027054108216432865, 0.028056112224448895, 0.029058116232464928, 0.03006012024048096, 0.03106212424849699, 0.03206412825651302, 0.033066132264529056, 0.03406813627254509, 0.03507014028056112, 0.03607214428857715, 0.03707414829659318, 0.038076152304609215, 0.03907815631262525, 0.04008016032064128, 0.041082164328657314, 0.04208416833667334, 0.04308617234468937, 0.044088176352705406, 0.04509018036072144, 0.04609218436873747, 0.047094188376753505, 0.04809619238476953, 0.049098196392785565, 0.0501002004008016, 0.05110220440881763, 0.052104208416833664, 0.0531062124248497, 0.05410821643286573, 0.055110220440881756, 0.05611222444889779, 0.05711422845691382, 0.058116232464929855, 0.05911823647294589, 0.06012024048096192, 0.06112224448897795, 0.06212424849699398, 0.06312625250501001, 0.06412825651302605, 0.06513026052104208, 0.06613226452905811, 0.06713426853707415, 0.06813627254509018, 0.06913827655310621, 0.07014028056112225, 0.07114228456913826, 0.0721442885771543, 0.07314629258517033, 0.07414829659318636, 0.0751503006012024, 0.07615230460921843, 0.07715430861723446, 0.0781563126252505, 0.07915831663326653, 0.08016032064128256, 0.0811623246492986, 0.08216432865731463, 0.08316633266533066, 0.08416833667334668, 0.08517034068136271, 0.08617234468937875, 0.08717434869739478, 0.08817635270541081, 0.08917835671342685, 0.09018036072144288, 0.09118236472945891, 0.09218436873747494, 0.09318637274549098, 0.09418837675350701, 0.09519038076152304, 0.09619238476953906, 0.0971943887775551, 0.09819639278557113, 0.09919839679358716, 0.1002004008016032, 0.10120240480961923, 0.10220440881763526, 0.1032064128256513, 0.10420841683366733, 0.10521042084168336, 0.1062124248496994, 0.10721442885771543, 0.10821643286573146, 0.10921843687374748, 0.11022044088176351, 0.11122244488977955, 0.11222444889779558, 0.11322645290581161, 0.11422845691382764, 0.11523046092184368, 0.11623246492985971, 0.11723446893787574, 0.11823647294589178, 0.11923847695390781, 0.12024048096192384, 0.12124248496993988, 0.1222444889779559, 0.12324649298597193, 0.12424849699398796, 0.125250501002004, 0.12625250501002003, 0.12725450901803606, 0.1282565130260521, 0.12925851703406813, 0.13026052104208416, 0.1312625250501002, 0.13226452905811623, 0.13326653306613226, 0.1342685370741483, 0.13527054108216433, 0.13627254509018036, 0.1372745490981964, 0.13827655310621242, 0.13927855711422846, 0.1402805611222445, 0.1412825651302605, 0.14228456913827653, 0.14328657314629256, 0.1442885771543086, 0.14529058116232463, 0.14629258517034066, 0.1472945891783567, 0.14829659318637273, 0.14929859719438876, 0.1503006012024048, 0.15130260521042083, 0.15230460921843686, 0.1533066132264529, 0.15430861723446893, 0.15531062124248496, 0.156312625250501, 0.15731462925851702, 0.15831663326653306, 0.1593186372745491, 0.16032064128256512, 0.16132264529058116, 0.1623246492985972, 0.16332665330661322, 0.16432865731462926, 0.1653306613226453, 0.16633266533066132, 0.16733466933867733, 0.16833667334669336, 0.1693386773547094, 0.17034068136272543, 0.17134268537074146, 0.1723446893787575, 0.17334669338677353, 0.17434869739478956, 0.1753507014028056, 0.17635270541082163, 0.17735470941883766, 0.1783567134268537, 0.17935871743486972, 0.18036072144288576, 0.1813627254509018, 0.18236472945891782, 0.18336673346693386, 0.1843687374749499, 0.18537074148296592, 0.18637274549098196, 0.187374749498998, 0.18837675350701402, 0.18937875751503006, 0.1903807615230461, 0.19138276553106212, 0.19238476953907813, 0.19338677354709416, 0.1943887775551102, 0.19539078156312623, 0.19639278557114226, 0.1973947895791583, 0.19839679358717432, 0.19939879759519036, 0.2004008016032064, 0.20140280561122242, 0.20240480961923846, 0.2034068136272545, 0.20440881763527052, 0.20541082164328656, 0.2064128256513026, 0.20741482965931862, 0.20841683366733466, 0.2094188376753507, 0.21042084168336672, 0.21142284569138275, 0.2124248496993988, 0.21342685370741482, 0.21442885771543085, 0.2154308617234469, 0.21643286573146292, 0.21743486973947895, 0.21843687374749496, 0.219438877755511, 0.22044088176352702, 0.22144288577154306, 0.2224448897795591, 0.22344689378757512, 0.22444889779559116, 0.2254509018036072, 0.22645290581162322, 0.22745490981963926, 0.2284569138276553, 0.22945891783567132, 0.23046092184368736, 0.2314629258517034, 0.23246492985971942, 0.23346693386773545, 0.2344689378757515, 0.23547094188376752, 0.23647294589178355, 0.2374749498997996, 0.23847695390781562, 0.23947895791583165, 0.24048096192384769, 0.24148296593186372, 0.24248496993987975, 0.24348697394789579, 0.2444889779559118, 0.24549098196392782, 0.24649298597194386, 0.2474949899799599, 0.24849699398797592, 0.24949899799599196, 0.250501002004008, 0.251503006012024, 0.25250501002004005, 0.2535070140280561, 0.2545090180360721, 0.25551102204408815, 0.2565130260521042, 0.2575150300601202, 0.25851703406813625, 0.2595190380761523, 0.2605210420841683, 0.26152304609218435, 0.2625250501002004, 0.2635270541082164, 0.26452905811623245, 0.2655310621242485, 0.2665330661322645, 0.26753507014028055, 0.2685370741482966, 0.2695390781563126, 0.27054108216432865, 0.2715430861723447, 0.2725450901803607, 0.27354709418837675, 0.2745490981963928, 0.2755511022044088, 0.27655310621242485, 0.2775551102204409, 0.2785571142284569, 0.27955911823647295, 0.280561122244489, 0.281563126252505, 0.282565130260521, 0.283567134268537, 0.28456913827655306, 0.2855711422845691, 0.2865731462925851, 0.28757515030060116, 0.2885771543086172, 0.2895791583166332, 0.29058116232464926, 0.2915831663326653, 0.2925851703406813, 0.29358717434869736, 0.2945891783567134, 0.2955911823647294, 0.29659318637274545, 0.2975951903807615, 0.2985971943887775, 0.29959919839679355, 0.3006012024048096, 0.3016032064128256, 0.30260521042084165, 0.3036072144288577, 0.3046092184368737, 0.30561122244488975, 0.3066132264529058, 0.3076152304609218, 0.30861723446893785, 0.3096192384769539, 0.3106212424849699, 0.31162324649298595, 0.312625250501002, 0.313627254509018, 0.31462925851703405, 0.3156312625250501, 0.3166332665330661, 0.31763527054108215, 0.3186372745490982, 0.3196392785571142, 0.32064128256513025, 0.3216432865731463, 0.3226452905811623, 0.32364729458917835, 0.3246492985971944, 0.3256513026052104, 0.32665330661322645, 0.3276553106212425, 0.3286573146292585, 0.32965931863727455, 0.3306613226452906, 0.3316633266533066, 0.33266533066132264, 0.3336673346693386, 0.33466933867735466, 0.3356713426853707, 0.3366733466933867, 0.33767535070140275, 0.3386773547094188, 0.3396793587174348, 0.34068136272545085, 0.3416833667334669, 0.3426853707414829, 0.34368737474949895, 0.344689378757515, 0.345691382765531, 0.34669338677354705, 0.3476953907815631, 0.3486973947895791, 0.34969939879759515, 0.3507014028056112, 0.3517034068136272, 0.35270541082164325, 0.3537074148296593, 0.3547094188376753, 0.35571142284569135, 0.3567134268537074, 0.3577154308617234, 0.35871743486973945, 0.3597194388777555, 0.3607214428857715, 0.36172344689378755, 0.3627254509018036, 0.3637274549098196, 0.36472945891783565, 0.3657314629258517, 0.3667334669338677, 0.36773547094188375, 0.3687374749498998, 0.3697394789579158, 0.37074148296593185, 0.3717434869739479, 0.3727454909819639, 0.37374749498997994, 0.374749498997996, 0.375751503006012, 0.37675350701402804, 0.3777555110220441, 0.3787575150300601, 0.37975951903807614, 0.3807615230460922, 0.3817635270541082, 0.38276553106212424, 0.3837675350701403, 0.38476953907815625, 0.3857715430861723, 0.3867735470941883, 0.38777555110220435, 0.3887775551102204, 0.3897795591182364, 0.39078156312625245, 0.3917835671342685, 0.3927855711422845, 0.39378757515030055, 0.3947895791583166, 0.3957915831663326, 0.39679358717434865, 0.3977955911823647, 0.3987975951903807, 0.39979959919839675, 0.4008016032064128, 0.4018036072144288, 0.40280561122244485, 0.4038076152304609, 0.4048096192384769, 0.40581162324649295, 0.406813627254509, 0.407815631262525, 0.40881763527054105, 0.4098196392785571, 0.4108216432865731, 0.41182364729458915, 0.4128256513026052, 0.4138276553106212, 0.41482965931863724, 0.4158316633266533, 0.4168336673346693, 0.41783567134268534, 0.4188376753507014, 0.4198396793587174, 0.42084168336673344, 0.4218436873747495, 0.4228456913827655, 0.42384769539078154, 0.4248496993987976, 0.4258517034068136, 0.42685370741482964, 0.4278557114228457, 0.4288577154308617, 0.42985971943887774, 0.4308617234468938, 0.4318637274549098, 0.43286573146292584, 0.4338677354709419, 0.4348697394789579, 0.43587174348697394, 0.4368737474949899, 0.43787575150300595, 0.438877755511022, 0.439879759519038, 0.44088176352705405, 0.4418837675350701, 0.4428857715430861, 0.44388777555110215, 0.4448897795591182, 0.4458917835671342, 0.44689378757515025, 0.4478957915831663, 0.4488977955911823, 0.44989979959919835, 0.4509018036072144, 0.4519038076152304, 0.45290581162324645, 0.4539078156312625, 0.4549098196392785, 0.45591182364729455, 0.4569138276553106, 0.4579158316633266, 0.45891783567134264, 0.4599198396793587, 0.4609218436873747, 0.46192384769539074, 0.4629258517034068, 0.4639278557114228, 0.46492985971943884, 0.4659318637274549, 0.4669338677354709, 0.46793587174348694, 0.468937875751503, 0.469939879759519, 0.47094188376753504, 0.4719438877755511, 0.4729458917835671, 0.47394789579158314, 0.4749498997995992, 0.4759519038076152, 0.47695390781563124, 0.4779559118236473, 0.4789579158316633, 0.47995991983967934, 0.48096192384769537, 0.4819639278557114, 0.48296593186372744, 0.48396793587174347, 0.4849699398797595, 0.48597194388777554, 0.48697394789579157, 0.48797595190380755, 0.4889779559118236, 0.4899799599198396, 0.49098196392785565, 0.4919839679358717, 0.4929859719438877, 0.49398797595190375, 0.4949899799599198, 0.4959919839679358, 0.49699398797595185, 0.4979959919839679, 0.4989979959919839, 0.5], 'l1_ratio': [0.0, 0.005050505050505051, 0.010101010101010102, 0.015151515151515152, 0.020202020202020204, 0.025252525252525256, 0.030303030303030304, 0.03535353535353536, 0.04040404040404041, 0.045454545454545456, 0.05050505050505051, 0.05555555555555556, 0.06060606060606061, 0.06565656565656566, 0.07070707070707072, 0.07575757575757576, 0.08080808080808081, 0.08585858585858587, 0.09090909090909091, 0.09595959595959597, 0.10101010101010102, 0.10606060606060606, 0.11111111111111112, 0.11616161616161617, 0.12121212121212122, 0.12626262626262627, 0.13131313131313133, 0.13636363636363638, 0.14141414141414144, 0.14646464646464646, 0.15151515151515152, 0.15656565656565657, 0.16161616161616163, 0.16666666666666669, 0.17171717171717174, 0.1767676767676768, 0.18181818181818182, 0.18686868686868688, 0.19191919191919193, 0.196969696969697, 0.20202020202020204, 0.2070707070707071, 0.21212121212121213, 0.21717171717171718, 0.22222222222222224, 0.2272727272727273, 0.23232323232323235, 0.2373737373737374, 0.24242424242424243, 0.2474747474747475, 0.25252525252525254, 0.2575757575757576, 0.26262626262626265, 0.2676767676767677, 0.27272727272727276, 0.2777777777777778, 0.2828282828282829, 0.2878787878787879, 0.29292929292929293, 0.297979797979798, 0.30303030303030304, 0.3080808080808081, 0.31313131313131315, 0.31818181818181823, 0.32323232323232326, 0.3282828282828283, 0.33333333333333337, 0.3383838383838384, 0.3434343434343435, 0.3484848484848485, 0.3535353535353536, 0.3585858585858586, 0.36363636363636365, 0.36868686868686873, 0.37373737373737376, 0.37878787878787884, 0.38383838383838387, 0.3888888888888889, 0.393939393939394, 0.398989898989899, 0.4040404040404041, 0.4090909090909091, 0.4141414141414142, 0.4191919191919192, 0.42424242424242425, 0.42929292929292934, 0.43434343434343436, 0.43939393939393945, 0.4444444444444445, 0.44949494949494956, 0.4545454545454546, 0.4595959595959596, 0.4646464646464647, 0.4696969696969697, 0.4747474747474748, 0.47979797979797983, 0.48484848484848486, 0.48989898989898994, 0.494949494949495, 0.5], 'max_iter': [2000, 2040, 2080, 2120, 2160, 2201, 2241, 2281, 2321, 2361, 2402, 2442, 2482, 2522, 2562, 2603, 2643, 2683, 2723, 2763, 2804, 2844, 2884, 2924, 2964, 3005, 3045, 3085, 3125, 3165, 3206, 3246, 3286, 3326, 3366, 3407, 3447, 3487, 3527, 3567, 3608, 3648, 3688, 3728, 3768, 3809, 3849, 3889, 3929, 3969, 4010, 4050, 4090, 4130, 4170, 4211, 4251, 4291, 4331, 4371, 4412, 4452, 4492, 4532, 4572, 4613, 4653, 4693, 4733, 4773, 4814, 4854, 4894, 4934, 4974, 5015, 5055, 5095, 5135, 5175, 5216, 5256, 5296, 5336, 5376, 5417, 5457, 5497, 5537, 5577, 5618, 5658, 5698, 5738, 5778, 5819, 5859, 5899, 5939, 5979, 6020, 6060, 6100, 6140, 6180, 6221, 6261, 6301, 6341, 6381, 6422, 6462, 6502, 6542, 6582, 6623, 6663, 6703, 6743, 6783, 6824, 6864, 6904, 6944, 6984, 7025, 7065, 7105, 7145, 7185, 7226, 7266, 7306, 7346, 7386, 7427, 7467, 7507, 7547, 7587, 7628, 7668, 7708, 7748, 7788, 7829, 7869, 7909, 7949, 7989, 8030, 8070, 8110, 8150, 8190, 8231, 8271, 8311, 8351, 8391, 8432, 8472, 8512, 8552, 8592, 8633, 8673, 8713, 8753, 8793, 8834, 8874, 8914, 8954, 8994, 9035, 9075, 9115, 9155, 9195, 9236, 9276, 9316, 9356, 9396, 9437, 9477, 9517, 9557, 9597, 9638, 9678, 9718, 9758, 9798, 9839, 9879, 9919, 9959, 10000], 'tol': [0.01, 0.009954773869346734, 0.009909547738693467, 0.0098643216080402, 0.009819095477386935, 0.009773869346733669, 0.009728643216080402, 0.009683417085427136, 0.009638190954773869, 0.009592964824120602, 0.009547738693467337, 0.00950251256281407, 0.009457286432160804, 0.009412060301507538, 0.009366834170854271, 0.009321608040201004, 0.00927638190954774, 0.009231155778894473, 0.009185929648241206, 0.00914070351758794, 0.009095477386934673, 0.009050251256281406, 0.009005025125628141, 0.008959798994974875, 0.008914572864321608, 0.008869346733668342, 0.008824120603015075, 0.008778894472361808, 0.008733668341708543, 0.008688442211055277, 0.00864321608040201, 0.008597989949748744, 0.008552763819095477, 0.00850753768844221, 0.008462311557788945, 0.008417085427135679, 0.008371859296482412, 0.008326633165829146, 0.008281407035175879, 0.008236180904522612, 0.008190954773869347, 0.00814572864321608, 0.008100502512562814, 0.008055276381909547, 0.008010050251256281, 0.007964824120603016, 0.007919597989949748, 0.007874371859296483, 0.007829145728643216, 0.0077839195979899495, 0.007738693467336683, 0.007693467336683416, 0.0076482412060301505, 0.007603015075376885, 0.007557788944723618, 0.0075125628140703515, 0.007467336683417085, 0.007422110552763818, 0.0073768844221105525, 0.007331658291457287, 0.00728643216080402, 0.0072412060301507535, 0.007195979899497487, 0.00715075376884422, 0.0071055276381909544, 0.007060301507537689, 0.007015075376884422, 0.0069698492462311554, 0.006924623115577889, 0.006879396984924622, 0.006834170854271356, 0.006788944723618091, 0.006743718592964824, 0.006698492462311557, 0.006653266331658291, 0.006608040201005024, 0.006562814070351758, 0.006517587939698493, 0.006472361809045226, 0.006427135678391959, 0.006381909547738693, 0.006336683417085426, 0.00629145728643216, 0.006246231155778894, 0.006201005025125628, 0.006155778894472361, 0.006110552763819095, 0.006065326633165829, 0.006020100502512562, 0.005974874371859296, 0.00592964824120603, 0.005884422110552763, 0.005839195979899497, 0.005793969849246231, 0.005748743718592964, 0.005703517587939698, 0.005658291457286432, 0.005613065326633165, 0.005567839195979899, 0.005522613065326632, 0.005477386934673366, 0.0054321608040201, 0.005386934673366833, 0.005341708542713567, 0.005296482412060301, 0.005251256281407034, 0.005206030150753768, 0.005160804020100502, 0.005115577889447235, 0.005070351758793969, 0.005025125628140703, 0.004979899497487436, 0.00493467336683417, 0.004889447236180904, 0.004844221105527637, 0.004798994974874371, 0.004753768844221105, 0.004708542713567838, 0.004663316582914572, 0.004618090452261306, 0.004572864321608039, 0.004527638190954773, 0.004482412060301507, 0.00443718592964824, 0.004391959798994974, 0.004346733668341708, 0.004301507537688441, 0.004256281407035175, 0.004211055276381909, 0.004165829145728642, 0.004120603015075376, 0.00407537688442211, 0.004030150753768843, 0.003984924623115577, 0.003939698492462311, 0.003894472361809044, 0.0038492462311557783, 0.0038040201005025117, 0.003758793969849245, 0.0037135678391959793, 0.0036683417085427127, 0.003623115577889446, 0.0035778894472361803, 0.0035326633165829137, 0.003487437185929647, 0.0034422110552763813, 0.0033969849246231146, 0.003351758793969848, 0.0033065326633165823, 0.0032613065326633156, 0.003216080402010049, 0.0031708542713567833, 0.0031256281407035166, 0.00308040201005025, 0.0030351758793969843, 0.0029899497487437176, 0.002944723618090451, 0.0028994974874371852, 0.0028542713567839186, 0.002809045226130652, 0.0027638190954773854, 0.0027185929648241196, 0.002673366834170853, 0.0026281407035175864, 0.0025829145728643206, 0.002537688442211054, 0.0024924623115577874, 0.0024472361809045216, 0.002402010050251255, 0.0023567839195979884, 0.0023115577889447226, 0.002266331658291456, 0.0022211055276381893, 0.0021758793969849227, 0.002130653266331658, 0.002085427135678391, 0.0020402010050251246, 0.001994974874371858, 0.0019497487437185913, 0.0019045226130653247, 0.0018592964824120598, 0.0018140703517587932, 0.0017688442211055266, 0.00172361809045226, 0.0016783919597989933, 0.0016331658291457267, 0.0015879396984924618, 0.0015427135678391952, 0.0014974874371859286, 0.001452261306532662, 0.0014070351758793953, 0.0013618090452261287, 0.0013165829145728638, 0.0012713567839195972, 0.0012261306532663305, 0.001180904522613064, 0.0011356783919597973, 0.0010904522613065307, 0.001045226130653264, 0.001], 'warm_start': ['True', 'False'], 'selection': ['cyclic', 'random']}\n"
     ]
    }
   ],
   "source": [
    "alpha = [float(x) for x in np.linspace(0, 0.50,500)]\n",
    "positive=['True','False']\n",
    "l1_ratio=[float(x) for x in np.linspace(0, 0.5,100)]\n",
    "max_iter=[int(x) for x in np.linspace(2000, 10000,200)]\n",
    "tol=[float(x) for x in np.linspace(0.01, 0.001,200)]\n",
    "warm_start = ['True','False']\n",
    "selection=['cyclic','random']\n",
    "copy_X=['True','False']\n",
    "\n",
    "random_grid = {'copy_X':copy_X,\n",
    "               'alpha':alpha,\n",
    "               'l1_ratio': l1_ratio,\n",
    "               'max_iter':max_iter,\n",
    "               'tol':tol,\n",
    "                'warm_start':warm_start,\n",
    "                'selection':selection\n",
    "               \n",
    "               \n",
    "                }\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "95622f55-f4ca-4104-9feb-585f93bbbbcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV 2/5] END copy_X=True, fit_intercept=True, positive=False;, score=0.559 total time=   0.1s\n",
      "[CV 3/5] END copy_X=True, fit_intercept=True, positive=True;, score=-1491335583445575312343040.000 total time=   0.1s\n",
      "[CV 4/5] END copy_X=True, fit_intercept=False, positive=False;, score=0.722 total time=   0.1s\n",
      "[CV 5/5] END copy_X=True, fit_intercept=False, positive=True;, score=0.772 total time=   0.1s\n",
      "[CV 1/5] END copy_X=False, fit_intercept=True, positive=True;, score=0.686 total time=   0.1s\n",
      "[CV 2/5] END copy_X=False, fit_intercept=False, positive=False;, score=0.559 total time=   0.1s\n",
      "[CV 3/5] END copy_X=False, fit_intercept=False, positive=True;, score=-1491335583445575312343040.000 total time=   0.1s\n",
      "[CV 4/5] END copy_X=True, fit_intercept=True, positive=False;, score=0.722 total time=   0.1s\n",
      "[CV 5/5] END criterion=poisson, max_depth=1000, max_features=sqrt, min_samples_leaf=8, min_samples_split=3, n_estimators=1000;, score=0.841 total time=   1.9s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=120, max_features=sqrt, min_samples_leaf=8, min_samples_split=4, n_estimators=200;, score=0.830 total time=   0.3s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=120, max_features=sqrt, min_samples_leaf=8, min_samples_split=4, n_estimators=200;, score=0.747 total time=   0.3s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=120, max_features=sqrt, min_samples_leaf=8, min_samples_split=4, n_estimators=200;, score=0.784 total time=   0.3s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=890, max_features=log2, min_samples_leaf=8, min_samples_split=14, n_estimators=200;, score=0.777 total time=   0.3s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=890, max_features=log2, min_samples_leaf=8, min_samples_split=14, n_estimators=200;, score=0.701 total time=   0.3s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=890, max_features=log2, min_samples_leaf=8, min_samples_split=14, n_estimators=200;, score=0.791 total time=   0.3s\n",
      "[CV 2/5] END criterion=poisson, max_depth=560, max_features=log2, min_samples_leaf=8, min_samples_split=5, n_estimators=1200;, score=0.694 total time=   1.7s\n",
      "[CV 3/5] END criterion=absolute_error, max_depth=1000, max_features=log2, min_samples_leaf=8, min_samples_split=4, n_estimators=1000;, score=0.666 total time=   5.9s\n",
      "[CV 4/5] END criterion=absolute_error, max_depth=890, max_features=log2, min_samples_leaf=6, min_samples_split=2, n_estimators=1000;, score=0.720 total time=   6.5s\n",
      "[CV 5/5] END criterion=absolute_error, max_depth=10, max_features=sqrt, min_samples_leaf=8, min_samples_split=4, n_estimators=1200;, score=0.823 total time=  10.8s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=890, max_features=sqrt, min_samples_leaf=1, min_samples_split=14, n_estimators=200;, score=0.813 total time=   0.4s\n",
      "[CV] END algorithm=brute, leaf_size=15, n_neighbors=124, p=2, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, leaf_size=18, n_neighbors=5, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=11, n_neighbors=110, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=kd_tree, leaf_size=15, n_neighbors=335, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, leaf_size=13, n_neighbors=335, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, leaf_size=13, n_neighbors=335, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, leaf_size=18, n_neighbors=237, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=brute, leaf_size=6, n_neighbors=117, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=brute, leaf_size=6, n_neighbors=117, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END ccp_alpha=1, criterion=absolute_error, max_depth=320, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=squared_error, max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END ccp_alpha=0, criterion=friedman_mse, max_depth=410, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END ccp_alpha=0, criterion=squared_error, max_depth=580, max_features=sqrt, min_samples_leaf=6, min_samples_split=14, splitter=best; total time=   0.0s\n",
      "[CV] END ccp_alpha=0, criterion=squared_error, max_depth=580, max_features=sqrt, min_samples_leaf=6, min_samples_split=14, splitter=best; total time=   0.0s\n",
      "[CV] END ccp_alpha=0, criterion=friedman_mse, max_depth=870, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END ccp_alpha=0, criterion=friedman_mse, max_depth=870, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END ccp_alpha=0, criterion=poisson, max_depth=300, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=poisson, max_depth=680, max_features=log2, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END ccp_alpha=0, criterion=absolute_error, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=14, splitter=random; total time=   0.0s\n",
      "[CV] END ccp_alpha=0, criterion=poisson, max_depth=300, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END alpha=0.0005510204081632653, eta0=0.05555555555555556, l1_ratio=0.09183673469387754, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=14303, n_iter_no_change=8, penalty=l1, tol=0.004636363636363636, validation_fraction=0.7040816326530612; total time=  21.2s\n",
      "[CV] END alpha=0.0009183673469387755, eta0=0.05555555555555556, l1_ratio=0.08163265306122448, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=13333, n_iter_no_change=2, penalty=l2, tol=0.007727272727272727, validation_fraction=0.3938775510204082; total time=   0.0s\n",
      "[CV] END alpha=0.0009183673469387755, eta0=0.05555555555555556, l1_ratio=0.08163265306122448, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=13333, n_iter_no_change=2, penalty=l2, tol=0.007727272727272727, validation_fraction=0.3938775510204082; total time=   0.1s\n",
      "[CV] END alpha=0.0009183673469387755, eta0=0.05555555555555556, l1_ratio=0.08163265306122448, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=13333, n_iter_no_change=2, penalty=l2, tol=0.007727272727272727, validation_fraction=0.3938775510204082; total time=   0.1s\n",
      "[CV] END alpha=0.00042857142857142855, eta0=0.05, l1_ratio=0.02040816326530612, learning_rate=constant, loss=squared_error, max_iter=16000, n_iter_no_change=6, penalty=elasticnet, tol=0.005727272727272727, validation_fraction=0.5408163265306123; total time=   0.0s\n",
      "[CV] END alpha=0.00042857142857142855, eta0=0.05, l1_ratio=0.02040816326530612, learning_rate=constant, loss=squared_error, max_iter=16000, n_iter_no_change=6, penalty=elasticnet, tol=0.005727272727272727, validation_fraction=0.5408163265306123; total time=   0.0s\n",
      "[CV] END alpha=0.00042857142857142855, eta0=0.05, l1_ratio=0.02040816326530612, learning_rate=constant, loss=squared_error, max_iter=16000, n_iter_no_change=6, penalty=elasticnet, tol=0.005727272727272727, validation_fraction=0.5408163265306123; total time=   0.0s\n",
      "[CV] END alpha=2.0408163265306123e-05, eta0=0.060606060606060615, l1_ratio=0.36734693877551017, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=16727, n_iter_no_change=6, penalty=l1, tol=0.0028181818181818178, validation_fraction=0.1; total time=  24.9s\n",
      "[CV] END alpha=4.0816326530612245e-05, eta0=0.05202020202020203, l1_ratio=0.08163265306122448, learning_rate=invscaling, loss=huber, max_iter=19030, n_iter_no_change=6, penalty=elasticnet, tol=0.006909090909090909, validation_fraction=0.6714285714285715; total time=  27.4s\n",
      "[CV] END alpha=0.0009183673469387755, eta0=0.05555555555555556, l1_ratio=0.08163265306122448, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=13333, n_iter_no_change=2, penalty=l2, tol=0.007727272727272727, validation_fraction=0.3938775510204082; total time=   0.1s\n",
      "[CV 1/5] END copy_X=True, fit_intercept=True, positive=False;, score=0.686 total time=   0.1s\n",
      "[CV 2/5] END copy_X=True, fit_intercept=True, positive=True;, score=0.559 total time=   0.1s\n",
      "[CV 3/5] END copy_X=True, fit_intercept=False, positive=False;, score=-1491335583445575312343040.000 total time=   0.1s\n",
      "[CV 4/5] END copy_X=True, fit_intercept=False, positive=True;, score=0.722 total time=   0.1s\n",
      "[CV 5/5] END copy_X=False, fit_intercept=True, positive=False;, score=0.772 total time=   0.1s\n",
      "[CV 1/5] END copy_X=False, fit_intercept=False, positive=False;, score=0.686 total time=   0.1s\n",
      "[CV 1/5] END copy_X=False, fit_intercept=False, positive=True;, score=0.686 total time=   0.1s\n",
      "[CV 3/5] END copy_X=True, fit_intercept=True, positive=False;, score=-1491335583445575312343040.000 total time=   0.2s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=670, max_features=sqrt, min_samples_leaf=6, min_samples_split=3, n_estimators=1200;, score=0.843 total time=   2.3s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=120, max_features=sqrt, min_samples_leaf=8, min_samples_split=4, n_estimators=200;, score=0.764 total time=   0.3s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=120, max_features=sqrt, min_samples_leaf=8, min_samples_split=4, n_estimators=200;, score=0.833 total time=   0.3s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=890, max_features=log2, min_samples_leaf=8, min_samples_split=14, n_estimators=200;, score=0.692 total time=   0.3s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=890, max_features=log2, min_samples_leaf=8, min_samples_split=14, n_estimators=200;, score=0.734 total time=   0.3s\n",
      "[CV 1/5] END criterion=poisson, max_depth=560, max_features=log2, min_samples_leaf=8, min_samples_split=5, n_estimators=1200;, score=0.772 total time=   1.8s\n",
      "[CV 2/5] END criterion=absolute_error, max_depth=1000, max_features=log2, min_samples_leaf=8, min_samples_split=4, n_estimators=1000;, score=0.675 total time=   5.8s\n",
      "[CV 3/5] END criterion=absolute_error, max_depth=890, max_features=log2, min_samples_leaf=6, min_samples_split=2, n_estimators=1000;, score=0.689 total time=   6.2s\n",
      "[CV 3/5] END criterion=absolute_error, max_depth=10, max_features=sqrt, min_samples_leaf=8, min_samples_split=4, n_estimators=1200;, score=0.739 total time=  10.7s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=890, max_features=sqrt, min_samples_leaf=1, min_samples_split=14, n_estimators=200;, score=0.810 total time=   0.4s\n",
      "[CV] END algorithm=brute, leaf_size=15, n_neighbors=124, p=2, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=auto, leaf_size=11, n_neighbors=110, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=kd_tree, leaf_size=15, n_neighbors=47, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, leaf_size=15, n_neighbors=47, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, leaf_size=18, n_neighbors=307, p=1, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, leaf_size=13, n_neighbors=166, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, leaf_size=6, n_neighbors=117, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=brute, leaf_size=18, n_neighbors=5, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=absolute_error, max_depth=320, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=squared_error, max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END ccp_alpha=0, criterion=friedman_mse, max_depth=410, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END ccp_alpha=0, criterion=squared_error, max_depth=580, max_features=sqrt, min_samples_leaf=6, min_samples_split=14, splitter=best; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=squared_error, max_depth=530, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END ccp_alpha=0, criterion=friedman_mse, max_depth=870, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END ccp_alpha=0, criterion=poisson, max_depth=300, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=poisson, max_depth=680, max_features=log2, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END ccp_alpha=0, criterion=absolute_error, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=14, splitter=random; total time=   0.0s\n",
      "[CV] END ccp_alpha=0, criterion=poisson, max_depth=300, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END alpha=6.122448979591836e-05, eta0=0.08535353535353536, l1_ratio=0.4387755102040816, learning_rate=constant, loss=huber, max_iter=19878, n_iter_no_change=1, penalty=l2, tol=0.008272727272727272, validation_fraction=0.49183673469387756; total time=   5.1s\n",
      "[CV] END alpha=6.122448979591836e-05, eta0=0.08535353535353536, l1_ratio=0.4387755102040816, learning_rate=constant, loss=huber, max_iter=19878, n_iter_no_change=1, penalty=l2, tol=0.008272727272727272, validation_fraction=0.49183673469387756; total time=   5.9s\n",
      "[CV] END alpha=6.122448979591836e-05, eta0=0.08535353535353536, l1_ratio=0.4387755102040816, learning_rate=constant, loss=huber, max_iter=19878, n_iter_no_change=1, penalty=l2, tol=0.008272727272727272, validation_fraction=0.49183673469387756; total time=   5.1s\n",
      "[CV] END alpha=6.122448979591836e-05, eta0=0.08535353535353536, l1_ratio=0.4387755102040816, learning_rate=constant, loss=huber, max_iter=19878, n_iter_no_change=1, penalty=l2, tol=0.008272727272727272, validation_fraction=0.49183673469387756; total time=   5.1s\n",
      "[CV] END alpha=0.0009183673469387755, eta0=0.05555555555555556, l1_ratio=0.08163265306122448, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=13333, n_iter_no_change=2, penalty=l2, tol=0.007727272727272727, validation_fraction=0.3938775510204082; total time=   0.1s\n",
      "[CV] END alpha=0.0009183673469387755, eta0=0.05555555555555556, l1_ratio=0.08163265306122448, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=13333, n_iter_no_change=2, penalty=l2, tol=0.007727272727272727, validation_fraction=0.3938775510204082; total time=   0.1s\n",
      "[CV] END alpha=0.00042857142857142855, eta0=0.05, l1_ratio=0.02040816326530612, learning_rate=constant, loss=squared_error, max_iter=16000, n_iter_no_change=6, penalty=elasticnet, tol=0.005727272727272727, validation_fraction=0.5408163265306123; total time=   0.0s\n",
      "[CV] END alpha=0.00042857142857142855, eta0=0.05, l1_ratio=0.02040816326530612, learning_rate=constant, loss=squared_error, max_iter=16000, n_iter_no_change=6, penalty=elasticnet, tol=0.005727272727272727, validation_fraction=0.5408163265306123; total time=   0.0s\n",
      "[CV] END alpha=2.0408163265306123e-05, eta0=0.060606060606060615, l1_ratio=0.36734693877551017, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=16727, n_iter_no_change=6, penalty=l1, tol=0.0028181818181818178, validation_fraction=0.1; total time=  23.7s\n",
      "[CV] END alpha=4.0816326530612245e-05, eta0=0.05202020202020203, l1_ratio=0.08163265306122448, learning_rate=invscaling, loss=huber, max_iter=19030, n_iter_no_change=6, penalty=elasticnet, tol=0.006909090909090909, validation_fraction=0.6714285714285715; total time=  26.9s\n",
      "[CV] END alpha=0.0005306122448979592, eta0=0.06767676767676768, l1_ratio=0.39795918367346933, learning_rate=adaptive, loss=huber, max_iter=19272, n_iter_no_change=6, penalty=l2, tol=0.0015454545454545443, validation_fraction=0.4755102040816327; total time=  13.1s\n",
      "[CV] END alpha=0.375751503006012, copy_X=True, l1_ratio=0.3484848484848485, max_iter=3005, selection=random, tol=0.004165829145728642, warm_start=False; total time=   0.0s\n",
      "[CV] END alpha=0.024048096192384766, copy_X=False, l1_ratio=0.12121212121212122, max_iter=2321, selection=cyclic, tol=0.009683417085427136, warm_start=True; total time=   0.1s\n",
      "ElasticNet() RandomCV Best Params : {'warm_start': 'True', 'tol': 0.009683417085427136, 'selection': 'cyclic', 'max_iter': 2321, 'l1_ratio': 0.12121212121212122, 'copy_X': 'False', 'alpha': 0.024048096192384766}\n",
      "ElasticNet() RandomCV Score: 0.8061969923154417\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Final score is  0.8061969923154417\n"
     ]
    }
   ],
   "source": [
    "hyperparameter_tuning(algo=\"ElasticNet()\",param_grid=random_grid,n_iter=10,cv=5,verbose=2,random_state=42,X_train=X_train,Y_train=Y_train,X_test=X_test,Y_test=Y_test,evaluation_metric=\"r2_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "0d745e93-d4ff-4131-96e4-86f431c9b58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# en=ElasticNet()\n",
    "# en_random_cv=RandomizedSearchCV(estimator=en,param_distributions=random_grid,n_iter=100,cv=5,verbose=0,random_state=100,n_jobs=-1)\n",
    "# en_random_cv.fit(X_train,Y_train)\n",
    "\n",
    "# best_params_=en_random_cv.best_params_\n",
    "# print(\"RandomCV Best Params :\",best_params_)\n",
    "# best_random_grid=en_random_cv.best_estimator_\n",
    "# y_pred7=best_random_grid.predict(X_test)\n",
    "# score_7=r2_score(Y_test,y_pred7)\n",
    "# print(\"RandomCV Score: \",score_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "9edc15ed-8b5a-4dac-9ebb-41e2d31bfb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid7=defaultdict(list)\n",
    "# for val in best_params_:\n",
    "#     param_grid7[val].append(best_params_[val])\n",
    "# print(param_grid7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "f4c9b668-460a-42db-9ade-3fb9b0cd949e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=ElasticNet()\n",
    "# grid_search=GridSearchCV(estimator=model,param_grid=param_grid7,cv=5,n_jobs=-1,verbose=3)\n",
    "# grid_search.fit(X_train,Y_train)\n",
    "# print(grid_search.best_estimator_)\n",
    "# best_grid2=grid_search.best_estimator_\n",
    "# final7=best_grid2.predict(X_test)\n",
    "# score_final7=r2_score(Y_test,final7)\n",
    "# print(score_final7)\n",
    "# accuracies[\"ElasticNet\"]=score_final7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "002e93f2-e515-4e66-91de-4340e3539ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8 Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "31f642c6-7d05-4099-a0ab-f90ea6957573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha = [float(x) for x in np.linspace(0, 0.50,500)]\n",
    "# positive=['True','False']\n",
    "# l1_ratio=[float(x) for x in np.linspace(0, 0.5,100)]\n",
    "# max_iter=[int(x) for x in np.linspace(2000, 10000,200)]\n",
    "# tol=[float(x) for x in np.linspace(0.01, 0.001,200)]\n",
    "# warm_start = ['True','False']\n",
    "# selection=['cyclic','random']\n",
    "# copy_X=['True','False']\n",
    "\n",
    "# random_grid = {'copy_X':copy_X,\n",
    "#                'alpha':alpha,\n",
    "#                'l1_ratio': l1_ratio,\n",
    "#                'max_iter':max_iter,\n",
    "#                'tol':tol,\n",
    "#                 'warm_start':warm_start,\n",
    "#                 'selection':selection\n",
    "               \n",
    "               \n",
    "#                 }\n",
    "# print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "1790528e-99ec-46a5-97d3-4c4697ec1c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': [0.0, 0.001002004008016032, 0.002004008016032064, 0.0030060120240480957, 0.004008016032064128, 0.00501002004008016, 0.0060120240480961915, 0.007014028056112224, 0.008016032064128256, 0.009018036072144287, 0.01002004008016032, 0.011022044088176352, 0.012024048096192383, 0.013026052104208416, 0.014028056112224447, 0.01503006012024048, 0.01603206412825651, 0.017034068136272545, 0.018036072144288574, 0.019038076152304607, 0.02004008016032064, 0.02104208416833667, 0.022044088176352703, 0.023046092184368736, 0.024048096192384766, 0.0250501002004008, 0.026052104208416832, 0.027054108216432865, 0.028056112224448895, 0.029058116232464928, 0.03006012024048096, 0.03106212424849699, 0.03206412825651302, 0.033066132264529056, 0.03406813627254509, 0.03507014028056112, 0.03607214428857715, 0.03707414829659318, 0.038076152304609215, 0.03907815631262525, 0.04008016032064128, 0.041082164328657314, 0.04208416833667334, 0.04308617234468937, 0.044088176352705406, 0.04509018036072144, 0.04609218436873747, 0.047094188376753505, 0.04809619238476953, 0.049098196392785565, 0.0501002004008016, 0.05110220440881763, 0.052104208416833664, 0.0531062124248497, 0.05410821643286573, 0.055110220440881756, 0.05611222444889779, 0.05711422845691382, 0.058116232464929855, 0.05911823647294589, 0.06012024048096192, 0.06112224448897795, 0.06212424849699398, 0.06312625250501001, 0.06412825651302605, 0.06513026052104208, 0.06613226452905811, 0.06713426853707415, 0.06813627254509018, 0.06913827655310621, 0.07014028056112225, 0.07114228456913826, 0.0721442885771543, 0.07314629258517033, 0.07414829659318636, 0.0751503006012024, 0.07615230460921843, 0.07715430861723446, 0.0781563126252505, 0.07915831663326653, 0.08016032064128256, 0.0811623246492986, 0.08216432865731463, 0.08316633266533066, 0.08416833667334668, 0.08517034068136271, 0.08617234468937875, 0.08717434869739478, 0.08817635270541081, 0.08917835671342685, 0.09018036072144288, 0.09118236472945891, 0.09218436873747494, 0.09318637274549098, 0.09418837675350701, 0.09519038076152304, 0.09619238476953906, 0.0971943887775551, 0.09819639278557113, 0.09919839679358716, 0.1002004008016032, 0.10120240480961923, 0.10220440881763526, 0.1032064128256513, 0.10420841683366733, 0.10521042084168336, 0.1062124248496994, 0.10721442885771543, 0.10821643286573146, 0.10921843687374748, 0.11022044088176351, 0.11122244488977955, 0.11222444889779558, 0.11322645290581161, 0.11422845691382764, 0.11523046092184368, 0.11623246492985971, 0.11723446893787574, 0.11823647294589178, 0.11923847695390781, 0.12024048096192384, 0.12124248496993988, 0.1222444889779559, 0.12324649298597193, 0.12424849699398796, 0.125250501002004, 0.12625250501002003, 0.12725450901803606, 0.1282565130260521, 0.12925851703406813, 0.13026052104208416, 0.1312625250501002, 0.13226452905811623, 0.13326653306613226, 0.1342685370741483, 0.13527054108216433, 0.13627254509018036, 0.1372745490981964, 0.13827655310621242, 0.13927855711422846, 0.1402805611222445, 0.1412825651302605, 0.14228456913827653, 0.14328657314629256, 0.1442885771543086, 0.14529058116232463, 0.14629258517034066, 0.1472945891783567, 0.14829659318637273, 0.14929859719438876, 0.1503006012024048, 0.15130260521042083, 0.15230460921843686, 0.1533066132264529, 0.15430861723446893, 0.15531062124248496, 0.156312625250501, 0.15731462925851702, 0.15831663326653306, 0.1593186372745491, 0.16032064128256512, 0.16132264529058116, 0.1623246492985972, 0.16332665330661322, 0.16432865731462926, 0.1653306613226453, 0.16633266533066132, 0.16733466933867733, 0.16833667334669336, 0.1693386773547094, 0.17034068136272543, 0.17134268537074146, 0.1723446893787575, 0.17334669338677353, 0.17434869739478956, 0.1753507014028056, 0.17635270541082163, 0.17735470941883766, 0.1783567134268537, 0.17935871743486972, 0.18036072144288576, 0.1813627254509018, 0.18236472945891782, 0.18336673346693386, 0.1843687374749499, 0.18537074148296592, 0.18637274549098196, 0.187374749498998, 0.18837675350701402, 0.18937875751503006, 0.1903807615230461, 0.19138276553106212, 0.19238476953907813, 0.19338677354709416, 0.1943887775551102, 0.19539078156312623, 0.19639278557114226, 0.1973947895791583, 0.19839679358717432, 0.19939879759519036, 0.2004008016032064, 0.20140280561122242, 0.20240480961923846, 0.2034068136272545, 0.20440881763527052, 0.20541082164328656, 0.2064128256513026, 0.20741482965931862, 0.20841683366733466, 0.2094188376753507, 0.21042084168336672, 0.21142284569138275, 0.2124248496993988, 0.21342685370741482, 0.21442885771543085, 0.2154308617234469, 0.21643286573146292, 0.21743486973947895, 0.21843687374749496, 0.219438877755511, 0.22044088176352702, 0.22144288577154306, 0.2224448897795591, 0.22344689378757512, 0.22444889779559116, 0.2254509018036072, 0.22645290581162322, 0.22745490981963926, 0.2284569138276553, 0.22945891783567132, 0.23046092184368736, 0.2314629258517034, 0.23246492985971942, 0.23346693386773545, 0.2344689378757515, 0.23547094188376752, 0.23647294589178355, 0.2374749498997996, 0.23847695390781562, 0.23947895791583165, 0.24048096192384769, 0.24148296593186372, 0.24248496993987975, 0.24348697394789579, 0.2444889779559118, 0.24549098196392782, 0.24649298597194386, 0.2474949899799599, 0.24849699398797592, 0.24949899799599196, 0.250501002004008, 0.251503006012024, 0.25250501002004005, 0.2535070140280561, 0.2545090180360721, 0.25551102204408815, 0.2565130260521042, 0.2575150300601202, 0.25851703406813625, 0.2595190380761523, 0.2605210420841683, 0.26152304609218435, 0.2625250501002004, 0.2635270541082164, 0.26452905811623245, 0.2655310621242485, 0.2665330661322645, 0.26753507014028055, 0.2685370741482966, 0.2695390781563126, 0.27054108216432865, 0.2715430861723447, 0.2725450901803607, 0.27354709418837675, 0.2745490981963928, 0.2755511022044088, 0.27655310621242485, 0.2775551102204409, 0.2785571142284569, 0.27955911823647295, 0.280561122244489, 0.281563126252505, 0.282565130260521, 0.283567134268537, 0.28456913827655306, 0.2855711422845691, 0.2865731462925851, 0.28757515030060116, 0.2885771543086172, 0.2895791583166332, 0.29058116232464926, 0.2915831663326653, 0.2925851703406813, 0.29358717434869736, 0.2945891783567134, 0.2955911823647294, 0.29659318637274545, 0.2975951903807615, 0.2985971943887775, 0.29959919839679355, 0.3006012024048096, 0.3016032064128256, 0.30260521042084165, 0.3036072144288577, 0.3046092184368737, 0.30561122244488975, 0.3066132264529058, 0.3076152304609218, 0.30861723446893785, 0.3096192384769539, 0.3106212424849699, 0.31162324649298595, 0.312625250501002, 0.313627254509018, 0.31462925851703405, 0.3156312625250501, 0.3166332665330661, 0.31763527054108215, 0.3186372745490982, 0.3196392785571142, 0.32064128256513025, 0.3216432865731463, 0.3226452905811623, 0.32364729458917835, 0.3246492985971944, 0.3256513026052104, 0.32665330661322645, 0.3276553106212425, 0.3286573146292585, 0.32965931863727455, 0.3306613226452906, 0.3316633266533066, 0.33266533066132264, 0.3336673346693386, 0.33466933867735466, 0.3356713426853707, 0.3366733466933867, 0.33767535070140275, 0.3386773547094188, 0.3396793587174348, 0.34068136272545085, 0.3416833667334669, 0.3426853707414829, 0.34368737474949895, 0.344689378757515, 0.345691382765531, 0.34669338677354705, 0.3476953907815631, 0.3486973947895791, 0.34969939879759515, 0.3507014028056112, 0.3517034068136272, 0.35270541082164325, 0.3537074148296593, 0.3547094188376753, 0.35571142284569135, 0.3567134268537074, 0.3577154308617234, 0.35871743486973945, 0.3597194388777555, 0.3607214428857715, 0.36172344689378755, 0.3627254509018036, 0.3637274549098196, 0.36472945891783565, 0.3657314629258517, 0.3667334669338677, 0.36773547094188375, 0.3687374749498998, 0.3697394789579158, 0.37074148296593185, 0.3717434869739479, 0.3727454909819639, 0.37374749498997994, 0.374749498997996, 0.375751503006012, 0.37675350701402804, 0.3777555110220441, 0.3787575150300601, 0.37975951903807614, 0.3807615230460922, 0.3817635270541082, 0.38276553106212424, 0.3837675350701403, 0.38476953907815625, 0.3857715430861723, 0.3867735470941883, 0.38777555110220435, 0.3887775551102204, 0.3897795591182364, 0.39078156312625245, 0.3917835671342685, 0.3927855711422845, 0.39378757515030055, 0.3947895791583166, 0.3957915831663326, 0.39679358717434865, 0.3977955911823647, 0.3987975951903807, 0.39979959919839675, 0.4008016032064128, 0.4018036072144288, 0.40280561122244485, 0.4038076152304609, 0.4048096192384769, 0.40581162324649295, 0.406813627254509, 0.407815631262525, 0.40881763527054105, 0.4098196392785571, 0.4108216432865731, 0.41182364729458915, 0.4128256513026052, 0.4138276553106212, 0.41482965931863724, 0.4158316633266533, 0.4168336673346693, 0.41783567134268534, 0.4188376753507014, 0.4198396793587174, 0.42084168336673344, 0.4218436873747495, 0.4228456913827655, 0.42384769539078154, 0.4248496993987976, 0.4258517034068136, 0.42685370741482964, 0.4278557114228457, 0.4288577154308617, 0.42985971943887774, 0.4308617234468938, 0.4318637274549098, 0.43286573146292584, 0.4338677354709419, 0.4348697394789579, 0.43587174348697394, 0.4368737474949899, 0.43787575150300595, 0.438877755511022, 0.439879759519038, 0.44088176352705405, 0.4418837675350701, 0.4428857715430861, 0.44388777555110215, 0.4448897795591182, 0.4458917835671342, 0.44689378757515025, 0.4478957915831663, 0.4488977955911823, 0.44989979959919835, 0.4509018036072144, 0.4519038076152304, 0.45290581162324645, 0.4539078156312625, 0.4549098196392785, 0.45591182364729455, 0.4569138276553106, 0.4579158316633266, 0.45891783567134264, 0.4599198396793587, 0.4609218436873747, 0.46192384769539074, 0.4629258517034068, 0.4639278557114228, 0.46492985971943884, 0.4659318637274549, 0.4669338677354709, 0.46793587174348694, 0.468937875751503, 0.469939879759519, 0.47094188376753504, 0.4719438877755511, 0.4729458917835671, 0.47394789579158314, 0.4749498997995992, 0.4759519038076152, 0.47695390781563124, 0.4779559118236473, 0.4789579158316633, 0.47995991983967934, 0.48096192384769537, 0.4819639278557114, 0.48296593186372744, 0.48396793587174347, 0.4849699398797595, 0.48597194388777554, 0.48697394789579157, 0.48797595190380755, 0.4889779559118236, 0.4899799599198396, 0.49098196392785565, 0.4919839679358717, 0.4929859719438877, 0.49398797595190375, 0.4949899799599198, 0.4959919839679358, 0.49699398797595185, 0.4979959919839679, 0.4989979959919839, 0.5], 'max_iter': [2000, 2016, 2032, 2048, 2064, 2080, 2096, 2112, 2128, 2144, 2160, 2176, 2192, 2208, 2224, 2240, 2256, 2272, 2288, 2304, 2320, 2336, 2352, 2368, 2384, 2400, 2416, 2432, 2448, 2464, 2480, 2496, 2513, 2529, 2545, 2561, 2577, 2593, 2609, 2625, 2641, 2657, 2673, 2689, 2705, 2721, 2737, 2753, 2769, 2785, 2801, 2817, 2833, 2849, 2865, 2881, 2897, 2913, 2929, 2945, 2961, 2977, 2993, 3010, 3026, 3042, 3058, 3074, 3090, 3106, 3122, 3138, 3154, 3170, 3186, 3202, 3218, 3234, 3250, 3266, 3282, 3298, 3314, 3330, 3346, 3362, 3378, 3394, 3410, 3426, 3442, 3458, 3474, 3490, 3507, 3523, 3539, 3555, 3571, 3587, 3603, 3619, 3635, 3651, 3667, 3683, 3699, 3715, 3731, 3747, 3763, 3779, 3795, 3811, 3827, 3843, 3859, 3875, 3891, 3907, 3923, 3939, 3955, 3971, 3987, 4004, 4020, 4036, 4052, 4068, 4084, 4100, 4116, 4132, 4148, 4164, 4180, 4196, 4212, 4228, 4244, 4260, 4276, 4292, 4308, 4324, 4340, 4356, 4372, 4388, 4404, 4420, 4436, 4452, 4468, 4484, 4501, 4517, 4533, 4549, 4565, 4581, 4597, 4613, 4629, 4645, 4661, 4677, 4693, 4709, 4725, 4741, 4757, 4773, 4789, 4805, 4821, 4837, 4853, 4869, 4885, 4901, 4917, 4933, 4949, 4965, 4981, 4997, 5014, 5030, 5046, 5062, 5078, 5094, 5110, 5126, 5142, 5158, 5174, 5190, 5206, 5222, 5238, 5254, 5270, 5286, 5302, 5318, 5334, 5350, 5366, 5382, 5398, 5414, 5430, 5446, 5462, 5478, 5494, 5511, 5527, 5543, 5559, 5575, 5591, 5607, 5623, 5639, 5655, 5671, 5687, 5703, 5719, 5735, 5751, 5767, 5783, 5799, 5815, 5831, 5847, 5863, 5879, 5895, 5911, 5927, 5943, 5959, 5975, 5991, 6008, 6024, 6040, 6056, 6072, 6088, 6104, 6120, 6136, 6152, 6168, 6184, 6200, 6216, 6232, 6248, 6264, 6280, 6296, 6312, 6328, 6344, 6360, 6376, 6392, 6408, 6424, 6440, 6456, 6472, 6488, 6505, 6521, 6537, 6553, 6569, 6585, 6601, 6617, 6633, 6649, 6665, 6681, 6697, 6713, 6729, 6745, 6761, 6777, 6793, 6809, 6825, 6841, 6857, 6873, 6889, 6905, 6921, 6937, 6953, 6969, 6985, 7002, 7018, 7034, 7050, 7066, 7082, 7098, 7114, 7130, 7146, 7162, 7178, 7194, 7210, 7226, 7242, 7258, 7274, 7290, 7306, 7322, 7338, 7354, 7370, 7386, 7402, 7418, 7434, 7450, 7466, 7482, 7498, 7515, 7531, 7547, 7563, 7579, 7595, 7611, 7627, 7643, 7659, 7675, 7691, 7707, 7723, 7739, 7755, 7771, 7787, 7803, 7819, 7835, 7851, 7867, 7883, 7899, 7915, 7931, 7947, 7963, 7979, 7995, 8012, 8028, 8044, 8060, 8076, 8092, 8108, 8124, 8140, 8156, 8172, 8188, 8204, 8220, 8236, 8252, 8268, 8284, 8300, 8316, 8332, 8348, 8364, 8380, 8396, 8412, 8428, 8444, 8460, 8476, 8492, 8509, 8525, 8541, 8557, 8573, 8589, 8605, 8621, 8637, 8653, 8669, 8685, 8701, 8717, 8733, 8749, 8765, 8781, 8797, 8813, 8829, 8845, 8861, 8877, 8893, 8909, 8925, 8941, 8957, 8973, 8989, 9006, 9022, 9038, 9054, 9070, 9086, 9102, 9118, 9134, 9150, 9166, 9182, 9198, 9214, 9230, 9246, 9262, 9278, 9294, 9310, 9326, 9342, 9358, 9374, 9390, 9406, 9422, 9438, 9454, 9470, 9486, 9503, 9519, 9535, 9551, 9567, 9583, 9599, 9615, 9631, 9647, 9663, 9679, 9695, 9711, 9727, 9743, 9759, 9775, 9791, 9807, 9823, 9839, 9855, 9871, 9887, 9903, 9919, 9935, 9951, 9967, 9983, 10000], 'tol': [0.01, 0.00996989966555184, 0.009939799331103678, 0.009909698996655518, 0.009879598662207358, 0.009849498327759198, 0.009819397993311036, 0.009789297658862876, 0.009759197324414716, 0.009729096989966556, 0.009698996655518394, 0.009668896321070234, 0.009638795986622074, 0.009608695652173913, 0.009578595317725752, 0.009548494983277592, 0.009518394648829432, 0.00948829431438127, 0.00945819397993311, 0.00942809364548495, 0.009397993311036789, 0.009367892976588629, 0.009337792642140469, 0.009307692307692308, 0.009277591973244147, 0.009247491638795987, 0.009217391304347827, 0.009187290969899665, 0.009157190635451505, 0.009127090301003345, 0.009096989966555185, 0.009066889632107023, 0.009036789297658863, 0.009006688963210703, 0.008976588628762543, 0.00894648829431438, 0.00891638795986622, 0.00888628762541806, 0.008856187290969899, 0.008826086956521739, 0.008795986622073579, 0.008765886287625419, 0.008735785953177257, 0.008705685618729097, 0.008675585284280937, 0.008645484949832777, 0.008615384615384615, 0.008585284280936455, 0.008555183946488295, 0.008525083612040133, 0.008494983277591973, 0.008464882943143813, 0.008434782608695653, 0.008404682274247491, 0.008374581939799331, 0.008344481605351171, 0.008314381270903011, 0.00828428093645485, 0.00825418060200669, 0.008224080267558529, 0.008193979933110367, 0.008163879598662207, 0.008133779264214047, 0.008103678929765885, 0.008073578595317725, 0.008043478260869565, 0.008013377926421405, 0.007983277591973245, 0.007953177257525083, 0.007923076923076923, 0.007892976588628763, 0.007862876254180601, 0.007832775919732441, 0.007802675585284281, 0.00777257525083612, 0.0077424749163879595, 0.0077123745819397994, 0.007682274247491639, 0.007652173913043478, 0.0076220735785953175, 0.0075919732441471575, 0.0075618729096989966, 0.007531772575250836, 0.007501672240802676, 0.0074715719063545155, 0.007441471571906355, 0.007411371237458194, 0.007381270903010034, 0.007351170568561873, 0.007321070234113712, 0.007290969899665552, 0.007260869565217392, 0.007230769230769231, 0.00720066889632107, 0.00717056856187291, 0.00714046822742475, 0.007110367892976589, 0.007080267558528428, 0.007050167224080268, 0.007020066889632107, 0.006989966555183946, 0.006959866220735786, 0.006929765886287626, 0.006899665551839465, 0.006869565217391304, 0.006839464882943144, 0.006809364548494983, 0.006779264214046822, 0.006749163879598662, 0.006719063545150502, 0.006688963210702341, 0.00665886287625418, 0.00662876254180602, 0.00659866220735786, 0.006568561872909699, 0.006538461538461538, 0.006508361204013378, 0.006478260869565217, 0.006448160535117056, 0.006418060200668896, 0.006387959866220736, 0.006357859531772575, 0.006327759197324414, 0.006297658862876254, 0.006267558528428093, 0.006237458193979932, 0.006207357859531772, 0.006177257525083612, 0.006147157190635451, 0.00611705685618729, 0.00608695652173913, 0.006056856187290969, 0.006026755852842809, 0.005996655518394648, 0.005966555183946488, 0.0059364548494983274, 0.005906354515050167, 0.0058762541806020065, 0.0058461538461538455, 0.0058160535117056855, 0.0057859531772575246, 0.0057558528428093645, 0.005725752508361204, 0.0056956521739130435, 0.005665551839464883, 0.0056354515050167225, 0.005605351170568562, 0.005575250836120401, 0.005545150501672241, 0.00551505016722408, 0.00548494983277592, 0.005454849498327759, 0.005424749163879599, 0.005394648829431438, 0.005364548494983278, 0.005334448160535117, 0.005304347826086956, 0.005274247491638796, 0.005244147157190635, 0.005214046822742475, 0.005183946488294314, 0.005153846153846154, 0.005123745819397993, 0.005093645484949833, 0.005063545150501672, 0.005033444816053511, 0.005003344481605351, 0.00497324414715719, 0.00494314381270903, 0.004913043478260869, 0.004882943143812709, 0.004852842809364548, 0.004822742474916388, 0.004792642140468227, 0.004762541806020066, 0.004732441471571906, 0.004702341137123745, 0.004672240802675585, 0.004642140468227424, 0.004612040133779264, 0.004581939799331103, 0.004551839464882943, 0.004521739130434782, 0.004491638795986621, 0.004461538461538461, 0.0044314381270903, 0.00440133779264214, 0.004371237458193979, 0.004341137123745819, 0.004311036789297658, 0.004280936454849498, 0.004250836120401337, 0.004220735785953177, 0.004190635451505016, 0.0041605351170568555, 0.004130434782608695, 0.0041003344481605345, 0.004070234113712374, 0.0040401337792642135, 0.0040100334448160534, 0.0039799331103678925, 0.0039498327759197325, 0.0039197324414715715, 0.0038896321070234106, 0.0038595317725752505, 0.0038294314381270896, 0.0037993311036789296, 0.0037692307692307686, 0.0037391304347826086, 0.0037090301003344477, 0.0036789297658862876, 0.0036488294314381267, 0.0036187290969899658, 0.0035886287625418057, 0.0035585284280936448, 0.0035284280936454847, 0.003498327759197324, 0.0034682274247491637, 0.003438127090301003, 0.0034080267558528428, 0.003377926421404682, 0.003347826086956521, 0.003317725752508361, 0.0032876254180602, 0.00325752508361204, 0.003227424749163879, 0.003197324414715719, 0.003167224080267558, 0.003137123745819398, 0.003107023411371237, 0.003076923076923076, 0.003046822742474916, 0.003016722408026755, 0.002986622073578595, 0.002956521739130434, 0.002926421404682274, 0.002896321070234113, 0.002866220735785953, 0.002836120401337792, 0.002806020066889631, 0.002775919732441471, 0.0027458193979933102, 0.00271571906354515, 0.0026856187290969892, 0.002655518394648829, 0.0026254180602006683, 0.002595317725752508, 0.0025652173913043473, 0.0025351170568561864, 0.0025050167224080263, 0.0024749163879598654, 0.0024448160535117053, 0.0024147157190635444, 0.0023846153846153843, 0.0023545150501672234, 0.0023244147157190633, 0.0022943143812709024, 0.0022642140468227415, 0.0022341137123745814, 0.0022040133779264205, 0.0021739130434782605, 0.0021438127090301004, 0.0021137123745819386, 0.0020836120401337786, 0.0020535117056856185, 0.0020234113712374584, 0.0019933110367892967, 0.0019632107023411366, 0.0019331103678929765, 0.0019030100334448147, 0.0018729096989966547, 0.0018428093645484946, 0.0018127090301003346, 0.0017826086956521728, 0.0017525083612040127, 0.0017224080267558527, 0.0016923076923076909, 0.0016622073578595308, 0.0016321070234113708, 0.0016020066889632107, 0.001571906354515049, 0.0015418060200668889, 0.0015117056856187288, 0.0014816053511705687, 0.001451505016722407, 0.001421404682274247, 0.0013913043478260868, 0.001361204013377925, 0.001331103678929765, 0.001301003344481605, 0.0012709030100334449, 0.001240802675585283, 0.001210702341137123, 0.001180602006688963, 0.0011505016722408012, 0.0011204013377926411, 0.001090301003344481, 0.001060200668896321, 0.0010301003344481592, 0.001], 'positive': ['True', 'False'], 'copy_X': ['True', 'False'], 'warm_start': ['True', 'False'], 'selection': ['cyclic', 'random']}\n"
     ]
    }
   ],
   "source": [
    "max_iter=[int(x) for x in np.linspace(2000, 10000,500)]\n",
    "tol=[float(x) for x in np.linspace(0.01, 0.001,300)]\n",
    "warm_start = ['True','False']\n",
    "selection=['cyclic','random']\n",
    "alpha = [float(x) for x in np.linspace(0,0.50,500)]\n",
    "# positive=['True','False']\n",
    "copy_X=['True','False']\n",
    "random_grid = {\n",
    "               'alpha':alpha,\n",
    "              \n",
    "               'max_iter':max_iter,\n",
    "               'tol':tol,\n",
    "                'positive':positive,\n",
    "                'copy_X':copy_X,\n",
    "                'warm_start':warm_start,\n",
    "                'selection':selection\n",
    "               \n",
    "               \n",
    "                }\n",
    "print(random_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "65634dbf-9acf-4e93-87bb-dc6a115ddf84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV 4/5] END copy_X=True, fit_intercept=True, positive=False;, score=0.722 total time=   0.1s\n",
      "[CV 1/5] END copy_X=True, fit_intercept=False, positive=False;, score=0.686 total time=   0.1s\n",
      "[CV 2/5] END copy_X=True, fit_intercept=False, positive=True;, score=0.559 total time=   0.1s\n",
      "[CV 2/5] END copy_X=False, fit_intercept=True, positive=False;, score=0.559 total time=   0.1s\n",
      "[CV 3/5] END copy_X=False, fit_intercept=True, positive=True;, score=-1491335583445575312343040.000 total time=   0.1s\n",
      "[CV 4/5] END copy_X=False, fit_intercept=False, positive=False;, score=0.722 total time=   0.1s\n",
      "[CV 5/5] END copy_X=False, fit_intercept=False, positive=True;, score=0.772 total time=   0.1s\n",
      "[CV 1/5] END criterion=poisson, max_depth=1000, max_features=sqrt, min_samples_leaf=8, min_samples_split=3, n_estimators=1000;, score=0.830 total time=   1.8s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=670, max_features=sqrt, min_samples_leaf=6, min_samples_split=3, n_estimators=1200;, score=0.778 total time=   2.1s\n",
      "[CV 4/5] END criterion=poisson, max_depth=560, max_features=log2, min_samples_leaf=8, min_samples_split=5, n_estimators=1200;, score=0.734 total time=   1.8s\n",
      "[CV 1/5] END criterion=absolute_error, max_depth=890, max_features=log2, min_samples_leaf=6, min_samples_split=2, n_estimators=1000;, score=0.754 total time=   6.3s\n",
      "[CV 2/5] END criterion=poisson, max_depth=670, max_features=log2, min_samples_leaf=6, min_samples_split=5, n_estimators=1800;, score=0.711 total time=   2.7s\n",
      "[CV 4/5] END criterion=poisson, max_depth=670, max_features=log2, min_samples_leaf=6, min_samples_split=5, n_estimators=1800;, score=0.749 total time=   2.7s\n",
      "[CV 2/5] END criterion=absolute_error, max_depth=10, max_features=sqrt, min_samples_leaf=8, min_samples_split=4, n_estimators=1200;, score=0.732 total time=  11.6s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=890, max_features=sqrt, min_samples_leaf=1, min_samples_split=14, n_estimators=200;, score=0.857 total time=   0.4s\n",
      "[CV] END algorithm=brute, leaf_size=15, n_neighbors=124, p=2, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, leaf_size=18, n_neighbors=5, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=auto, leaf_size=11, n_neighbors=110, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=auto, leaf_size=11, n_neighbors=110, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=kd_tree, leaf_size=15, n_neighbors=47, p=2, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=kd_tree, leaf_size=13, n_neighbors=335, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, leaf_size=13, n_neighbors=166, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=ball_tree, leaf_size=13, n_neighbors=166, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=kd_tree, leaf_size=18, n_neighbors=237, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=brute, leaf_size=18, n_neighbors=5, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=absolute_error, max_depth=320, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random; total time=   0.0s\n",
      "[CV] END ccp_alpha=0, criterion=squared_error, max_depth=580, max_features=sqrt, min_samples_leaf=6, min_samples_split=14, splitter=best; total time=   0.0s\n",
      "[CV] END ccp_alpha=0, criterion=squared_error, max_depth=580, max_features=sqrt, min_samples_leaf=6, min_samples_split=14, splitter=best; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=poisson, max_depth=100, max_features=log2, min_samples_leaf=8, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=poisson, max_depth=100, max_features=log2, min_samples_leaf=8, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END ccp_alpha=0, criterion=absolute_error, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=14, splitter=random; total time=   0.0s\n",
      "[CV] END ccp_alpha=0, criterion=poisson, max_depth=300, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END alpha=0.0005510204081632653, eta0=0.05555555555555556, l1_ratio=0.09183673469387754, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=14303, n_iter_no_change=8, penalty=l1, tol=0.004636363636363636, validation_fraction=0.7040816326530612; total time=  21.6s\n",
      "[CV] END alpha=2.0408163265306123e-05, eta0=0.060606060606060615, l1_ratio=0.36734693877551017, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=16727, n_iter_no_change=6, penalty=l1, tol=0.0028181818181818178, validation_fraction=0.1; total time=  24.8s\n",
      "[CV] END alpha=0.0005306122448979592, eta0=0.06767676767676768, l1_ratio=0.39795918367346933, learning_rate=adaptive, loss=huber, max_iter=19272, n_iter_no_change=6, penalty=l2, tol=0.0015454545454545443, validation_fraction=0.4755102040816327; total time=  13.2s\n",
      "[CV] END alpha=0.0005306122448979592, eta0=0.06767676767676768, l1_ratio=0.39795918367346933, learning_rate=adaptive, loss=huber, max_iter=19272, n_iter_no_change=6, penalty=l2, tol=0.0015454545454545443, validation_fraction=0.4755102040816327; total time=  13.1s\n",
      "[CV] END alpha=0.0009183673469387755, eta0=0.05555555555555556, l1_ratio=0.08163265306122448, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=13333, n_iter_no_change=2, penalty=l2, tol=0.007727272727272727, validation_fraction=0.3938775510204082; total time=   0.1s\n",
      "[CV] END alpha=0.024048096192384766, copy_X=False, l1_ratio=0.12121212121212122, max_iter=2321, selection=cyclic, tol=0.009683417085427136, warm_start=True; total time=   0.1s\n",
      "[CV] END alpha=0.37374749498997994, copy_X=True, l1_ratio=0.08080808080808081, max_iter=8110, selection=cyclic, tol=0.0026281407035175864, warm_start=False; total time=   0.0s\n",
      "[CV] END alpha=0.08016032064128256, copy_X=True, l1_ratio=0.10606060606060606, max_iter=6582, selection=random, tol=0.002673366834170853, warm_start=True; total time=   0.0s\n",
      "[CV] END alpha=0.281563126252505, copy_X=False, l1_ratio=0.3535353535353536, max_iter=8190, selection=random, tol=0.0098643216080402, warm_start=True; total time=   0.0s\n",
      "[CV] END alpha=0.281563126252505, copy_X=False, l1_ratio=0.3535353535353536, max_iter=8190, selection=random, tol=0.0098643216080402, warm_start=True; total time=   0.0s\n",
      "[CV] END alpha=0.4478957915831663, copy_X=True, l1_ratio=0.4444444444444445, max_iter=6462, selection=random, tol=0.004120603015075376, warm_start=True; total time=   0.0s\n",
      "[CV] END alpha=0.4218436873747495, copy_X=False, l1_ratio=0.3282828282828283, max_iter=7507, selection=random, tol=0.005884422110552763, warm_start=False; total time=   0.0s\n",
      "[CV] END alpha=0.49098196392785565, copy_X=True, l1_ratio=0.010101010101010102, max_iter=8351, selection=cyclic, tol=0.005613065326633165, warm_start=True; total time=   0.0s\n",
      "[CV] END alpha=0.024048096192384766, copy_X=False, l1_ratio=0.12121212121212122, max_iter=2321, selection=cyclic, tol=0.009683417085427136, warm_start=True; total time=   0.1s\n",
      "[CV] END alpha=0.3286573146292585, copy_X=True, max_iter=6312, positive=True, selection=random, tol=0.006779264214046822, warm_start=True; total time=   0.7s\n",
      "[CV] END alpha=0.4158316633266533, copy_X=True, max_iter=4709, positive=True, selection=random, tol=0.007321070234113712, warm_start=True; total time=   0.3s\n",
      "[CV] END alpha=0.17334669338677353, copy_X=True, max_iter=7130, positive=True, selection=cyclic, tol=0.0058461538461538455, warm_start=True; total time=   0.3s\n",
      "[CV] END alpha=0.17334669338677353, copy_X=True, max_iter=7130, positive=True, selection=cyclic, tol=0.0058461538461538455, warm_start=True; total time=   0.5s\n",
      "[CV] END alpha=0.27955911823647295, copy_X=True, max_iter=4613, positive=True, selection=cyclic, tol=0.007321070234113712, warm_start=True; total time=   0.2s\n",
      "[CV] END alpha=0.27955911823647295, copy_X=True, max_iter=4613, positive=True, selection=cyclic, tol=0.007321070234113712, warm_start=True; total time=   0.2s\n",
      "[CV] END alpha=0.1783567134268537, copy_X=False, max_iter=8605, positive=True, selection=cyclic, tol=0.006779264214046822, warm_start=True; total time=   0.5s\n",
      "[CV 5/5] END copy_X=True, fit_intercept=True, positive=False;, score=0.772 total time=   0.1s\n",
      "[CV 5/5] END copy_X=True, fit_intercept=True, positive=True;, score=0.772 total time=   0.1s\n",
      "[CV 1/5] END copy_X=True, fit_intercept=False, positive=True;, score=0.686 total time=   0.1s\n",
      "[CV 3/5] END copy_X=False, fit_intercept=True, positive=False;, score=-1491335583445575312343040.000 total time=   0.1s\n",
      "[CV 4/5] END copy_X=False, fit_intercept=True, positive=True;, score=0.722 total time=   0.1s\n",
      "[CV 5/5] END copy_X=False, fit_intercept=False, positive=False;, score=0.772 total time=   0.1s\n",
      "[CV 1/5] END copy_X=True, fit_intercept=True, positive=False;, score=0.686 total time=   0.1s\n",
      "[CV 2/5] END criterion=poisson, max_depth=1000, max_features=sqrt, min_samples_leaf=8, min_samples_split=3, n_estimators=1000;, score=0.751 total time=   1.9s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=670, max_features=sqrt, min_samples_leaf=6, min_samples_split=3, n_estimators=1200;, score=0.847 total time=   2.1s\n",
      "[CV 5/5] END criterion=poisson, max_depth=560, max_features=log2, min_samples_leaf=8, min_samples_split=5, n_estimators=1200;, score=0.793 total time=   1.8s\n",
      "[CV 5/5] END criterion=absolute_error, max_depth=1000, max_features=log2, min_samples_leaf=8, min_samples_split=4, n_estimators=1000;, score=0.767 total time=   5.7s\n",
      "[CV 5/5] END criterion=absolute_error, max_depth=890, max_features=log2, min_samples_leaf=6, min_samples_split=2, n_estimators=1000;, score=0.781 total time=   6.1s\n",
      "[CV 4/5] END criterion=absolute_error, max_depth=10, max_features=sqrt, min_samples_leaf=8, min_samples_split=4, n_estimators=1200;, score=0.762 total time=  11.6s\n",
      "[CV] END algorithm=brute, leaf_size=15, n_neighbors=124, p=2, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=auto, leaf_size=11, n_neighbors=110, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=kd_tree, leaf_size=15, n_neighbors=47, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, leaf_size=15, n_neighbors=47, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=ball_tree, leaf_size=18, n_neighbors=307, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=ball_tree, leaf_size=18, n_neighbors=307, p=1, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=kd_tree, leaf_size=18, n_neighbors=237, p=2, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=brute, leaf_size=6, n_neighbors=117, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=brute, leaf_size=18, n_neighbors=5, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=squared_error, max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=squared_error, max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END ccp_alpha=0, criterion=friedman_mse, max_depth=410, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=squared_error, max_depth=530, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=squared_error, max_depth=530, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=random; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=poisson, max_depth=100, max_features=log2, min_samples_leaf=8, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=poisson, max_depth=100, max_features=log2, min_samples_leaf=8, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END ccp_alpha=0, criterion=poisson, max_depth=300, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=poisson, max_depth=680, max_features=log2, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END ccp_alpha=0, criterion=poisson, max_depth=300, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END alpha=0.0005510204081632653, eta0=0.05555555555555556, l1_ratio=0.09183673469387754, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=14303, n_iter_no_change=8, penalty=l1, tol=0.004636363636363636, validation_fraction=0.7040816326530612; total time=  21.9s\n",
      "[CV] END alpha=2.0408163265306123e-05, eta0=0.060606060606060615, l1_ratio=0.36734693877551017, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=16727, n_iter_no_change=6, penalty=l1, tol=0.0028181818181818178, validation_fraction=0.1; total time=  23.9s\n",
      "[CV] END alpha=4.0816326530612245e-05, eta0=0.05202020202020203, l1_ratio=0.08163265306122448, learning_rate=invscaling, loss=huber, max_iter=19030, n_iter_no_change=6, penalty=elasticnet, tol=0.006909090909090909, validation_fraction=0.6714285714285715; total time=  27.4s\n",
      "[CV] END alpha=0.0009183673469387755, eta0=0.05555555555555556, l1_ratio=0.08163265306122448, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=13333, n_iter_no_change=2, penalty=l2, tol=0.007727272727272727, validation_fraction=0.3938775510204082; total time=   0.0s\n",
      "[CV] END alpha=0.375751503006012, copy_X=True, l1_ratio=0.3484848484848485, max_iter=3005, selection=random, tol=0.004165829145728642, warm_start=False; total time=   0.0s\n",
      "[CV] END alpha=0.024048096192384766, copy_X=False, l1_ratio=0.12121212121212122, max_iter=2321, selection=cyclic, tol=0.009683417085427136, warm_start=True; total time=   0.1s\n",
      "[CV] END alpha=0.37374749498997994, copy_X=True, l1_ratio=0.08080808080808081, max_iter=8110, selection=cyclic, tol=0.0026281407035175864, warm_start=False; total time=   0.0s\n",
      "[CV] END alpha=0.37374749498997994, copy_X=True, l1_ratio=0.08080808080808081, max_iter=8110, selection=cyclic, tol=0.0026281407035175864, warm_start=False; total time=   0.0s\n",
      "[CV] END alpha=0.3286573146292585, copy_X=True, l1_ratio=0.27272727272727276, max_iter=8592, selection=random, tol=0.0076482412060301505, warm_start=False; total time=   0.0s\n",
      "[CV] END alpha=0.281563126252505, copy_X=False, l1_ratio=0.3535353535353536, max_iter=8190, selection=random, tol=0.0098643216080402, warm_start=True; total time=   0.0s\n",
      "[CV] END alpha=0.4478957915831663, copy_X=True, l1_ratio=0.4444444444444445, max_iter=6462, selection=random, tol=0.004120603015075376, warm_start=True; total time=   0.0s\n",
      "[CV] END alpha=0.4478957915831663, copy_X=True, l1_ratio=0.4444444444444445, max_iter=6462, selection=random, tol=0.004120603015075376, warm_start=True; total time=   0.0s\n",
      "[CV] END alpha=0.49098196392785565, copy_X=True, l1_ratio=0.010101010101010102, max_iter=8351, selection=cyclic, tol=0.005613065326633165, warm_start=True; total time=   0.0s\n",
      "[CV] END alpha=0.024048096192384766, copy_X=False, l1_ratio=0.12121212121212122, max_iter=2321, selection=cyclic, tol=0.009683417085427136, warm_start=True; total time=   0.1s\n",
      "[CV] END alpha=0.4158316633266533, copy_X=True, max_iter=4709, positive=True, selection=random, tol=0.007321070234113712, warm_start=True; total time=   0.3s\n",
      "[CV] END alpha=0.4158316633266533, copy_X=True, max_iter=4709, positive=True, selection=random, tol=0.007321070234113712, warm_start=True; total time=   0.6s\n",
      "[CV] END alpha=0.17635270541082163, copy_X=False, max_iter=2897, positive=True, selection=cyclic, tol=0.0013913043478260868, warm_start=True; total time=   0.6s\n",
      "[CV] END alpha=0.27955911823647295, copy_X=True, max_iter=5302, positive=True, selection=cyclic, tol=0.0017224080267558527, warm_start=True; total time=   0.3s\n",
      "[CV] END alpha=0.27955911823647295, copy_X=True, max_iter=5302, positive=True, selection=cyclic, tol=0.0017224080267558527, warm_start=True; total time=   0.3s\n",
      "[CV] END alpha=0.1783567134268537, copy_X=False, max_iter=8605, positive=True, selection=cyclic, tol=0.006779264214046822, warm_start=True; total time=   0.2s\n",
      "[CV] END alpha=0.1783567134268537, copy_X=False, max_iter=8605, positive=True, selection=cyclic, tol=0.006779264214046822, warm_start=True; total time=   0.4s\n",
      "Lasso() RandomCV Best Params : {'warm_start': 'True', 'tol': 0.007321070234113712, 'selection': 'random', 'positive': 'True', 'max_iter': 4709, 'copy_X': 'True', 'alpha': 0.4158316633266533}\n",
      "Lasso() RandomCV Score: 0.7442431317433171\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END copy_X=True, fit_intercept=True, positive=True;, score=0.686 total time=   0.1s\n",
      "[CV 2/5] END copy_X=True, fit_intercept=False, positive=False;, score=0.559 total time=   0.1s\n",
      "[CV 3/5] END copy_X=True, fit_intercept=False, positive=True;, score=-1491335583445575312343040.000 total time=   0.1s\n",
      "[CV 4/5] END copy_X=False, fit_intercept=True, positive=False;, score=0.722 total time=   0.1s\n",
      "[CV 5/5] END copy_X=False, fit_intercept=True, positive=True;, score=0.772 total time=   0.1s\n",
      "[CV 2/5] END copy_X=False, fit_intercept=False, positive=True;, score=0.559 total time=   0.1s\n",
      "[CV 2/5] END copy_X=True, fit_intercept=True, positive=False;, score=0.559 total time=   0.1s\n",
      "[CV 3/5] END criterion=poisson, max_depth=1000, max_features=sqrt, min_samples_leaf=8, min_samples_split=3, n_estimators=1000;, score=0.760 total time=   1.8s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=670, max_features=sqrt, min_samples_leaf=6, min_samples_split=3, n_estimators=1200;, score=0.761 total time=   2.1s\n",
      "[CV 3/5] END criterion=poisson, max_depth=560, max_features=log2, min_samples_leaf=8, min_samples_split=5, n_estimators=1200;, score=0.703 total time=   1.7s\n",
      "[CV 4/5] END criterion=absolute_error, max_depth=1000, max_features=log2, min_samples_leaf=8, min_samples_split=4, n_estimators=1000;, score=0.699 total time=   6.0s\n",
      "[CV 1/5] END criterion=poisson, max_depth=670, max_features=log2, min_samples_leaf=6, min_samples_split=5, n_estimators=1800;, score=0.788 total time=   2.7s\n",
      "[CV 3/5] END criterion=poisson, max_depth=670, max_features=log2, min_samples_leaf=6, min_samples_split=5, n_estimators=1800;, score=0.723 total time=   2.6s\n",
      "[CV 1/5] END criterion=absolute_error, max_depth=10, max_features=sqrt, min_samples_leaf=8, min_samples_split=4, n_estimators=1200;, score=0.805 total time=  10.7s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=890, max_features=sqrt, min_samples_leaf=1, min_samples_split=14, n_estimators=200;, score=0.775 total time=   0.4s\n",
      "[CV] END algorithm=brute, leaf_size=18, n_neighbors=5, p=2, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=brute, leaf_size=18, n_neighbors=5, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END algorithm=kd_tree, leaf_size=15, n_neighbors=335, p=2, weights=uniform; total time=   0.1s\n",
      "[CV] END algorithm=kd_tree, leaf_size=15, n_neighbors=335, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, leaf_size=13, n_neighbors=335, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, leaf_size=13, n_neighbors=335, p=2, weights=distance; total time=   0.2s\n",
      "[CV] END algorithm=kd_tree, leaf_size=18, n_neighbors=237, p=2, weights=uniform; total time=   0.2s\n",
      "[CV] END algorithm=brute, leaf_size=6, n_neighbors=117, p=1, weights=distance; total time=   0.1s\n",
      "[CV] END algorithm=brute, leaf_size=18, n_neighbors=5, p=2, weights=distance; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=absolute_error, max_depth=320, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random; total time=   0.0s\n",
      "[CV] END ccp_alpha=0, criterion=friedman_mse, max_depth=410, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END ccp_alpha=0, criterion=friedman_mse, max_depth=410, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, splitter=best; total time=   0.0s\n",
      "[CV] END ccp_alpha=0, criterion=friedman_mse, max_depth=870, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END ccp_alpha=0, criterion=friedman_mse, max_depth=870, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END ccp_alpha=0, criterion=poisson, max_depth=300, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=best; total time=   0.0s\n",
      "[CV] END ccp_alpha=1, criterion=poisson, max_depth=680, max_features=log2, min_samples_leaf=4, min_samples_split=5, splitter=random; total time=   0.0s\n",
      "[CV] END ccp_alpha=0, criterion=absolute_error, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=14, splitter=random; total time=   0.0s\n",
      "[CV] END alpha=0.0005510204081632653, eta0=0.05555555555555556, l1_ratio=0.09183673469387754, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=14303, n_iter_no_change=8, penalty=l1, tol=0.004636363636363636, validation_fraction=0.7040816326530612; total time=  21.7s\n",
      "[CV] END alpha=2.0408163265306123e-05, eta0=0.060606060606060615, l1_ratio=0.36734693877551017, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=16727, n_iter_no_change=6, penalty=l1, tol=0.0028181818181818178, validation_fraction=0.1; total time=  24.1s\n",
      "[CV] END alpha=4.0816326530612245e-05, eta0=0.05202020202020203, l1_ratio=0.08163265306122448, learning_rate=invscaling, loss=huber, max_iter=19030, n_iter_no_change=6, penalty=elasticnet, tol=0.006909090909090909, validation_fraction=0.6714285714285715; total time=  27.1s\n",
      "[CV] END alpha=0.0009183673469387755, eta0=0.05555555555555556, l1_ratio=0.08163265306122448, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=13333, n_iter_no_change=2, penalty=l2, tol=0.007727272727272727, validation_fraction=0.3938775510204082; total time=   0.0s\n",
      "[CV] END alpha=0.375751503006012, copy_X=True, l1_ratio=0.3484848484848485, max_iter=3005, selection=random, tol=0.004165829145728642, warm_start=False; total time=   0.0s\n",
      "[CV] END alpha=0.37374749498997994, copy_X=True, l1_ratio=0.08080808080808081, max_iter=8110, selection=cyclic, tol=0.0026281407035175864, warm_start=False; total time=   0.0s\n",
      "[CV] END alpha=0.37374749498997994, copy_X=True, l1_ratio=0.08080808080808081, max_iter=8110, selection=cyclic, tol=0.0026281407035175864, warm_start=False; total time=   0.0s\n",
      "[CV] END alpha=0.08016032064128256, copy_X=True, l1_ratio=0.10606060606060606, max_iter=6582, selection=random, tol=0.002673366834170853, warm_start=True; total time=   0.0s\n",
      "[CV] END alpha=0.08016032064128256, copy_X=True, l1_ratio=0.10606060606060606, max_iter=6582, selection=random, tol=0.002673366834170853, warm_start=True; total time=   0.0s\n",
      "[CV] END alpha=0.3306613226452906, copy_X=True, l1_ratio=0.07070707070707072, max_iter=9678, selection=random, tol=0.0021758793969849227, warm_start=True; total time=   0.0s\n",
      "[CV] END alpha=0.4478957915831663, copy_X=True, l1_ratio=0.4444444444444445, max_iter=6462, selection=random, tol=0.004120603015075376, warm_start=True; total time=   0.0s\n",
      "[CV] END alpha=0.4218436873747495, copy_X=False, l1_ratio=0.3282828282828283, max_iter=7507, selection=random, tol=0.005884422110552763, warm_start=False; total time=   0.0s\n",
      "[CV] END alpha=0.024048096192384766, copy_X=False, l1_ratio=0.12121212121212122, max_iter=2321, selection=cyclic, tol=0.009683417085427136, warm_start=True; total time=   0.1s\n",
      "[CV] END alpha=0.3286573146292585, copy_X=True, max_iter=6312, positive=True, selection=random, tol=0.006779264214046822, warm_start=True; total time=   0.4s\n",
      "[CV] END alpha=0.4158316633266533, copy_X=True, max_iter=4709, positive=True, selection=random, tol=0.007321070234113712, warm_start=True; total time=   0.5s\n",
      "[CV] END alpha=0.17635270541082163, copy_X=False, max_iter=2897, positive=True, selection=cyclic, tol=0.0013913043478260868, warm_start=True; total time=   0.5s\n",
      "[CV] END alpha=0.17334669338677353, copy_X=True, max_iter=7130, positive=True, selection=cyclic, tol=0.0058461538461538455, warm_start=True; total time=   0.3s\n",
      "[CV] END alpha=0.27955911823647295, copy_X=True, max_iter=5302, positive=True, selection=cyclic, tol=0.0017224080267558527, warm_start=True; total time=   0.6s\n",
      "[CV] END alpha=0.1783567134268537, copy_X=False, max_iter=8605, positive=True, selection=cyclic, tol=0.006779264214046822, warm_start=True; total time=   0.5s\n",
      "[CV] END alpha=0.18036072144288576, copy_X=False, max_iter=9246, positive=True, selection=random, tol=0.005996655518394648, warm_start=False; total time=   0.7s\n",
      "[CV] END alpha=0.25551102204408815, copy_X=False, max_iter=4725, positive=True, selection=cyclic, tol=0.005575250836120401, warm_start=False; total time=   0.5s\n",
      "Final score is  0.7442522278615189\n"
     ]
    }
   ],
   "source": [
    "hyperparameter_tuning(algo=\"Lasso()\",param_grid=random_grid,n_iter=10,cv=5,verbose=2,random_state=42,X_train=X_train,Y_train=Y_train,X_test=X_test,Y_test=Y_test,evaluation_metric=\"r2_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "39d3cc51-896a-40f7-b054-4aa7292beda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lasso=Lasso()\n",
    "# lasso_random_cv=RandomizedSearchCV(estimator=lasso,param_distributions=random_grid,n_iter=100,cv=5,verbose=0,random_state=100,n_jobs=-1)\n",
    "# lasso_random_cv.fit(X_train,Y_train)\n",
    "\n",
    "# best_params_=lasso_random_cv.best_params_\n",
    "# print(\"RandomCV Best Params :\",best_params_)\n",
    "# best_random_grid=lasso_random_cv.best_estimator_\n",
    "# y_pred8=best_random_grid.predict(X_test)\n",
    "# score_8=r2_score(Y_test,y_pred8)\n",
    "# print(\"RandomCV Score: \",score_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "969a2eba-a27a-439f-91bd-6c515f294e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid8=defaultdict(list)\n",
    "# for val in best_params_:\n",
    "#     param_grid8[val].append(best_params_[val])\n",
    "# print(param_grid8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "287bd780-0547-4030-9542-6838397890e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "9d9c4a31-bf56-4ef1-9507-404c74187183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=Lasso()\n",
    "# grid_search=GridSearchCV(estimator=model,param_grid=param_grid8,cv=5,n_jobs=-1,verbose=3)\n",
    "# grid_search.fit(X_train,Y_train)\n",
    "# print(grid_search.best_estimator_)\n",
    "# best_grid2=grid_search.best_estimator_\n",
    "# final8=best_grid2.predict(X_test)\n",
    "# score_final8=r2_score(Y_test,final8)\n",
    "# print(score_final8)\n",
    "# accuracies[\"Lasso\"]=score_final8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "e03ddb79-98f3-44be-ab10-779acdec79ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9 Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "d8ba451f-ca1f-448e-bde5-fd475a803231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': [0.1, 0.10100250626566416, 0.10200501253132832, 0.10300751879699249, 0.10401002506265665, 0.10501253132832081, 0.10601503759398496, 0.10701754385964912, 0.1080200501253133, 0.10902255639097745, 0.11002506265664161, 0.11102756892230577, 0.11203007518796992, 0.1130325814536341, 0.11403508771929825, 0.11503759398496241, 0.11604010025062657, 0.11704260651629073, 0.1180451127819549, 0.11904761904761905, 0.12005012531328321, 0.12105263157894737, 0.12205513784461153, 0.1230576441102757, 0.12406015037593986, 0.12506265664160401, 0.12606516290726819, 0.12706766917293233, 0.1280701754385965, 0.12907268170426067, 0.13007518796992482, 0.131077694235589, 0.13208020050125313, 0.1330827067669173, 0.13408521303258147, 0.13508771929824562, 0.1360902255639098, 0.13709273182957393, 0.1380952380952381, 0.13909774436090228, 0.14010025062656642, 0.1411027568922306, 0.14210526315789473, 0.1431077694235589, 0.14411027568922308, 0.14511278195488722, 0.1461152882205514, 0.14711779448621554, 0.1481203007518797, 0.14912280701754388, 0.15012531328320802, 0.1511278195488722, 0.15213032581453634, 0.1531328320802005, 0.15413533834586468, 0.15513784461152882, 0.156140350877193, 0.15714285714285714, 0.1581453634085213, 0.15914786967418548, 0.16015037593984963, 0.1611528822055138, 0.16215538847117794, 0.1631578947368421, 0.16416040100250628, 0.16516290726817043, 0.16616541353383457, 0.16716791979949874, 0.16817042606516291, 0.16917293233082709, 0.17017543859649123, 0.17117794486215537, 0.17218045112781954, 0.17318295739348372, 0.1741854636591479, 0.17518796992481203, 0.17619047619047618, 0.17719298245614035, 0.17819548872180452, 0.1791979949874687, 0.18020050125313283, 0.18120300751879698, 0.18220551378446115, 0.18320802005012532, 0.1842105263157895, 0.18521303258145363, 0.18621553884711778, 0.18721804511278195, 0.18822055137844612, 0.1892230576441103, 0.19022556390977444, 0.19122807017543858, 0.19223057644110275, 0.19323308270676692, 0.1942355889724311, 0.19523809523809524, 0.1962406015037594, 0.19724310776942355, 0.19824561403508772, 0.1992481203007519, 0.20025062656641604, 0.2012531328320802, 0.20225563909774436, 0.20325814536340853, 0.2042606516290727, 0.20526315789473684, 0.206265664160401, 0.20726817042606516, 0.20827067669172933, 0.2092731829573935, 0.21027568922305764, 0.21127819548872181, 0.21228070175438596, 0.21328320802005013, 0.2142857142857143, 0.21528822055137845, 0.21629072681704262, 0.21729323308270676, 0.21829573934837093, 0.2192982456140351, 0.22030075187969925, 0.22130325814536342, 0.22230576441102756, 0.22330827067669173, 0.2243107769423559, 0.22531328320802005, 0.22631578947368422, 0.22731829573934836, 0.22832080200501254, 0.2293233082706767, 0.23032581453634085, 0.23132832080200502, 0.23233082706766917, 0.23333333333333334, 0.2343358395989975, 0.23533834586466165, 0.23634085213032582, 0.23734335839598997, 0.23834586466165414, 0.2393483709273183, 0.24035087719298245, 0.24135338345864663, 0.24235588972431077, 0.24335839598997494, 0.2443609022556391, 0.24536340852130326, 0.24636591478696743, 0.24736842105263157, 0.24837092731829574, 0.2493734335839599, 0.25037593984962403, 0.25137844611528826, 0.2523809523809524, 0.25338345864661654, 0.2543859649122807, 0.25538847117794483, 0.25639097744360906, 0.2573934837092732, 0.25839598997493735, 0.2593984962406015, 0.26040100250626563, 0.26140350877192986, 0.262406015037594, 0.26340852130325815, 0.2644110275689223, 0.26541353383458643, 0.26641604010025066, 0.2674185463659148, 0.26842105263157895, 0.2694235588972431, 0.27042606516290724, 0.27142857142857146, 0.2724310776942356, 0.27343358395989975, 0.2744360902255639, 0.27543859649122804, 0.27644110275689227, 0.2774436090225564, 0.27844611528822055, 0.2794486215538847, 0.28045112781954884, 0.28145363408521307, 0.2824561403508772, 0.28345864661654135, 0.2844611528822055, 0.28546365914786964, 0.28646616541353387, 0.287468671679198, 0.28847117794486216, 0.2894736842105263, 0.29047619047619044, 0.29147869674185467, 0.2924812030075188, 0.29348370927318296, 0.29448621553884713, 0.29548872180451125, 0.29649122807017547, 0.2974937343358396, 0.29849624060150376, 0.29949874686716793, 0.30050125313283205, 0.3015037593984963, 0.3025062656641604, 0.30350877192982456, 0.30451127819548873, 0.30551378446115285, 0.3065162907268171, 0.3075187969924812, 0.30852130325814536, 0.30952380952380953, 0.31052631578947365, 0.3115288220551379, 0.312531328320802, 0.31353383458646616, 0.31453634085213034, 0.31553884711779445, 0.3165413533834587, 0.3175438596491228, 0.31854636591478697, 0.31954887218045114, 0.32055137844611525, 0.3215538847117795, 0.3225563909774436, 0.32355889724310777, 0.32456140350877194, 0.32556390977443606, 0.3265664160401003, 0.3275689223057644, 0.32857142857142857, 0.32957393483709274, 0.33057644110275686, 0.3315789473684211, 0.3325814536340852, 0.33358395989974937, 0.33458646616541354, 0.33558897243107766, 0.3365914786967419, 0.337593984962406, 0.3385964912280702, 0.33959899749373434, 0.34060150375939846, 0.3416040100250627, 0.3426065162907268, 0.343609022556391, 0.34461152882205515, 0.34561403508771926, 0.3466165413533835, 0.3476190476190476, 0.3486215538847118, 0.34962406015037595, 0.35062656641604006, 0.3516290726817043, 0.3526315789473684, 0.35363408521303263, 0.35463659147869675, 0.35563909774436087, 0.3566416040100251, 0.3576441102756892, 0.35864661654135344, 0.35964912280701755, 0.36065162907268167, 0.3616541353383459, 0.36265664160401, 0.36365914786967424, 0.36466165413533835, 0.36566416040100247, 0.3666666666666667, 0.3676691729323308, 0.36867167919799504, 0.36967418546365916, 0.37067669172932327, 0.3716791979949875, 0.3726817042606516, 0.37368421052631584, 0.37468671679197996, 0.3756892230576441, 0.3766917293233083, 0.3776942355889724, 0.37869674185463664, 0.37969924812030076, 0.3807017543859649, 0.3817042606516291, 0.3827067669172932, 0.38370927318295744, 0.38471177944862156, 0.3857142857142857, 0.3867167919799499, 0.387719298245614, 0.38872180451127825, 0.38972431077694236, 0.3907268170426065, 0.3917293233082707, 0.3927318295739348, 0.39373433583959905, 0.39473684210526316, 0.3957393483709273, 0.3967418546365915, 0.3977443609022556, 0.39874686716791985, 0.39974937343358397, 0.4007518796992481, 0.4017543859649123, 0.4027568922305764, 0.40375939849624065, 0.40476190476190477, 0.4057644110275689, 0.4067669172932331, 0.4077694235588972, 0.40877192982456145, 0.40977443609022557, 0.4107769423558897, 0.4117794486215539, 0.412781954887218, 0.41378446115288225, 0.41478696741854637, 0.4157894736842105, 0.4167919799498747, 0.41779448621553883, 0.41879699248120306, 0.4197994987468672, 0.4208020050125313, 0.4218045112781955, 0.42280701754385963, 0.42380952380952386, 0.424812030075188, 0.4258145363408521, 0.4268170426065163, 0.42781954887218043, 0.42882205513784466, 0.4298245614035088, 0.4308270676691729, 0.4318295739348371, 0.43283208020050123, 0.43383458646616546, 0.4348370927318296, 0.4358395989974937, 0.4368421052631579, 0.43784461152882204, 0.43884711779448626, 0.4398496240601504, 0.4408521303258145, 0.4418546365914787, 0.44285714285714284, 0.44385964912280707, 0.4448621553884712, 0.4458646616541353, 0.4468671679197995, 0.44786967418546364, 0.44887218045112787, 0.449874686716792, 0.4508771929824561, 0.4518796992481203, 0.45288220551378444, 0.45388471177944867, 0.4548872180451128, 0.4558897243107769, 0.4568922305764411, 0.45789473684210524, 0.45889724310776947, 0.4598997493734336, 0.4609022556390977, 0.46190476190476193, 0.46290726817042605, 0.46390977443609027, 0.4649122807017544, 0.4659147869674185, 0.46691729323308273, 0.46791979949874685, 0.4689223057644111, 0.4699248120300752, 0.4709273182957393, 0.47192982456140353, 0.47293233082706765, 0.4739348370927319, 0.474937343358396, 0.4759398496240601, 0.47694235588972433, 0.47794486215538845, 0.4789473684210527, 0.4799498746867168, 0.4809523809523809, 0.48195488721804514, 0.48295739348370925, 0.4839598997493735, 0.4849624060150376, 0.4859649122807017, 0.48696741854636594, 0.48796992481203005, 0.4889724310776943, 0.4899749373433584, 0.4909774436090225, 0.49197994987468674, 0.49298245614035086, 0.4939849624060151, 0.4949874686716792, 0.4959899749373433, 0.49699248120300754, 0.49799498746867166, 0.4989974937343359, 0.5], 'max_iter': [2000, 2040, 2080, 2120, 2160, 2201, 2241, 2281, 2321, 2361, 2402, 2442, 2482, 2522, 2562, 2603, 2643, 2683, 2723, 2763, 2804, 2844, 2884, 2924, 2964, 3005, 3045, 3085, 3125, 3165, 3206, 3246, 3286, 3326, 3366, 3407, 3447, 3487, 3527, 3567, 3608, 3648, 3688, 3728, 3768, 3809, 3849, 3889, 3929, 3969, 4010, 4050, 4090, 4130, 4170, 4211, 4251, 4291, 4331, 4371, 4412, 4452, 4492, 4532, 4572, 4613, 4653, 4693, 4733, 4773, 4814, 4854, 4894, 4934, 4974, 5015, 5055, 5095, 5135, 5175, 5216, 5256, 5296, 5336, 5376, 5417, 5457, 5497, 5537, 5577, 5618, 5658, 5698, 5738, 5778, 5819, 5859, 5899, 5939, 5979, 6020, 6060, 6100, 6140, 6180, 6221, 6261, 6301, 6341, 6381, 6422, 6462, 6502, 6542, 6582, 6623, 6663, 6703, 6743, 6783, 6824, 6864, 6904, 6944, 6984, 7025, 7065, 7105, 7145, 7185, 7226, 7266, 7306, 7346, 7386, 7427, 7467, 7507, 7547, 7587, 7628, 7668, 7708, 7748, 7788, 7829, 7869, 7909, 7949, 7989, 8030, 8070, 8110, 8150, 8190, 8231, 8271, 8311, 8351, 8391, 8432, 8472, 8512, 8552, 8592, 8633, 8673, 8713, 8753, 8793, 8834, 8874, 8914, 8954, 8994, 9035, 9075, 9115, 9155, 9195, 9236, 9276, 9316, 9356, 9396, 9437, 9477, 9517, 9557, 9597, 9638, 9678, 9718, 9758, 9798, 9839, 9879, 9919, 9959, 10000], 'tol': [0.01, 0.009954773869346734, 0.009909547738693467, 0.0098643216080402, 0.009819095477386935, 0.009773869346733669, 0.009728643216080402, 0.009683417085427136, 0.009638190954773869, 0.009592964824120602, 0.009547738693467337, 0.00950251256281407, 0.009457286432160804, 0.009412060301507538, 0.009366834170854271, 0.009321608040201004, 0.00927638190954774, 0.009231155778894473, 0.009185929648241206, 0.00914070351758794, 0.009095477386934673, 0.009050251256281406, 0.009005025125628141, 0.008959798994974875, 0.008914572864321608, 0.008869346733668342, 0.008824120603015075, 0.008778894472361808, 0.008733668341708543, 0.008688442211055277, 0.00864321608040201, 0.008597989949748744, 0.008552763819095477, 0.00850753768844221, 0.008462311557788945, 0.008417085427135679, 0.008371859296482412, 0.008326633165829146, 0.008281407035175879, 0.008236180904522612, 0.008190954773869347, 0.00814572864321608, 0.008100502512562814, 0.008055276381909547, 0.008010050251256281, 0.007964824120603016, 0.007919597989949748, 0.007874371859296483, 0.007829145728643216, 0.0077839195979899495, 0.007738693467336683, 0.007693467336683416, 0.0076482412060301505, 0.007603015075376885, 0.007557788944723618, 0.0075125628140703515, 0.007467336683417085, 0.007422110552763818, 0.0073768844221105525, 0.007331658291457287, 0.00728643216080402, 0.0072412060301507535, 0.007195979899497487, 0.00715075376884422, 0.0071055276381909544, 0.007060301507537689, 0.007015075376884422, 0.0069698492462311554, 0.006924623115577889, 0.006879396984924622, 0.006834170854271356, 0.006788944723618091, 0.006743718592964824, 0.006698492462311557, 0.006653266331658291, 0.006608040201005024, 0.006562814070351758, 0.006517587939698493, 0.006472361809045226, 0.006427135678391959, 0.006381909547738693, 0.006336683417085426, 0.00629145728643216, 0.006246231155778894, 0.006201005025125628, 0.006155778894472361, 0.006110552763819095, 0.006065326633165829, 0.006020100502512562, 0.005974874371859296, 0.00592964824120603, 0.005884422110552763, 0.005839195979899497, 0.005793969849246231, 0.005748743718592964, 0.005703517587939698, 0.005658291457286432, 0.005613065326633165, 0.005567839195979899, 0.005522613065326632, 0.005477386934673366, 0.0054321608040201, 0.005386934673366833, 0.005341708542713567, 0.005296482412060301, 0.005251256281407034, 0.005206030150753768, 0.005160804020100502, 0.005115577889447235, 0.005070351758793969, 0.005025125628140703, 0.004979899497487436, 0.00493467336683417, 0.004889447236180904, 0.004844221105527637, 0.004798994974874371, 0.004753768844221105, 0.004708542713567838, 0.004663316582914572, 0.004618090452261306, 0.004572864321608039, 0.004527638190954773, 0.004482412060301507, 0.00443718592964824, 0.004391959798994974, 0.004346733668341708, 0.004301507537688441, 0.004256281407035175, 0.004211055276381909, 0.004165829145728642, 0.004120603015075376, 0.00407537688442211, 0.004030150753768843, 0.003984924623115577, 0.003939698492462311, 0.003894472361809044, 0.0038492462311557783, 0.0038040201005025117, 0.003758793969849245, 0.0037135678391959793, 0.0036683417085427127, 0.003623115577889446, 0.0035778894472361803, 0.0035326633165829137, 0.003487437185929647, 0.0034422110552763813, 0.0033969849246231146, 0.003351758793969848, 0.0033065326633165823, 0.0032613065326633156, 0.003216080402010049, 0.0031708542713567833, 0.0031256281407035166, 0.00308040201005025, 0.0030351758793969843, 0.0029899497487437176, 0.002944723618090451, 0.0028994974874371852, 0.0028542713567839186, 0.002809045226130652, 0.0027638190954773854, 0.0027185929648241196, 0.002673366834170853, 0.0026281407035175864, 0.0025829145728643206, 0.002537688442211054, 0.0024924623115577874, 0.0024472361809045216, 0.002402010050251255, 0.0023567839195979884, 0.0023115577889447226, 0.002266331658291456, 0.0022211055276381893, 0.0021758793969849227, 0.002130653266331658, 0.002085427135678391, 0.0020402010050251246, 0.001994974874371858, 0.0019497487437185913, 0.0019045226130653247, 0.0018592964824120598, 0.0018140703517587932, 0.0017688442211055266, 0.00172361809045226, 0.0016783919597989933, 0.0016331658291457267, 0.0015879396984924618, 0.0015427135678391952, 0.0014974874371859286, 0.001452261306532662, 0.0014070351758793953, 0.0013618090452261287, 0.0013165829145728638, 0.0012713567839195972, 0.0012261306532663305, 0.001180904522613064, 0.0011356783919597973, 0.0010904522613065307, 0.001045226130653264, 0.001], 'positive': ['False'], 'copy_X': ['True', 'False'], 'solver': ['auto']}\n"
     ]
    }
   ],
   "source": [
    "max_iter=[int(x) for x in np.linspace(2000, 10000,200)]\n",
    "tol=[float(x) for x in np.linspace(0.01, 0.001,200)]\n",
    "alpha = [float(x) for x in np.linspace(0.1,0.50,400)]\n",
    "positive=['False']\n",
    "copy_X=['True','False']\n",
    "solver=[\"auto\"]\n",
    "\n",
    "random_grid = {\n",
    "               'alpha':alpha,\n",
    "              \n",
    "               'max_iter':max_iter,\n",
    "               'tol':tol,\n",
    "                'positive':positive,\n",
    "                'copy_X':copy_X,\n",
    "                'solver':solver\n",
    "               \n",
    "               \n",
    "                }\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "dcff6032-101e-4f88-b4f3-f34464b8b5d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Ridge() RandomCV Best Params : {'tol': 0.007738693467336683, 'solver': 'auto', 'positive': 'False', 'max_iter': 3567, 'copy_X': 'False', 'alpha': 0.3917293233082707}\n",
      "Ridge() RandomCV Score: 0.8350408062056907\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Final score is  0.8350408062056907\n"
     ]
    }
   ],
   "source": [
    "hyperparameter_tuning(algo=\"Ridge()\",param_grid=random_grid,n_iter=10,cv=5,verbose=2,random_state=42,X_train=X_train,Y_train=Y_train,X_test=X_test,Y_test=Y_test,evaluation_metric=\"r2_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "48b2927c-6780-461a-865a-0dada3e32d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ridge=Ridge()\n",
    "# ridge_random_cv=RandomizedSearchCV(estimator=ridge,param_distributions=random_grid,n_iter=100,cv=5,verbose=0,random_state=100,n_jobs=-1)\n",
    "# ridge_random_cv.fit(X_train,Y_train)\n",
    "\n",
    "# best_params_=ridge_random_cv.best_params_\n",
    "# print(\"RandomCV Best Params :\",best_params_)\n",
    "# best_random_grid=ridge_random_cv.best_estimator_\n",
    "# y_pred9=best_random_grid.predict(X_test)\n",
    "# score_9=r2_score(Y_test,y_pred9)\n",
    "# print(\"RandomCV Score: \",score_9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "c2875580-d424-4c36-8504-41e1ac645c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid9=defaultdict(list)\n",
    "# for val in best_params_:\n",
    "#     param_grid9[val].append(best_params_[val])\n",
    "# print(param_grid9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "48325357-fd66-4ee0-944c-b6295647c4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=Ridge()\n",
    "# grid_search=GridSearchCV(estimator=model,param_grid=param_grid9,cv=5,n_jobs=-1,verbose=3)\n",
    "# grid_search.fit(X_train,Y_train)\n",
    "# print(grid_search.best_estimator_)\n",
    "# best_grid2=grid_search.best_estimator_\n",
    "# final9=best_grid2.predict(X_test)\n",
    "# score_final9=r2_score(Y_test,final9)\n",
    "# print(score_final9)\n",
    "# accuracies[\"Ridge\"]=score_final9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "757341cd-1404-4b86-9799-7cc143a90aac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LinearRegression()': -1.3643518980430038e+23,\n",
       " 'RandomForestRegressor()': 0.8201522653525275,\n",
       " 'SVR()': -7.943707625401863e-05,\n",
       " 'KNeighborsRegressor()': 0.7073273687494936,\n",
       " 'DecisionTreeRegressor()': 0.6699070971484998,\n",
       " 'SGDRegressor()': 0.7848215372436905,\n",
       " 'ElasticNet()': 0.8061969923154417,\n",
       " 'Lasso()': 0.7442522278615189,\n",
       " 'Ridge()': 0.8350408062056907}"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49692bca-f241-40d9-9de6-b6ee7638227a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0714a8-194b-4b89-8bff-44e8c06d935f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5573bcb8-4b0f-4724-a68b-125e5601fb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# sfs1 = SFS(RandomForestRegressor(), \n",
    "#                k_features=(3,len(X_train.columns)), \n",
    "#                forward=True, \n",
    "#                floating=False, \n",
    "#                verbose=1,\n",
    "#                scoring='r2',\n",
    "#                cv=5,\n",
    "#                n_jobs=-1)\n",
    "# sfs1=sfs1.fit(X_train, Y_train)\n",
    "# print(\"sfs1 max score features are :\",sfs1.k_feature_names_)\n",
    "# print(\"sfs1 max score is :\",sfs1.k_score_)\n",
    "# print()\n",
    "# model_=RandomForestRegressor()\n",
    "# model_.fit(X_train.loc[:,list(sfs1.k_feature_names_)],Y_train)\n",
    "# score=model_.score(X_test.loc[:,list(sfs1.k_feature_names_)],Y_test)\n",
    "# print(\"Prediction using selected features is :\",score)\n",
    "# accuracies[\"RandomForestRegressor\"]=score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c50c4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sfs1 = SFS(SVR(), \n",
    "#            k_features=(3,len(X_train.columns)), \n",
    "#            forward=True, \n",
    "#            floating=False, \n",
    "#            verbose=1,\n",
    "#            scoring='r2',\n",
    "#            cv=5,\n",
    "#            n_jobs=-1)\n",
    "# sfs1=sfs1.fit(X_train, Y_train)\n",
    "# print(\"sfs1 max score features are :\",sfs1.k_feature_names_)\n",
    "# print(\"sfs1 max score is :\",sfs1.k_score_)\n",
    "# print()\n",
    "# model_=SVR()\n",
    "# model_.fit(X_train.loc[:,list(sfs1.k_feature_names_)],Y_train)\n",
    "# score=model_.score(X_test.loc[:,list(sfs1.k_feature_names_)],Y_test)\n",
    "# print(\"Prediction using selected features is :\",score)\n",
    "# accuracies[\"SVR\"]=score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8980a5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sfs1 = SFS(KNeighborsRegressor(), \n",
    "#            k_features=(3,len(X_train.columns)), \n",
    "#            forward=True, \n",
    "#            floating=False, \n",
    "#            verbose=1,\n",
    "#            scoring='r2',\n",
    "#            cv=5,\n",
    "#            n_jobs=-1)\n",
    "# sfs1=sfs1.fit(X_train, Y_train)\n",
    "# print(\"sfs1 max score features are :\",sfs1.k_feature_names_)\n",
    "# print(\"sfs1 max score is :\",sfs1.k_score_)\n",
    "# print()\n",
    "# model_=KNeighborsRegressor()\n",
    "# model_.fit(X_train.loc[:,list(sfs1.k_feature_names_)],Y_train)\n",
    "# score=model_.score(X_test.loc[:,list(sfs1.k_feature_names_)],Y_test)\n",
    "# print(\"Prediction using selected features is :\",score)\n",
    "# accuracies[\"KNeighborsRegressor\"]=score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d210de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sfs1 = SFS(DecisionTreeRegressor(), \n",
    "#                k_features=(3,len(X_train.columns)), \n",
    "#                forward=True, \n",
    "#                floating=False, \n",
    "#                verbose=1,\n",
    "#                scoring='r2',\n",
    "#                cv=5,\n",
    "#                n_jobs=-1)\n",
    "# sfs1=sfs1.fit(X_train, Y_train)\n",
    "# print(\"sfs1 max score features are :\",sfs1.k_feature_names_)\n",
    "# print(\"sfs1 max score is :\",sfs1.k_score_)\n",
    "# print()\n",
    "# model_=DecisionTreeRegressor()\n",
    "# model_.fit(X_train.loc[:,list(sfs1.k_feature_names_)],Y_train)\n",
    "# score=model_.score(X_test.loc[:,list(sfs1.k_feature_names_)],Y_test)\n",
    "# print(\"Prediction using selected features is :\",score)\n",
    "# accuracies[\"DecisionTreeRegressor\"]=score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7552b8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sfs1 = SFS(SGDRegressor(), \n",
    "#                k_features=(3,len(X_train.columns)), \n",
    "#                forward=True, \n",
    "#                floating=False, \n",
    "#                verbose=1,\n",
    "#                scoring='r2',\n",
    "#                cv=5,\n",
    "#                n_jobs=-1)\n",
    "# sfs1=sfs1.fit(X_train, Y_train)\n",
    "# print(\"sfs1 max score features are :\",sfs1.k_feature_names_)\n",
    "# print(\"sfs1 max score is :\",sfs1.k_score_)\n",
    "# print()\n",
    "# model_=SGDRegressor()\n",
    "# model_.fit(X_train.loc[:,list(sfs1.k_feature_names_)],Y_train)\n",
    "# score=model_.score(X_test.loc[:,list(sfs1.k_feature_names_)],Y_test)\n",
    "# print(\"Prediction using selected features is :\",score)\n",
    "# accuracies[\"SGDRegressor\"]=score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "e6060cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sfs1 = SFS(ElasticNet(), \n",
    "#                k_features=(3,len(X_train.columns)), \n",
    "#                forward=True, \n",
    "#                floating=False, \n",
    "#                verbose=1,\n",
    "#                scoring='r2',\n",
    "#                cv=5,\n",
    "#                n_jobs=-1)\n",
    "# sfs1=sfs1.fit(X_train, Y_train)\n",
    "# print(\"sfs1 max score features are :\",sfs1.k_feature_names_)\n",
    "# print(\"sfs1 max score is :\",sfs1.k_score_)\n",
    "# print()\n",
    "# model_=ElasticNet()\n",
    "# model_.fit(X_train.loc[:,list(sfs1.k_feature_names_)],Y_train)\n",
    "# score=model_.score(X_test.loc[:,list(sfs1.k_feature_names_)],Y_test)\n",
    "# print(\"Prediction using selected features is :\",score)\n",
    "# accuracies[\"ElasticNet\"]=score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "9caeb8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sfs1 = SFS(Lasso(), \n",
    "#                k_features=(3,len(X_train.columns)), \n",
    "#                forward=True, \n",
    "#                floating=False, \n",
    "#                verbose=1,\n",
    "#                scoring='r2',\n",
    "#                cv=5,\n",
    "#                n_jobs=-1)\n",
    "# sfs1=sfs1.fit(X_train, Y_train)\n",
    "# print(\"sfs1 max score features are :\",sfs1.k_feature_names_)\n",
    "# print(\"sfs1 max score is :\",sfs1.k_score_)\n",
    "# print()\n",
    "# model_=Lasso()\n",
    "# model_.fit(X_train.loc[:,list(sfs1.k_feature_names_)],Y_train)\n",
    "# score=model_.score(X_test.loc[:,list(sfs1.k_feature_names_)],Y_test)\n",
    "# print(\"Prediction using selected features is :\",score)\n",
    "# accuracies[\"Lasso\"]=score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f002ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sfs1 = SFS(Ridge(), \n",
    "#                k_features=(3,len(X_train.columns)), \n",
    "#                forward=True, \n",
    "#                floating=False, \n",
    "#                verbose=1,\n",
    "#                scoring='r2',\n",
    "#                cv=5,\n",
    "#                n_jobs=-1)\n",
    "# sfs1=sfs1.fit(X_train, Y_train)\n",
    "# print(\"sfs1 max score features are :\",sfs1.k_feature_names_)\n",
    "# print(\"sfs1 max score is :\",sfs1.k_score_)\n",
    "# print()\n",
    "# model_=Ridge()\n",
    "# model_.fit(X_train.loc[:,list(sfs1.k_feature_names_)],Y_train)\n",
    "# score=model_.score(X_test.loc[:,list(sfs1.k_feature_names_)],Y_test)\n",
    "# print(\"Prediction using selected features is :\",score)\n",
    "# accuracies[\"Ridge\"]=score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c321e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b21196c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a64d9c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2d9060-53c4-4991-b3e7-b3342b622c6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bdcef6-1147-4b56-b7c0-f56fc4ec2a44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9466320b-145c-4a8a-a347-690994f7e1d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7da7d8-3924-4710-b506-aaf35ac6f7c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
