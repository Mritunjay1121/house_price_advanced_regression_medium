{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "addeba46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler,minmax_scale,StandardScaler\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression,ElasticNet,Lasso,Ridge\n",
    "from sklearn.linear_model import SGDRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "298c7238",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.read_csv(\"house_price_train.csv\")\n",
    "df_train.drop(\"Id\",axis=1,inplace=True) ## reduntatnt\n",
    "output_col=df_train['SalePrice']\n",
    "df_train=df_train.drop('SalePrice',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0a57d23f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>...</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>13175</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9042</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GdPrv</td>\n",
       "      <td>Shed</td>\n",
       "      <td>2500</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0             60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1             20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2             60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3             70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4             60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "...          ...      ...          ...      ...    ...   ...      ...   \n",
       "1455          60       RL         62.0     7917   Pave   NaN      Reg   \n",
       "1456          20       RL         85.0    13175   Pave   NaN      Reg   \n",
       "1457          70       RL         66.0     9042   Pave   NaN      Reg   \n",
       "1458          20       RL         68.0     9717   Pave   NaN      Reg   \n",
       "1459          20       RL         75.0     9937   Pave   NaN      Reg   \n",
       "\n",
       "     LandContour Utilities LotConfig  ... ScreenPorch PoolArea PoolQC  Fence  \\\n",
       "0            Lvl    AllPub    Inside  ...           0        0    NaN    NaN   \n",
       "1            Lvl    AllPub       FR2  ...           0        0    NaN    NaN   \n",
       "2            Lvl    AllPub    Inside  ...           0        0    NaN    NaN   \n",
       "3            Lvl    AllPub    Corner  ...           0        0    NaN    NaN   \n",
       "4            Lvl    AllPub       FR2  ...           0        0    NaN    NaN   \n",
       "...          ...       ...       ...  ...         ...      ...    ...    ...   \n",
       "1455         Lvl    AllPub    Inside  ...           0        0    NaN    NaN   \n",
       "1456         Lvl    AllPub    Inside  ...           0        0    NaN  MnPrv   \n",
       "1457         Lvl    AllPub    Inside  ...           0        0    NaN  GdPrv   \n",
       "1458         Lvl    AllPub    Inside  ...           0        0    NaN    NaN   \n",
       "1459         Lvl    AllPub    Inside  ...           0        0    NaN    NaN   \n",
       "\n",
       "     MiscFeature MiscVal  MoSold  YrSold  SaleType  SaleCondition  \n",
       "0            NaN       0       2    2008        WD         Normal  \n",
       "1            NaN       0       5    2007        WD         Normal  \n",
       "2            NaN       0       9    2008        WD         Normal  \n",
       "3            NaN       0       2    2006        WD        Abnorml  \n",
       "4            NaN       0      12    2008        WD         Normal  \n",
       "...          ...     ...     ...     ...       ...            ...  \n",
       "1455         NaN       0       8    2007        WD         Normal  \n",
       "1456         NaN       0       2    2010        WD         Normal  \n",
       "1457        Shed    2500       5    2010        WD         Normal  \n",
       "1458         NaN       0       4    2010        WD         Normal  \n",
       "1459         NaN       0       6    2008        WD         Normal  \n",
       "\n",
       "[1460 rows x 79 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "5c0c131a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSSubClass         int64\n",
       "MSZoning          object\n",
       "LotFrontage      float64\n",
       "LotArea            int64\n",
       "Street            object\n",
       "                  ...   \n",
       "MiscVal            int64\n",
       "MoSold             int64\n",
       "YrSold             int64\n",
       "SaleType          object\n",
       "SaleCondition     object\n",
       "Length: 79, dtype: object"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3c48be5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>...</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>13175</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9042</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GdPrv</td>\n",
       "      <td>Shed</td>\n",
       "      <td>2500</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0             60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1             20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2             60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3             70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4             60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "...          ...      ...          ...      ...    ...   ...      ...   \n",
       "1455          60       RL         62.0     7917   Pave   NaN      Reg   \n",
       "1456          20       RL         85.0    13175   Pave   NaN      Reg   \n",
       "1457          70       RL         66.0     9042   Pave   NaN      Reg   \n",
       "1458          20       RL         68.0     9717   Pave   NaN      Reg   \n",
       "1459          20       RL         75.0     9937   Pave   NaN      Reg   \n",
       "\n",
       "     LandContour Utilities LotConfig  ... ScreenPorch PoolArea PoolQC  Fence  \\\n",
       "0            Lvl    AllPub    Inside  ...           0        0    NaN    NaN   \n",
       "1            Lvl    AllPub       FR2  ...           0        0    NaN    NaN   \n",
       "2            Lvl    AllPub    Inside  ...           0        0    NaN    NaN   \n",
       "3            Lvl    AllPub    Corner  ...           0        0    NaN    NaN   \n",
       "4            Lvl    AllPub       FR2  ...           0        0    NaN    NaN   \n",
       "...          ...       ...       ...  ...         ...      ...    ...    ...   \n",
       "1455         Lvl    AllPub    Inside  ...           0        0    NaN    NaN   \n",
       "1456         Lvl    AllPub    Inside  ...           0        0    NaN  MnPrv   \n",
       "1457         Lvl    AllPub    Inside  ...           0        0    NaN  GdPrv   \n",
       "1458         Lvl    AllPub    Inside  ...           0        0    NaN    NaN   \n",
       "1459         Lvl    AllPub    Inside  ...           0        0    NaN    NaN   \n",
       "\n",
       "     MiscFeature MiscVal  MoSold  YrSold  SaleType  SaleCondition  \n",
       "0            NaN       0       2    2008        WD         Normal  \n",
       "1            NaN       0       5    2007        WD         Normal  \n",
       "2            NaN       0       9    2008        WD         Normal  \n",
       "3            NaN       0       2    2006        WD        Abnorml  \n",
       "4            NaN       0      12    2008        WD         Normal  \n",
       "...          ...     ...     ...     ...       ...            ...  \n",
       "1455         NaN       0       8    2007        WD         Normal  \n",
       "1456         NaN       0       2    2010        WD         Normal  \n",
       "1457        Shed    2500       5    2010        WD         Normal  \n",
       "1458         NaN       0       4    2010        WD         Normal  \n",
       "1459         NaN       0       6    2008        WD         Normal  \n",
       "\n",
       "[1460 rows x 79 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb1810d",
   "metadata": {},
   "source": [
    "## PREPROCESSING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2362e143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.columns[df_train.isnull().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c24bff98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.heatmap(df_train.isnull(),yticklabels=False,cbar=False,cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "bf96993b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(30,30))\n",
    "# sns.heatmap(pd.concat([df_train,output_col],axis=1).loc[:,list(pd.concat([df_train,output_col],axis=1).select_dtypes(include= np.number).columns)].corr(method='spearman'),annot=True,cmap=\"RdYlGn\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "5e1da23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(nrows = 12, ncols = 3)    # axes is 2d array (3x3)\n",
    "# axes = axes.flatten()         # Convert axes to 1d array of length 9\n",
    "# fig.set_size_inches(30,30)\n",
    "# cols=list(df_train.select_dtypes(include= np.number).columns)\n",
    "# for ax, col in zip(axes, cols):\n",
    "#     print()\n",
    "#     sns.boxplot(df_train[col], ax = ax)\n",
    "#     ax.set_title(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "dbc808bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(nrows = 12, ncols = 3)    # axes is 2d array (3x3)\n",
    "# axes = axes.flatten()         # Convert axes to 1d array of length 9\n",
    "# fig.set_size_inches(30,30)\n",
    "# cols=list(df_train.select_dtypes(include= np.number).columns)\n",
    "# for ax, col in zip(axes, cols):\n",
    "#     print()\n",
    "#     sns.distplot(df_train[col], ax = ax)\n",
    "#     ax.set_title(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "24b291d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def column_with_most_reduntant_null_values(threshold,df_train:pd.DataFrame):\n",
    "    null_cols=[]\n",
    "    for col in df_train.columns:\n",
    "        if df_train[col].isnull().sum()>=(threshold*len(df_train)):\n",
    "            null_cols.append(col)\n",
    "    df_train.drop(null_cols,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6db73cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_with_most_reduntant_null_values(threshold=0.5,df_train=df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "1ed65a14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>...</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>35</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>13175</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9042</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2500</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass MSZoning  LotFrontage  LotArea Street LotShape LandContour  \\\n",
       "0             60       RL         65.0     8450   Pave      Reg         Lvl   \n",
       "1             20       RL         80.0     9600   Pave      Reg         Lvl   \n",
       "2             60       RL         68.0    11250   Pave      IR1         Lvl   \n",
       "3             70       RL         60.0     9550   Pave      IR1         Lvl   \n",
       "4             60       RL         84.0    14260   Pave      IR1         Lvl   \n",
       "...          ...      ...          ...      ...    ...      ...         ...   \n",
       "1455          60       RL         62.0     7917   Pave      Reg         Lvl   \n",
       "1456          20       RL         85.0    13175   Pave      Reg         Lvl   \n",
       "1457          70       RL         66.0     9042   Pave      Reg         Lvl   \n",
       "1458          20       RL         68.0     9717   Pave      Reg         Lvl   \n",
       "1459          20       RL         75.0     9937   Pave      Reg         Lvl   \n",
       "\n",
       "     Utilities LotConfig LandSlope  ... OpenPorchSF EnclosedPorch 3SsnPorch  \\\n",
       "0       AllPub    Inside       Gtl  ...          61             0         0   \n",
       "1       AllPub       FR2       Gtl  ...           0             0         0   \n",
       "2       AllPub    Inside       Gtl  ...          42             0         0   \n",
       "3       AllPub    Corner       Gtl  ...          35           272         0   \n",
       "4       AllPub       FR2       Gtl  ...          84             0         0   \n",
       "...        ...       ...       ...  ...         ...           ...       ...   \n",
       "1455    AllPub    Inside       Gtl  ...          40             0         0   \n",
       "1456    AllPub    Inside       Gtl  ...           0             0         0   \n",
       "1457    AllPub    Inside       Gtl  ...          60             0         0   \n",
       "1458    AllPub    Inside       Gtl  ...           0           112         0   \n",
       "1459    AllPub    Inside       Gtl  ...          68             0         0   \n",
       "\n",
       "     ScreenPorch PoolArea  MiscVal  MoSold  YrSold  SaleType SaleCondition  \n",
       "0              0        0        0       2    2008        WD        Normal  \n",
       "1              0        0        0       5    2007        WD        Normal  \n",
       "2              0        0        0       9    2008        WD        Normal  \n",
       "3              0        0        0       2    2006        WD       Abnorml  \n",
       "4              0        0        0      12    2008        WD        Normal  \n",
       "...          ...      ...      ...     ...     ...       ...           ...  \n",
       "1455           0        0        0       8    2007        WD        Normal  \n",
       "1456           0        0        0       2    2010        WD        Normal  \n",
       "1457           0        0     2500       5    2010        WD        Normal  \n",
       "1458           0        0        0       4    2010        WD        Normal  \n",
       "1459           0        0        0       6    2008        WD        Normal  \n",
       "\n",
       "[1460 rows x 75 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7db7fe1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_cols=list(df_train.select_dtypes(include= np.number).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "45120957",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols=list(df_train.select_dtypes(exclude= np.number).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4308bada",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_correlated=dict()\n",
    "for col1 in continuous_cols:\n",
    "    for col2 in continuous_cols:\n",
    "        if col1!=col2 and abs(df_train[col1].corr(df_train[col2],method='spearman'))>=0.80:\n",
    "            if (col1 not in most_correlated) and (col2 not in most_correlated):\n",
    "                most_correlated[col1]=col2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5007bc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop(columns=list(most_correlated),axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f8e886ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_null_values(for_numerical_cols:str,for_categorical_cols:str,df_train):\n",
    "    for cols in df_train.columns:\n",
    "        if df_train[cols].dtype==\"int64\" or df_train[cols].dtype==\"float64\":\n",
    "            if for_numerical_cols==\"median\":\n",
    "                median_=df_train[cols].median()\n",
    "                df_train[cols].fillna(median_,inplace=True)\n",
    "        elif df_train[cols].dtype==\"object\":\n",
    "            if for_categorical_cols==\"most_frequent\":\n",
    "                d=list(df_train[cols].value_counts().index) # most frequent\n",
    "                df_train[cols].fillna(d[0],inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c650d76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_null_values(for_numerical_cols=\"median\",for_categorical_cols=\"most_frequent\",df_train=df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "13f5495b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_train.columns:\n",
    "    if df_train[col].isnull().sum()>(0):\n",
    "\n",
    "        print(col,df_train[col].isnull().sum(),df_train[col].dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "fcb707f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_cols=list(df_train.select_dtypes(include= np.number).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "5db0ff8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols=list(df_train.select_dtypes(exclude= np.number).columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037fd6a6-16b3-4231-9a17-f0168da59a19",
   "metadata": {},
   "source": [
    "Here we are encoding our categorical columns using 'one_hot_encoding' as a strategy. We will be experimenting other strategies later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "2a741245",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def encoding_categorical_cols(df_train:pd.DataFrame,categorical_columns:list,strategy:str):\n",
    "    df_categorical=pd.DataFrame(df_train.loc[:,categorical_columns])\n",
    "    if strategy==\"labelencoder\":\n",
    "        for col in list(df_categorical.columns):\n",
    "            cat=[]\n",
    "            d={}\n",
    "\n",
    "            cat.append([df_categorical[col].value_counts().index,len(df_categorical[col].value_counts().index)])\n",
    "\n",
    "            for j in range(int(cat[0][1])):\n",
    "                d[str(cat[0][0][j])]=j\n",
    "            df_categorical[col]=df_categorical[col].map(d)\n",
    "        df_train.drop(categorical_columns,axis=1,inplace=True)\n",
    "        \n",
    "        df_train=pd.concat([df_train,df_categorical],axis=1)\n",
    "        \n",
    "    if strategy==\"onehotencoder\":\n",
    "        one_hot_encoded=pd.get_dummies(df_categorical)\n",
    "        # print(one_hot_encoded)\n",
    "        df_train.drop(categorical_columns,axis=1,inplace=True)\n",
    "        df_train=pd.concat([df_train,one_hot_encoded],axis=1)\n",
    "    return df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "bb34ffe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=encoding_categorical_cols(df_train=df_train,categorical_columns=categorical_cols,strategy=\"onehotencoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "adc20103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>...</th>\n",
       "      <th>SaleType_ConLw</th>\n",
       "      <th>SaleType_New</th>\n",
       "      <th>SaleType_Oth</th>\n",
       "      <th>SaleType_WD</th>\n",
       "      <th>SaleCondition_Abnorml</th>\n",
       "      <th>SaleCondition_AdjLand</th>\n",
       "      <th>SaleCondition_Alloca</th>\n",
       "      <th>SaleCondition_Family</th>\n",
       "      <th>SaleCondition_Normal</th>\n",
       "      <th>SaleCondition_Partial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>196.0</td>\n",
       "      <td>706</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978</td>\n",
       "      <td>0</td>\n",
       "      <td>284</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2002</td>\n",
       "      <td>162.0</td>\n",
       "      <td>486</td>\n",
       "      <td>0</td>\n",
       "      <td>434</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216</td>\n",
       "      <td>0</td>\n",
       "      <td>540</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>350.0</td>\n",
       "      <td>655</td>\n",
       "      <td>0</td>\n",
       "      <td>490</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>60</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>953</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>20</td>\n",
       "      <td>85.0</td>\n",
       "      <td>13175</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1988</td>\n",
       "      <td>119.0</td>\n",
       "      <td>790</td>\n",
       "      <td>163</td>\n",
       "      <td>589</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>70</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9042</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>275</td>\n",
       "      <td>0</td>\n",
       "      <td>877</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>20</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49</td>\n",
       "      <td>1029</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>20</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>830</td>\n",
       "      <td>290</td>\n",
       "      <td>136</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 271 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  \\\n",
       "0             60         65.0     8450            7            5   \n",
       "1             20         80.0     9600            6            8   \n",
       "2             60         68.0    11250            7            5   \n",
       "3             70         60.0     9550            7            5   \n",
       "4             60         84.0    14260            8            5   \n",
       "...          ...          ...      ...          ...          ...   \n",
       "1455          60         62.0     7917            6            5   \n",
       "1456          20         85.0    13175            6            6   \n",
       "1457          70         66.0     9042            7            9   \n",
       "1458          20         68.0     9717            5            6   \n",
       "1459          20         75.0     9937            5            6   \n",
       "\n",
       "      YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  BsmtUnfSF  ...  \\\n",
       "0             2003       196.0         706           0        150  ...   \n",
       "1             1976         0.0         978           0        284  ...   \n",
       "2             2002       162.0         486           0        434  ...   \n",
       "3             1970         0.0         216           0        540  ...   \n",
       "4             2000       350.0         655           0        490  ...   \n",
       "...            ...         ...         ...         ...        ...  ...   \n",
       "1455          2000         0.0           0           0        953  ...   \n",
       "1456          1988       119.0         790         163        589  ...   \n",
       "1457          2006         0.0         275           0        877  ...   \n",
       "1458          1996         0.0          49        1029          0  ...   \n",
       "1459          1965         0.0         830         290        136  ...   \n",
       "\n",
       "      SaleType_ConLw  SaleType_New  SaleType_Oth  SaleType_WD  \\\n",
       "0                  0             0             0            1   \n",
       "1                  0             0             0            1   \n",
       "2                  0             0             0            1   \n",
       "3                  0             0             0            1   \n",
       "4                  0             0             0            1   \n",
       "...              ...           ...           ...          ...   \n",
       "1455               0             0             0            1   \n",
       "1456               0             0             0            1   \n",
       "1457               0             0             0            1   \n",
       "1458               0             0             0            1   \n",
       "1459               0             0             0            1   \n",
       "\n",
       "      SaleCondition_Abnorml  SaleCondition_AdjLand  SaleCondition_Alloca  \\\n",
       "0                         0                      0                     0   \n",
       "1                         0                      0                     0   \n",
       "2                         0                      0                     0   \n",
       "3                         1                      0                     0   \n",
       "4                         0                      0                     0   \n",
       "...                     ...                    ...                   ...   \n",
       "1455                      0                      0                     0   \n",
       "1456                      0                      0                     0   \n",
       "1457                      0                      0                     0   \n",
       "1458                      0                      0                     0   \n",
       "1459                      0                      0                     0   \n",
       "\n",
       "      SaleCondition_Family  SaleCondition_Normal  SaleCondition_Partial  \n",
       "0                        0                     1                      0  \n",
       "1                        0                     1                      0  \n",
       "2                        0                     1                      0  \n",
       "3                        0                     0                      0  \n",
       "4                        0                     1                      0  \n",
       "...                    ...                   ...                    ...  \n",
       "1455                     0                     1                      0  \n",
       "1456                     0                     1                      0  \n",
       "1457                     0                     1                      0  \n",
       "1458                     0                     1                      0  \n",
       "1459                     0                     1                      0  \n",
       "\n",
       "[1460 rows x 271 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e63bcfff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>...</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>56.897260</td>\n",
       "      <td>69.863699</td>\n",
       "      <td>10516.828082</td>\n",
       "      <td>6.099315</td>\n",
       "      <td>5.575342</td>\n",
       "      <td>1984.865753</td>\n",
       "      <td>103.117123</td>\n",
       "      <td>443.639726</td>\n",
       "      <td>46.549315</td>\n",
       "      <td>567.240411</td>\n",
       "      <td>...</td>\n",
       "      <td>472.980137</td>\n",
       "      <td>94.244521</td>\n",
       "      <td>46.660274</td>\n",
       "      <td>21.954110</td>\n",
       "      <td>3.409589</td>\n",
       "      <td>15.060959</td>\n",
       "      <td>2.758904</td>\n",
       "      <td>43.489041</td>\n",
       "      <td>6.321918</td>\n",
       "      <td>2007.815753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>42.300571</td>\n",
       "      <td>22.027677</td>\n",
       "      <td>9981.264932</td>\n",
       "      <td>1.382997</td>\n",
       "      <td>1.112799</td>\n",
       "      <td>20.645407</td>\n",
       "      <td>180.731373</td>\n",
       "      <td>456.098091</td>\n",
       "      <td>161.319273</td>\n",
       "      <td>441.866955</td>\n",
       "      <td>...</td>\n",
       "      <td>213.804841</td>\n",
       "      <td>125.338794</td>\n",
       "      <td>66.256028</td>\n",
       "      <td>61.119149</td>\n",
       "      <td>29.317331</td>\n",
       "      <td>55.757415</td>\n",
       "      <td>40.177307</td>\n",
       "      <td>496.123024</td>\n",
       "      <td>2.703626</td>\n",
       "      <td>1.328095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1300.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2006.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>7553.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1967.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>223.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>334.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2007.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>9478.500000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>383.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>477.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2008.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>70.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>11601.500000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>164.250000</td>\n",
       "      <td>712.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>808.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>576.000000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2009.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>190.000000</td>\n",
       "      <td>313.000000</td>\n",
       "      <td>215245.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>5644.000000</td>\n",
       "      <td>1474.000000</td>\n",
       "      <td>2336.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1418.000000</td>\n",
       "      <td>857.000000</td>\n",
       "      <td>547.000000</td>\n",
       "      <td>552.000000</td>\n",
       "      <td>508.000000</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>738.000000</td>\n",
       "      <td>15500.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        MSSubClass  LotFrontage        LotArea  OverallQual  OverallCond  \\\n",
       "count  1460.000000  1460.000000    1460.000000  1460.000000  1460.000000   \n",
       "mean     56.897260    69.863699   10516.828082     6.099315     5.575342   \n",
       "std      42.300571    22.027677    9981.264932     1.382997     1.112799   \n",
       "min      20.000000    21.000000    1300.000000     1.000000     1.000000   \n",
       "25%      20.000000    60.000000    7553.500000     5.000000     5.000000   \n",
       "50%      50.000000    69.000000    9478.500000     6.000000     5.000000   \n",
       "75%      70.000000    79.000000   11601.500000     7.000000     6.000000   \n",
       "max     190.000000   313.000000  215245.000000    10.000000     9.000000   \n",
       "\n",
       "       YearRemodAdd   MasVnrArea   BsmtFinSF1   BsmtFinSF2    BsmtUnfSF  ...  \\\n",
       "count   1460.000000  1460.000000  1460.000000  1460.000000  1460.000000  ...   \n",
       "mean    1984.865753   103.117123   443.639726    46.549315   567.240411  ...   \n",
       "std       20.645407   180.731373   456.098091   161.319273   441.866955  ...   \n",
       "min     1950.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "25%     1967.000000     0.000000     0.000000     0.000000   223.000000  ...   \n",
       "50%     1994.000000     0.000000   383.500000     0.000000   477.500000  ...   \n",
       "75%     2004.000000   164.250000   712.250000     0.000000   808.000000  ...   \n",
       "max     2010.000000  1600.000000  5644.000000  1474.000000  2336.000000  ...   \n",
       "\n",
       "        GarageArea   WoodDeckSF  OpenPorchSF  EnclosedPorch    3SsnPorch  \\\n",
       "count  1460.000000  1460.000000  1460.000000    1460.000000  1460.000000   \n",
       "mean    472.980137    94.244521    46.660274      21.954110     3.409589   \n",
       "std     213.804841   125.338794    66.256028      61.119149    29.317331   \n",
       "min       0.000000     0.000000     0.000000       0.000000     0.000000   \n",
       "25%     334.500000     0.000000     0.000000       0.000000     0.000000   \n",
       "50%     480.000000     0.000000    25.000000       0.000000     0.000000   \n",
       "75%     576.000000   168.000000    68.000000       0.000000     0.000000   \n",
       "max    1418.000000   857.000000   547.000000     552.000000   508.000000   \n",
       "\n",
       "       ScreenPorch     PoolArea       MiscVal       MoSold       YrSold  \n",
       "count  1460.000000  1460.000000   1460.000000  1460.000000  1460.000000  \n",
       "mean     15.060959     2.758904     43.489041     6.321918  2007.815753  \n",
       "std      55.757415    40.177307    496.123024     2.703626     1.328095  \n",
       "min       0.000000     0.000000      0.000000     1.000000  2006.000000  \n",
       "25%       0.000000     0.000000      0.000000     5.000000  2007.000000  \n",
       "50%       0.000000     0.000000      0.000000     6.000000  2008.000000  \n",
       "75%       0.000000     0.000000      0.000000     8.000000  2009.000000  \n",
       "max     480.000000   738.000000  15500.000000    12.000000  2010.000000  \n",
       "\n",
       "[8 rows x 32 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.loc[:,continuous_cols].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f1709177",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_train.columns:\n",
    "    if df_train[col].isnull().sum()>0:\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf599849-f69c-4693-9e61-9db515d6ab51",
   "metadata": {},
   "source": [
    "Since in previous model we tried min max scaler here we will try Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "152a28be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>...</th>\n",
       "      <th>SaleType_ConLw</th>\n",
       "      <th>SaleType_New</th>\n",
       "      <th>SaleType_Oth</th>\n",
       "      <th>SaleType_WD</th>\n",
       "      <th>SaleCondition_Abnorml</th>\n",
       "      <th>SaleCondition_AdjLand</th>\n",
       "      <th>SaleCondition_Alloca</th>\n",
       "      <th>SaleCondition_Family</th>\n",
       "      <th>SaleCondition_Normal</th>\n",
       "      <th>SaleCondition_Partial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.073375</td>\n",
       "      <td>-0.220875</td>\n",
       "      <td>-0.207142</td>\n",
       "      <td>0.651479</td>\n",
       "      <td>-0.517200</td>\n",
       "      <td>0.878668</td>\n",
       "      <td>0.514104</td>\n",
       "      <td>0.575425</td>\n",
       "      <td>-0.288653</td>\n",
       "      <td>-0.944591</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058621</td>\n",
       "      <td>-0.301962</td>\n",
       "      <td>-0.045376</td>\n",
       "      <td>0.390293</td>\n",
       "      <td>-0.272616</td>\n",
       "      <td>-0.052414</td>\n",
       "      <td>-0.091035</td>\n",
       "      <td>-0.117851</td>\n",
       "      <td>0.467651</td>\n",
       "      <td>-0.305995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.872563</td>\n",
       "      <td>0.460320</td>\n",
       "      <td>-0.091886</td>\n",
       "      <td>-0.071836</td>\n",
       "      <td>2.179628</td>\n",
       "      <td>-0.429577</td>\n",
       "      <td>-0.570750</td>\n",
       "      <td>1.171992</td>\n",
       "      <td>-0.288653</td>\n",
       "      <td>-0.641228</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058621</td>\n",
       "      <td>-0.301962</td>\n",
       "      <td>-0.045376</td>\n",
       "      <td>0.390293</td>\n",
       "      <td>-0.272616</td>\n",
       "      <td>-0.052414</td>\n",
       "      <td>-0.091035</td>\n",
       "      <td>-0.117851</td>\n",
       "      <td>0.467651</td>\n",
       "      <td>-0.305995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.073375</td>\n",
       "      <td>-0.084636</td>\n",
       "      <td>0.073480</td>\n",
       "      <td>0.651479</td>\n",
       "      <td>-0.517200</td>\n",
       "      <td>0.830215</td>\n",
       "      <td>0.325915</td>\n",
       "      <td>0.092907</td>\n",
       "      <td>-0.288653</td>\n",
       "      <td>-0.301643</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058621</td>\n",
       "      <td>-0.301962</td>\n",
       "      <td>-0.045376</td>\n",
       "      <td>0.390293</td>\n",
       "      <td>-0.272616</td>\n",
       "      <td>-0.052414</td>\n",
       "      <td>-0.091035</td>\n",
       "      <td>-0.117851</td>\n",
       "      <td>0.467651</td>\n",
       "      <td>-0.305995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.309859</td>\n",
       "      <td>-0.447940</td>\n",
       "      <td>-0.096897</td>\n",
       "      <td>0.651479</td>\n",
       "      <td>-0.517200</td>\n",
       "      <td>-0.720298</td>\n",
       "      <td>-0.570750</td>\n",
       "      <td>-0.499274</td>\n",
       "      <td>-0.288653</td>\n",
       "      <td>-0.061670</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058621</td>\n",
       "      <td>-0.301962</td>\n",
       "      <td>-0.045376</td>\n",
       "      <td>0.390293</td>\n",
       "      <td>3.668167</td>\n",
       "      <td>-0.052414</td>\n",
       "      <td>-0.091035</td>\n",
       "      <td>-0.117851</td>\n",
       "      <td>-2.138345</td>\n",
       "      <td>-0.305995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.073375</td>\n",
       "      <td>0.641972</td>\n",
       "      <td>0.375148</td>\n",
       "      <td>1.374795</td>\n",
       "      <td>-0.517200</td>\n",
       "      <td>0.733308</td>\n",
       "      <td>1.366489</td>\n",
       "      <td>0.463568</td>\n",
       "      <td>-0.288653</td>\n",
       "      <td>-0.174865</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058621</td>\n",
       "      <td>-0.301962</td>\n",
       "      <td>-0.045376</td>\n",
       "      <td>0.390293</td>\n",
       "      <td>-0.272616</td>\n",
       "      <td>-0.052414</td>\n",
       "      <td>-0.091035</td>\n",
       "      <td>-0.117851</td>\n",
       "      <td>0.467651</td>\n",
       "      <td>-0.305995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>0.073375</td>\n",
       "      <td>-0.357114</td>\n",
       "      <td>-0.260560</td>\n",
       "      <td>-0.071836</td>\n",
       "      <td>-0.517200</td>\n",
       "      <td>0.733308</td>\n",
       "      <td>-0.570750</td>\n",
       "      <td>-0.973018</td>\n",
       "      <td>-0.288653</td>\n",
       "      <td>0.873321</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058621</td>\n",
       "      <td>-0.301962</td>\n",
       "      <td>-0.045376</td>\n",
       "      <td>0.390293</td>\n",
       "      <td>-0.272616</td>\n",
       "      <td>-0.052414</td>\n",
       "      <td>-0.091035</td>\n",
       "      <td>-0.117851</td>\n",
       "      <td>0.467651</td>\n",
       "      <td>-0.305995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>-0.872563</td>\n",
       "      <td>0.687385</td>\n",
       "      <td>0.266407</td>\n",
       "      <td>-0.071836</td>\n",
       "      <td>0.381743</td>\n",
       "      <td>0.151865</td>\n",
       "      <td>0.087911</td>\n",
       "      <td>0.759659</td>\n",
       "      <td>0.722112</td>\n",
       "      <td>0.049262</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058621</td>\n",
       "      <td>-0.301962</td>\n",
       "      <td>-0.045376</td>\n",
       "      <td>0.390293</td>\n",
       "      <td>-0.272616</td>\n",
       "      <td>-0.052414</td>\n",
       "      <td>-0.091035</td>\n",
       "      <td>-0.117851</td>\n",
       "      <td>0.467651</td>\n",
       "      <td>-0.305995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>0.309859</td>\n",
       "      <td>-0.175462</td>\n",
       "      <td>-0.147810</td>\n",
       "      <td>0.651479</td>\n",
       "      <td>3.078570</td>\n",
       "      <td>1.024029</td>\n",
       "      <td>-0.570750</td>\n",
       "      <td>-0.369871</td>\n",
       "      <td>-0.288653</td>\n",
       "      <td>0.701265</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058621</td>\n",
       "      <td>-0.301962</td>\n",
       "      <td>-0.045376</td>\n",
       "      <td>0.390293</td>\n",
       "      <td>-0.272616</td>\n",
       "      <td>-0.052414</td>\n",
       "      <td>-0.091035</td>\n",
       "      <td>-0.117851</td>\n",
       "      <td>0.467651</td>\n",
       "      <td>-0.305995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>-0.872563</td>\n",
       "      <td>-0.084636</td>\n",
       "      <td>-0.080160</td>\n",
       "      <td>-0.795151</td>\n",
       "      <td>0.381743</td>\n",
       "      <td>0.539493</td>\n",
       "      <td>-0.570750</td>\n",
       "      <td>-0.865548</td>\n",
       "      <td>6.092188</td>\n",
       "      <td>-1.284176</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058621</td>\n",
       "      <td>-0.301962</td>\n",
       "      <td>-0.045376</td>\n",
       "      <td>0.390293</td>\n",
       "      <td>-0.272616</td>\n",
       "      <td>-0.052414</td>\n",
       "      <td>-0.091035</td>\n",
       "      <td>-0.117851</td>\n",
       "      <td>0.467651</td>\n",
       "      <td>-0.305995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>-0.872563</td>\n",
       "      <td>0.233255</td>\n",
       "      <td>-0.058112</td>\n",
       "      <td>-0.795151</td>\n",
       "      <td>0.381743</td>\n",
       "      <td>-0.962566</td>\n",
       "      <td>-0.570750</td>\n",
       "      <td>0.847389</td>\n",
       "      <td>1.509640</td>\n",
       "      <td>-0.976285</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058621</td>\n",
       "      <td>-0.301962</td>\n",
       "      <td>-0.045376</td>\n",
       "      <td>0.390293</td>\n",
       "      <td>-0.272616</td>\n",
       "      <td>-0.052414</td>\n",
       "      <td>-0.091035</td>\n",
       "      <td>-0.117851</td>\n",
       "      <td>0.467651</td>\n",
       "      <td>-0.305995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 271 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass  LotFrontage   LotArea  OverallQual  OverallCond  \\\n",
       "0       0.073375    -0.220875 -0.207142     0.651479    -0.517200   \n",
       "1      -0.872563     0.460320 -0.091886    -0.071836     2.179628   \n",
       "2       0.073375    -0.084636  0.073480     0.651479    -0.517200   \n",
       "3       0.309859    -0.447940 -0.096897     0.651479    -0.517200   \n",
       "4       0.073375     0.641972  0.375148     1.374795    -0.517200   \n",
       "...          ...          ...       ...          ...          ...   \n",
       "1455    0.073375    -0.357114 -0.260560    -0.071836    -0.517200   \n",
       "1456   -0.872563     0.687385  0.266407    -0.071836     0.381743   \n",
       "1457    0.309859    -0.175462 -0.147810     0.651479     3.078570   \n",
       "1458   -0.872563    -0.084636 -0.080160    -0.795151     0.381743   \n",
       "1459   -0.872563     0.233255 -0.058112    -0.795151     0.381743   \n",
       "\n",
       "      YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  BsmtUnfSF  ...  \\\n",
       "0         0.878668    0.514104    0.575425   -0.288653  -0.944591  ...   \n",
       "1        -0.429577   -0.570750    1.171992   -0.288653  -0.641228  ...   \n",
       "2         0.830215    0.325915    0.092907   -0.288653  -0.301643  ...   \n",
       "3        -0.720298   -0.570750   -0.499274   -0.288653  -0.061670  ...   \n",
       "4         0.733308    1.366489    0.463568   -0.288653  -0.174865  ...   \n",
       "...            ...         ...         ...         ...        ...  ...   \n",
       "1455      0.733308   -0.570750   -0.973018   -0.288653   0.873321  ...   \n",
       "1456      0.151865    0.087911    0.759659    0.722112   0.049262  ...   \n",
       "1457      1.024029   -0.570750   -0.369871   -0.288653   0.701265  ...   \n",
       "1458      0.539493   -0.570750   -0.865548    6.092188  -1.284176  ...   \n",
       "1459     -0.962566   -0.570750    0.847389    1.509640  -0.976285  ...   \n",
       "\n",
       "      SaleType_ConLw  SaleType_New  SaleType_Oth  SaleType_WD  \\\n",
       "0          -0.058621     -0.301962     -0.045376     0.390293   \n",
       "1          -0.058621     -0.301962     -0.045376     0.390293   \n",
       "2          -0.058621     -0.301962     -0.045376     0.390293   \n",
       "3          -0.058621     -0.301962     -0.045376     0.390293   \n",
       "4          -0.058621     -0.301962     -0.045376     0.390293   \n",
       "...              ...           ...           ...          ...   \n",
       "1455       -0.058621     -0.301962     -0.045376     0.390293   \n",
       "1456       -0.058621     -0.301962     -0.045376     0.390293   \n",
       "1457       -0.058621     -0.301962     -0.045376     0.390293   \n",
       "1458       -0.058621     -0.301962     -0.045376     0.390293   \n",
       "1459       -0.058621     -0.301962     -0.045376     0.390293   \n",
       "\n",
       "      SaleCondition_Abnorml  SaleCondition_AdjLand  SaleCondition_Alloca  \\\n",
       "0                 -0.272616              -0.052414             -0.091035   \n",
       "1                 -0.272616              -0.052414             -0.091035   \n",
       "2                 -0.272616              -0.052414             -0.091035   \n",
       "3                  3.668167              -0.052414             -0.091035   \n",
       "4                 -0.272616              -0.052414             -0.091035   \n",
       "...                     ...                    ...                   ...   \n",
       "1455              -0.272616              -0.052414             -0.091035   \n",
       "1456              -0.272616              -0.052414             -0.091035   \n",
       "1457              -0.272616              -0.052414             -0.091035   \n",
       "1458              -0.272616              -0.052414             -0.091035   \n",
       "1459              -0.272616              -0.052414             -0.091035   \n",
       "\n",
       "      SaleCondition_Family  SaleCondition_Normal  SaleCondition_Partial  \n",
       "0                -0.117851              0.467651              -0.305995  \n",
       "1                -0.117851              0.467651              -0.305995  \n",
       "2                -0.117851              0.467651              -0.305995  \n",
       "3                -0.117851             -2.138345              -0.305995  \n",
       "4                -0.117851              0.467651              -0.305995  \n",
       "...                    ...                   ...                    ...  \n",
       "1455             -0.117851              0.467651              -0.305995  \n",
       "1456             -0.117851              0.467651              -0.305995  \n",
       "1457             -0.117851              0.467651              -0.305995  \n",
       "1458             -0.117851              0.467651              -0.305995  \n",
       "1459             -0.117851              0.467651              -0.305995  \n",
       "\n",
       "[1460 rows x 271 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler=StandardScaler()\n",
    "df_train=pd.DataFrame(scaler.fit_transform(df_train),columns=df_train.columns)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "589aafd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df_train\n",
    "Y=output_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "00b848d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      1460.000000\n",
       "mean     180921.195890\n",
       "std       79442.502883\n",
       "min       34900.000000\n",
       "25%      129975.000000\n",
       "50%      163000.000000\n",
       "75%      214000.000000\n",
       "max      755000.000000\n",
       "Name: SalePrice, dtype: float64"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "8fd67785",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_accuracies={}\n",
    "highest_accuracies={}\n",
    "algorithms_tested=[\"LinearRegression()\",\"RandomForestRegressor()\",\"SVR()\",\"KNeighborsRegressor()\",\"SGDRegressor()\",\"DecisionTreeRegressor()\",\"ElasticNet()\",\"Lasso()\",\"Ridge()\"]\n",
    "for al in algorithms_tested:\n",
    "    avg_accuracies[al]=0\n",
    "    highest_accuracies[al]=float('-inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "9bda032f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def algo_testing(algo:str,test_size:float,X,Y,evaluation_metric:str,random_state,shuffle):\n",
    "    model=eval(algo)\n",
    "    evaluation_metric=eval(evaluation_metric)\n",
    "    X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=random_state,shuffle=shuffle)\n",
    "   \n",
    "    model.fit(X_train,Y_train)\n",
    "    predicted=model.predict(X_test)\n",
    "    \n",
    "    r2=evaluation_metric(Y_test, predicted)\n",
    "    print(f\"Testing r2_score of {model} is \",r2)\n",
    "    print(f\"Training r2_score of {model} is \", model.score(X_train,Y_train))\n",
    "    if highest_accuracies[algo]<r2:\n",
    "        \n",
    "        highest_accuracies[algo]=r2\n",
    "    avg_accuracies[algo]+=r2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "f4ef88bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of LinearRegression() is  -1.539751037825976e+21\n",
      "Training r2_score of LinearRegression() is  0.9345893825769673\n",
      "Testing r2_score of LinearRegression() is  -1.7128141859805561e+22\n",
      "Training r2_score of LinearRegression() is  0.9256930450748304\n",
      "Testing r2_score of LinearRegression() is  -5.232635840790468e+21\n",
      "Training r2_score of LinearRegression() is  0.9385576050650912\n",
      "Testing r2_score of LinearRegression() is  -1.7197027197530286e+20\n",
      "Training r2_score of LinearRegression() is  0.9304342992356781\n",
      "Testing r2_score of LinearRegression() is  -1.0373310492970141e+26\n",
      "Training r2_score of LinearRegression() is  0.9324405395365196\n",
      "Testing r2_score of LinearRegression() is  -1.508357946968199e+21\n",
      "Training r2_score of LinearRegression() is  0.9433138059364679\n",
      "Testing r2_score of LinearRegression() is  -4.066621638023612e+23\n",
      "Training r2_score of LinearRegression() is  0.9332922152627217\n",
      "Testing r2_score of LinearRegression() is  -2.2422126407348416e+25\n",
      "Training r2_score of LinearRegression() is  0.9401482257044744\n",
      "Testing r2_score of LinearRegression() is  -1.1894754917472301e+26\n",
      "Training r2_score of LinearRegression() is  0.9290227747288025\n",
      "Testing r2_score of LinearRegression() is  -7.6455027498081125e+25\n",
      "Training r2_score of LinearRegression() is  0.9368786989090876\n",
      "Testing r2_score of LinearRegression() is  -4.981588829115236e+21\n",
      "Training r2_score of LinearRegression() is  0.9316616280729288\n",
      "Testing r2_score of LinearRegression() is  -3.3388304190910285e+23\n",
      "Training r2_score of LinearRegression() is  0.9432639902951762\n",
      "Testing r2_score of LinearRegression() is  -9.173302650618278e+24\n",
      "Training r2_score of LinearRegression() is  0.9345638042964985\n",
      "Testing r2_score of LinearRegression() is  -2.306902518477235e+18\n",
      "Training r2_score of LinearRegression() is  0.9356024594329506\n",
      "Testing r2_score of LinearRegression() is  -5.114908154665286e+24\n",
      "Training r2_score of LinearRegression() is  0.942490202582533\n",
      "Testing r2_score of LinearRegression() is  -2.757250482470065e+23\n",
      "Training r2_score of LinearRegression() is  0.9409227059256052\n",
      "Testing r2_score of LinearRegression() is  -3.6845632419780888e+25\n",
      "Training r2_score of LinearRegression() is  0.9416529720813358\n",
      "Testing r2_score of LinearRegression() is  -1.8565405781597627e+25\n",
      "Training r2_score of LinearRegression() is  0.9381095171563872\n",
      "Testing r2_score of LinearRegression() is  -2.6067296025673214e+21\n",
      "Training r2_score of LinearRegression() is  0.932880623870225\n",
      "Testing r2_score of LinearRegression() is  -4.215114574948019e+25\n",
      "Training r2_score of LinearRegression() is  0.9320028276395542\n",
      "Testing r2_score of LinearRegression() is  -7.641471540138866e+23\n",
      "Training r2_score of LinearRegression() is  0.9332751719129893\n",
      "Testing r2_score of LinearRegression() is  -7.584969399256094e+16\n",
      "Training r2_score of LinearRegression() is  0.9415905929094592\n",
      "Testing r2_score of LinearRegression() is  -1.4449803278443535e+20\n",
      "Training r2_score of LinearRegression() is  0.931075108542452\n",
      "Testing r2_score of LinearRegression() is  -1.9528407958082314e+25\n",
      "Training r2_score of LinearRegression() is  0.9293630342599924\n",
      "Testing r2_score of LinearRegression() is  -5.875934503035149e+23\n",
      "Training r2_score of LinearRegression() is  0.9306335517442228\n",
      "Testing r2_score of LinearRegression() is  -3.3151834353234503e+25\n",
      "Training r2_score of LinearRegression() is  0.9333245129330043\n",
      "Testing r2_score of LinearRegression() is  -1.9950928222844772e+26\n",
      "Training r2_score of LinearRegression() is  0.9412164131601414\n",
      "Testing r2_score of LinearRegression() is  -1.224867932749688e+22\n",
      "Training r2_score of LinearRegression() is  0.9362321509848646\n",
      "Testing r2_score of LinearRegression() is  -1.2326275156765103e+26\n",
      "Training r2_score of LinearRegression() is  0.9421816579980813\n",
      "Testing r2_score of LinearRegression() is  -1.0407826326135713e+23\n",
      "Training r2_score of LinearRegression() is  0.9365316407106244\n",
      "Testing r2_score of LinearRegression() is  -4.2140485891517e+25\n",
      "Training r2_score of LinearRegression() is  0.934155210577354\n",
      "Testing r2_score of LinearRegression() is  -8.78395974262334e+22\n",
      "Training r2_score of LinearRegression() is  0.9305018345553455\n",
      "Testing r2_score of LinearRegression() is  -1.8812196333485087e+25\n",
      "Training r2_score of LinearRegression() is  0.9297708873388781\n",
      "Testing r2_score of LinearRegression() is  -5.427308388507053e+23\n",
      "Training r2_score of LinearRegression() is  0.9296837016678919\n",
      "Testing r2_score of LinearRegression() is  -4.2397573328378836e+20\n",
      "Training r2_score of LinearRegression() is  0.9441871068879487\n",
      "Testing r2_score of LinearRegression() is  -1.7447176204483334e+26\n",
      "Training r2_score of LinearRegression() is  0.9399285585294727\n",
      "Testing r2_score of LinearRegression() is  -2.0434711145945406e+26\n",
      "Training r2_score of LinearRegression() is  0.9313263355526529\n",
      "Testing r2_score of LinearRegression() is  -8.883397752920845e+21\n",
      "Training r2_score of LinearRegression() is  0.9313396081771175\n",
      "Testing r2_score of LinearRegression() is  -1.2855710665637219e+23\n",
      "Training r2_score of LinearRegression() is  0.9388728877466184\n",
      "Testing r2_score of LinearRegression() is  -1.137292005327957e+23\n",
      "Training r2_score of LinearRegression() is  0.936683951808958\n",
      "Testing r2_score of LinearRegression() is  -4.784600358086597e+23\n",
      "Training r2_score of LinearRegression() is  0.9303934014301167\n",
      "Testing r2_score of LinearRegression() is  -1.1728285247623274e+24\n",
      "Training r2_score of LinearRegression() is  0.9315984823555058\n",
      "Testing r2_score of LinearRegression() is  0.8951031755457303\n",
      "Training r2_score of LinearRegression() is  0.9314365073232362\n",
      "Testing r2_score of LinearRegression() is  -4.770003970166902e+25\n",
      "Training r2_score of LinearRegression() is  0.928591620327005\n",
      "Testing r2_score of LinearRegression() is  -6.950717581793148e+23\n",
      "Training r2_score of LinearRegression() is  0.940039146520746\n",
      "Testing r2_score of LinearRegression() is  -4.3889290240740915e+25\n",
      "Training r2_score of LinearRegression() is  0.9277380722491039\n",
      "Testing r2_score of LinearRegression() is  -7.932697129506799e+25\n",
      "Training r2_score of LinearRegression() is  0.9409611191477678\n",
      "Testing r2_score of LinearRegression() is  -9.577670116833706e+24\n",
      "Training r2_score of LinearRegression() is  0.9402727988358921\n",
      "Testing r2_score of LinearRegression() is  -5.917202224989384e+24\n",
      "Training r2_score of LinearRegression() is  0.9304070688096464\n",
      "Testing r2_score of LinearRegression() is  -1.614184417772492e+21\n",
      "Training r2_score of LinearRegression() is  0.9342457618883012\n"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    algo_testing(algo=\"LinearRegression()\",test_size=0.2,X=X,Y=Y,evaluation_metric=\"r2_score\",random_state=None,shuffle=True)\n",
    "avg_accuracies[\"LinearRegression()\"]/=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "b06caf4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of RandomForestRegressor() is  0.8233690417765596\n",
      "Training r2_score of RandomForestRegressor() is  0.9791057206536223\n",
      "Testing r2_score of RandomForestRegressor() is  0.8543947264934038\n",
      "Training r2_score of RandomForestRegressor() is  0.9772959371098769\n",
      "Testing r2_score of RandomForestRegressor() is  0.8633327253112995\n",
      "Training r2_score of RandomForestRegressor() is  0.9778148483279407\n",
      "Testing r2_score of RandomForestRegressor() is  0.8609336081354353\n",
      "Training r2_score of RandomForestRegressor() is  0.9794265006039783\n",
      "Testing r2_score of RandomForestRegressor() is  0.8651133083117395\n",
      "Training r2_score of RandomForestRegressor() is  0.9788109254413672\n",
      "Testing r2_score of RandomForestRegressor() is  0.8091391949685209\n",
      "Training r2_score of RandomForestRegressor() is  0.9768866158132107\n",
      "Testing r2_score of RandomForestRegressor() is  0.7841501895128442\n",
      "Training r2_score of RandomForestRegressor() is  0.9806425709089347\n",
      "Testing r2_score of RandomForestRegressor() is  0.8046370580667828\n",
      "Training r2_score of RandomForestRegressor() is  0.9802367634352822\n",
      "Testing r2_score of RandomForestRegressor() is  0.8978867544299124\n",
      "Training r2_score of RandomForestRegressor() is  0.9774807671137495\n",
      "Testing r2_score of RandomForestRegressor() is  0.7767897674413751\n",
      "Training r2_score of RandomForestRegressor() is  0.9792828891311447\n",
      "Testing r2_score of RandomForestRegressor() is  0.8210248515335243\n",
      "Training r2_score of RandomForestRegressor() is  0.9786716768500052\n",
      "Testing r2_score of RandomForestRegressor() is  0.835580222169391\n",
      "Training r2_score of RandomForestRegressor() is  0.9760438731003472\n",
      "Testing r2_score of RandomForestRegressor() is  0.8749422491850635\n",
      "Training r2_score of RandomForestRegressor() is  0.9777337796576833\n",
      "Testing r2_score of RandomForestRegressor() is  0.882517499652745\n",
      "Training r2_score of RandomForestRegressor() is  0.9751653985741731\n",
      "Testing r2_score of RandomForestRegressor() is  0.8927628818439783\n",
      "Training r2_score of RandomForestRegressor() is  0.978482089112079\n",
      "Testing r2_score of RandomForestRegressor() is  0.79558055526296\n",
      "Training r2_score of RandomForestRegressor() is  0.9752980544624488\n",
      "Testing r2_score of RandomForestRegressor() is  0.8574545695912643\n",
      "Training r2_score of RandomForestRegressor() is  0.9782563761810464\n",
      "Testing r2_score of RandomForestRegressor() is  0.8363199394160904\n",
      "Training r2_score of RandomForestRegressor() is  0.97807680365638\n",
      "Testing r2_score of RandomForestRegressor() is  0.8711148082414943\n",
      "Training r2_score of RandomForestRegressor() is  0.9786272490170045\n",
      "Testing r2_score of RandomForestRegressor() is  0.869085708399256\n",
      "Training r2_score of RandomForestRegressor() is  0.9780549476998073\n",
      "Testing r2_score of RandomForestRegressor() is  0.8569074851748117\n",
      "Training r2_score of RandomForestRegressor() is  0.972906442325405\n",
      "Testing r2_score of RandomForestRegressor() is  0.8295748242793692\n",
      "Training r2_score of RandomForestRegressor() is  0.9788943384261213\n",
      "Testing r2_score of RandomForestRegressor() is  0.8519459697863878\n",
      "Training r2_score of RandomForestRegressor() is  0.9787395495775723\n",
      "Testing r2_score of RandomForestRegressor() is  0.8873030061381357\n",
      "Training r2_score of RandomForestRegressor() is  0.977169010480605\n",
      "Testing r2_score of RandomForestRegressor() is  0.8370402242807863\n",
      "Training r2_score of RandomForestRegressor() is  0.9796072053165596\n",
      "Testing r2_score of RandomForestRegressor() is  0.8806150434434451\n",
      "Training r2_score of RandomForestRegressor() is  0.9784503594969721\n",
      "Testing r2_score of RandomForestRegressor() is  0.8322452714050843\n",
      "Training r2_score of RandomForestRegressor() is  0.978544917689659\n",
      "Testing r2_score of RandomForestRegressor() is  0.8254784786095773\n",
      "Training r2_score of RandomForestRegressor() is  0.9780606208574979\n",
      "Testing r2_score of RandomForestRegressor() is  0.8277869159378586\n",
      "Training r2_score of RandomForestRegressor() is  0.9756201517521985\n",
      "Testing r2_score of RandomForestRegressor() is  0.7398481645621976\n",
      "Training r2_score of RandomForestRegressor() is  0.9814912478749165\n",
      "Testing r2_score of RandomForestRegressor() is  0.8518879406724925\n",
      "Training r2_score of RandomForestRegressor() is  0.9793310696251708\n",
      "Testing r2_score of RandomForestRegressor() is  0.8894245379404181\n",
      "Training r2_score of RandomForestRegressor() is  0.9758472922358127\n",
      "Testing r2_score of RandomForestRegressor() is  0.8634995317374277\n",
      "Training r2_score of RandomForestRegressor() is  0.9785863450194786\n",
      "Testing r2_score of RandomForestRegressor() is  0.839540957371302\n",
      "Training r2_score of RandomForestRegressor() is  0.9781625326648753\n",
      "Testing r2_score of RandomForestRegressor() is  0.8756407777237639\n",
      "Training r2_score of RandomForestRegressor() is  0.9761917844385564\n",
      "Testing r2_score of RandomForestRegressor() is  0.8092469846327045\n",
      "Training r2_score of RandomForestRegressor() is  0.9808607469793168\n",
      "Testing r2_score of RandomForestRegressor() is  0.8729509402980582\n",
      "Training r2_score of RandomForestRegressor() is  0.9766120095959478\n",
      "Testing r2_score of RandomForestRegressor() is  0.8567017170718819\n",
      "Training r2_score of RandomForestRegressor() is  0.9780141596932789\n",
      "Testing r2_score of RandomForestRegressor() is  0.8205267636244171\n",
      "Training r2_score of RandomForestRegressor() is  0.977848642076515\n",
      "Testing r2_score of RandomForestRegressor() is  0.8517854246462053\n",
      "Training r2_score of RandomForestRegressor() is  0.976154820492941\n",
      "Testing r2_score of RandomForestRegressor() is  0.8518625200439619\n",
      "Training r2_score of RandomForestRegressor() is  0.9786409830704831\n",
      "Testing r2_score of RandomForestRegressor() is  0.8554773465959996\n",
      "Training r2_score of RandomForestRegressor() is  0.9774616283550822\n",
      "Testing r2_score of RandomForestRegressor() is  0.7904770450590538\n",
      "Training r2_score of RandomForestRegressor() is  0.980540859212712\n",
      "Testing r2_score of RandomForestRegressor() is  0.8684127108271582\n",
      "Training r2_score of RandomForestRegressor() is  0.9781110489213366\n",
      "Testing r2_score of RandomForestRegressor() is  0.8267107716613384\n",
      "Training r2_score of RandomForestRegressor() is  0.9770740808216594\n",
      "Testing r2_score of RandomForestRegressor() is  0.8262212040101022\n",
      "Training r2_score of RandomForestRegressor() is  0.9806616508465964\n",
      "Testing r2_score of RandomForestRegressor() is  0.8185964714384286\n",
      "Training r2_score of RandomForestRegressor() is  0.9792956555270792\n",
      "Testing r2_score of RandomForestRegressor() is  0.8735644451374812\n",
      "Training r2_score of RandomForestRegressor() is  0.9779874728962603\n",
      "Testing r2_score of RandomForestRegressor() is  0.8488778498893416\n",
      "Training r2_score of RandomForestRegressor() is  0.9778309321719314\n",
      "Testing r2_score of RandomForestRegressor() is  0.8550892225631446\n",
      "Training r2_score of RandomForestRegressor() is  0.9782672008247505\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(50):\n",
    "    algo_testing(algo=\"RandomForestRegressor()\",test_size=0.2,X=X,Y=Y,evaluation_metric=\"r2_score\",random_state=None,shuffle=True)\n",
    "avg_accuracies[\"RandomForestRegressor()\"]/=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d7120024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of SVR() is  -0.015349567441290235\n",
      "Training r2_score of SVR() is  -0.04805805045234135\n",
      "Testing r2_score of SVR() is  -0.11100163670076424\n",
      "Training r2_score of SVR() is  -0.059402018471431894\n",
      "Testing r2_score of SVR() is  -0.03442843832074782\n",
      "Training r2_score of SVR() is  -0.04970913036550373\n",
      "Testing r2_score of SVR() is  -0.09352473603087064\n",
      "Training r2_score of SVR() is  -0.054954870001078904\n",
      "Testing r2_score of SVR() is  -0.050132892726428624\n",
      "Training r2_score of SVR() is  -0.04572946762536523\n",
      "Testing r2_score of SVR() is  -0.030870702426350816\n",
      "Training r2_score of SVR() is  -0.0628155109114259\n",
      "Testing r2_score of SVR() is  -0.03748436059883464\n",
      "Training r2_score of SVR() is  -0.0405169022980465\n",
      "Testing r2_score of SVR() is  -0.06918823539247132\n",
      "Training r2_score of SVR() is  -0.05034985298703609\n",
      "Testing r2_score of SVR() is  -0.0644066316545695\n",
      "Training r2_score of SVR() is  -0.05430844171384441\n",
      "Testing r2_score of SVR() is  -0.08189540302306497\n",
      "Training r2_score of SVR() is  -0.05624827667501564\n",
      "Testing r2_score of SVR() is  -0.048008469598157966\n",
      "Training r2_score of SVR() is  -0.0443777746491647\n",
      "Testing r2_score of SVR() is  -0.06137813104521883\n",
      "Training r2_score of SVR() is  -0.0531146068647943\n",
      "Testing r2_score of SVR() is  -0.06324866432720566\n",
      "Training r2_score of SVR() is  -0.04812401985576398\n",
      "Testing r2_score of SVR() is  -0.07457156404886178\n",
      "Training r2_score of SVR() is  -0.0517550816506811\n",
      "Testing r2_score of SVR() is  -0.03773493621001878\n",
      "Training r2_score of SVR() is  -0.04669671921371488\n",
      "Testing r2_score of SVR() is  -0.050689778896731985\n",
      "Training r2_score of SVR() is  -0.04684948772383257\n",
      "Testing r2_score of SVR() is  -0.07374791857165075\n",
      "Training r2_score of SVR() is  -0.05338837508711847\n",
      "Testing r2_score of SVR() is  -0.0451414092735114\n",
      "Training r2_score of SVR() is  -0.04577932968215492\n",
      "Testing r2_score of SVR() is  -0.05727822318148301\n",
      "Training r2_score of SVR() is  -0.04568660449615436\n",
      "Testing r2_score of SVR() is  -0.06054811632450896\n",
      "Training r2_score of SVR() is  -0.044786247915158395\n",
      "Testing r2_score of SVR() is  -0.1330777972041588\n",
      "Training r2_score of SVR() is  -0.05554183311116723\n",
      "Testing r2_score of SVR() is  -0.02792263018781016\n",
      "Training r2_score of SVR() is  -0.0496041538745966\n",
      "Testing r2_score of SVR() is  -0.06077528322319803\n",
      "Training r2_score of SVR() is  -0.047767820903309666\n",
      "Testing r2_score of SVR() is  -0.04013328662699389\n",
      "Training r2_score of SVR() is  -0.048237600666986236\n",
      "Testing r2_score of SVR() is  -0.018646982245896115\n",
      "Training r2_score of SVR() is  -0.0502290516878483\n",
      "Testing r2_score of SVR() is  -0.08669265363900247\n",
      "Training r2_score of SVR() is  -0.04827857840775862\n",
      "Testing r2_score of SVR() is  -0.010589228103145443\n",
      "Training r2_score of SVR() is  -0.050106023462607174\n",
      "Testing r2_score of SVR() is  -0.02984585449159516\n",
      "Training r2_score of SVR() is  -0.042789780586793835\n",
      "Testing r2_score of SVR() is  -0.10091978244802657\n",
      "Training r2_score of SVR() is  -0.061406207399413715\n",
      "Testing r2_score of SVR() is  -0.0656074910297717\n",
      "Training r2_score of SVR() is  -0.047595885189212206\n",
      "Testing r2_score of SVR() is  -0.12391974754832291\n",
      "Training r2_score of SVR() is  -0.057324793081719116\n",
      "Testing r2_score of SVR() is  -0.10817873582003479\n",
      "Training r2_score of SVR() is  -0.05570999089517459\n",
      "Testing r2_score of SVR() is  -0.051865643476282086\n",
      "Training r2_score of SVR() is  -0.04998248962706198\n",
      "Testing r2_score of SVR() is  -0.033213755847946835\n",
      "Training r2_score of SVR() is  -0.04780856916516196\n",
      "Testing r2_score of SVR() is  -0.05591601305746119\n",
      "Training r2_score of SVR() is  -0.04902539436942566\n",
      "Testing r2_score of SVR() is  -0.03586517153350188\n",
      "Training r2_score of SVR() is  -0.04235164112963319\n",
      "Testing r2_score of SVR() is  -0.05036787940509968\n",
      "Training r2_score of SVR() is  -0.043744798779107086\n",
      "Testing r2_score of SVR() is  -0.047498110686596595\n",
      "Training r2_score of SVR() is  -0.04038370120469992\n",
      "Testing r2_score of SVR() is  -0.046961952123338646\n",
      "Training r2_score of SVR() is  -0.05861178350368057\n",
      "Testing r2_score of SVR() is  -0.033450434552375174\n",
      "Training r2_score of SVR() is  -0.05486168410751491\n",
      "Testing r2_score of SVR() is  -0.06517321419210909\n",
      "Training r2_score of SVR() is  -0.054114950288725705\n",
      "Testing r2_score of SVR() is  -0.020345508880903918\n",
      "Training r2_score of SVR() is  -0.046021917510888244\n",
      "Testing r2_score of SVR() is  -0.06176023273234321\n",
      "Training r2_score of SVR() is  -0.04972598332904643\n",
      "Testing r2_score of SVR() is  -0.06560167317416798\n",
      "Training r2_score of SVR() is  -0.05425298135374357\n",
      "Testing r2_score of SVR() is  -0.041811531262263335\n",
      "Training r2_score of SVR() is  -0.04777704979070729\n",
      "Testing r2_score of SVR() is  -0.06271822422730078\n",
      "Training r2_score of SVR() is  -0.04860931455865458\n",
      "Testing r2_score of SVR() is  -0.053218760160823164\n",
      "Training r2_score of SVR() is  -0.049717140151478656\n",
      "Testing r2_score of SVR() is  -0.09347633093046515\n",
      "Training r2_score of SVR() is  -0.04862318932979348\n",
      "Testing r2_score of SVR() is  -0.05298911355385849\n",
      "Training r2_score of SVR() is  -0.05275715447878371\n",
      "Testing r2_score of SVR() is  -0.09961671698570296\n",
      "Training r2_score of SVR() is  -0.04901064542762579\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(50):\n",
    "\n",
    "    algo_testing(algo=\"SVR()\",test_size=0.2,X=X,Y=Y,evaluation_metric=\"r2_score\",random_state=None,shuffle=True)\n",
    "avg_accuracies[\"SVR()\"]/=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "4e14d14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of KNeighborsRegressor() is  0.6721877497805362\n",
      "Training r2_score of KNeighborsRegressor() is  0.8100570481871896\n",
      "Testing r2_score of KNeighborsRegressor() is  0.6970166969477563\n",
      "Training r2_score of KNeighborsRegressor() is  0.8019077193938918\n",
      "Testing r2_score of KNeighborsRegressor() is  0.7422201177022547\n",
      "Training r2_score of KNeighborsRegressor() is  0.8021868486977619\n",
      "Testing r2_score of KNeighborsRegressor() is  0.739530624187851\n",
      "Training r2_score of KNeighborsRegressor() is  0.7882725540486557\n",
      "Testing r2_score of KNeighborsRegressor() is  0.6707897132728929\n",
      "Training r2_score of KNeighborsRegressor() is  0.8163304309955465\n",
      "Testing r2_score of KNeighborsRegressor() is  0.6297753292324233\n",
      "Training r2_score of KNeighborsRegressor() is  0.8257201834750694\n",
      "Testing r2_score of KNeighborsRegressor() is  0.6510557125686713\n",
      "Training r2_score of KNeighborsRegressor() is  0.8096746595938835\n",
      "Testing r2_score of KNeighborsRegressor() is  0.7183398284433067\n",
      "Training r2_score of KNeighborsRegressor() is  0.8081030034008394\n",
      "Testing r2_score of KNeighborsRegressor() is  0.7158736087708164\n",
      "Training r2_score of KNeighborsRegressor() is  0.8049456655328052\n",
      "Testing r2_score of KNeighborsRegressor() is  0.7751135239890257\n",
      "Training r2_score of KNeighborsRegressor() is  0.7942435534625544\n",
      "Testing r2_score of KNeighborsRegressor() is  0.6415786786393919\n",
      "Training r2_score of KNeighborsRegressor() is  0.8269285956121426\n",
      "Testing r2_score of KNeighborsRegressor() is  0.7527264397152554\n",
      "Training r2_score of KNeighborsRegressor() is  0.7879657042624\n",
      "Testing r2_score of KNeighborsRegressor() is  0.6841635742466912\n",
      "Training r2_score of KNeighborsRegressor() is  0.8166461752724632\n",
      "Testing r2_score of KNeighborsRegressor() is  0.707102464621292\n",
      "Training r2_score of KNeighborsRegressor() is  0.8148442105323142\n",
      "Testing r2_score of KNeighborsRegressor() is  0.640452018484968\n",
      "Training r2_score of KNeighborsRegressor() is  0.8135356811058807\n",
      "Testing r2_score of KNeighborsRegressor() is  0.7094672734624363\n",
      "Training r2_score of KNeighborsRegressor() is  0.8032706628098766\n",
      "Testing r2_score of KNeighborsRegressor() is  0.6141981506095564\n",
      "Training r2_score of KNeighborsRegressor() is  0.8215163639163516\n",
      "Testing r2_score of KNeighborsRegressor() is  0.7172105836422669\n",
      "Training r2_score of KNeighborsRegressor() is  0.8023167476540952\n",
      "Testing r2_score of KNeighborsRegressor() is  0.7360389510928216\n",
      "Training r2_score of KNeighborsRegressor() is  0.8086221646392657\n",
      "Testing r2_score of KNeighborsRegressor() is  0.7832797862200869\n",
      "Training r2_score of KNeighborsRegressor() is  0.7938280159657287\n",
      "Testing r2_score of KNeighborsRegressor() is  0.7681286378808605\n",
      "Training r2_score of KNeighborsRegressor() is  0.790166370241991\n",
      "Testing r2_score of KNeighborsRegressor() is  0.6445636587264221\n",
      "Training r2_score of KNeighborsRegressor() is  0.8175307322318202\n",
      "Testing r2_score of KNeighborsRegressor() is  0.6816359184810425\n",
      "Training r2_score of KNeighborsRegressor() is  0.8064532237248978\n",
      "Testing r2_score of KNeighborsRegressor() is  0.6663856926724018\n",
      "Training r2_score of KNeighborsRegressor() is  0.8134503214225844\n",
      "Testing r2_score of KNeighborsRegressor() is  0.63888324618192\n",
      "Training r2_score of KNeighborsRegressor() is  0.8217734157874383\n",
      "Testing r2_score of KNeighborsRegressor() is  0.6732199483229218\n",
      "Training r2_score of KNeighborsRegressor() is  0.8152979913762973\n",
      "Testing r2_score of KNeighborsRegressor() is  0.6648246368620512\n",
      "Training r2_score of KNeighborsRegressor() is  0.8208763903962659\n",
      "Testing r2_score of KNeighborsRegressor() is  0.6874388331768027\n",
      "Training r2_score of KNeighborsRegressor() is  0.8149365311867344\n",
      "Testing r2_score of KNeighborsRegressor() is  0.7338590782924139\n",
      "Training r2_score of KNeighborsRegressor() is  0.8083342705140881\n",
      "Testing r2_score of KNeighborsRegressor() is  0.6816945243010293\n",
      "Training r2_score of KNeighborsRegressor() is  0.8070639905261532\n",
      "Testing r2_score of KNeighborsRegressor() is  0.6965955452294428\n",
      "Training r2_score of KNeighborsRegressor() is  0.811668746409763\n",
      "Testing r2_score of KNeighborsRegressor() is  0.6839027712829394\n",
      "Training r2_score of KNeighborsRegressor() is  0.8067501891817627\n",
      "Testing r2_score of KNeighborsRegressor() is  0.6816796264080691\n",
      "Training r2_score of KNeighborsRegressor() is  0.8109124855979792\n",
      "Testing r2_score of KNeighborsRegressor() is  0.7126244453970922\n",
      "Training r2_score of KNeighborsRegressor() is  0.8084779092881457\n",
      "Testing r2_score of KNeighborsRegressor() is  0.6966639142207158\n",
      "Training r2_score of KNeighborsRegressor() is  0.8090238592022986\n",
      "Testing r2_score of KNeighborsRegressor() is  0.699229726690157\n",
      "Training r2_score of KNeighborsRegressor() is  0.816854772676178\n",
      "Testing r2_score of KNeighborsRegressor() is  0.669040150942589\n",
      "Training r2_score of KNeighborsRegressor() is  0.8061046114940491\n",
      "Testing r2_score of KNeighborsRegressor() is  0.7416115507130642\n",
      "Training r2_score of KNeighborsRegressor() is  0.8042451051279729\n",
      "Testing r2_score of KNeighborsRegressor() is  0.7757703267263961\n",
      "Training r2_score of KNeighborsRegressor() is  0.7964650376661643\n",
      "Testing r2_score of KNeighborsRegressor() is  0.7190758132417507\n",
      "Training r2_score of KNeighborsRegressor() is  0.8053621949512385\n",
      "Testing r2_score of KNeighborsRegressor() is  0.6405275931054378\n",
      "Training r2_score of KNeighborsRegressor() is  0.8158196350056685\n",
      "Testing r2_score of KNeighborsRegressor() is  0.7245113285024141\n",
      "Training r2_score of KNeighborsRegressor() is  0.8157787552540836\n",
      "Testing r2_score of KNeighborsRegressor() is  0.6260361954898137\n",
      "Training r2_score of KNeighborsRegressor() is  0.82171859544716\n",
      "Testing r2_score of KNeighborsRegressor() is  0.7517072222602506\n",
      "Training r2_score of KNeighborsRegressor() is  0.8090830526260604\n",
      "Testing r2_score of KNeighborsRegressor() is  0.7760840172876458\n",
      "Training r2_score of KNeighborsRegressor() is  0.7965091670764609\n",
      "Testing r2_score of KNeighborsRegressor() is  0.6501616855767121\n",
      "Training r2_score of KNeighborsRegressor() is  0.8156762800164533\n",
      "Testing r2_score of KNeighborsRegressor() is  0.7580514994407067\n",
      "Training r2_score of KNeighborsRegressor() is  0.8059562475072823\n",
      "Testing r2_score of KNeighborsRegressor() is  0.721381941203918\n",
      "Training r2_score of KNeighborsRegressor() is  0.8005745977135081\n",
      "Testing r2_score of KNeighborsRegressor() is  0.7196192452662256\n",
      "Training r2_score of KNeighborsRegressor() is  0.8092599363336072\n",
      "Testing r2_score of KNeighborsRegressor() is  0.7655737204933026\n",
      "Training r2_score of KNeighborsRegressor() is  0.8116374856423828\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(50):\n",
    "\n",
    "    algo_testing(algo=\"KNeighborsRegressor()\",test_size=0.2,X=X,Y=Y,evaluation_metric=\"r2_score\",random_state=None,shuffle=True)\n",
    "avg_accuracies[\"KNeighborsRegressor()\"]/=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "936a00a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of SGDRegressor() is  -735.5404873406032\n",
      "Training r2_score of SGDRegressor() is  -14388.692345438283\n",
      "Testing r2_score of SGDRegressor() is  -650.9564135603733\n",
      "Training r2_score of SGDRegressor() is  -22394.089021286192\n",
      "Testing r2_score of SGDRegressor() is  -589.7558723599734\n",
      "Training r2_score of SGDRegressor() is  -31762.122440729592\n",
      "Testing r2_score of SGDRegressor() is  -676.5932481670072\n",
      "Training r2_score of SGDRegressor() is  -32848.41090393299\n",
      "Testing r2_score of SGDRegressor() is  -921.8365832008185\n",
      "Training r2_score of SGDRegressor() is  -43901.169013018254\n",
      "Testing r2_score of SGDRegressor() is  -76.82624708341157\n",
      "Training r2_score of SGDRegressor() is  -5204.37107423593\n",
      "Testing r2_score of SGDRegressor() is  -35.61446689664289\n",
      "Training r2_score of SGDRegressor() is  -2124.1277552552733\n",
      "Testing r2_score of SGDRegressor() is  -629.2649536653724\n",
      "Training r2_score of SGDRegressor() is  -21616.379206549627\n",
      "Testing r2_score of SGDRegressor() is  -897.0096580508122\n",
      "Training r2_score of SGDRegressor() is  -73345.06188911035\n",
      "Testing r2_score of SGDRegressor() is  -3680.297570974225\n",
      "Training r2_score of SGDRegressor() is  -84105.61016650606\n",
      "Testing r2_score of SGDRegressor() is  -616.2809923576941\n",
      "Training r2_score of SGDRegressor() is  -23724.474342909354\n",
      "Testing r2_score of SGDRegressor() is  -94.87954281479293\n",
      "Training r2_score of SGDRegressor() is  -8735.95238675038\n",
      "Testing r2_score of SGDRegressor() is  -763.2724948398661\n",
      "Training r2_score of SGDRegressor() is  -19089.74139320833\n",
      "Testing r2_score of SGDRegressor() is  -0.7054021471548115\n",
      "Training r2_score of SGDRegressor() is  -9.042467944667951\n",
      "Testing r2_score of SGDRegressor() is  -422.8266095952066\n",
      "Training r2_score of SGDRegressor() is  -11353.467444502465\n",
      "Testing r2_score of SGDRegressor() is  -1629.69158422335\n",
      "Training r2_score of SGDRegressor() is  -34531.66581957748\n",
      "Testing r2_score of SGDRegressor() is  -1859.7628180326906\n",
      "Training r2_score of SGDRegressor() is  -45724.153404274744\n",
      "Testing r2_score of SGDRegressor() is  -712.7053436665359\n",
      "Training r2_score of SGDRegressor() is  -35410.02749590111\n",
      "Testing r2_score of SGDRegressor() is  -2790.6537028782163\n",
      "Training r2_score of SGDRegressor() is  -86961.49002980933\n",
      "Testing r2_score of SGDRegressor() is  -583.3174920327166\n",
      "Training r2_score of SGDRegressor() is  -26948.887938513715\n",
      "Testing r2_score of SGDRegressor() is  -888.8556718323283\n",
      "Training r2_score of SGDRegressor() is  -21702.78459961577\n",
      "Testing r2_score of SGDRegressor() is  -6108.64892363979\n",
      "Training r2_score of SGDRegressor() is  -91079.73764809329\n",
      "Testing r2_score of SGDRegressor() is  -1298.6676214842619\n",
      "Training r2_score of SGDRegressor() is  -16858.269185848956\n",
      "Testing r2_score of SGDRegressor() is  -62.57069414227652\n",
      "Training r2_score of SGDRegressor() is  -144.7102505088041\n",
      "Testing r2_score of SGDRegressor() is  -1558.1662606038217\n",
      "Training r2_score of SGDRegressor() is  -17619.41141033108\n",
      "Testing r2_score of SGDRegressor() is  -588.2599986210344\n",
      "Training r2_score of SGDRegressor() is  -25711.075124650084\n",
      "Testing r2_score of SGDRegressor() is  -1305.5675437909067\n",
      "Training r2_score of SGDRegressor() is  -23647.76323175919\n",
      "Testing r2_score of SGDRegressor() is  -66.25727585839745\n",
      "Training r2_score of SGDRegressor() is  -3495.504054785947\n",
      "Testing r2_score of SGDRegressor() is  -594.240996574038\n",
      "Training r2_score of SGDRegressor() is  -74987.70473401087\n",
      "Testing r2_score of SGDRegressor() is  -48.11322230877896\n",
      "Training r2_score of SGDRegressor() is  -208.23708451657825\n",
      "Testing r2_score of SGDRegressor() is  -1553.5512031000792\n",
      "Training r2_score of SGDRegressor() is  -32032.404960399406\n",
      "Testing r2_score of SGDRegressor() is  -991.4124710253149\n",
      "Training r2_score of SGDRegressor() is  -42676.92894367994\n",
      "Testing r2_score of SGDRegressor() is  -9976.174476991115\n",
      "Training r2_score of SGDRegressor() is  -60393.77730136124\n",
      "Testing r2_score of SGDRegressor() is  -820.5141313350257\n",
      "Training r2_score of SGDRegressor() is  -47241.07645917696\n",
      "Testing r2_score of SGDRegressor() is  -1348.4641139070372\n",
      "Training r2_score of SGDRegressor() is  -30838.136903479688\n",
      "Testing r2_score of SGDRegressor() is  -616.4236829292531\n",
      "Training r2_score of SGDRegressor() is  -40670.016815845614\n",
      "Testing r2_score of SGDRegressor() is  -653.1818136356236\n",
      "Training r2_score of SGDRegressor() is  -22448.121808336033\n",
      "Testing r2_score of SGDRegressor() is  -54.71674207114686\n",
      "Training r2_score of SGDRegressor() is  -2918.9179378614954\n",
      "Testing r2_score of SGDRegressor() is  -2928.4332601715696\n",
      "Training r2_score of SGDRegressor() is  -65974.48961292637\n",
      "Testing r2_score of SGDRegressor() is  -2320.1950241634627\n",
      "Training r2_score of SGDRegressor() is  -14158.337860760294\n",
      "Testing r2_score of SGDRegressor() is  -9141.520346314634\n",
      "Training r2_score of SGDRegressor() is  -38871.116018287066\n",
      "Testing r2_score of SGDRegressor() is  -2955.917184098736\n",
      "Training r2_score of SGDRegressor() is  -55028.66082985286\n",
      "Testing r2_score of SGDRegressor() is  -770.7517662439606\n",
      "Training r2_score of SGDRegressor() is  -39822.76553268195\n",
      "Testing r2_score of SGDRegressor() is  -604.6215457962492\n",
      "Training r2_score of SGDRegressor() is  -70621.54597720844\n",
      "Testing r2_score of SGDRegressor() is  -6544.230846696026\n",
      "Training r2_score of SGDRegressor() is  -65668.17278852432\n",
      "Testing r2_score of SGDRegressor() is  -1967.8323645324554\n",
      "Training r2_score of SGDRegressor() is  -36735.23689582844\n",
      "Testing r2_score of SGDRegressor() is  -166.98058853122438\n",
      "Training r2_score of SGDRegressor() is  -14960.298805409142\n",
      "Testing r2_score of SGDRegressor() is  -2037.548876441436\n",
      "Training r2_score of SGDRegressor() is  -76672.93125721534\n",
      "Testing r2_score of SGDRegressor() is  -3390.252306518046\n",
      "Training r2_score of SGDRegressor() is  -70041.51437949105\n",
      "Testing r2_score of SGDRegressor() is  -819.8138866081132\n",
      "Training r2_score of SGDRegressor() is  -22541.1195416556\n"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "\n",
    "    algo_testing(algo=\"SGDRegressor()\",test_size=0.2,X=X,Y=Y,evaluation_metric=\"r2_score\",random_state=None,shuffle=True)\n",
    "avg_accuracies[\"SGDRegressor()\"]/=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "5194e10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of DecisionTreeRegressor() is  0.6953465856240442\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.7265557865149035\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.783121728203183\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.7483698959277003\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.7066862263822686\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.7304370135541858\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.7433775358974234\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.6712834911736202\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.7439844246037834\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.549892150529107\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.7393322865264378\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.7272062211230493\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.5337824587276762\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.6582201238990917\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.6482336736242487\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.6804472719292168\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.5853888842640919\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.6011239116405906\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.6447669041337727\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.5627639691058206\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.7271607331021969\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.7081904994206991\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.615826210059989\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.6774512882661126\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.6711756511794612\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.7449729396951157\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.5379106196752065\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.7531997537978066\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.7987965033268374\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.540850930783028\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.6632962554222348\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.7366714015480218\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.6925346188963419\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.7312669417314059\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.756507922121556\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.7297464474322123\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.736179163042857\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.7578095676128864\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.7181147271950075\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.8086875022148331\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.7321071942093176\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.600193772619378\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.7531712060409609\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.5248147218888644\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.7205590559490089\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.703791749353248\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.7243329635150202\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.6605341814201585\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.6636068785188185\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.7150658844533753\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "\n",
    "    algo_testing(algo=\"DecisionTreeRegressor()\",test_size=0.2,X=X,Y=Y,evaluation_metric=\"r2_score\",random_state=None,shuffle=True)\n",
    "avg_accuracies[\"DecisionTreeRegressor()\"]/=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "fba45bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of ElasticNet() is  0.8564245098116802\n",
      "Training r2_score of ElasticNet() is  0.906913964578639\n",
      "Testing r2_score of ElasticNet() is  0.8278709614886547\n",
      "Training r2_score of ElasticNet() is  0.9119172384822346\n",
      "Testing r2_score of ElasticNet() is  0.7351853872864931\n",
      "Training r2_score of ElasticNet() is  0.9128640047350756\n",
      "Testing r2_score of ElasticNet() is  0.8216935101632108\n",
      "Training r2_score of ElasticNet() is  0.9155952652372701\n",
      "Testing r2_score of ElasticNet() is  0.8920221862270223\n",
      "Training r2_score of ElasticNet() is  0.9016133183334472\n",
      "Testing r2_score of ElasticNet() is  0.8586500275862988\n",
      "Training r2_score of ElasticNet() is  0.9060451594844624\n",
      "Testing r2_score of ElasticNet() is  0.8969870292889464\n",
      "Training r2_score of ElasticNet() is  0.9035644237256613\n",
      "Testing r2_score of ElasticNet() is  0.8774888889555138\n",
      "Training r2_score of ElasticNet() is  0.9061689171194819\n",
      "Testing r2_score of ElasticNet() is  0.7370937475047352\n",
      "Training r2_score of ElasticNet() is  0.9105654765347095\n",
      "Testing r2_score of ElasticNet() is  0.8463600244664204\n",
      "Training r2_score of ElasticNet() is  0.9040899267274091\n",
      "Testing r2_score of ElasticNet() is  0.8731195136502498\n",
      "Training r2_score of ElasticNet() is  0.9030817321407943\n",
      "Testing r2_score of ElasticNet() is  0.8862016459868426\n",
      "Training r2_score of ElasticNet() is  0.9028172201279266\n",
      "Testing r2_score of ElasticNet() is  0.8973492860701142\n",
      "Training r2_score of ElasticNet() is  0.8975425712873832\n",
      "Testing r2_score of ElasticNet() is  0.8675534649506621\n",
      "Training r2_score of ElasticNet() is  0.9013322855354573\n",
      "Testing r2_score of ElasticNet() is  0.8071511984951087\n",
      "Training r2_score of ElasticNet() is  0.9127682747163279\n",
      "Testing r2_score of ElasticNet() is  0.7033137049732641\n",
      "Training r2_score of ElasticNet() is  0.9180674535930224\n",
      "Testing r2_score of ElasticNet() is  0.7702234920172245\n",
      "Training r2_score of ElasticNet() is  0.9043949894553475\n",
      "Testing r2_score of ElasticNet() is  0.7363703211953072\n",
      "Training r2_score of ElasticNet() is  0.9104622701302498\n",
      "Testing r2_score of ElasticNet() is  0.862426234393712\n",
      "Training r2_score of ElasticNet() is  0.9061334847961166\n",
      "Testing r2_score of ElasticNet() is  0.6975369267495517\n",
      "Training r2_score of ElasticNet() is  0.9110383031155644\n",
      "Testing r2_score of ElasticNet() is  0.7409322215602419\n",
      "Training r2_score of ElasticNet() is  0.9131897333027233\n",
      "Testing r2_score of ElasticNet() is  0.8337712316359334\n",
      "Training r2_score of ElasticNet() is  0.9125445203027968\n",
      "Testing r2_score of ElasticNet() is  0.7334129959725273\n",
      "Training r2_score of ElasticNet() is  0.9058910710645922\n",
      "Testing r2_score of ElasticNet() is  0.7291197925747286\n",
      "Training r2_score of ElasticNet() is  0.9091724496447469\n",
      "Testing r2_score of ElasticNet() is  0.8757603221970232\n",
      "Training r2_score of ElasticNet() is  0.9064310131519725\n",
      "Testing r2_score of ElasticNet() is  0.7848394464803294\n",
      "Training r2_score of ElasticNet() is  0.9203243338356231\n",
      "Testing r2_score of ElasticNet() is  0.717176181775399\n",
      "Training r2_score of ElasticNet() is  0.9149559852336375\n",
      "Testing r2_score of ElasticNet() is  0.8830072431823067\n",
      "Training r2_score of ElasticNet() is  0.904132086267423\n",
      "Testing r2_score of ElasticNet() is  0.860020718354656\n",
      "Training r2_score of ElasticNet() is  0.9034272910553379\n",
      "Testing r2_score of ElasticNet() is  0.8142350409466091\n",
      "Training r2_score of ElasticNet() is  0.9127653434459905\n",
      "Testing r2_score of ElasticNet() is  0.8446868089460371\n",
      "Training r2_score of ElasticNet() is  0.9072034323167674\n",
      "Testing r2_score of ElasticNet() is  0.8377638721176336\n",
      "Training r2_score of ElasticNet() is  0.9071826319029221\n",
      "Testing r2_score of ElasticNet() is  0.8742900837088997\n",
      "Training r2_score of ElasticNet() is  0.9064888291114352\n",
      "Testing r2_score of ElasticNet() is  0.8359462290922283\n",
      "Training r2_score of ElasticNet() is  0.911522748229789\n",
      "Testing r2_score of ElasticNet() is  0.7512718250484411\n",
      "Training r2_score of ElasticNet() is  0.905058486983676\n",
      "Testing r2_score of ElasticNet() is  0.7336105980473511\n",
      "Training r2_score of ElasticNet() is  0.9067617033799293\n",
      "Testing r2_score of ElasticNet() is  0.8737761318535546\n",
      "Training r2_score of ElasticNet() is  0.9073011336705797\n",
      "Testing r2_score of ElasticNet() is  0.8704058557051502\n",
      "Training r2_score of ElasticNet() is  0.9043941647662596\n",
      "Testing r2_score of ElasticNet() is  0.701554576679829\n",
      "Training r2_score of ElasticNet() is  0.909491754560934\n",
      "Testing r2_score of ElasticNet() is  0.6658945575882874\n",
      "Training r2_score of ElasticNet() is  0.9166223690390018\n",
      "Testing r2_score of ElasticNet() is  0.7396470524300622\n",
      "Training r2_score of ElasticNet() is  0.9095166937888168\n",
      "Testing r2_score of ElasticNet() is  0.6680027894563132\n",
      "Training r2_score of ElasticNet() is  0.9147261259184729\n",
      "Testing r2_score of ElasticNet() is  0.728714681348389\n",
      "Training r2_score of ElasticNet() is  0.9099541741858069\n",
      "Testing r2_score of ElasticNet() is  0.841150829898905\n",
      "Training r2_score of ElasticNet() is  0.9100451402444344\n",
      "Testing r2_score of ElasticNet() is  0.8541368444245038\n",
      "Training r2_score of ElasticNet() is  0.9080715699294328\n",
      "Testing r2_score of ElasticNet() is  0.809570897298709\n",
      "Training r2_score of ElasticNet() is  0.9121785598305139\n",
      "Testing r2_score of ElasticNet() is  0.7656883409663104\n",
      "Training r2_score of ElasticNet() is  0.9080456673002526\n",
      "Testing r2_score of ElasticNet() is  0.7694384637227509\n",
      "Training r2_score of ElasticNet() is  0.9070393842758137\n",
      "Testing r2_score of ElasticNet() is  0.8958398732424703\n",
      "Training r2_score of ElasticNet() is  0.902902866578647\n",
      "Testing r2_score of ElasticNet() is  0.6960729419769949\n",
      "Training r2_score of ElasticNet() is  0.9188239954024285\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "for i in range(50):\n",
    "\n",
    "    algo_testing(algo=\"ElasticNet()\",test_size=0.2,X=X,Y=Y,evaluation_metric=\"r2_score\",random_state=None,shuffle=True)\n",
    "avg_accuracies[\"ElasticNet()\"]/=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "1c5627ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.260e+09, tolerance: 7.222e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.8811526750123415\n",
      "Training r2_score of Lasso() is  0.9343472613582364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.988e+09, tolerance: 7.097e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.8905387562225988\n",
      "Training r2_score of Lasso() is  0.9301392089620669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.298e+10, tolerance: 7.791e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.7667970263935804\n",
      "Training r2_score of Lasso() is  0.9417684539911094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.148e+10, tolerance: 7.334e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.8939074077944327\n",
      "Training r2_score of Lasso() is  0.9315795349825031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.599e+10, tolerance: 7.548e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.8881654586932394\n",
      "Training r2_score of Lasso() is  0.9315946777416795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.472e+10, tolerance: 6.754e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.8857906877355141\n",
      "Training r2_score of Lasso() is  0.9313531518535985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.806e+10, tolerance: 7.737e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.7925721380525689\n",
      "Training r2_score of Lasso() is  0.9373574715920298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.809e+10, tolerance: 7.384e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.9161969769460542\n",
      "Training r2_score of Lasso() is  0.928254207331756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.125e+09, tolerance: 7.413e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.7910351060553868\n",
      "Training r2_score of Lasso() is  0.9444232923574598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.872e+10, tolerance: 7.171e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.8820502722740099\n",
      "Training r2_score of Lasso() is  0.9316171487823139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.545e+10, tolerance: 7.319e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.689019386561192\n",
      "Training r2_score of Lasso() is  0.9274361610995713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.169e+10, tolerance: 7.236e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.8965098744333689\n",
      "Training r2_score of Lasso() is  0.9301849074191342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.106e+10, tolerance: 7.451e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.7995080654974224\n",
      "Training r2_score of Lasso() is  0.9424911076562755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.530e+10, tolerance: 7.297e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.7893109626471262\n",
      "Training r2_score of Lasso() is  0.9463339625889323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.467e+10, tolerance: 7.040e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.83672895095309\n",
      "Training r2_score of Lasso() is  0.9379398090108151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.163e+10, tolerance: 7.843e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.8922739313000967\n",
      "Training r2_score of Lasso() is  0.9286843932471451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.213e+10, tolerance: 7.084e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.5685380760680401\n",
      "Training r2_score of Lasso() is  0.9399383022162225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.698e+09, tolerance: 7.403e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.8980010054683414\n",
      "Training r2_score of Lasso() is  0.9300987462695307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.597e+10, tolerance: 6.774e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.8771526813764573\n",
      "Training r2_score of Lasso() is  0.9370744458046543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.581e+10, tolerance: 7.455e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.8802646337423741\n",
      "Training r2_score of Lasso() is  0.9313565905418429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.173e+10, tolerance: 7.442e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.7803546852023793\n",
      "Training r2_score of Lasso() is  0.9437105101095927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.132e+10, tolerance: 7.292e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.889734154988582\n",
      "Training r2_score of Lasso() is  0.9326616703085859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.144e+10, tolerance: 7.311e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.883912861211615\n",
      "Training r2_score of Lasso() is  0.9347805932731484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.065e+10, tolerance: 7.285e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.9091754069584759\n",
      "Training r2_score of Lasso() is  0.927972529780342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.399e+09, tolerance: 6.865e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.8926255999061982\n",
      "Training r2_score of Lasso() is  0.9304783689156875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.591e+10, tolerance: 7.359e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.5403918688216438\n",
      "Training r2_score of Lasso() is  0.9364688854024911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.530e+10, tolerance: 7.536e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.906240646814781\n",
      "Training r2_score of Lasso() is  0.9266713949919848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.338e+10, tolerance: 7.420e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.8804704642755447\n",
      "Training r2_score of Lasso() is  0.9325042584970199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.392e+10, tolerance: 7.666e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.7849969801089036\n",
      "Training r2_score of Lasso() is  0.939622470727232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.220e+10, tolerance: 7.896e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.4810934043112868\n",
      "Training r2_score of Lasso() is  0.9323326979728005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.298e+10, tolerance: 7.624e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.9138536635501723\n",
      "Training r2_score of Lasso() is  0.9257821639739966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.949e+10, tolerance: 7.731e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.7603145269904945\n",
      "Training r2_score of Lasso() is  0.9416840950856904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.038e+10, tolerance: 7.228e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.6951606901896425\n",
      "Training r2_score of Lasso() is  0.9307676792611823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.002e+10, tolerance: 7.379e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.7941805401725508\n",
      "Training r2_score of Lasso() is  0.9428104174657068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.420e+10, tolerance: 7.319e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.7907948979270218\n",
      "Training r2_score of Lasso() is  0.9384543811216819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.504e+10, tolerance: 7.418e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.8776099194430731\n",
      "Training r2_score of Lasso() is  0.9348100616008301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.210e+10, tolerance: 7.346e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.8538489255553344\n",
      "Training r2_score of Lasso() is  0.9392171531576144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.256e+09, tolerance: 7.994e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.8730572553205694\n",
      "Training r2_score of Lasso() is  0.9320494296310498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.282e+09, tolerance: 7.572e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.8890901314315529\n",
      "Training r2_score of Lasso() is  0.9292691424724465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.378e+10, tolerance: 7.081e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.8920337709827488\n",
      "Training r2_score of Lasso() is  0.9304309708386849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.572e+10, tolerance: 7.429e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.9111878935349293\n",
      "Training r2_score of Lasso() is  0.928113000223559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.646e+10, tolerance: 7.388e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.907766553813142\n",
      "Training r2_score of Lasso() is  0.9289316458540048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.333e+10, tolerance: 7.762e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.874449995843058\n",
      "Training r2_score of Lasso() is  0.9329967444444319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.196e+10, tolerance: 7.500e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.8964453993040902\n",
      "Training r2_score of Lasso() is  0.930856174234929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.536e+10, tolerance: 6.920e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.9028562197262309\n",
      "Training r2_score of Lasso() is  0.9268993163822196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.304e+10, tolerance: 7.484e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.8720106048656182\n",
      "Training r2_score of Lasso() is  0.9361121509220077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.342e+10, tolerance: 7.253e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.8878062074135503\n",
      "Training r2_score of Lasso() is  0.9328018597318269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.002e+10, tolerance: 7.376e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.9042324843125807\n",
      "Training r2_score of Lasso() is  0.9295665315833953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.095e+10, tolerance: 7.407e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.8905501760777369\n",
      "Training r2_score of Lasso() is  0.9312608654048151\n",
      "Testing r2_score of Lasso() is  0.8570835525635287\n",
      "Training r2_score of Lasso() is  0.9370062335824776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.333e+10, tolerance: 6.921e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for i in range(50):\n",
    "\n",
    "    algo_testing(algo=\"Lasso()\",test_size=0.2,X=X,Y=Y,evaluation_metric=\"r2_score\",random_state=None,shuffle=True)\n",
    "avg_accuracies[\"Lasso()\"]/=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "ec55c398",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Ridge() is  0.4361290398199821\n",
      "Training r2_score of Ridge() is  0.9403912881394018\n",
      "Testing r2_score of Ridge() is  0.9005031510480609\n",
      "Training r2_score of Ridge() is  0.9305965154869189\n",
      "Testing r2_score of Ridge() is  0.8276974241553583\n",
      "Training r2_score of Ridge() is  0.937732552212235\n",
      "Testing r2_score of Ridge() is  0.8842126562113937\n",
      "Training r2_score of Ridge() is  0.9294784042983715\n",
      "Testing r2_score of Ridge() is  0.8871526644656155\n",
      "Training r2_score of Ridge() is  0.9320016438674943\n",
      "Testing r2_score of Ridge() is  0.8133500200768946\n",
      "Training r2_score of Ridge() is  0.9415642195506532\n",
      "Testing r2_score of Ridge() is  0.8152500787086676\n",
      "Training r2_score of Ridge() is  0.9376721322877665\n",
      "Testing r2_score of Ridge() is  0.8907579170020056\n",
      "Training r2_score of Ridge() is  0.9300855911377097\n",
      "Testing r2_score of Ridge() is  0.8921702179502455\n",
      "Training r2_score of Ridge() is  0.9310562456673763\n",
      "Testing r2_score of Ridge() is  0.8972828497115249\n",
      "Training r2_score of Ridge() is  0.9308274765051784\n",
      "Testing r2_score of Ridge() is  0.8210030142745659\n",
      "Training r2_score of Ridge() is  0.9394590220816743\n",
      "Testing r2_score of Ridge() is  0.6873332564056758\n",
      "Training r2_score of Ridge() is  0.9322196955265382\n",
      "Testing r2_score of Ridge() is  0.868646574621324\n",
      "Training r2_score of Ridge() is  0.9320354752311901\n",
      "Testing r2_score of Ridge() is  0.8980011404883453\n",
      "Training r2_score of Ridge() is  0.931241152057707\n",
      "Testing r2_score of Ridge() is  0.7567391112165931\n",
      "Training r2_score of Ridge() is  0.9424085277236884\n",
      "Testing r2_score of Ridge() is  0.8051808567964583\n",
      "Training r2_score of Ridge() is  0.9381906531394723\n",
      "Testing r2_score of Ridge() is  0.8522339874667244\n",
      "Training r2_score of Ridge() is  0.9343631116189667\n",
      "Testing r2_score of Ridge() is  0.5995872223728462\n",
      "Training r2_score of Ridge() is  0.9311178334025179\n",
      "Testing r2_score of Ridge() is  0.8840395183583999\n",
      "Training r2_score of Ridge() is  0.9293654879911742\n",
      "Testing r2_score of Ridge() is  0.7990587161890883\n",
      "Training r2_score of Ridge() is  0.9468722945386822\n",
      "Testing r2_score of Ridge() is  0.744463566884112\n",
      "Training r2_score of Ridge() is  0.9395194682714245\n",
      "Testing r2_score of Ridge() is  0.7761408493292474\n",
      "Training r2_score of Ridge() is  0.9419011297772989\n",
      "Testing r2_score of Ridge() is  0.8006083268196584\n",
      "Training r2_score of Ridge() is  0.9364876918183225\n",
      "Testing r2_score of Ridge() is  0.8828186665475263\n",
      "Training r2_score of Ridge() is  0.9295413779664181\n",
      "Testing r2_score of Ridge() is  0.881462134212966\n",
      "Training r2_score of Ridge() is  0.9314295572485692\n",
      "Testing r2_score of Ridge() is  0.8993227628093566\n",
      "Training r2_score of Ridge() is  0.930980024998781\n",
      "Testing r2_score of Ridge() is  0.8632367057469896\n",
      "Training r2_score of Ridge() is  0.9322157102655965\n",
      "Testing r2_score of Ridge() is  0.8860999409852182\n",
      "Training r2_score of Ridge() is  0.9309853831173138\n",
      "Testing r2_score of Ridge() is  0.8862249254223916\n",
      "Training r2_score of Ridge() is  0.9303894917559805\n",
      "Testing r2_score of Ridge() is  0.8745313484270777\n",
      "Training r2_score of Ridge() is  0.9325554604177205\n",
      "Testing r2_score of Ridge() is  0.8872557343240436\n",
      "Training r2_score of Ridge() is  0.9306938609881004\n",
      "Testing r2_score of Ridge() is  0.8642219195629827\n",
      "Training r2_score of Ridge() is  0.9324839194263964\n",
      "Testing r2_score of Ridge() is  0.8833389696599201\n",
      "Training r2_score of Ridge() is  0.9289083480780804\n",
      "Testing r2_score of Ridge() is  0.8911892723381829\n",
      "Training r2_score of Ridge() is  0.93437806804916\n",
      "Testing r2_score of Ridge() is  0.8674327645183447\n",
      "Training r2_score of Ridge() is  0.9324100446732476\n",
      "Testing r2_score of Ridge() is  0.6052957691695078\n",
      "Training r2_score of Ridge() is  0.9260561055923281\n",
      "Testing r2_score of Ridge() is  0.7549657780146168\n",
      "Training r2_score of Ridge() is  0.9450652264031827\n",
      "Testing r2_score of Ridge() is  0.8585603847834608\n",
      "Training r2_score of Ridge() is  0.9334726841489739\n",
      "Testing r2_score of Ridge() is  0.882189630959602\n",
      "Training r2_score of Ridge() is  0.9327658159101435\n",
      "Testing r2_score of Ridge() is  0.5218930170209088\n",
      "Training r2_score of Ridge() is  0.9396562166302971\n",
      "Testing r2_score of Ridge() is  0.8770584971197111\n",
      "Training r2_score of Ridge() is  0.9321683043222232\n",
      "Testing r2_score of Ridge() is  0.8898076702311799\n",
      "Training r2_score of Ridge() is  0.9305905685467676\n",
      "Testing r2_score of Ridge() is  0.9010450773118726\n",
      "Training r2_score of Ridge() is  0.9286205319592225\n",
      "Testing r2_score of Ridge() is  0.8915271927722561\n",
      "Training r2_score of Ridge() is  0.9321609167423853\n",
      "Testing r2_score of Ridge() is  0.7747743965358738\n",
      "Training r2_score of Ridge() is  0.9385963580708137\n",
      "Testing r2_score of Ridge() is  0.6158361764864078\n",
      "Training r2_score of Ridge() is  0.930744654471859\n",
      "Testing r2_score of Ridge() is  0.9035119117762086\n",
      "Training r2_score of Ridge() is  0.9308411974964932\n",
      "Testing r2_score of Ridge() is  0.8831320019992088\n",
      "Training r2_score of Ridge() is  0.9327923084855948\n",
      "Testing r2_score of Ridge() is  0.8935301892855001\n",
      "Training r2_score of Ridge() is  0.9298405822296518\n",
      "Testing r2_score of Ridge() is  0.7879426018931699\n",
      "Training r2_score of Ridge() is  0.9407976231485762\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(50):\n",
    "\n",
    "    algo_testing(algo=\"Ridge()\",test_size=0.2,X=X,Y=Y,evaluation_metric=\"r2_score\",random_state=None,shuffle=True)\n",
    "avg_accuracies[\"Ridge()\"]/=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "a9aed687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LinearRegression()': -2.8815820013183232e+25,\n",
       " 'RandomForestRegressor()': 0.8438274041261193,\n",
       " 'SVR()': -0.05877579110286479,\n",
       " 'KNeighborsRegressor()': 0.7009720664001358,\n",
       " 'SGDRegressor()': -1610.9935264770722,\n",
       " 'DecisionTreeRegressor()': 0.6876969565575236,\n",
       " 'ElasticNet()': 0.8036152101898719,\n",
       " 'Lasso()': 0.8381768710968853,\n",
       " 'Ridge()': 0.8229149520057455}"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "80b71c05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LinearRegression()': 0.8951031755457303,\n",
       " 'RandomForestRegressor()': 0.8978867544299124,\n",
       " 'SVR()': -0.010589228103145443,\n",
       " 'KNeighborsRegressor()': 0.7832797862200869,\n",
       " 'SGDRegressor()': -0.7054021471548115,\n",
       " 'DecisionTreeRegressor()': 0.8086875022148331,\n",
       " 'ElasticNet()': 0.8973492860701142,\n",
       " 'Lasso()': 0.9161969769460542,\n",
       " 'Ridge()': 0.9035119117762086}"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highest_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfaf0fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f121ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c8e6fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c321e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a64d9c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee71221-46cd-4f6d-8a8a-09eb9b64aa2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fab150-ef23-4110-bc56-7921a694d747",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
