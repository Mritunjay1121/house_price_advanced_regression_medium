{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d60c41ae-5ec6-434c-b42f-b7b16514a128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlxtend in /usr/local/lib/python3.9/dist-packages (0.21.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from mlxtend) (63.1.0)\n",
      "Requirement already satisfied: joblib>=0.13.2 in /usr/local/lib/python3.9/dist-packages (from mlxtend) (1.1.0)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from mlxtend) (3.5.2)\n",
      "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.9/dist-packages (from mlxtend) (1.8.1)\n",
      "Requirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.9/dist-packages (from mlxtend) (1.23.1)\n",
      "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.9/dist-packages (from mlxtend) (1.4.3)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.9/dist-packages (from mlxtend) (1.1.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.0.0->mlxtend) (9.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.0.0->mlxtend) (3.0.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.0.0->mlxtend) (4.34.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.0.0->mlxtend) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.0.0->mlxtend) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.0.0->mlxtend) (1.4.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.0.0->mlxtend) (21.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=0.24.2->mlxtend) (2022.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=1.0.2->mlxtend) (3.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.14.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "addeba46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "import scipy.stats as stat\n",
    "import importlib\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "298c7238",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.read_csv(\"house_price_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0a57d23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop(\"Id\",axis=1,inplace=True) ## reduntatnt\n",
    "output_col=df_train['SalePrice']\n",
    "df_train.drop('SalePrice',axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "22fc7cf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>...</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>13175</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9042</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GdPrv</td>\n",
       "      <td>Shed</td>\n",
       "      <td>2500</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0             60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1             20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2             60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3             70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4             60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "...          ...      ...          ...      ...    ...   ...      ...   \n",
       "1455          60       RL         62.0     7917   Pave   NaN      Reg   \n",
       "1456          20       RL         85.0    13175   Pave   NaN      Reg   \n",
       "1457          70       RL         66.0     9042   Pave   NaN      Reg   \n",
       "1458          20       RL         68.0     9717   Pave   NaN      Reg   \n",
       "1459          20       RL         75.0     9937   Pave   NaN      Reg   \n",
       "\n",
       "     LandContour Utilities LotConfig  ... ScreenPorch PoolArea PoolQC  Fence  \\\n",
       "0            Lvl    AllPub    Inside  ...           0        0    NaN    NaN   \n",
       "1            Lvl    AllPub       FR2  ...           0        0    NaN    NaN   \n",
       "2            Lvl    AllPub    Inside  ...           0        0    NaN    NaN   \n",
       "3            Lvl    AllPub    Corner  ...           0        0    NaN    NaN   \n",
       "4            Lvl    AllPub       FR2  ...           0        0    NaN    NaN   \n",
       "...          ...       ...       ...  ...         ...      ...    ...    ...   \n",
       "1455         Lvl    AllPub    Inside  ...           0        0    NaN    NaN   \n",
       "1456         Lvl    AllPub    Inside  ...           0        0    NaN  MnPrv   \n",
       "1457         Lvl    AllPub    Inside  ...           0        0    NaN  GdPrv   \n",
       "1458         Lvl    AllPub    Inside  ...           0        0    NaN    NaN   \n",
       "1459         Lvl    AllPub    Inside  ...           0        0    NaN    NaN   \n",
       "\n",
       "     MiscFeature MiscVal  MoSold  YrSold  SaleType  SaleCondition  \n",
       "0            NaN       0       2    2008        WD         Normal  \n",
       "1            NaN       0       5    2007        WD         Normal  \n",
       "2            NaN       0       9    2008        WD         Normal  \n",
       "3            NaN       0       2    2006        WD        Abnorml  \n",
       "4            NaN       0      12    2008        WD         Normal  \n",
       "...          ...     ...     ...     ...       ...            ...  \n",
       "1455         NaN       0       8    2007        WD         Normal  \n",
       "1456         NaN       0       2    2010        WD         Normal  \n",
       "1457        Shed    2500       5    2010        WD         Normal  \n",
       "1458         NaN       0       4    2010        WD         Normal  \n",
       "1459         NaN       0       6    2008        WD         Normal  \n",
       "\n",
       "[1460 rows x 79 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9d780948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1201.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1452.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>56.897260</td>\n",
       "      <td>70.049958</td>\n",
       "      <td>10516.828082</td>\n",
       "      <td>6.099315</td>\n",
       "      <td>5.575342</td>\n",
       "      <td>1971.267808</td>\n",
       "      <td>1984.865753</td>\n",
       "      <td>103.685262</td>\n",
       "      <td>443.639726</td>\n",
       "      <td>46.549315</td>\n",
       "      <td>...</td>\n",
       "      <td>472.980137</td>\n",
       "      <td>94.244521</td>\n",
       "      <td>46.660274</td>\n",
       "      <td>21.954110</td>\n",
       "      <td>3.409589</td>\n",
       "      <td>15.060959</td>\n",
       "      <td>2.758904</td>\n",
       "      <td>43.489041</td>\n",
       "      <td>6.321918</td>\n",
       "      <td>2007.815753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>42.300571</td>\n",
       "      <td>24.284752</td>\n",
       "      <td>9981.264932</td>\n",
       "      <td>1.382997</td>\n",
       "      <td>1.112799</td>\n",
       "      <td>30.202904</td>\n",
       "      <td>20.645407</td>\n",
       "      <td>181.066207</td>\n",
       "      <td>456.098091</td>\n",
       "      <td>161.319273</td>\n",
       "      <td>...</td>\n",
       "      <td>213.804841</td>\n",
       "      <td>125.338794</td>\n",
       "      <td>66.256028</td>\n",
       "      <td>61.119149</td>\n",
       "      <td>29.317331</td>\n",
       "      <td>55.757415</td>\n",
       "      <td>40.177307</td>\n",
       "      <td>496.123024</td>\n",
       "      <td>2.703626</td>\n",
       "      <td>1.328095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1300.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1872.000000</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2006.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>7553.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1954.000000</td>\n",
       "      <td>1967.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>334.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2007.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>9478.500000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1973.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>383.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2008.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>70.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>11601.500000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>712.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>576.000000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2009.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>190.000000</td>\n",
       "      <td>313.000000</td>\n",
       "      <td>215245.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>5644.000000</td>\n",
       "      <td>1474.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1418.000000</td>\n",
       "      <td>857.000000</td>\n",
       "      <td>547.000000</td>\n",
       "      <td>552.000000</td>\n",
       "      <td>508.000000</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>738.000000</td>\n",
       "      <td>15500.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        MSSubClass  LotFrontage        LotArea  OverallQual  OverallCond  \\\n",
       "count  1460.000000  1201.000000    1460.000000  1460.000000  1460.000000   \n",
       "mean     56.897260    70.049958   10516.828082     6.099315     5.575342   \n",
       "std      42.300571    24.284752    9981.264932     1.382997     1.112799   \n",
       "min      20.000000    21.000000    1300.000000     1.000000     1.000000   \n",
       "25%      20.000000    59.000000    7553.500000     5.000000     5.000000   \n",
       "50%      50.000000    69.000000    9478.500000     6.000000     5.000000   \n",
       "75%      70.000000    80.000000   11601.500000     7.000000     6.000000   \n",
       "max     190.000000   313.000000  215245.000000    10.000000     9.000000   \n",
       "\n",
       "         YearBuilt  YearRemodAdd   MasVnrArea   BsmtFinSF1   BsmtFinSF2  ...  \\\n",
       "count  1460.000000   1460.000000  1452.000000  1460.000000  1460.000000  ...   \n",
       "mean   1971.267808   1984.865753   103.685262   443.639726    46.549315  ...   \n",
       "std      30.202904     20.645407   181.066207   456.098091   161.319273  ...   \n",
       "min    1872.000000   1950.000000     0.000000     0.000000     0.000000  ...   \n",
       "25%    1954.000000   1967.000000     0.000000     0.000000     0.000000  ...   \n",
       "50%    1973.000000   1994.000000     0.000000   383.500000     0.000000  ...   \n",
       "75%    2000.000000   2004.000000   166.000000   712.250000     0.000000  ...   \n",
       "max    2010.000000   2010.000000  1600.000000  5644.000000  1474.000000  ...   \n",
       "\n",
       "        GarageArea   WoodDeckSF  OpenPorchSF  EnclosedPorch    3SsnPorch  \\\n",
       "count  1460.000000  1460.000000  1460.000000    1460.000000  1460.000000   \n",
       "mean    472.980137    94.244521    46.660274      21.954110     3.409589   \n",
       "std     213.804841   125.338794    66.256028      61.119149    29.317331   \n",
       "min       0.000000     0.000000     0.000000       0.000000     0.000000   \n",
       "25%     334.500000     0.000000     0.000000       0.000000     0.000000   \n",
       "50%     480.000000     0.000000    25.000000       0.000000     0.000000   \n",
       "75%     576.000000   168.000000    68.000000       0.000000     0.000000   \n",
       "max    1418.000000   857.000000   547.000000     552.000000   508.000000   \n",
       "\n",
       "       ScreenPorch     PoolArea       MiscVal       MoSold       YrSold  \n",
       "count  1460.000000  1460.000000   1460.000000  1460.000000  1460.000000  \n",
       "mean     15.060959     2.758904     43.489041     6.321918  2007.815753  \n",
       "std      55.757415    40.177307    496.123024     2.703626     1.328095  \n",
       "min       0.000000     0.000000      0.000000     1.000000  2006.000000  \n",
       "25%       0.000000     0.000000      0.000000     5.000000  2007.000000  \n",
       "50%       0.000000     0.000000      0.000000     6.000000  2008.000000  \n",
       "75%       0.000000     0.000000      0.000000     8.000000  2009.000000  \n",
       "max     480.000000   738.000000  15500.000000    12.000000  2010.000000  \n",
       "\n",
       "[8 rows x 36 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3c48be5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSSubClass         0\n",
       "MSZoning           0\n",
       "LotFrontage      259\n",
       "LotArea            0\n",
       "Street             0\n",
       "                ... \n",
       "MiscVal            0\n",
       "MoSold             0\n",
       "YrSold             0\n",
       "SaleType           0\n",
       "SaleCondition      0\n",
       "Length: 79, dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "598c821b-4254-4129-8cf9-0a9b4d50eb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns which have zero values in more than 50% rows are removed\n",
    "def column_with_most_reduntant_values(reduntant_value,df_train:pd.DataFrame,threshold:float):\n",
    "    reduntant_counts={}\n",
    "    columns_with_most_reduntant_counts=[]\n",
    "    for col in df_train.columns:\n",
    "        if df_train[col].dtypes=='int' or df_train[col].dtypes=='float':\n",
    "            for values in df_train[col]:\n",
    "                if values==reduntant_value:\n",
    "                    reduntant_counts[col]=1+reduntant_counts.get(col,0)\n",
    "    for col in reduntant_counts:\n",
    "        if reduntant_counts[col]>=(threshold*len(df_train)):\n",
    "            columns_with_most_reduntant_counts.append(col)\n",
    "    df_train.drop(columns_with_most_reduntant_counts,axis=1,inplace=True)\n",
    "        \n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ac57fe70-5f53-4bdb-9607-238484acd4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_with_most_reduntant_values(reduntant_value=0,df_train=df_train,threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4d518c35-78eb-49f2-a59e-1e8ec94ad72c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>...</th>\n",
       "      <th>GarageCond</th>\n",
       "      <th>PavedDrive</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>...</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>13175</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9042</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GdPrv</td>\n",
       "      <td>Shed</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0             60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1             20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2             60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3             70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4             60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "...          ...      ...          ...      ...    ...   ...      ...   \n",
       "1455          60       RL         62.0     7917   Pave   NaN      Reg   \n",
       "1456          20       RL         85.0    13175   Pave   NaN      Reg   \n",
       "1457          70       RL         66.0     9042   Pave   NaN      Reg   \n",
       "1458          20       RL         68.0     9717   Pave   NaN      Reg   \n",
       "1459          20       RL         75.0     9937   Pave   NaN      Reg   \n",
       "\n",
       "     LandContour Utilities LotConfig  ... GarageCond PavedDrive OpenPorchSF  \\\n",
       "0            Lvl    AllPub    Inside  ...         TA          Y          61   \n",
       "1            Lvl    AllPub       FR2  ...         TA          Y           0   \n",
       "2            Lvl    AllPub    Inside  ...         TA          Y          42   \n",
       "3            Lvl    AllPub    Corner  ...         TA          Y          35   \n",
       "4            Lvl    AllPub       FR2  ...         TA          Y          84   \n",
       "...          ...       ...       ...  ...        ...        ...         ...   \n",
       "1455         Lvl    AllPub    Inside  ...         TA          Y          40   \n",
       "1456         Lvl    AllPub    Inside  ...         TA          Y           0   \n",
       "1457         Lvl    AllPub    Inside  ...         TA          Y          60   \n",
       "1458         Lvl    AllPub    Inside  ...         TA          Y           0   \n",
       "1459         Lvl    AllPub    Inside  ...         TA          Y          68   \n",
       "\n",
       "     PoolQC  Fence MiscFeature  MoSold  YrSold  SaleType  SaleCondition  \n",
       "0       NaN    NaN         NaN       2    2008        WD         Normal  \n",
       "1       NaN    NaN         NaN       5    2007        WD         Normal  \n",
       "2       NaN    NaN         NaN       9    2008        WD         Normal  \n",
       "3       NaN    NaN         NaN       2    2006        WD        Abnorml  \n",
       "4       NaN    NaN         NaN      12    2008        WD         Normal  \n",
       "...     ...    ...         ...     ...     ...       ...            ...  \n",
       "1455    NaN    NaN         NaN       8    2007        WD         Normal  \n",
       "1456    NaN  MnPrv         NaN       2    2010        WD         Normal  \n",
       "1457    NaN  GdPrv        Shed       5    2010        WD         Normal  \n",
       "1458    NaN    NaN         NaN       4    2010        WD         Normal  \n",
       "1459    NaN    NaN         NaN       6    2008        WD         Normal  \n",
       "\n",
       "[1460 rows x 66 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3aec5d13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Deleting columns which have more than 50% NULL values\n",
    "\n",
    "def column_with_most_reduntant_null_values(threshold,df_train:pd.DataFrame):\n",
    "    null_cols=[]\n",
    "    for col in df_train.columns:\n",
    "        if df_train[col].isnull().sum()>=(threshold*len(df_train)):\n",
    "            null_cols.append(col)\n",
    "    df_train.drop(null_cols,axis=1,inplace=True)\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "45e43969-8c4c-4da2-916c-9c31dbf3a687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(column_with_most_reduntant_null_values(threshold=0.5,X=df_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "390c6267-15fd-4ddf-b3fd-f3a91a12c080",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_with_most_reduntant_null_values(threshold=0.5,df_train=df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1ed65a14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>...</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>GarageQual</th>\n",
       "      <th>GarageCond</th>\n",
       "      <th>PavedDrive</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>548</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>460</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>608</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>42</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>642</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>836</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>84</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>460</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>40</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>13175</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>500</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9042</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>252</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>60</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>240</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>276</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>68</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass MSZoning  LotFrontage  LotArea Street LotShape LandContour  \\\n",
       "0             60       RL         65.0     8450   Pave      Reg         Lvl   \n",
       "1             20       RL         80.0     9600   Pave      Reg         Lvl   \n",
       "2             60       RL         68.0    11250   Pave      IR1         Lvl   \n",
       "3             70       RL         60.0     9550   Pave      IR1         Lvl   \n",
       "4             60       RL         84.0    14260   Pave      IR1         Lvl   \n",
       "...          ...      ...          ...      ...    ...      ...         ...   \n",
       "1455          60       RL         62.0     7917   Pave      Reg         Lvl   \n",
       "1456          20       RL         85.0    13175   Pave      Reg         Lvl   \n",
       "1457          70       RL         66.0     9042   Pave      Reg         Lvl   \n",
       "1458          20       RL         68.0     9717   Pave      Reg         Lvl   \n",
       "1459          20       RL         75.0     9937   Pave      Reg         Lvl   \n",
       "\n",
       "     Utilities LotConfig LandSlope  ... GarageCars GarageArea GarageQual  \\\n",
       "0       AllPub    Inside       Gtl  ...          2        548         TA   \n",
       "1       AllPub       FR2       Gtl  ...          2        460         TA   \n",
       "2       AllPub    Inside       Gtl  ...          2        608         TA   \n",
       "3       AllPub    Corner       Gtl  ...          3        642         TA   \n",
       "4       AllPub       FR2       Gtl  ...          3        836         TA   \n",
       "...        ...       ...       ...  ...        ...        ...        ...   \n",
       "1455    AllPub    Inside       Gtl  ...          2        460         TA   \n",
       "1456    AllPub    Inside       Gtl  ...          2        500         TA   \n",
       "1457    AllPub    Inside       Gtl  ...          1        252         TA   \n",
       "1458    AllPub    Inside       Gtl  ...          1        240         TA   \n",
       "1459    AllPub    Inside       Gtl  ...          1        276         TA   \n",
       "\n",
       "     GarageCond PavedDrive  OpenPorchSF  MoSold  YrSold  SaleType  \\\n",
       "0            TA          Y           61       2    2008        WD   \n",
       "1            TA          Y            0       5    2007        WD   \n",
       "2            TA          Y           42       9    2008        WD   \n",
       "3            TA          Y           35       2    2006        WD   \n",
       "4            TA          Y           84      12    2008        WD   \n",
       "...         ...        ...          ...     ...     ...       ...   \n",
       "1455         TA          Y           40       8    2007        WD   \n",
       "1456         TA          Y            0       2    2010        WD   \n",
       "1457         TA          Y           60       5    2010        WD   \n",
       "1458         TA          Y            0       4    2010        WD   \n",
       "1459         TA          Y           68       6    2008        WD   \n",
       "\n",
       "     SaleCondition  \n",
       "0           Normal  \n",
       "1           Normal  \n",
       "2           Normal  \n",
       "3          Abnorml  \n",
       "4           Normal  \n",
       "...            ...  \n",
       "1455        Normal  \n",
       "1456        Normal  \n",
       "1457        Normal  \n",
       "1458        Normal  \n",
       "1459        Normal  \n",
       "\n",
       "[1460 rows x 62 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f731ac41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for cols in df_train.columns:\n",
    "    if df_train[cols].dtype==\"int64\":\n",
    "        # print(cols,i)\n",
    "        i+=1\n",
    "    elif df_train[cols].dtype==\"object\":\n",
    "#         print(cols,i)\n",
    "        i+=1\n",
    "#     elif df_train[cols].dtype==\"float64\":\n",
    "#         print(cols,i)\n",
    "# #         i+=1\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b7285ad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>...</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>GarageQual</th>\n",
       "      <th>GarageCond</th>\n",
       "      <th>PavedDrive</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>548</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>460</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>608</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>42</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>642</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>836</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>84</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>460</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>40</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>13175</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>500</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9042</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>252</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>60</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>240</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>276</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>68</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass MSZoning  LotFrontage  LotArea Street LotShape LandContour  \\\n",
       "0             60       RL         65.0     8450   Pave      Reg         Lvl   \n",
       "1             20       RL         80.0     9600   Pave      Reg         Lvl   \n",
       "2             60       RL         68.0    11250   Pave      IR1         Lvl   \n",
       "3             70       RL         60.0     9550   Pave      IR1         Lvl   \n",
       "4             60       RL         84.0    14260   Pave      IR1         Lvl   \n",
       "...          ...      ...          ...      ...    ...      ...         ...   \n",
       "1455          60       RL         62.0     7917   Pave      Reg         Lvl   \n",
       "1456          20       RL         85.0    13175   Pave      Reg         Lvl   \n",
       "1457          70       RL         66.0     9042   Pave      Reg         Lvl   \n",
       "1458          20       RL         68.0     9717   Pave      Reg         Lvl   \n",
       "1459          20       RL         75.0     9937   Pave      Reg         Lvl   \n",
       "\n",
       "     Utilities LotConfig LandSlope  ... GarageCars GarageArea GarageQual  \\\n",
       "0       AllPub    Inside       Gtl  ...          2        548         TA   \n",
       "1       AllPub       FR2       Gtl  ...          2        460         TA   \n",
       "2       AllPub    Inside       Gtl  ...          2        608         TA   \n",
       "3       AllPub    Corner       Gtl  ...          3        642         TA   \n",
       "4       AllPub       FR2       Gtl  ...          3        836         TA   \n",
       "...        ...       ...       ...  ...        ...        ...        ...   \n",
       "1455    AllPub    Inside       Gtl  ...          2        460         TA   \n",
       "1456    AllPub    Inside       Gtl  ...          2        500         TA   \n",
       "1457    AllPub    Inside       Gtl  ...          1        252         TA   \n",
       "1458    AllPub    Inside       Gtl  ...          1        240         TA   \n",
       "1459    AllPub    Inside       Gtl  ...          1        276         TA   \n",
       "\n",
       "     GarageCond PavedDrive  OpenPorchSF  MoSold  YrSold  SaleType  \\\n",
       "0            TA          Y           61       2    2008        WD   \n",
       "1            TA          Y            0       5    2007        WD   \n",
       "2            TA          Y           42       9    2008        WD   \n",
       "3            TA          Y           35       2    2006        WD   \n",
       "4            TA          Y           84      12    2008        WD   \n",
       "...         ...        ...          ...     ...     ...       ...   \n",
       "1455         TA          Y           40       8    2007        WD   \n",
       "1456         TA          Y            0       2    2010        WD   \n",
       "1457         TA          Y           60       5    2010        WD   \n",
       "1458         TA          Y            0       4    2010        WD   \n",
       "1459         TA          Y           68       6    2008        WD   \n",
       "\n",
       "     SaleCondition  \n",
       "0           Normal  \n",
       "1           Normal  \n",
       "2           Normal  \n",
       "3          Abnorml  \n",
       "4           Normal  \n",
       "...            ...  \n",
       "1455        Normal  \n",
       "1456        Normal  \n",
       "1457        Normal  \n",
       "1458        Normal  \n",
       "1459        Normal  \n",
       "\n",
       "[1460 rows x 62 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9928a0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling Null Values\n",
    "\n",
    "def fill_null_values(for_numerical_cols:str,for_categorical_cols:str,df_train):\n",
    "    for cols in df_train.columns:\n",
    "        if df_train[cols].dtype==\"int64\" or df_train[cols].dtype==\"float64\":\n",
    "            if for_numerical_cols==\"median\":\n",
    "                median_=df_train[cols].median()\n",
    "                df_train[cols].fillna(median_,inplace=True)\n",
    "        elif df_train[cols].dtype==\"object\":\n",
    "            if for_categorical_cols==\"most_frequent\":\n",
    "                d=list(df_train[cols].value_counts().index) # most frequent\n",
    "                df_train[cols].fillna(d[0],inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9c256fcd-de29-4a4b-b910-5326262601cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_null_values(for_numerical_cols=\"median\",for_categorical_cols=\"most_frequent\",df_train=df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "13f5495b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_train.columns:\n",
    "    if df_train[col].isnull().sum()>(0):\n",
    "\n",
    "        print(col,df[col].isnull().sum(),df_train[col].dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e468feff-0a9c-4f0e-a7df-f8f66655fcb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>...</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>GarageQual</th>\n",
       "      <th>GarageCond</th>\n",
       "      <th>PavedDrive</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>548</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>460</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>608</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>42</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>642</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>836</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>84</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>460</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>40</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>13175</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>500</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9042</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>252</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>60</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>240</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>276</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>68</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass MSZoning  LotFrontage  LotArea Street LotShape LandContour  \\\n",
       "0             60       RL         65.0     8450   Pave      Reg         Lvl   \n",
       "1             20       RL         80.0     9600   Pave      Reg         Lvl   \n",
       "2             60       RL         68.0    11250   Pave      IR1         Lvl   \n",
       "3             70       RL         60.0     9550   Pave      IR1         Lvl   \n",
       "4             60       RL         84.0    14260   Pave      IR1         Lvl   \n",
       "...          ...      ...          ...      ...    ...      ...         ...   \n",
       "1455          60       RL         62.0     7917   Pave      Reg         Lvl   \n",
       "1456          20       RL         85.0    13175   Pave      Reg         Lvl   \n",
       "1457          70       RL         66.0     9042   Pave      Reg         Lvl   \n",
       "1458          20       RL         68.0     9717   Pave      Reg         Lvl   \n",
       "1459          20       RL         75.0     9937   Pave      Reg         Lvl   \n",
       "\n",
       "     Utilities LotConfig LandSlope  ... GarageCars GarageArea GarageQual  \\\n",
       "0       AllPub    Inside       Gtl  ...          2        548         TA   \n",
       "1       AllPub       FR2       Gtl  ...          2        460         TA   \n",
       "2       AllPub    Inside       Gtl  ...          2        608         TA   \n",
       "3       AllPub    Corner       Gtl  ...          3        642         TA   \n",
       "4       AllPub       FR2       Gtl  ...          3        836         TA   \n",
       "...        ...       ...       ...  ...        ...        ...        ...   \n",
       "1455    AllPub    Inside       Gtl  ...          2        460         TA   \n",
       "1456    AllPub    Inside       Gtl  ...          2        500         TA   \n",
       "1457    AllPub    Inside       Gtl  ...          1        252         TA   \n",
       "1458    AllPub    Inside       Gtl  ...          1        240         TA   \n",
       "1459    AllPub    Inside       Gtl  ...          1        276         TA   \n",
       "\n",
       "     GarageCond PavedDrive  OpenPorchSF  MoSold  YrSold  SaleType  \\\n",
       "0            TA          Y           61       2    2008        WD   \n",
       "1            TA          Y            0       5    2007        WD   \n",
       "2            TA          Y           42       9    2008        WD   \n",
       "3            TA          Y           35       2    2006        WD   \n",
       "4            TA          Y           84      12    2008        WD   \n",
       "...         ...        ...          ...     ...     ...       ...   \n",
       "1455         TA          Y           40       8    2007        WD   \n",
       "1456         TA          Y            0       2    2010        WD   \n",
       "1457         TA          Y           60       5    2010        WD   \n",
       "1458         TA          Y            0       4    2010        WD   \n",
       "1459         TA          Y           68       6    2008        WD   \n",
       "\n",
       "     SaleCondition  \n",
       "0           Normal  \n",
       "1           Normal  \n",
       "2           Normal  \n",
       "3          Abnorml  \n",
       "4           Normal  \n",
       "...            ...  \n",
       "1455        Normal  \n",
       "1456        Normal  \n",
       "1457        Normal  \n",
       "1458        Normal  \n",
       "1459        Normal  \n",
       "\n",
       "[1460 rows x 62 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fcb707f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_cols=list(df_train.select_dtypes(include= np.number).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8c5627c5-6f9f-4e18-ae8d-48d91f242201",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols=list(df_train.select_dtypes(exclude= np.number).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e527d259",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MSZoning',\n",
       " 'Street',\n",
       " 'LotShape',\n",
       " 'LandContour',\n",
       " 'Utilities',\n",
       " 'LotConfig',\n",
       " 'LandSlope',\n",
       " 'Neighborhood',\n",
       " 'Condition1',\n",
       " 'Condition2',\n",
       " 'BldgType',\n",
       " 'HouseStyle',\n",
       " 'RoofStyle',\n",
       " 'RoofMatl',\n",
       " 'Exterior1st',\n",
       " 'Exterior2nd',\n",
       " 'MasVnrType',\n",
       " 'ExterQual',\n",
       " 'ExterCond',\n",
       " 'Foundation',\n",
       " 'BsmtQual',\n",
       " 'BsmtCond',\n",
       " 'BsmtExposure',\n",
       " 'BsmtFinType1',\n",
       " 'BsmtFinType2',\n",
       " 'Heating',\n",
       " 'HeatingQC',\n",
       " 'CentralAir',\n",
       " 'Electrical',\n",
       " 'KitchenQual',\n",
       " 'Functional',\n",
       " 'FireplaceQu',\n",
       " 'GarageType',\n",
       " 'GarageFinish',\n",
       " 'GarageQual',\n",
       " 'GarageCond',\n",
       " 'PavedDrive',\n",
       " 'SaleType',\n",
       " 'SaleCondition']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "938be803-6549-4586-a0d1-212fac08104c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"MSZoning\"].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9205dbe5-2bb3-468d-8e02-35b5ce90833d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(nrows = 6, ncols = 4)    # axes is 2d array (3x3)\n",
    "# axes = axes.flatten()         # Convert axes to 1d array of length 9\n",
    "# fig.set_size_inches(40, 40)\n",
    "\n",
    "# for ax, col in zip(axes, continuous_cols):\n",
    "#     print()\n",
    "#     sns.distplot(df_train[col], ax = ax,kde=True)\n",
    "#     ax.set_title(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "dbbdbcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(nrows = 6, ncols = 4)#   skew axes is 2d array (3x3)\n",
    "# axes = axes.flatten()         # Convert axes to 1d array of length 9\n",
    "# fig.set_size_inches(40, 40)\n",
    "\n",
    "# for ax, col in zip(axes, continuous_cols):\n",
    "#     # print()\n",
    "#     sns.boxplot(df_train[col], ax = ax)\n",
    "#     ax.set_title(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9192f5ff-e384-4144-bbce-641ed883309f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(20,15))\n",
    "# sns.heatmap(df_train.loc[:,continuous_cols].corr(method='spearman'),annot=True,cmap=\"RdYlGn\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "71b4cde3-7bbd-4799-8b58-a4fb0efb5534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.set(rc={'figure.figsize':(40,40)})\n",
    "# cData_attr = df_train.loc[:,continuous_cols]\n",
    "# sns.pairplot(cData_attr, diag_kind='kde')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "26eaf9a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>...</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>706</td>\n",
       "      <td>150</td>\n",
       "      <td>856</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>2</td>\n",
       "      <td>548</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>978</td>\n",
       "      <td>284</td>\n",
       "      <td>1262</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>2</td>\n",
       "      <td>460</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>486</td>\n",
       "      <td>434</td>\n",
       "      <td>920</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>2</td>\n",
       "      <td>608</td>\n",
       "      <td>42</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>216</td>\n",
       "      <td>540</td>\n",
       "      <td>756</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>3</td>\n",
       "      <td>642</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>655</td>\n",
       "      <td>490</td>\n",
       "      <td>1145</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>836</td>\n",
       "      <td>84</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>60</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1999</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>953</td>\n",
       "      <td>953</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>2</td>\n",
       "      <td>460</td>\n",
       "      <td>40</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>20</td>\n",
       "      <td>85.0</td>\n",
       "      <td>13175</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1978</td>\n",
       "      <td>1988</td>\n",
       "      <td>790</td>\n",
       "      <td>589</td>\n",
       "      <td>1542</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1978.0</td>\n",
       "      <td>2</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>70</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9042</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>1941</td>\n",
       "      <td>2006</td>\n",
       "      <td>275</td>\n",
       "      <td>877</td>\n",
       "      <td>1152</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1941.0</td>\n",
       "      <td>1</td>\n",
       "      <td>252</td>\n",
       "      <td>60</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>20</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1950</td>\n",
       "      <td>1996</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>1078</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>1</td>\n",
       "      <td>240</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>20</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1965</td>\n",
       "      <td>1965</td>\n",
       "      <td>830</td>\n",
       "      <td>136</td>\n",
       "      <td>1256</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1965.0</td>\n",
       "      <td>1</td>\n",
       "      <td>276</td>\n",
       "      <td>68</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0             60         65.0     8450            7            5       2003   \n",
       "1             20         80.0     9600            6            8       1976   \n",
       "2             60         68.0    11250            7            5       2001   \n",
       "3             70         60.0     9550            7            5       1915   \n",
       "4             60         84.0    14260            8            5       2000   \n",
       "...          ...          ...      ...          ...          ...        ...   \n",
       "1455          60         62.0     7917            6            5       1999   \n",
       "1456          20         85.0    13175            6            6       1978   \n",
       "1457          70         66.0     9042            7            9       1941   \n",
       "1458          20         68.0     9717            5            6       1950   \n",
       "1459          20         75.0     9937            5            6       1965   \n",
       "\n",
       "      YearRemodAdd  BsmtFinSF1  BsmtUnfSF  TotalBsmtSF  ...  BedroomAbvGr  \\\n",
       "0             2003         706        150          856  ...             3   \n",
       "1             1976         978        284         1262  ...             3   \n",
       "2             2002         486        434          920  ...             3   \n",
       "3             1970         216        540          756  ...             3   \n",
       "4             2000         655        490         1145  ...             4   \n",
       "...            ...         ...        ...          ...  ...           ...   \n",
       "1455          2000           0        953          953  ...             3   \n",
       "1456          1988         790        589         1542  ...             3   \n",
       "1457          2006         275        877         1152  ...             4   \n",
       "1458          1996          49          0         1078  ...             2   \n",
       "1459          1965         830        136         1256  ...             3   \n",
       "\n",
       "      KitchenAbvGr  TotRmsAbvGrd  Fireplaces  GarageYrBlt  GarageCars  \\\n",
       "0                1             8           0       2003.0           2   \n",
       "1                1             6           1       1976.0           2   \n",
       "2                1             6           1       2001.0           2   \n",
       "3                1             7           1       1998.0           3   \n",
       "4                1             9           1       2000.0           3   \n",
       "...            ...           ...         ...          ...         ...   \n",
       "1455             1             7           1       1999.0           2   \n",
       "1456             1             7           2       1978.0           2   \n",
       "1457             1             9           2       1941.0           1   \n",
       "1458             1             5           0       1950.0           1   \n",
       "1459             1             6           0       1965.0           1   \n",
       "\n",
       "      GarageArea  OpenPorchSF  MoSold  YrSold  \n",
       "0            548           61       2    2008  \n",
       "1            460            0       5    2007  \n",
       "2            608           42       9    2008  \n",
       "3            642           35       2    2006  \n",
       "4            836           84      12    2008  \n",
       "...          ...          ...     ...     ...  \n",
       "1455         460           40       8    2007  \n",
       "1456         500            0       2    2010  \n",
       "1457         252           60       5    2010  \n",
       "1458         240            0       4    2010  \n",
       "1459         276           68       6    2008  \n",
       "\n",
       "[1460 rows x 23 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.loc[:,continuous_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "03f87857-2de4-4520-ab1b-b00cc28803ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MSSubClass',\n",
       " 'LotFrontage',\n",
       " 'LotArea',\n",
       " 'OverallQual',\n",
       " 'OverallCond',\n",
       " 'YearBuilt',\n",
       " 'YearRemodAdd',\n",
       " 'BsmtFinSF1',\n",
       " 'BsmtUnfSF',\n",
       " 'TotalBsmtSF',\n",
       " '1stFlrSF',\n",
       " 'GrLivArea',\n",
       " 'FullBath',\n",
       " 'BedroomAbvGr',\n",
       " 'KitchenAbvGr',\n",
       " 'TotRmsAbvGrd',\n",
       " 'Fireplaces',\n",
       " 'GarageYrBlt',\n",
       " 'GarageCars',\n",
       " 'GarageArea',\n",
       " 'OpenPorchSF',\n",
       " 'MoSold',\n",
       " 'YrSold']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "continuous_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4d88b603-83e1-4bfd-89e4-a1301aeed7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.concat([output_col,df_train],axis=1) # since rows will be deleted here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a6a01c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -55.0 , 145.0 ]\n",
      "[ 30.0 , 110.0 ]\n",
      "[ 2440.0 , 16936.0 ]\n",
      "[ 2.0 , 10.0 ]\n",
      "[ 3.5 , 7.5 ]\n",
      "[ 1887.0 , 2071.0 ]\n",
      "[ 1909.0 , 2061.0 ]\n",
      "[ -1099.125 , 1831.875 ]\n",
      "[ -636.375 , 1718.625 ]\n",
      "[ 141.25 , 1983.25 ]\n",
      "[ 207.25 , 2053.25 ]\n",
      "[ 236.25 , 2622.25 ]\n",
      "[ -0.5 , 3.5 ]\n",
      "[ 0.5 , 4.5 ]\n",
      "[ 1.0 , 1.0 ]\n",
      "[ 2.0 , 10.0 ]\n",
      "[ -1.5 , 2.5 ]\n",
      "[ 1904.5 , 2060.5 ]\n",
      "[ -0.5 , 3.5 ]\n",
      "[ -11.5 , 928.5 ]\n",
      "[ -102.0 , 170.0 ]\n",
      "[ -2.0 , 14.0 ]\n",
      "[ 2004.0 , 2012.0 ]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for col in continuous_cols:\n",
    "    q1=df_train[col].quantile(0.25)\n",
    "    q3=df_train[col].quantile(0.75)\n",
    "    iqr=q3-q1\n",
    "    l=q1-1.5*iqr\n",
    "    h=q3+1.5*iqr\n",
    "    print(\"[\",l,\",\",h,\"]\")\n",
    "    df_train = df_train[(df_train[col] <= h)]# & (df_train[col] >=l)] \n",
    "    df_train =df_train[(df_train[col] >=l)] \n",
    "   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1106dbc8-8495-4c6c-9a79-8f5388f4b1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_col=df_train['SalePrice']\n",
    "df_train.drop(\"SalePrice\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d2cc9e77-caf8-4f99-b317-ab717acdba09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>...</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>GarageQual</th>\n",
       "      <th>GarageCond</th>\n",
       "      <th>PavedDrive</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>548</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>608</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>42</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>642</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>836</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>84</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>14115</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>480</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>78.0</td>\n",
       "      <td>9262</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>840</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>36</td>\n",
       "      <td>5</td>\n",
       "      <td>2009</td>\n",
       "      <td>New</td>\n",
       "      <td>Partial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>20</td>\n",
       "      <td>FV</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7500</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>400</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>113</td>\n",
       "      <td>10</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>460</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>40</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>240</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>276</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>68</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>953 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass MSZoning  LotFrontage  LotArea Street LotShape LandContour  \\\n",
       "0             60       RL         65.0     8450   Pave      Reg         Lvl   \n",
       "2             60       RL         68.0    11250   Pave      IR1         Lvl   \n",
       "3             70       RL         60.0     9550   Pave      IR1         Lvl   \n",
       "4             60       RL         84.0    14260   Pave      IR1         Lvl   \n",
       "5             50       RL         85.0    14115   Pave      IR1         Lvl   \n",
       "...          ...      ...          ...      ...    ...      ...         ...   \n",
       "1451          20       RL         78.0     9262   Pave      Reg         Lvl   \n",
       "1454          20       FV         62.0     7500   Pave      Reg         Lvl   \n",
       "1455          60       RL         62.0     7917   Pave      Reg         Lvl   \n",
       "1458          20       RL         68.0     9717   Pave      Reg         Lvl   \n",
       "1459          20       RL         75.0     9937   Pave      Reg         Lvl   \n",
       "\n",
       "     Utilities LotConfig LandSlope  ... GarageCars GarageArea GarageQual  \\\n",
       "0       AllPub    Inside       Gtl  ...          2        548         TA   \n",
       "2       AllPub    Inside       Gtl  ...          2        608         TA   \n",
       "3       AllPub    Corner       Gtl  ...          3        642         TA   \n",
       "4       AllPub       FR2       Gtl  ...          3        836         TA   \n",
       "5       AllPub    Inside       Gtl  ...          2        480         TA   \n",
       "...        ...       ...       ...  ...        ...        ...        ...   \n",
       "1451    AllPub    Inside       Gtl  ...          3        840         TA   \n",
       "1454    AllPub    Inside       Gtl  ...          2        400         TA   \n",
       "1455    AllPub    Inside       Gtl  ...          2        460         TA   \n",
       "1458    AllPub    Inside       Gtl  ...          1        240         TA   \n",
       "1459    AllPub    Inside       Gtl  ...          1        276         TA   \n",
       "\n",
       "     GarageCond PavedDrive  OpenPorchSF  MoSold  YrSold  SaleType  \\\n",
       "0            TA          Y           61       2    2008        WD   \n",
       "2            TA          Y           42       9    2008        WD   \n",
       "3            TA          Y           35       2    2006        WD   \n",
       "4            TA          Y           84      12    2008        WD   \n",
       "5            TA          Y           30      10    2009        WD   \n",
       "...         ...        ...          ...     ...     ...       ...   \n",
       "1451         TA          Y           36       5    2009       New   \n",
       "1454         TA          Y          113      10    2009        WD   \n",
       "1455         TA          Y           40       8    2007        WD   \n",
       "1458         TA          Y            0       4    2010        WD   \n",
       "1459         TA          Y           68       6    2008        WD   \n",
       "\n",
       "     SaleCondition  \n",
       "0           Normal  \n",
       "2           Normal  \n",
       "3          Abnorml  \n",
       "4           Normal  \n",
       "5           Normal  \n",
       "...            ...  \n",
       "1451       Partial  \n",
       "1454        Normal  \n",
       "1455        Normal  \n",
       "1458        Normal  \n",
       "1459        Normal  \n",
       "\n",
       "[953 rows x 62 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4cef4726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MSZoning',\n",
       " 'Street',\n",
       " 'LotShape',\n",
       " 'LandContour',\n",
       " 'Utilities',\n",
       " 'LotConfig',\n",
       " 'LandSlope',\n",
       " 'Neighborhood',\n",
       " 'Condition1',\n",
       " 'Condition2',\n",
       " 'BldgType',\n",
       " 'HouseStyle',\n",
       " 'RoofStyle',\n",
       " 'RoofMatl',\n",
       " 'Exterior1st',\n",
       " 'Exterior2nd',\n",
       " 'MasVnrType',\n",
       " 'ExterQual',\n",
       " 'ExterCond',\n",
       " 'Foundation',\n",
       " 'BsmtQual',\n",
       " 'BsmtCond',\n",
       " 'BsmtExposure',\n",
       " 'BsmtFinType1',\n",
       " 'BsmtFinType2',\n",
       " 'Heating',\n",
       " 'HeatingQC',\n",
       " 'CentralAir',\n",
       " 'Electrical',\n",
       " 'KitchenQual',\n",
       " 'Functional',\n",
       " 'FireplaceQu',\n",
       " 'GarageType',\n",
       " 'GarageFinish',\n",
       " 'GarageQual',\n",
       " 'GarageCond',\n",
       " 'PavedDrive',\n",
       " 'SaleType',\n",
       " 'SaleCondition']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f97b5f6b-648a-43cb-8849-0fec976df2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def encoding_categorical_cols(df_train:pd.DataFrame,categorical_columns:list,strategy:str):\n",
    "    df_categorical=pd.DataFrame(df_train.loc[:,categorical_columns])\n",
    "    if strategy==\"labelencoder\":\n",
    "        for col in list(df_categorical.columns):\n",
    "            cat=[]\n",
    "            d={}\n",
    "\n",
    "            cat.append([df_categorical[col].value_counts().index,len(df_categorical[col].value_counts().index)])\n",
    "\n",
    "            for j in range(int(cat[0][1])):\n",
    "                d[str(cat[0][0][j])]=j\n",
    "            df_categorical[col]=df_categorical[col].map(d)\n",
    "        df_train.drop(categorical_columns,axis=1,inplace=True)\n",
    "        \n",
    "        df_train=pd.concat([df_train,df_categorical],axis=1)\n",
    "        \n",
    "    if strategy==\"onehotencoder\":\n",
    "        one_hot_encoded=pd.get_dummies(df_categorical)\n",
    "        # print(one_hot_encoded)\n",
    "        df_train.drop(categorical_columns,axis=1,inplace=True)\n",
    "        df_train=pd.concat([df_train,one_hot_encoded],axis=1)\n",
    "    return df_train\n",
    "        \n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b7d27212-4bf2-45ac-bce7-50ade37f1709",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=encoding_categorical_cols(df_train=df_train,categorical_columns=categorical_cols,strategy=\"labelencoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c3780d5c-cb7c-4836-b97b-8fd4dc8e051e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>...</th>\n",
       "      <th>KitchenQual</th>\n",
       "      <th>Functional</th>\n",
       "      <th>FireplaceQu</th>\n",
       "      <th>GarageType</th>\n",
       "      <th>GarageFinish</th>\n",
       "      <th>GarageQual</th>\n",
       "      <th>GarageCond</th>\n",
       "      <th>PavedDrive</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>706</td>\n",
       "      <td>150</td>\n",
       "      <td>856</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>486</td>\n",
       "      <td>434</td>\n",
       "      <td>920</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>216</td>\n",
       "      <td>540</td>\n",
       "      <td>756</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>655</td>\n",
       "      <td>490</td>\n",
       "      <td>1145</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50</td>\n",
       "      <td>85.0</td>\n",
       "      <td>14115</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1993</td>\n",
       "      <td>1995</td>\n",
       "      <td>732</td>\n",
       "      <td>64</td>\n",
       "      <td>796</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451</th>\n",
       "      <td>20</td>\n",
       "      <td>78.0</td>\n",
       "      <td>9262</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2008</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>1573</td>\n",
       "      <td>1573</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>20</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7500</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2004</td>\n",
       "      <td>2005</td>\n",
       "      <td>410</td>\n",
       "      <td>811</td>\n",
       "      <td>1221</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>60</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1999</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>953</td>\n",
       "      <td>953</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>20</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1950</td>\n",
       "      <td>1996</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>1078</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>20</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1965</td>\n",
       "      <td>1965</td>\n",
       "      <td>830</td>\n",
       "      <td>136</td>\n",
       "      <td>1256</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>953 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0             60         65.0     8450            7            5       2003   \n",
       "2             60         68.0    11250            7            5       2001   \n",
       "3             70         60.0     9550            7            5       1915   \n",
       "4             60         84.0    14260            8            5       2000   \n",
       "5             50         85.0    14115            5            5       1993   \n",
       "...          ...          ...      ...          ...          ...        ...   \n",
       "1451          20         78.0     9262            8            5       2008   \n",
       "1454          20         62.0     7500            7            5       2004   \n",
       "1455          60         62.0     7917            6            5       1999   \n",
       "1458          20         68.0     9717            5            6       1950   \n",
       "1459          20         75.0     9937            5            6       1965   \n",
       "\n",
       "      YearRemodAdd  BsmtFinSF1  BsmtUnfSF  TotalBsmtSF  ...  KitchenQual  \\\n",
       "0             2003         706        150          856  ...            1   \n",
       "2             2002         486        434          920  ...            1   \n",
       "3             1970         216        540          756  ...            1   \n",
       "4             2000         655        490         1145  ...            1   \n",
       "5             1995         732         64          796  ...            0   \n",
       "...            ...         ...        ...          ...  ...          ...   \n",
       "1451          2009           0       1573         1573  ...            2   \n",
       "1454          2005         410        811         1221  ...            1   \n",
       "1455          2000           0        953          953  ...            0   \n",
       "1458          1996          49          0         1078  ...            1   \n",
       "1459          1965         830        136         1256  ...            0   \n",
       "\n",
       "      Functional  FireplaceQu  GarageType  GarageFinish  GarageQual  \\\n",
       "0              0            0           0             1           0   \n",
       "2              0            1           0             1           0   \n",
       "3              0            0           1             0           0   \n",
       "4              0            1           0             1           0   \n",
       "5              0            0           0             0           0   \n",
       "...          ...          ...         ...           ...         ...   \n",
       "1451           0            0           0             2           0   \n",
       "1454           0            0           0             1           0   \n",
       "1455           0            1           0             1           0   \n",
       "1458           0            0           0             0           0   \n",
       "1459           0            0           0             2           0   \n",
       "\n",
       "      GarageCond  PavedDrive  SaleType  SaleCondition  \n",
       "0              0           0         0              0  \n",
       "2              0           0         0              0  \n",
       "3              0           0         0              2  \n",
       "4              0           0         0              0  \n",
       "5              0           0         0              0  \n",
       "...          ...         ...       ...            ...  \n",
       "1451           0           0         1              1  \n",
       "1454           0           0         0              0  \n",
       "1455           0           0         0              0  \n",
       "1458           0           0         0              0  \n",
       "1459           0           0         0              0  \n",
       "\n",
       "[953 rows x 62 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "792d9fa3-dc99-4342-8826-206eeb185ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSZoning\n",
      "Street\n",
      "LotShape\n",
      "LandContour\n",
      "Utilities\n",
      "LotConfig\n",
      "LandSlope\n",
      "Neighborhood\n",
      "Condition1\n",
      "Condition2\n",
      "BldgType\n",
      "HouseStyle\n",
      "RoofStyle\n",
      "RoofMatl\n",
      "Exterior1st\n",
      "Exterior2nd\n",
      "MasVnrType\n",
      "ExterQual\n",
      "ExterCond\n",
      "Foundation\n",
      "BsmtQual\n",
      "BsmtCond\n",
      "BsmtExposure\n",
      "BsmtFinType1\n",
      "BsmtFinType2\n",
      "Heating\n",
      "HeatingQC\n",
      "CentralAir\n",
      "Electrical\n",
      "KitchenQual\n",
      "Functional\n",
      "FireplaceQu\n",
      "GarageType\n",
      "GarageFinish\n",
      "GarageQual\n",
      "GarageCond\n",
      "PavedDrive\n",
      "SaleType\n",
      "SaleCondition\n"
     ]
    }
   ],
   "source": [
    "for col in categorical_cols:\n",
    "    if col in set(df_train.columns):\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e63bcfff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>...</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>953.000000</td>\n",
       "      <td>953.000000</td>\n",
       "      <td>953.000000</td>\n",
       "      <td>953.000000</td>\n",
       "      <td>953.000000</td>\n",
       "      <td>953.000000</td>\n",
       "      <td>953.000000</td>\n",
       "      <td>953.000000</td>\n",
       "      <td>953.000000</td>\n",
       "      <td>953.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>953.000000</td>\n",
       "      <td>953.0</td>\n",
       "      <td>953.000000</td>\n",
       "      <td>953.000000</td>\n",
       "      <td>953.000000</td>\n",
       "      <td>953.000000</td>\n",
       "      <td>953.000000</td>\n",
       "      <td>953.000000</td>\n",
       "      <td>953.000000</td>\n",
       "      <td>953.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>47.675761</td>\n",
       "      <td>68.954879</td>\n",
       "      <td>9337.533054</td>\n",
       "      <td>6.111228</td>\n",
       "      <td>5.498426</td>\n",
       "      <td>1974.242392</td>\n",
       "      <td>1984.696747</td>\n",
       "      <td>445.371459</td>\n",
       "      <td>567.120672</td>\n",
       "      <td>1056.137461</td>\n",
       "      <td>...</td>\n",
       "      <td>2.790136</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.253935</td>\n",
       "      <td>0.581322</td>\n",
       "      <td>1979.776495</td>\n",
       "      <td>1.754460</td>\n",
       "      <td>467.279119</td>\n",
       "      <td>36.126967</td>\n",
       "      <td>6.265477</td>\n",
       "      <td>2007.809024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>30.136712</td>\n",
       "      <td>14.082256</td>\n",
       "      <td>2665.346804</td>\n",
       "      <td>1.249458</td>\n",
       "      <td>0.790069</td>\n",
       "      <td>28.708602</td>\n",
       "      <td>20.807273</td>\n",
       "      <td>405.964996</td>\n",
       "      <td>404.340239</td>\n",
       "      <td>313.161547</td>\n",
       "      <td>...</td>\n",
       "      <td>0.661062</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.291759</td>\n",
       "      <td>0.592271</td>\n",
       "      <td>24.089979</td>\n",
       "      <td>0.678716</td>\n",
       "      <td>186.486093</td>\n",
       "      <td>44.027298</td>\n",
       "      <td>2.722424</td>\n",
       "      <td>1.332860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>2887.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1890.000000</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>264.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1906.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2006.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>7758.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1956.000000</td>\n",
       "      <td>1965.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>836.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1963.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2007.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>9240.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1977.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>410.000000</td>\n",
       "      <td>486.000000</td>\n",
       "      <td>1004.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1981.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>476.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2008.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>10998.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2002.000000</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>713.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>1258.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2002.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>576.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2009.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>120.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>16770.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2009.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>1646.000000</td>\n",
       "      <td>1710.000000</td>\n",
       "      <td>1976.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>928.000000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MSSubClass  LotFrontage       LotArea  OverallQual  OverallCond  \\\n",
       "count  953.000000   953.000000    953.000000   953.000000   953.000000   \n",
       "mean    47.675761    68.954879   9337.533054     6.111228     5.498426   \n",
       "std     30.136712    14.082256   2665.346804     1.249458     0.790069   \n",
       "min     20.000000    30.000000   2887.000000     2.000000     4.000000   \n",
       "25%     20.000000    60.000000   7758.000000     5.000000     5.000000   \n",
       "50%     50.000000    69.000000   9240.000000     6.000000     5.000000   \n",
       "75%     60.000000    78.000000  10998.000000     7.000000     6.000000   \n",
       "max    120.000000   110.000000  16770.000000    10.000000     7.000000   \n",
       "\n",
       "         YearBuilt  YearRemodAdd   BsmtFinSF1    BsmtUnfSF  TotalBsmtSF  ...  \\\n",
       "count   953.000000    953.000000   953.000000   953.000000   953.000000  ...   \n",
       "mean   1974.242392   1984.696747   445.371459   567.120672  1056.137461  ...   \n",
       "std      28.708602     20.807273   405.964996   404.340239   313.161547  ...   \n",
       "min    1890.000000   1950.000000     0.000000     0.000000   264.000000  ...   \n",
       "25%    1956.000000   1965.000000     0.000000   255.000000   836.000000  ...   \n",
       "50%    1977.000000   1994.000000   410.000000   486.000000  1004.000000  ...   \n",
       "75%    2002.000000   2004.000000   713.000000   801.000000  1258.000000  ...   \n",
       "max    2009.000000   2010.000000  1646.000000  1710.000000  1976.000000  ...   \n",
       "\n",
       "       BedroomAbvGr  KitchenAbvGr  TotRmsAbvGrd  Fireplaces  GarageYrBlt  \\\n",
       "count    953.000000         953.0    953.000000  953.000000   953.000000   \n",
       "mean       2.790136           1.0      6.253935    0.581322  1979.776495   \n",
       "std        0.661062           0.0      1.291759    0.592271    24.089979   \n",
       "min        1.000000           1.0      3.000000    0.000000  1906.000000   \n",
       "25%        2.000000           1.0      5.000000    0.000000  1963.000000   \n",
       "50%        3.000000           1.0      6.000000    1.000000  1981.000000   \n",
       "75%        3.000000           1.0      7.000000    1.000000  2002.000000   \n",
       "max        4.000000           1.0     10.000000    2.000000  2010.000000   \n",
       "\n",
       "       GarageCars  GarageArea  OpenPorchSF      MoSold       YrSold  \n",
       "count  953.000000  953.000000   953.000000  953.000000   953.000000  \n",
       "mean     1.754460  467.279119    36.126967    6.265477  2007.809024  \n",
       "std      0.678716  186.486093    44.027298    2.722424     1.332860  \n",
       "min      0.000000    0.000000     0.000000    1.000000  2006.000000  \n",
       "25%      1.000000  336.000000     0.000000    4.000000  2007.000000  \n",
       "50%      2.000000  476.000000    20.000000    6.000000  2008.000000  \n",
       "75%      2.000000  576.000000    62.000000    8.000000  2009.000000  \n",
       "max      3.000000  928.000000   170.000000   12.000000  2010.000000  \n",
       "\n",
       "[8 rows x 23 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.loc[:,continuous_cols].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4b450e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "### SCALING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "152a28be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>...</th>\n",
       "      <th>KitchenQual</th>\n",
       "      <th>Functional</th>\n",
       "      <th>FireplaceQu</th>\n",
       "      <th>GarageType</th>\n",
       "      <th>GarageFinish</th>\n",
       "      <th>GarageQual</th>\n",
       "      <th>GarageCond</th>\n",
       "      <th>PavedDrive</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.400706</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.949580</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.428919</td>\n",
       "      <td>0.087719</td>\n",
       "      <td>0.345794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4750</td>\n",
       "      <td>0.602391</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.932773</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.295261</td>\n",
       "      <td>0.253801</td>\n",
       "      <td>0.383178</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.479939</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.210084</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.131227</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.287383</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6750</td>\n",
       "      <td>0.819203</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.924370</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.397934</td>\n",
       "      <td>0.286550</td>\n",
       "      <td>0.514603</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.808759</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.865546</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.444714</td>\n",
       "      <td>0.037427</td>\n",
       "      <td>0.310748</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.459195</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.991597</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.919883</td>\n",
       "      <td>0.764603</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.332277</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.957983</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.249089</td>\n",
       "      <td>0.474269</td>\n",
       "      <td>0.558995</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.362314</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.915966</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.557310</td>\n",
       "      <td>0.402453</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4750</td>\n",
       "      <td>0.491969</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.504202</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.029769</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.475467</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.507815</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.630252</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.504253</td>\n",
       "      <td>0.079532</td>\n",
       "      <td>0.579439</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>953 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     MSSubClass  LotFrontage   LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0           0.4       0.4375  0.400706        0.625     0.333333   0.949580   \n",
       "1           0.4       0.4750  0.602391        0.625     0.333333   0.932773   \n",
       "2           0.5       0.3750  0.479939        0.625     0.333333   0.210084   \n",
       "3           0.4       0.6750  0.819203        0.750     0.333333   0.924370   \n",
       "4           0.3       0.6875  0.808759        0.375     0.333333   0.865546   \n",
       "..          ...          ...       ...          ...          ...        ...   \n",
       "948         0.0       0.6000  0.459195        0.750     0.333333   0.991597   \n",
       "949         0.0       0.4000  0.332277        0.625     0.333333   0.957983   \n",
       "950         0.4       0.4000  0.362314        0.500     0.333333   0.915966   \n",
       "951         0.0       0.4750  0.491969        0.375     0.666667   0.504202   \n",
       "952         0.0       0.5625  0.507815        0.375     0.666667   0.630252   \n",
       "\n",
       "     YearRemodAdd  BsmtFinSF1  BsmtUnfSF  TotalBsmtSF  ...  KitchenQual  \\\n",
       "0        0.883333    0.428919   0.087719     0.345794  ...     0.333333   \n",
       "1        0.866667    0.295261   0.253801     0.383178  ...     0.333333   \n",
       "2        0.333333    0.131227   0.315789     0.287383  ...     0.333333   \n",
       "3        0.833333    0.397934   0.286550     0.514603  ...     0.333333   \n",
       "4        0.750000    0.444714   0.037427     0.310748  ...     0.000000   \n",
       "..            ...         ...        ...          ...  ...          ...   \n",
       "948      0.983333    0.000000   0.919883     0.764603  ...     0.666667   \n",
       "949      0.916667    0.249089   0.474269     0.558995  ...     0.333333   \n",
       "950      0.833333    0.000000   0.557310     0.402453  ...     0.000000   \n",
       "951      0.766667    0.029769   0.000000     0.475467  ...     0.333333   \n",
       "952      0.250000    0.504253   0.079532     0.579439  ...     0.000000   \n",
       "\n",
       "     Functional  FireplaceQu  GarageType  GarageFinish  GarageQual  \\\n",
       "0           0.0         0.00         0.0           0.5         0.0   \n",
       "1           0.0         0.25         0.0           0.5         0.0   \n",
       "2           0.0         0.00         0.2           0.0         0.0   \n",
       "3           0.0         0.25         0.0           0.5         0.0   \n",
       "4           0.0         0.00         0.0           0.0         0.0   \n",
       "..          ...          ...         ...           ...         ...   \n",
       "948         0.0         0.00         0.0           1.0         0.0   \n",
       "949         0.0         0.00         0.0           0.5         0.0   \n",
       "950         0.0         0.25         0.0           0.5         0.0   \n",
       "951         0.0         0.00         0.0           0.0         0.0   \n",
       "952         0.0         0.00         0.0           1.0         0.0   \n",
       "\n",
       "     GarageCond  PavedDrive  SaleType  SaleCondition  \n",
       "0           0.0         0.0     0.000            0.0  \n",
       "1           0.0         0.0     0.000            0.0  \n",
       "2           0.0         0.0     0.000            0.4  \n",
       "3           0.0         0.0     0.000            0.0  \n",
       "4           0.0         0.0     0.000            0.0  \n",
       "..          ...         ...       ...            ...  \n",
       "948         0.0         0.0     0.125            0.2  \n",
       "949         0.0         0.0     0.000            0.0  \n",
       "950         0.0         0.0     0.000            0.0  \n",
       "951         0.0         0.0     0.000            0.0  \n",
       "952         0.0         0.0     0.000            0.0  \n",
       "\n",
       "[953 rows x 62 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler=scaler=MinMaxScaler()\n",
    "df_train=pd.DataFrame(scaler.fit_transform(df_train),columns=df_train.columns,)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2b0069d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "589aafd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df_train\n",
    "Y=output_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "8abd68cd-17bb-4328-9838-79ab0285d8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=None,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e5515b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies_with_sfs={}\n",
    "accuracies_with_hyperparameter_tuning={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "957e0080-bb8e-440a-af5a-aa14083c603d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_tuning(algo:str,param_grid:dict,n_iter:int,cv:int,verbose:int,random_state:int,X_train,Y_train,X_test,Y_test,evaluation_metric:str):\n",
    "    model=eval(algo)\n",
    "    evaluation_metric=eval(evaluation_metric)\n",
    "    \n",
    "    model_random_cv=RandomizedSearchCV(estimator=model,param_distributions=param_grid,n_iter=n_iter,cv=cv,verbose=verbose,random_state=random_state,n_jobs=-1)\n",
    "    model_random_cv.fit(X_train,Y_train)\n",
    "    best_params_=model_random_cv.best_params_\n",
    "    print(f\"{model} RandomCV Best Params :\",best_params_)\n",
    "    best_random_grid=model_random_cv.best_estimator_\n",
    "    y_pred=best_random_grid.predict(X_test)\n",
    "    \n",
    "    score=evaluation_metric(Y_test,y_pred)\n",
    "    print(f\"{model} RandomCV Score:\",score)\n",
    "    \n",
    "    \n",
    "    \n",
    "    param_grid=defaultdict(list)\n",
    "    for val in best_params_:\n",
    "        param_grid[val].append(best_params_[val])\n",
    "    \n",
    "    \n",
    "    model_for_gcv=eval(algo)\n",
    "    \n",
    "    grid_search=GridSearchCV(estimator=model_for_gcv,param_grid=param_grid,cv=cv,n_jobs=-1,verbose=verbose)\n",
    "    grid_search.fit(X_train,Y_train)\n",
    "    best_grid2=grid_search.best_estimator_\n",
    "    y_pred2=best_grid2.predict(X_test)\n",
    "    score_1=evaluation_metric(Y_test,y_pred2)\n",
    "    print(\"Final score is \",score_1)\n",
    "    accuracies_with_hyperparameter_tuning[algo]=score_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1a163e58-15fa-4495-9c64-c7a406bd6b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sf_selector(algo:str,forward:bool,floating:bool,scoring:int,X_train,Y_train,X_test,Y_test,min_featues:int,cv:int,verbose:int):\n",
    "    model=eval(algo)\n",
    "    sfs=SFS(model, \n",
    "           k_features=(min_featues,len(X_train.columns)), \n",
    "           forward=forward, \n",
    "           floating=floating, \n",
    "           verbose=verbose,\n",
    "           scoring=scoring,\n",
    "           cv=cv,\n",
    "           n_jobs=-1)\n",
    "    sfs=sfs.fit(X_train, Y_train)\n",
    "    print(\"Selected Features\",sfs.k_feature_names_)\n",
    "    model_=eval(algo)\n",
    "    model_.fit(X_train.loc[:,list(sfs.k_feature_names_)],Y_train)\n",
    "    score=model_.score(X_test.loc[:,list(sfs.k_feature_names_)],Y_test)\n",
    "    print(f\"Prediction using selected features using {model_} is :\",score)\n",
    "    accuracies_with_sfs[model]=score\n",
    "    return sfs.k_feature_names_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "92438a29-6755-499f-be39-2013f6515b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  62 out of  62 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:02:39] Features: 1/62 -- score: 0.679844490313643[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  61 out of  61 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:02:39] Features: 2/62 -- score: 0.7560091134401516[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:02:39] Features: 3/62 -- score: 0.8182279341038639[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  59 out of  59 | elapsed:    0.2s finished\n",
      "\n",
      "[2023-02-01 16:02:39] Features: 4/62 -- score: 0.8421545708346148[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  58 out of  58 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:02:40] Features: 5/62 -- score: 0.8581764029120634[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  57 out of  57 | elapsed:    0.2s finished\n",
      "\n",
      "[2023-02-01 16:02:40] Features: 6/62 -- score: 0.8662324302591922[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  56 out of  56 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:02:40] Features: 7/62 -- score: 0.8726551861138105[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  55 out of  55 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:02:40] Features: 8/62 -- score: 0.876786551058068[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  54 out of  54 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:02:40] Features: 9/62 -- score: 0.881179158286125[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  53 out of  53 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:02:40] Features: 10/62 -- score: 0.8853017940405928[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  52 out of  52 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:02:40] Features: 11/62 -- score: 0.8886270263546558[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  51 out of  51 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:02:41] Features: 12/62 -- score: 0.8915199844114159[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:02:41] Features: 13/62 -- score: 0.8940649973284586[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  49 out of  49 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:02:41] Features: 14/62 -- score: 0.8959317227753955[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:02:41] Features: 15/62 -- score: 0.896716169547369[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  36 out of  47 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  47 out of  47 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:02:41] Features: 16/62 -- score: 0.897335549277226[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  46 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  46 out of  46 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:02:41] Features: 17/62 -- score: 0.8980496631636123[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 out of  45 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:02:41] Features: 18/62 -- score: 0.8987335962303951[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  44 out of  44 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:02:41] Features: 19/62 -- score: 0.8994125540803305[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  32 out of  43 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  43 out of  43 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:02:42] Features: 20/62 -- score: 0.8999032401375813[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 out of  42 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:02:42] Features: 21/62 -- score: 0.9002107432435473[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  41 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  41 out of  41 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:02:42] Features: 22/62 -- score: 0.9004898064969126[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:02:42] Features: 23/62 -- score: 0.9007502262955936[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  28 out of  39 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  39 out of  39 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:02:42] Features: 24/62 -- score: 0.9009872559810177[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  38 out of  38 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:02:42] Features: 25/62 -- score: 0.9012262934845628[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 out of  37 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  37 out of  37 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:02:42] Features: 26/62 -- score: 0.9013926519962225[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  36 out of  36 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:02:42] Features: 27/62 -- score: 0.9017000210444424[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  35 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:02:42] Features: 28/62 -- score: 0.9017696064563339[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  23 out of  34 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  34 out of  34 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:02:43] Features: 29/62 -- score: 0.9018143050550782[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  22 out of  33 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  33 out of  33 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:02:43] Features: 30/62 -- score: 0.9018143050550783[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  32 out of  32 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:02:43] Features: 31/62 -- score: 0.9017732592226253[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  31 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  31 out of  31 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:02:43] Features: 32/62 -- score: 0.901723673185898[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:02:43] Features: 33/62 -- score: 0.901666678690286[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  29 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  29 out of  29 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:02:43] Features: 34/62 -- score: 0.9015837805161404[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  28 out of  28 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:02:43] Features: 35/62 -- score: 0.9014943498166724[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  27 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:02:43] Features: 36/62 -- score: 0.9013591080612937[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 out of  26 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:02:44] Features: 37/62 -- score: 0.9012342902311333[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  14 out of  25 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:02:44] Features: 38/62 -- score: 0.9010627510780564[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:02:44] Features: 39/62 -- score: 0.9008472685903026[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  23 out of  23 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:02:44] Features: 40/62 -- score: 0.9006268372675166[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  22 out of  22 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:02:44] Features: 41/62 -- score: 0.9003650941142937[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  21 out of  21 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  21 out of  21 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:02:44] Features: 42/62 -- score: 0.9001038935352351[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:02:44] Features: 43/62 -- score: 0.8999240235281551[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  19 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:02:44] Features: 44/62 -- score: 0.8996705538490314[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  18 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:02:44] Features: 45/62 -- score: 0.8993895424664629[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  17 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  17 out of  17 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:02:44] Features: 46/62 -- score: 0.89906200999348[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  14 out of  16 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  16 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:02:45] Features: 47/62 -- score: 0.8987198888569786[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  15 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:02:45] Features: 48/62 -- score: 0.8984210094310974[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  14 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  14 out of  14 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:02:45] Features: 49/62 -- score: 0.8980638903846179[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of  13 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:02:45] Features: 50/62 -- score: 0.8977130420772681[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  12 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:02:45] Features: 51/62 -- score: 0.8973096181151003[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  11 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:02:45] Features: 52/62 -- score: 0.8970113262465758[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:02:45] Features: 53/62 -- score: -2.1565397155251964e+21[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   9 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "\n",
      "[2023-02-01 16:02:45] Features: 54/62 -- score: -4.043832757853623e+19[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   8 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.0s finished\n",
      "\n",
      "[2023-02-01 16:02:45] Features: 55/62 -- score: -4.1494614468282004e+20[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "\n",
      "[2023-02-01 16:02:45] Features: 56/62 -- score: -2.9376836195205314e+21[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.0s finished\n",
      "\n",
      "[2023-02-01 16:02:45] Features: 57/62 -- score: -7.360741779055658e+19[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "\n",
      "[2023-02-01 16:02:45] Features: 58/62 -- score: -6.237032193874374e+20[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    0.0s finished\n",
      "\n",
      "[2023-02-01 16:02:45] Features: 59/62 -- score: -3.330047479220816e+18[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "\n",
      "[2023-02-01 16:02:45] Features: 60/62 -- score: -6.683607040057655e+20[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features ('LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'BsmtFinSF1', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', 'GrLivArea', 'FullBath', 'BedroomAbvGr', 'KitchenAbvGr', 'Fireplaces', 'GarageYrBlt', 'GarageCars', 'LandContour', 'Neighborhood', 'Condition1', 'MasVnrType', 'Foundation', 'BsmtQual', 'BsmtExposure', 'BsmtFinType1', 'HeatingQC', 'KitchenQual', 'Functional', 'GarageType', 'SaleType')\n",
      "Prediction using selected features using LinearRegression() is : 0.876824053780785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "\n",
      "[2023-02-01 16:02:45] Features: 61/62 -- score: -1.7688938852202822e+21[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "\n",
      "[2023-02-01 16:02:45] Features: 62/62 -- score: -7.649652750287426e+20"
     ]
    }
   ],
   "source": [
    "selected_features=sf_selector(algo=\"LinearRegression()\",forward=True,floating=False,scoring=\"r2\",X_train=X_train,Y_train=Y_train,X_test=X_test,Y_test=Y_test,min_featues=3,cv=5,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "dbd8950b-8067-4850-a196-034b1428fd86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_intercept': ['True', 'False'], 'positive': ['False', 'True'], 'copy_X': ['True', 'False']}\n"
     ]
    }
   ],
   "source": [
    "fit_intercept = [\"True\",\"False\"]\n",
    "copy_X =[\"True\",\"False\"] \n",
    "positive=[\"False\",\"True\"]\n",
    "\n",
    "random_grid = {'fit_intercept': fit_intercept,\n",
    "               'positive': positive,\n",
    "               'copy_X': copy_X}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b34dc51d-9cbb-4619-86cb-25e0fcc835c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "LinearRegression() RandomCV Best Params : {'positive': 'False', 'fit_intercept': 'True', 'copy_X': 'True'}\n",
      "LinearRegression() RandomCV Score: 0.8636738877114871\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Final score is  0.8636738877114871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_search.py:306: UserWarning: The total space of parameters 8 is smaller than n_iter=100. Running 8 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "hyperparameter_tuning(algo=\"LinearRegression()\",param_grid=random_grid,n_iter=100,cv=5,verbose=3,random_state=42,X_train=X_train.loc[:,list(selected_features)],Y_train=Y_train,X_test=X_test.loc[:,list(selected_features)],Y_test=Y_test,evaluation_metric=\"r2_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b422611-18c1-40fb-9be6-552925fdf828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "592d113b-8e2f-42e6-b2d2-704aa9737c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done  62 out of  62 | elapsed:    6.0s finished\n",
      "\n",
      "[2023-02-01 16:07:02] Features: 1/62 -- score: 0.7093234258882394[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  61 out of  61 | elapsed:    6.3s finished\n",
      "\n",
      "[2023-02-01 16:07:09] Features: 2/62 -- score: 0.7537844909020834[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:    6.4s finished\n",
      "\n",
      "[2023-02-01 16:07:15] Features: 3/62 -- score: 0.7664695333447206[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done  59 out of  59 | elapsed:    6.7s finished\n",
      "\n",
      "[2023-02-01 16:07:22] Features: 4/62 -- score: 0.7776578878061334[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done  58 out of  58 | elapsed:    6.3s finished\n",
      "\n",
      "[2023-02-01 16:07:28] Features: 5/62 -- score: 0.7864257086463257[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done  57 out of  57 | elapsed:    6.5s finished\n",
      "\n",
      "[2023-02-01 16:07:34] Features: 6/62 -- score: 0.7933826233587078[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done  56 out of  56 | elapsed:    6.7s finished\n",
      "\n",
      "[2023-02-01 16:07:41] Features: 7/62 -- score: 0.8038198652845375[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done  55 out of  55 | elapsed:    8.9s finished\n",
      "\n",
      "[2023-02-01 16:07:50] Features: 8/62 -- score: 0.8551130763889765[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=-1)]: Done  54 out of  54 | elapsed:   10.0s finished\n",
      "\n",
      "[2023-02-01 16:08:00] Features: 9/62 -- score: 0.8708837169538814[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    5.8s\n",
      "[Parallel(n_jobs=-1)]: Done  53 out of  53 | elapsed:   10.4s finished\n",
      "\n",
      "[2023-02-01 16:08:11] Features: 10/62 -- score: 0.880377835317358[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=-1)]: Done  52 out of  52 | elapsed:   11.3s finished\n",
      "\n",
      "[2023-02-01 16:08:22] Features: 11/62 -- score: 0.8854509049608896[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Done  51 out of  51 | elapsed:   11.5s finished\n",
      "\n",
      "[2023-02-01 16:08:33] Features: 12/62 -- score: 0.886163720199184[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   11.8s finished\n",
      "\n",
      "[2023-02-01 16:08:45] Features: 13/62 -- score: 0.8909350877913264[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=-1)]: Done  49 out of  49 | elapsed:   12.8s finished\n",
      "\n",
      "[2023-02-01 16:08:58] Features: 14/62 -- score: 0.8921752920125254[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:   11.5s finished\n",
      "\n",
      "[2023-02-01 16:09:10] Features: 15/62 -- score: 0.8919626028809908[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=-1)]: Done  47 out of  47 | elapsed:   12.4s finished\n",
      "\n",
      "[2023-02-01 16:09:22] Features: 16/62 -- score: 0.8921484357083251[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    8.0s\n",
      "[Parallel(n_jobs=-1)]: Done  46 out of  46 | elapsed:   12.6s finished\n",
      "\n",
      "[2023-02-01 16:09:34] Features: 17/62 -- score: 0.8924032294235686[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:   12.2s finished\n",
      "\n",
      "[2023-02-01 16:09:47] Features: 18/62 -- score: 0.8930816904532737[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=-1)]: Done  44 out of  44 | elapsed:   12.5s finished\n",
      "\n",
      "[2023-02-01 16:09:59] Features: 19/62 -- score: 0.8934006022872106[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=-1)]: Done  43 out of  43 | elapsed:   12.1s finished\n",
      "\n",
      "[2023-02-01 16:10:11] Features: 20/62 -- score: 0.8921968076492732[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=-1)]: Done  42 out of  42 | elapsed:   11.9s finished\n",
      "\n",
      "[2023-02-01 16:10:23] Features: 21/62 -- score: 0.8945152295551629[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=-1)]: Done  41 out of  41 | elapsed:   11.0s finished\n",
      "\n",
      "[2023-02-01 16:10:34] Features: 22/62 -- score: 0.8921438492801222[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:   11.6s finished\n",
      "\n",
      "[2023-02-01 16:10:46] Features: 23/62 -- score: 0.8931594121749755[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  39 out of  39 | elapsed:   12.2s finished\n",
      "\n",
      "[2023-02-01 16:10:58] Features: 24/62 -- score: 0.8930856956604684[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  38 out of  38 | elapsed:   12.2s finished\n",
      "\n",
      "[2023-02-01 16:11:10] Features: 25/62 -- score: 0.8938286600064643[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  37 out of  37 | elapsed:   12.5s finished\n",
      "\n",
      "[2023-02-01 16:11:23] Features: 26/62 -- score: 0.8923514691945897[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  36 out of  36 | elapsed:   10.8s finished\n",
      "\n",
      "[2023-02-01 16:11:34] Features: 27/62 -- score: 0.8921876807672684[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  35 | elapsed:   11.6s finished\n",
      "\n",
      "[2023-02-01 16:11:45] Features: 28/62 -- score: 0.8931763596799598[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 out of  34 | elapsed:   11.2s finished\n",
      "\n",
      "[2023-02-01 16:11:56] Features: 29/62 -- score: 0.8910021466892036[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 out of  33 | elapsed:   11.1s finished\n",
      "\n",
      "[2023-02-01 16:12:08] Features: 30/62 -- score: 0.8917779425945703[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  32 out of  32 | elapsed:   11.2s finished\n",
      "\n",
      "[2023-02-01 16:12:19] Features: 31/62 -- score: 0.8913370772642178[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  31 out of  31 | elapsed:   11.2s finished\n",
      "\n",
      "[2023-02-01 16:12:30] Features: 32/62 -- score: 0.8924835533978295[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    9.8s finished\n",
      "\n",
      "[2023-02-01 16:12:40] Features: 33/62 -- score: 0.8921394555408014[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  29 out of  29 | elapsed:    9.8s finished\n",
      "\n",
      "[2023-02-01 16:12:50] Features: 34/62 -- score: 0.8914690257401746[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  28 out of  28 | elapsed:   10.6s finished\n",
      "\n",
      "[2023-02-01 16:13:00] Features: 35/62 -- score: 0.8936141991753308[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:   10.3s finished\n",
      "\n",
      "[2023-02-01 16:13:10] Features: 36/62 -- score: 0.8915756346841981[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 out of  26 | elapsed:   10.8s finished\n",
      "\n",
      "[2023-02-01 16:13:21] Features: 37/62 -- score: 0.890755461927174[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:   10.8s finished\n",
      "\n",
      "[2023-02-01 16:13:32] Features: 38/62 -- score: 0.8902172402593026[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:    9.2s finished\n",
      "\n",
      "[2023-02-01 16:13:41] Features: 39/62 -- score: 0.8915107429376488[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  23 out of  23 | elapsed:    9.4s finished\n",
      "\n",
      "[2023-02-01 16:13:51] Features: 40/62 -- score: 0.8909567509913334[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  22 out of  22 | elapsed:    8.9s finished\n",
      "\n",
      "[2023-02-01 16:14:00] Features: 41/62 -- score: 0.8905747160612197[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  21 out of  21 | elapsed:    9.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  21 out of  21 | elapsed:    9.5s finished\n",
      "\n",
      "[2023-02-01 16:14:09] Features: 42/62 -- score: 0.8909801337462981[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    9.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    9.0s finished\n",
      "\n",
      "[2023-02-01 16:14:18] Features: 43/62 -- score: 0.8904535112938656[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  19 | elapsed:    9.0s finished\n",
      "\n",
      "[2023-02-01 16:14:27] Features: 44/62 -- score: 0.8909959778204503[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  18 | elapsed:    7.4s finished\n",
      "\n",
      "[2023-02-01 16:14:34] Features: 45/62 -- score: 0.8883951754479191[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  17 | elapsed:    7.3s remaining:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  17 out of  17 | elapsed:    7.7s finished\n",
      "\n",
      "[2023-02-01 16:14:42] Features: 46/62 -- score: 0.8898948226759942[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  14 out of  16 | elapsed:    7.2s remaining:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  16 | elapsed:    7.4s finished\n",
      "\n",
      "[2023-02-01 16:14:49] Features: 47/62 -- score: 0.8904453111808843[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  15 | elapsed:    5.1s remaining:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    7.7s finished\n",
      "\n",
      "[2023-02-01 16:14:57] Features: 48/62 -- score: 0.8878539704004158[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  14 | elapsed:    5.5s remaining:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done  14 out of  14 | elapsed:    7.9s finished\n",
      "\n",
      "[2023-02-01 16:15:05] Features: 49/62 -- score: 0.8879659789021286[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of  13 | elapsed:    5.4s remaining:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done  13 out of  13 | elapsed:    7.9s finished\n",
      "\n",
      "[2023-02-01 16:15:13] Features: 50/62 -- score: 0.8880364437626878[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  12 | elapsed:    5.4s remaining:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    6.0s finished\n",
      "\n",
      "[2023-02-01 16:15:19] Features: 51/62 -- score: 0.887739678089171[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  11 | elapsed:    2.9s remaining:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  11 | elapsed:    5.5s finished\n",
      "\n",
      "[2023-02-01 16:15:24] Features: 52/62 -- score: 0.8880555310788086[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    2.9s remaining:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    5.6s finished\n",
      "\n",
      "[2023-02-01 16:15:30] Features: 53/62 -- score: 0.8891640256902213[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   9 | elapsed:    3.0s remaining:    5.9s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    5.8s finished\n",
      "\n",
      "[2023-02-01 16:15:36] Features: 54/62 -- score: 0.8872114193883377[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   8 | elapsed:    2.8s remaining:    8.4s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    5.6s finished\n",
      "\n",
      "[2023-02-01 16:15:41] Features: 55/62 -- score: 0.8871745049721321[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   7 | elapsed:    2.9s remaining:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of   7 | elapsed:    5.7s finished\n",
      "\n",
      "[2023-02-01 16:15:47] Features: 56/62 -- score: 0.8856611559386185[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    2.9s remaining:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    3.1s finished\n",
      "\n",
      "[2023-02-01 16:15:50] Features: 57/62 -- score: 0.8856860148596869[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    3.2s remaining:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    3.4s finished\n",
      "\n",
      "[2023-02-01 16:15:54] Features: 58/62 -- score: 0.8859573259518101[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   4 | elapsed:    3.0s remaining:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    3.0s finished\n",
      "\n",
      "[2023-02-01 16:15:57] Features: 59/62 -- score: 0.8860641467844538[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    3.1s finished\n",
      "\n",
      "[2023-02-01 16:16:00] Features: 60/62 -- score: 0.8860878428521255[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    3.1s finished\n",
      "\n",
      "[2023-02-01 16:16:03] Features: 61/62 -- score: 0.883084682006664[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    3.2s finished\n",
      "\n",
      "[2023-02-01 16:16:06] Features: 62/62 -- score: 0.8820928528105126"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features ('MSSubClass', 'LotArea', 'OverallQual', 'OverallCond', 'YearBuilt', 'BsmtFinSF1', 'TotalBsmtSF', 'GrLivArea', 'KitchenAbvGr', 'GarageCars', 'Street', 'Utilities', 'LandSlope', 'BldgType', 'ExterQual', 'BsmtQual', 'BsmtFinType1', 'CentralAir', 'KitchenQual', 'Functional', 'SaleCondition')\n",
      "Prediction using selected features using RandomForestRegressor() is : 0.8877877845818886\n"
     ]
    }
   ],
   "source": [
    "selected_features=sf_selector(algo=\"RandomForestRegressor()\",forward=True,floating=False,scoring=\"r2\",X_train=X_train,Y_train=Y_train,X_test=X_test,Y_test=Y_test,min_featues=3,cv=5,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a21fe5f0-c814-4ebd-9a41-441280463653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['sqrt', 'log2'], 'max_depth': [10, 120, 230, 340, 450, 560, 670, 780, 890, 1000], 'min_samples_split': [2, 3, 4, 5, 10, 14], 'min_samples_leaf': [1, 2, 4, 6, 8], 'criterion': ['squared_error', 'absolute_error', 'friedman_mse', 'poisson']}\n"
     ]
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['sqrt','log2']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 1000,10)]\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2,3,4, 5, 10,14]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4,6,8]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "              'criterion':['squared_error','absolute_error','friedman_mse','poisson']}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "8df51d97-ab65-40bd-a511-8e69f62b5991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "[CV 5/5] END copy_X=True, fit_intercept=True, positive=False;, score=0.911 total time=   0.0s\n",
      "[CV 1/5] END copy_X=True, fit_intercept=False, positive=False;, score=0.897 total time=   0.0s\n",
      "[CV 1/5] END copy_X=False, fit_intercept=True, positive=False;, score=0.897 total time=   0.0s\n",
      "[CV 2/5] END copy_X=False, fit_intercept=True, positive=False;, score=0.858 total time=   0.0s\n",
      "[CV 5/5] END copy_X=False, fit_intercept=False, positive=False;, score=0.911 total time=   0.0s\n",
      "[CV 1/5] END copy_X=False, fit_intercept=False, positive=True;, score=0.897 total time=   0.0s\n",
      "[CV 4/5] END copy_X=True, fit_intercept=True, positive=False;, score=0.912 total time=   0.0s\n",
      "[CV 2/5] END copy_X=True, fit_intercept=True, positive=False;, score=0.905 total time=   0.0s\n",
      "[CV 2/5] END copy_X=True, fit_intercept=True, positive=True;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END copy_X=True, fit_intercept=False, positive=False;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END copy_X=True, fit_intercept=False, positive=False;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END copy_X=False, fit_intercept=True, positive=False;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END copy_X=False, fit_intercept=True, positive=True;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END copy_X=False, fit_intercept=False, positive=True;, score=0.905 total time=   0.0s\n",
      "[CV 2/5] END copy_X=True, fit_intercept=True, positive=False;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END criterion=poisson, max_depth=1000, max_features=sqrt, min_samples_leaf=8, min_samples_split=3, n_estimators=1000;, score=0.895 total time=   1.7s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=120, max_features=sqrt, min_samples_leaf=8, min_samples_split=4, n_estimators=200;, score=0.869 total time=   0.2s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=120, max_features=sqrt, min_samples_leaf=8, min_samples_split=4, n_estimators=200;, score=0.860 total time=   0.2s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=890, max_features=log2, min_samples_leaf=8, min_samples_split=14, n_estimators=200;, score=0.853 total time=   0.3s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=890, max_features=log2, min_samples_leaf=8, min_samples_split=14, n_estimators=200;, score=0.895 total time=   0.3s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=890, max_features=log2, min_samples_leaf=8, min_samples_split=14, n_estimators=200;, score=0.853 total time=   0.3s\n",
      "[CV 5/5] END criterion=poisson, max_depth=560, max_features=log2, min_samples_leaf=8, min_samples_split=5, n_estimators=1200;, score=0.856 total time=   1.6s\n",
      "[CV 1/5] END criterion=absolute_error, max_depth=890, max_features=log2, min_samples_leaf=6, min_samples_split=2, n_estimators=1000;, score=0.853 total time=   3.8s\n",
      "[CV 2/5] END criterion=poisson, max_depth=670, max_features=log2, min_samples_leaf=6, min_samples_split=5, n_estimators=1800;, score=0.882 total time=   2.6s\n",
      "[CV 5/5] END criterion=poisson, max_depth=670, max_features=log2, min_samples_leaf=6, min_samples_split=5, n_estimators=1800;, score=0.863 total time=   2.4s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=890, max_features=sqrt, min_samples_leaf=1, min_samples_split=14, n_estimators=200;, score=0.869 total time=   0.3s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=890, max_features=sqrt, min_samples_leaf=1, min_samples_split=14, n_estimators=200;, score=0.897 total time=   0.3s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=890, max_features=sqrt, min_samples_leaf=1, min_samples_split=14, n_estimators=200;, score=0.908 total time=   0.3s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=890, max_features=sqrt, min_samples_leaf=1, min_samples_split=14, n_estimators=200;, score=0.875 total time=   0.3s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=890, max_features=sqrt, min_samples_leaf=1, min_samples_split=14, n_estimators=200;, score=0.873 total time=   0.3s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=780, max_features=sqrt, min_samples_leaf=6, min_samples_split=10, n_estimators=1400;, score=0.859 total time=   1.9s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=780, max_features=sqrt, min_samples_leaf=6, min_samples_split=10, n_estimators=1400;, score=0.861 total time=   1.8s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=450, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=800;, score=0.918 total time=   1.2s\n",
      "[CV 4/5] END criterion=absolute_error, max_depth=890, max_features=log2, min_samples_leaf=8, min_samples_split=4, n_estimators=800;, score=0.849 total time=   3.0s\n",
      "[CV 2/5] END criterion=absolute_error, max_depth=340, max_features=log2, min_samples_leaf=6, min_samples_split=10, n_estimators=600;, score=0.873 total time=   2.3s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=230, max_features=log2, min_samples_leaf=6, min_samples_split=2, n_estimators=1200;, score=0.882 total time=   1.5s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=120, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=2000;, score=0.907 total time=   2.6s\n",
      "[CV 5/5] END criterion=poisson, max_depth=890, max_features=log2, min_samples_leaf=6, min_samples_split=14, n_estimators=800;, score=0.861 total time=   1.1s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=890, max_features=log2, min_samples_leaf=6, min_samples_split=5, n_estimators=400;, score=0.860 total time=   0.6s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=890, max_features=log2, min_samples_leaf=6, min_samples_split=5, n_estimators=400;, score=0.860 total time=   0.5s\n",
      "[CV 1/5] END criterion=absolute_error, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.858 total time=   0.8s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=1000, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=1800;, score=0.891 total time=   2.4s\n",
      "[CV 3/5] END criterion=poisson, max_depth=450, max_features=log2, min_samples_leaf=6, min_samples_split=14, n_estimators=2000;, score=0.900 total time=   2.6s\n",
      "[CV 4/5] END criterion=poisson, max_depth=230, max_features=log2, min_samples_leaf=8, min_samples_split=4, n_estimators=2000;, score=0.859 total time=   2.6s\n",
      "[CV 5/5] END criterion=absolute_error, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=1400;, score=0.880 total time=   6.4s\n",
      "[CV 2/5] END criterion=poisson, max_depth=120, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=600;, score=0.903 total time=   0.9s\n",
      "[CV 4/5] END criterion=poisson, max_depth=120, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=600;, score=0.885 total time=   0.9s\n",
      "[CV 1/5] END criterion=poisson, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=3, n_estimators=400;, score=0.864 total time=   0.7s\n",
      "[CV 3/5] END criterion=poisson, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=3, n_estimators=400;, score=0.906 total time=   0.6s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=450, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=1600;, score=0.903 total time=   2.2s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=10, max_features=sqrt, min_samples_leaf=6, min_samples_split=2, n_estimators=2000;, score=0.882 total time=   2.6s\n",
      "[CV 4/5] END criterion=poisson, max_depth=120, max_features=log2, min_samples_leaf=6, min_samples_split=5, n_estimators=1800;, score=0.869 total time=   2.5s\n",
      "[CV 1/5] END criterion=poisson, max_depth=560, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=600;, score=0.871 total time=   0.9s\n",
      "[CV 4/5] END criterion=poisson, max_depth=560, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=600;, score=0.885 total time=   0.9s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=340, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=2000;, score=0.886 total time=   2.9s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=1000, max_features=log2, min_samples_leaf=6, min_samples_split=5, n_estimators=600;, score=0.882 total time=   0.8s\n",
      "[CV 3/5] END copy_X=True, fit_intercept=True, positive=False;, score=0.900 total time=   0.0s\n",
      "[CV 4/5] END copy_X=True, fit_intercept=True, positive=True;, score=0.912 total time=   0.0s\n",
      "[CV 2/5] END copy_X=True, fit_intercept=False, positive=True;, score=0.858 total time=   0.0s\n",
      "[CV 3/5] END copy_X=True, fit_intercept=False, positive=True;, score=0.900 total time=   0.0s\n",
      "[CV 4/5] END copy_X=False, fit_intercept=True, positive=True;, score=0.912 total time=   0.0s\n",
      "[CV 5/5] END copy_X=False, fit_intercept=True, positive=True;, score=0.911 total time=   0.0s\n",
      "[CV 3/5] END copy_X=False, fit_intercept=False, positive=True;, score=0.900 total time=   0.0s\n",
      "[CV 3/5] END copy_X=True, fit_intercept=True, positive=False;, score=0.900 total time=   0.0s\n",
      "[CV 3/5] END copy_X=True, fit_intercept=True, positive=False;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END copy_X=True, fit_intercept=True, positive=True;, score=0.892 total time=   0.0s\n",
      "[CV 2/5] END copy_X=True, fit_intercept=False, positive=True;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END copy_X=True, fit_intercept=False, positive=True;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END copy_X=False, fit_intercept=True, positive=True;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END copy_X=False, fit_intercept=True, positive=True;, score=0.883 total time=   0.0s\n",
      "[CV 5/5] END copy_X=False, fit_intercept=False, positive=True;, score=0.883 total time=   0.0s\n",
      "[CV 4/5] END criterion=poisson, max_depth=1000, max_features=sqrt, min_samples_leaf=8, min_samples_split=3, n_estimators=1000;, score=0.861 total time=   1.4s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=670, max_features=sqrt, min_samples_leaf=6, min_samples_split=3, n_estimators=1200;, score=0.883 total time=   1.5s\n",
      "[CV 1/5] END criterion=poisson, max_depth=560, max_features=log2, min_samples_leaf=8, min_samples_split=5, n_estimators=1200;, score=0.855 total time=   1.6s\n",
      "[CV 4/5] END criterion=absolute_error, max_depth=1000, max_features=log2, min_samples_leaf=8, min_samples_split=4, n_estimators=1000;, score=0.849 total time=   3.6s\n",
      "[CV 4/5] END criterion=absolute_error, max_depth=890, max_features=log2, min_samples_leaf=6, min_samples_split=2, n_estimators=1000;, score=0.859 total time=   3.9s\n",
      "[CV 2/5] END criterion=absolute_error, max_depth=10, max_features=sqrt, min_samples_leaf=8, min_samples_split=4, n_estimators=1200;, score=0.866 total time=   4.3s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=780, max_features=sqrt, min_samples_leaf=6, min_samples_split=10, n_estimators=1400;, score=0.884 total time=   1.8s\n",
      "[CV 3/5] END criterion=poisson, max_depth=670, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=600;, score=0.915 total time=   0.9s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=450, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=800;, score=0.891 total time=   1.2s\n",
      "[CV 5/5] END criterion=absolute_error, max_depth=890, max_features=log2, min_samples_leaf=8, min_samples_split=4, n_estimators=800;, score=0.849 total time=   3.0s\n",
      "[CV 3/5] END criterion=absolute_error, max_depth=340, max_features=log2, min_samples_leaf=6, min_samples_split=10, n_estimators=600;, score=0.897 total time=   2.5s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=230, max_features=log2, min_samples_leaf=6, min_samples_split=2, n_estimators=1200;, score=0.863 total time=   1.5s\n",
      "[CV 1/5] END criterion=poisson, max_depth=890, max_features=log2, min_samples_leaf=6, min_samples_split=14, n_estimators=800;, score=0.861 total time=   1.1s\n",
      "[CV 2/5] END criterion=poisson, max_depth=890, max_features=log2, min_samples_leaf=6, min_samples_split=14, n_estimators=800;, score=0.882 total time=   1.1s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=450, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=800;, score=0.910 total time=   1.1s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=890, max_features=log2, min_samples_leaf=6, min_samples_split=5, n_estimators=400;, score=0.884 total time=   0.5s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=890, max_features=sqrt, min_samples_leaf=8, min_samples_split=3, n_estimators=400;, score=0.875 total time=   0.5s\n",
      "[CV 3/5] END criterion=absolute_error, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.906 total time=   0.8s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=1000, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=1800;, score=0.875 total time=   2.3s\n",
      "[CV 5/5] END criterion=poisson, max_depth=450, max_features=log2, min_samples_leaf=6, min_samples_split=14, n_estimators=2000;, score=0.862 total time=   2.7s\n",
      "[CV 1/5] END criterion=absolute_error, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=1400;, score=0.869 total time=   6.3s\n",
      "[CV 3/5] END criterion=absolute_error, max_depth=450, max_features=sqrt, min_samples_leaf=8, min_samples_split=4, n_estimators=1400;, score=0.889 total time=   5.4s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=450, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=1600;, score=0.872 total time=   2.2s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=10, max_features=sqrt, min_samples_leaf=6, min_samples_split=2, n_estimators=2000;, score=0.900 total time=   2.5s\n",
      "[CV 3/5] END criterion=poisson, max_depth=120, max_features=log2, min_samples_leaf=6, min_samples_split=5, n_estimators=1800;, score=0.901 total time=   2.5s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=560, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1200;, score=0.891 total time=   2.0s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=230, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1600;, score=0.872 total time=   2.3s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=230, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1600;, score=0.888 total time=   2.3s\n",
      "[CV 4/5] END criterion=absolute_error, max_depth=890, max_features=log2, min_samples_leaf=8, min_samples_split=14, n_estimators=1000;, score=0.850 total time=   3.7s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=560, max_features=log2, min_samples_leaf=8, min_samples_split=3, n_estimators=1400;, score=0.854 total time=   1.9s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=450, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=600;, score=0.870 total time=   1.1s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=450, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=600;, score=0.899 total time=   0.8s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=450, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=600;, score=0.912 total time=   0.8s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=450, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=600;, score=0.881 total time=   0.8s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=450, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=600;, score=0.876 total time=   0.8s\n",
      "[CV 1/5] END criterion=poisson, max_depth=670, max_features=sqrt, min_samples_leaf=4, min_samples_split=14, n_estimators=1600;, score=0.864 total time=   2.2s\n",
      "[CV 2/5] END criterion=poisson, max_depth=670, max_features=sqrt, min_samples_leaf=4, min_samples_split=14, n_estimators=1600;, score=0.886 total time=   2.2s\n",
      "[CV 3/5] END criterion=absolute_error, max_depth=780, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=1600;, score=0.905 total time=   6.7s\n",
      "[CV 1/5] END criterion=absolute_error, max_depth=780, max_features=log2, min_samples_leaf=1, min_samples_split=14, n_estimators=1200;, score=0.866 total time=   5.9s\n",
      "[CV 3/5] END criterion=absolute_error, max_depth=780, max_features=sqrt, min_samples_leaf=1, min_samples_split=14, n_estimators=800;, score=0.909 total time=   3.7s\n",
      "[CV 4/5] END criterion=absolute_error, max_depth=450, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=800;, score=0.888 total time=   4.2s\n",
      "[CV 1/5] END copy_X=True, fit_intercept=True, positive=False;, score=0.897 total time=   0.0s\n",
      "[CV 2/5] END copy_X=True, fit_intercept=True, positive=True;, score=0.858 total time=   0.0s\n",
      "[CV 3/5] END copy_X=True, fit_intercept=False, positive=False;, score=0.900 total time=   0.0s\n",
      "[CV 4/5] END copy_X=True, fit_intercept=False, positive=False;, score=0.912 total time=   0.0s\n",
      "[CV 5/5] END copy_X=False, fit_intercept=True, positive=False;, score=0.911 total time=   0.0s\n",
      "[CV 1/5] END copy_X=False, fit_intercept=True, positive=True;, score=0.897 total time=   0.0s\n",
      "[CV 2/5] END copy_X=False, fit_intercept=False, positive=True;, score=0.858 total time=   0.0s\n",
      "[CV 5/5] END copy_X=False, fit_intercept=False, positive=True;, score=0.911 total time=   0.0s\n",
      "[CV 5/5] END copy_X=True, fit_intercept=True, positive=False;, score=0.883 total time=   0.0s\n",
      "[CV 5/5] END copy_X=True, fit_intercept=True, positive=True;, score=0.883 total time=   0.0s\n",
      "[CV 4/5] END copy_X=True, fit_intercept=False, positive=True;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END copy_X=True, fit_intercept=False, positive=True;, score=0.883 total time=   0.0s\n",
      "[CV 2/5] END copy_X=False, fit_intercept=True, positive=True;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END copy_X=False, fit_intercept=True, positive=True;, score=0.918 total time=   0.0s\n",
      "[CV 3/5] END copy_X=False, fit_intercept=False, positive=True;, score=0.918 total time=   0.0s\n",
      "[CV 3/5] END copy_X=True, fit_intercept=True, positive=False;, score=0.918 total time=   0.0s\n",
      "[CV 1/5] END criterion=poisson, max_depth=1000, max_features=sqrt, min_samples_leaf=8, min_samples_split=3, n_estimators=1000;, score=0.856 total time=   1.7s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=120, max_features=sqrt, min_samples_leaf=8, min_samples_split=4, n_estimators=200;, score=0.856 total time=   0.3s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=120, max_features=sqrt, min_samples_leaf=8, min_samples_split=4, n_estimators=200;, score=0.892 total time=   0.2s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=120, max_features=sqrt, min_samples_leaf=8, min_samples_split=4, n_estimators=200;, score=0.853 total time=   0.3s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=890, max_features=log2, min_samples_leaf=8, min_samples_split=14, n_estimators=200;, score=0.876 total time=   0.2s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=890, max_features=log2, min_samples_leaf=8, min_samples_split=14, n_estimators=200;, score=0.854 total time=   0.2s\n",
      "[CV 4/5] END criterion=poisson, max_depth=560, max_features=log2, min_samples_leaf=8, min_samples_split=5, n_estimators=1200;, score=0.859 total time=   1.5s\n",
      "[CV 2/5] END criterion=absolute_error, max_depth=1000, max_features=log2, min_samples_leaf=8, min_samples_split=4, n_estimators=1000;, score=0.867 total time=   3.6s\n",
      "[CV 3/5] END criterion=absolute_error, max_depth=890, max_features=log2, min_samples_leaf=6, min_samples_split=2, n_estimators=1000;, score=0.898 total time=   3.9s\n",
      "[CV 1/5] END criterion=absolute_error, max_depth=10, max_features=sqrt, min_samples_leaf=8, min_samples_split=4, n_estimators=1200;, score=0.845 total time=   4.4s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=780, max_features=sqrt, min_samples_leaf=6, min_samples_split=10, n_estimators=1400;, score=0.902 total time=   1.8s\n",
      "[CV 4/5] END criterion=poisson, max_depth=670, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=600;, score=0.888 total time=   0.9s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=450, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=800;, score=0.889 total time=   1.2s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=670, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=800;, score=0.864 total time=   1.1s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=670, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=800;, score=0.894 total time=   1.1s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=670, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=800;, score=0.873 total time=   1.1s\n",
      "[CV 5/5] END criterion=absolute_error, max_depth=340, max_features=log2, min_samples_leaf=6, min_samples_split=10, n_estimators=600;, score=0.859 total time=   2.7s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=120, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=2000;, score=0.892 total time=   2.6s\n",
      "[CV 4/5] END criterion=poisson, max_depth=890, max_features=log2, min_samples_leaf=6, min_samples_split=14, n_estimators=800;, score=0.865 total time=   1.1s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=450, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=800;, score=0.888 total time=   1.2s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=890, max_features=sqrt, min_samples_leaf=8, min_samples_split=3, n_estimators=400;, score=0.893 total time=   0.5s\n",
      "[CV 5/5] END criterion=absolute_error, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.867 total time=   0.8s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=1000, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=1800;, score=0.869 total time=   2.3s\n",
      "[CV 1/5] END criterion=poisson, max_depth=230, max_features=log2, min_samples_leaf=8, min_samples_split=4, n_estimators=2000;, score=0.854 total time=   2.7s\n",
      "[CV 2/5] END criterion=absolute_error, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=1400;, score=0.903 total time=   6.3s\n",
      "[CV 2/5] END criterion=absolute_error, max_depth=450, max_features=sqrt, min_samples_leaf=8, min_samples_split=4, n_estimators=1400;, score=0.865 total time=   5.1s\n",
      "[CV 4/5] END criterion=poisson, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=3, n_estimators=400;, score=0.876 total time=   0.6s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=450, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=1600;, score=0.884 total time=   2.2s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=10, max_features=sqrt, min_samples_leaf=6, min_samples_split=2, n_estimators=2000;, score=0.862 total time=   2.5s\n",
      "[CV 5/5] END criterion=poisson, max_depth=120, max_features=log2, min_samples_leaf=6, min_samples_split=5, n_estimators=1800;, score=0.864 total time=   2.5s\n",
      "[CV 3/5] END criterion=poisson, max_depth=560, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=600;, score=0.913 total time=   1.0s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=340, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=2000;, score=0.907 total time=   2.9s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=230, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1600;, score=0.917 total time=   2.4s\n",
      "[CV 3/5] END criterion=absolute_error, max_depth=890, max_features=log2, min_samples_leaf=8, min_samples_split=14, n_estimators=1000;, score=0.889 total time=   3.7s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=560, max_features=log2, min_samples_leaf=8, min_samples_split=3, n_estimators=1400;, score=0.859 total time=   1.8s\n",
      "[CV 5/5] END criterion=absolute_error, max_depth=450, max_features=log2, min_samples_leaf=4, min_samples_split=3, n_estimators=1800;, score=0.868 total time=   8.5s\n",
      "[CV 2/5] END criterion=absolute_error, max_depth=780, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=1600;, score=0.888 total time=   6.7s\n",
      "[CV 4/5] END criterion=absolute_error, max_depth=450, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=600;, score=0.883 total time=   2.8s\n",
      "[CV 5/5] END criterion=absolute_error, max_depth=780, max_features=log2, min_samples_leaf=1, min_samples_split=14, n_estimators=1200;, score=0.875 total time=   5.9s\n",
      "[CV 2/5] END criterion=absolute_error, max_depth=450, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=800;, score=0.909 total time=   4.4s\n",
      "[CV 3/5] END criterion=absolute_error, max_depth=780, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=800;, score=0.917 total time=   4.1s\n",
      "[CV 4/5] END copy_X=True, fit_intercept=True, positive=False;, score=0.912 total time=   0.0s\n",
      "[CV 5/5] END copy_X=True, fit_intercept=True, positive=True;, score=0.911 total time=   0.0s\n",
      "[CV 4/5] END copy_X=True, fit_intercept=False, positive=True;, score=0.912 total time=   0.0s\n",
      "[CV 5/5] END copy_X=True, fit_intercept=False, positive=True;, score=0.911 total time=   0.0s\n",
      "[CV 1/5] END copy_X=False, fit_intercept=False, positive=False;, score=0.897 total time=   0.0s\n",
      "[CV 2/5] END copy_X=False, fit_intercept=False, positive=False;, score=0.858 total time=   0.0s\n",
      "[CV 1/5] END copy_X=True, fit_intercept=True, positive=False;, score=0.897 total time=   0.0s\n",
      "[CV 1/5] END copy_X=True, fit_intercept=True, positive=False;, score=0.881 total time=   0.0s\n",
      "[CV 3/5] END copy_X=True, fit_intercept=True, positive=True;, score=0.918 total time=   0.0s\n",
      "[CV 5/5] END copy_X=True, fit_intercept=False, positive=False;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END copy_X=True, fit_intercept=False, positive=True;, score=0.881 total time=   0.0s\n",
      "[CV 1/5] END copy_X=False, fit_intercept=False, positive=False;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END copy_X=False, fit_intercept=False, positive=False;, score=0.905 total time=   0.0s\n",
      "[CV 4/5] END copy_X=False, fit_intercept=False, positive=True;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END copy_X=True, fit_intercept=True, positive=False;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=670, max_features=sqrt, min_samples_leaf=6, min_samples_split=3, n_estimators=1200;, score=0.862 total time=   1.6s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=670, max_features=sqrt, min_samples_leaf=6, min_samples_split=3, n_estimators=1200;, score=0.862 total time=   1.5s\n",
      "[CV 1/5] END criterion=absolute_error, max_depth=1000, max_features=log2, min_samples_leaf=8, min_samples_split=4, n_estimators=1000;, score=0.844 total time=   3.7s\n",
      "[CV 2/5] END criterion=absolute_error, max_depth=890, max_features=log2, min_samples_leaf=6, min_samples_split=2, n_estimators=1000;, score=0.875 total time=   3.8s\n",
      "[CV 3/5] END criterion=poisson, max_depth=670, max_features=log2, min_samples_leaf=6, min_samples_split=5, n_estimators=1800;, score=0.901 total time=   2.4s\n",
      "[CV 5/5] END criterion=absolute_error, max_depth=10, max_features=sqrt, min_samples_leaf=8, min_samples_split=4, n_estimators=1200;, score=0.847 total time=   4.4s\n",
      "[CV 2/5] END criterion=poisson, max_depth=670, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=600;, score=0.907 total time=   0.9s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=450, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=800;, score=0.911 total time=   1.2s\n",
      "[CV 3/5] END criterion=absolute_error, max_depth=890, max_features=log2, min_samples_leaf=8, min_samples_split=4, n_estimators=800;, score=0.892 total time=   2.9s\n",
      "[CV 1/5] END criterion=absolute_error, max_depth=340, max_features=log2, min_samples_leaf=6, min_samples_split=10, n_estimators=600;, score=0.851 total time=   2.4s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=230, max_features=log2, min_samples_leaf=6, min_samples_split=2, n_estimators=1200;, score=0.902 total time=   1.9s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=120, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=2000;, score=0.869 total time=   2.5s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=450, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=800;, score=0.918 total time=   1.2s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=890, max_features=log2, min_samples_leaf=6, min_samples_split=5, n_estimators=400;, score=0.865 total time=   0.5s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=890, max_features=sqrt, min_samples_leaf=8, min_samples_split=3, n_estimators=400;, score=0.855 total time=   0.5s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=1000, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=1800;, score=0.865 total time=   2.3s\n",
      "[CV 2/5] END criterion=poisson, max_depth=450, max_features=log2, min_samples_leaf=6, min_samples_split=14, n_estimators=2000;, score=0.880 total time=   2.7s\n",
      "[CV 3/5] END criterion=poisson, max_depth=230, max_features=log2, min_samples_leaf=8, min_samples_split=4, n_estimators=2000;, score=0.894 total time=   2.6s\n",
      "[CV 4/5] END criterion=absolute_error, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=1400;, score=0.883 total time=   6.3s\n",
      "[CV 1/5] END criterion=poisson, max_depth=120, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=600;, score=0.872 total time=   0.9s\n",
      "[CV 3/5] END criterion=poisson, max_depth=120, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=600;, score=0.914 total time=   0.9s\n",
      "[CV 5/5] END criterion=poisson, max_depth=120, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=600;, score=0.881 total time=   0.9s\n",
      "[CV 2/5] END criterion=poisson, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=3, n_estimators=400;, score=0.893 total time=   0.6s\n",
      "[CV 5/5] END criterion=poisson, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=3, n_estimators=400;, score=0.872 total time=   0.6s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=450, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=1600;, score=0.880 total time=   2.3s\n",
      "[CV 1/5] END criterion=poisson, max_depth=120, max_features=log2, min_samples_leaf=6, min_samples_split=5, n_estimators=1800;, score=0.861 total time=   2.5s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=560, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1200;, score=0.914 total time=   2.0s\n",
      "[CV 2/5] END criterion=poisson, max_depth=560, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=600;, score=0.902 total time=   1.0s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=340, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=2000;, score=0.873 total time=   3.0s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=230, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1600;, score=0.907 total time=   2.3s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=1000, max_features=log2, min_samples_leaf=6, min_samples_split=5, n_estimators=600;, score=0.862 total time=   0.8s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=560, max_features=log2, min_samples_leaf=8, min_samples_split=3, n_estimators=1400;, score=0.854 total time=   1.9s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=560, max_features=log2, min_samples_leaf=8, min_samples_split=3, n_estimators=1400;, score=0.874 total time=   2.2s\n",
      "[CV 1/5] END criterion=absolute_error, max_depth=450, max_features=log2, min_samples_leaf=4, min_samples_split=3, n_estimators=1800;, score=0.858 total time=   8.2s\n",
      "[CV 4/5] END criterion=poisson, max_depth=670, max_features=sqrt, min_samples_leaf=4, min_samples_split=14, n_estimators=1600;, score=0.871 total time=   2.2s\n",
      "[CV 5/5] END criterion=absolute_error, max_depth=780, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=1600;, score=0.869 total time=   6.6s\n",
      "[CV 3/5] END criterion=absolute_error, max_depth=780, max_features=log2, min_samples_leaf=1, min_samples_split=14, n_estimators=1200;, score=0.908 total time=   5.8s\n",
      "[CV 4/5] END criterion=absolute_error, max_depth=780, max_features=sqrt, min_samples_leaf=1, min_samples_split=14, n_estimators=800;, score=0.876 total time=   3.7s\n",
      "[CV 5/5] END criterion=absolute_error, max_depth=450, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=800;, score=0.889 total time=   4.4s\n",
      "[CV 1/5] END criterion=absolute_error, max_depth=890, max_features=sqrt, min_samples_leaf=6, min_samples_split=5, n_estimators=1400;, score=0.852 total time=   5.3s\n",
      "[CV 2/5] END criterion=poisson, max_depth=1000, max_features=log2, min_samples_leaf=6, min_samples_split=3, n_estimators=1600;, score=0.881 total time=   2.3s\n",
      "[CV 1/5] END copy_X=True, fit_intercept=True, positive=True;, score=0.897 total time=   0.0s\n",
      "[CV 2/5] END copy_X=True, fit_intercept=False, positive=False;, score=0.858 total time=   0.0s\n",
      "[CV 3/5] END copy_X=False, fit_intercept=True, positive=False;, score=0.900 total time=   0.0s\n",
      "[CV 4/5] END copy_X=False, fit_intercept=True, positive=False;, score=0.912 total time=   0.0s\n",
      "[CV 3/5] END copy_X=False, fit_intercept=False, positive=False;, score=0.900 total time=   0.0s\n",
      "[CV 4/5] END copy_X=False, fit_intercept=False, positive=False;, score=0.912 total time=   0.0s\n",
      "[CV 2/5] END copy_X=True, fit_intercept=True, positive=False;, score=0.858 total time=   0.0s\n",
      "[CV 4/5] END copy_X=True, fit_intercept=True, positive=False;, score=0.892 total time=   0.0s\n",
      "[CV 2/5] END copy_X=True, fit_intercept=False, positive=False;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END copy_X=False, fit_intercept=True, positive=False;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END copy_X=False, fit_intercept=True, positive=False;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END copy_X=False, fit_intercept=False, positive=False;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END copy_X=False, fit_intercept=False, positive=True;, score=0.881 total time=   0.0s\n",
      "[CV 4/5] END copy_X=True, fit_intercept=True, positive=False;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END criterion=poisson, max_depth=1000, max_features=sqrt, min_samples_leaf=8, min_samples_split=3, n_estimators=1000;, score=0.855 total time=   1.4s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=670, max_features=sqrt, min_samples_leaf=6, min_samples_split=3, n_estimators=1200;, score=0.900 total time=   1.5s\n",
      "[CV 2/5] END criterion=poisson, max_depth=560, max_features=log2, min_samples_leaf=8, min_samples_split=5, n_estimators=1200;, score=0.871 total time=   1.6s\n",
      "[CV 3/5] END criterion=absolute_error, max_depth=1000, max_features=log2, min_samples_leaf=8, min_samples_split=4, n_estimators=1000;, score=0.890 total time=   3.7s\n",
      "[CV 5/5] END criterion=absolute_error, max_depth=890, max_features=log2, min_samples_leaf=6, min_samples_split=2, n_estimators=1000;, score=0.858 total time=   3.9s\n",
      "[CV 3/5] END criterion=absolute_error, max_depth=10, max_features=sqrt, min_samples_leaf=8, min_samples_split=4, n_estimators=1200;, score=0.889 total time=   4.4s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=780, max_features=sqrt, min_samples_leaf=6, min_samples_split=10, n_estimators=1400;, score=0.869 total time=   1.8s\n",
      "[CV 5/5] END criterion=poisson, max_depth=670, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=600;, score=0.884 total time=   0.9s\n",
      "[CV 1/5] END criterion=absolute_error, max_depth=890, max_features=log2, min_samples_leaf=8, min_samples_split=4, n_estimators=800;, score=0.844 total time=   2.9s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=670, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=800;, score=0.909 total time=   1.2s\n",
      "[CV 4/5] END criterion=absolute_error, max_depth=340, max_features=log2, min_samples_leaf=6, min_samples_split=10, n_estimators=600;, score=0.858 total time=   2.6s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=120, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=2000;, score=0.866 total time=   2.8s\n",
      "[CV 3/5] END criterion=poisson, max_depth=890, max_features=log2, min_samples_leaf=6, min_samples_split=14, n_estimators=800;, score=0.901 total time=   1.1s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=450, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=800;, score=0.892 total time=   1.2s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=890, max_features=sqrt, min_samples_leaf=8, min_samples_split=3, n_estimators=400;, score=0.852 total time=   0.5s\n",
      "[CV 2/5] END criterion=absolute_error, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.886 total time=   0.8s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=1000, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=1800;, score=0.908 total time=   2.4s\n",
      "[CV 4/5] END criterion=poisson, max_depth=450, max_features=log2, min_samples_leaf=6, min_samples_split=14, n_estimators=2000;, score=0.866 total time=   2.6s\n",
      "[CV 5/5] END criterion=poisson, max_depth=230, max_features=log2, min_samples_leaf=8, min_samples_split=4, n_estimators=2000;, score=0.855 total time=   2.6s\n",
      "[CV 1/5] END criterion=absolute_error, max_depth=450, max_features=sqrt, min_samples_leaf=8, min_samples_split=4, n_estimators=1400;, score=0.846 total time=   5.1s\n",
      "[CV 5/5] END criterion=absolute_error, max_depth=450, max_features=sqrt, min_samples_leaf=8, min_samples_split=4, n_estimators=1400;, score=0.849 total time=   5.2s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=10, max_features=sqrt, min_samples_leaf=6, min_samples_split=2, n_estimators=2000;, score=0.860 total time=   2.7s\n",
      "[CV 2/5] END criterion=poisson, max_depth=120, max_features=log2, min_samples_leaf=6, min_samples_split=5, n_estimators=1800;, score=0.881 total time=   2.4s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=560, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1200;, score=0.919 total time=   2.1s\n",
      "[CV 5/5] END criterion=poisson, max_depth=560, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=600;, score=0.883 total time=   0.9s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=340, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=2000;, score=0.882 total time=   2.9s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=1000, max_features=log2, min_samples_leaf=6, min_samples_split=5, n_estimators=600;, score=0.861 total time=   0.8s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=1000, max_features=log2, min_samples_leaf=6, min_samples_split=5, n_estimators=600;, score=0.901 total time=   0.8s\n",
      "[CV 1/5] END criterion=absolute_error, max_depth=890, max_features=log2, min_samples_leaf=8, min_samples_split=14, n_estimators=1000;, score=0.845 total time=   4.2s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=670, max_features=sqrt, min_samples_leaf=8, min_samples_split=14, n_estimators=200;, score=0.859 total time=   0.3s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=670, max_features=sqrt, min_samples_leaf=8, min_samples_split=14, n_estimators=200;, score=0.892 total time=   0.3s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=670, max_features=sqrt, min_samples_leaf=8, min_samples_split=14, n_estimators=200;, score=0.854 total time=   0.3s\n",
      "[CV 3/5] END criterion=absolute_error, max_depth=450, max_features=log2, min_samples_leaf=4, min_samples_split=3, n_estimators=1800;, score=0.905 total time=   8.1s\n",
      "[CV 5/5] END criterion=poisson, max_depth=670, max_features=sqrt, min_samples_leaf=4, min_samples_split=14, n_estimators=1600;, score=0.866 total time=   2.2s\n",
      "[CV 1/5] END criterion=absolute_error, max_depth=450, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=600;, score=0.868 total time=   3.0s\n",
      "[CV 2/5] END criterion=absolute_error, max_depth=450, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=600;, score=0.902 total time=   2.8s\n",
      "[CV 5/5] END criterion=absolute_error, max_depth=450, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=600;, score=0.882 total time=   2.8s\n",
      "[CV 1/5] END criterion=absolute_error, max_depth=780, max_features=sqrt, min_samples_leaf=1, min_samples_split=14, n_estimators=800;, score=0.865 total time=   3.9s\n",
      "[CV 5/5] END criterion=absolute_error, max_depth=780, max_features=sqrt, min_samples_leaf=1, min_samples_split=14, n_estimators=800;, score=0.871 total time=   3.7s\n",
      "[CV 1/5] END criterion=absolute_error, max_depth=780, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=800;, score=0.877 total time=   4.2s\n",
      "[CV 2/5] END criterion=absolute_error, max_depth=890, max_features=sqrt, min_samples_leaf=6, min_samples_split=5, n_estimators=1400;, score=0.876 total time=   5.5s\n",
      "[CV 3/5] END criterion=poisson, max_depth=1000, max_features=log2, min_samples_leaf=6, min_samples_split=3, n_estimators=1600;, score=0.899 total time=   2.1s\n",
      "[CV 2/5] END copy_X=True, fit_intercept=True, positive=False;, score=0.858 total time=   0.0s\n",
      "[CV 3/5] END copy_X=True, fit_intercept=True, positive=True;, score=0.900 total time=   0.0s\n",
      "[CV 5/5] END copy_X=True, fit_intercept=False, positive=False;, score=0.911 total time=   0.0s\n",
      "[CV 1/5] END copy_X=True, fit_intercept=False, positive=True;, score=0.897 total time=   0.0s\n",
      "[CV 2/5] END copy_X=False, fit_intercept=True, positive=True;, score=0.858 total time=   0.0s\n",
      "[CV 3/5] END copy_X=False, fit_intercept=True, positive=True;, score=0.900 total time=   0.0s\n",
      "[CV 4/5] END copy_X=False, fit_intercept=False, positive=True;, score=0.912 total time=   0.0s\n",
      "[CV 5/5] END copy_X=True, fit_intercept=True, positive=False;, score=0.911 total time=   0.0s\n",
      "[CV 1/5] END copy_X=True, fit_intercept=True, positive=True;, score=0.881 total time=   0.0s\n",
      "[CV 1/5] END copy_X=True, fit_intercept=False, positive=False;, score=0.881 total time=   0.0s\n",
      "[CV 1/5] END copy_X=False, fit_intercept=True, positive=False;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END copy_X=False, fit_intercept=True, positive=False;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END copy_X=False, fit_intercept=False, positive=False;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END copy_X=False, fit_intercept=False, positive=False;, score=0.892 total time=   0.0s\n",
      "[CV 1/5] END copy_X=True, fit_intercept=True, positive=False;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END criterion=poisson, max_depth=1000, max_features=sqrt, min_samples_leaf=8, min_samples_split=3, n_estimators=1000;, score=0.873 total time=   1.4s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=670, max_features=sqrt, min_samples_leaf=6, min_samples_split=3, n_estimators=1200;, score=0.868 total time=   1.5s\n",
      "[CV 3/5] END criterion=poisson, max_depth=560, max_features=log2, min_samples_leaf=8, min_samples_split=5, n_estimators=1200;, score=0.894 total time=   1.6s\n",
      "[CV 5/5] END criterion=absolute_error, max_depth=1000, max_features=log2, min_samples_leaf=8, min_samples_split=4, n_estimators=1000;, score=0.849 total time=   3.6s\n",
      "[CV 1/5] END criterion=poisson, max_depth=670, max_features=log2, min_samples_leaf=6, min_samples_split=5, n_estimators=1800;, score=0.861 total time=   2.5s\n",
      "[CV 4/5] END criterion=poisson, max_depth=670, max_features=log2, min_samples_leaf=6, min_samples_split=5, n_estimators=1800;, score=0.870 total time=   2.4s\n",
      "[CV 4/5] END criterion=absolute_error, max_depth=10, max_features=sqrt, min_samples_leaf=8, min_samples_split=4, n_estimators=1200;, score=0.850 total time=   4.3s\n",
      "[CV 1/5] END criterion=poisson, max_depth=670, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=600;, score=0.875 total time=   0.9s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=450, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=800;, score=0.876 total time=   1.2s\n",
      "[CV 2/5] END criterion=absolute_error, max_depth=890, max_features=log2, min_samples_leaf=8, min_samples_split=4, n_estimators=800;, score=0.867 total time=   2.9s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=670, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=800;, score=0.879 total time=   1.1s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=230, max_features=log2, min_samples_leaf=6, min_samples_split=2, n_estimators=1200;, score=0.860 total time=   1.5s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=230, max_features=log2, min_samples_leaf=6, min_samples_split=2, n_estimators=1200;, score=0.866 total time=   1.6s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=120, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=2000;, score=0.876 total time=   2.7s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=450, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=800;, score=0.875 total time=   1.2s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=890, max_features=log2, min_samples_leaf=6, min_samples_split=5, n_estimators=400;, score=0.902 total time=   0.5s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=890, max_features=sqrt, min_samples_leaf=8, min_samples_split=3, n_estimators=400;, score=0.857 total time=   0.5s\n",
      "[CV 4/5] END criterion=absolute_error, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=200;, score=0.870 total time=   0.8s\n",
      "[CV 1/5] END criterion=poisson, max_depth=450, max_features=log2, min_samples_leaf=6, min_samples_split=14, n_estimators=2000;, score=0.860 total time=   2.7s\n",
      "[CV 2/5] END criterion=poisson, max_depth=230, max_features=log2, min_samples_leaf=8, min_samples_split=4, n_estimators=2000;, score=0.873 total time=   2.6s\n",
      "[CV 3/5] END criterion=absolute_error, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=1400;, score=0.912 total time=   6.4s\n",
      "[CV 4/5] END criterion=absolute_error, max_depth=450, max_features=sqrt, min_samples_leaf=8, min_samples_split=4, n_estimators=1400;, score=0.849 total time=   5.2s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=450, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=1600;, score=0.914 total time=   2.2s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=10, max_features=sqrt, min_samples_leaf=6, min_samples_split=2, n_estimators=2000;, score=0.867 total time=   2.6s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=560, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1200;, score=0.876 total time=   2.0s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=560, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1200;, score=0.890 total time=   2.0s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=340, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=2000;, score=0.915 total time=   2.9s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=230, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=1600;, score=0.885 total time=   2.3s\n",
      "[CV 5/5] END criterion=absolute_error, max_depth=890, max_features=log2, min_samples_leaf=8, min_samples_split=14, n_estimators=1000;, score=0.849 total time=   3.7s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=670, max_features=sqrt, min_samples_leaf=8, min_samples_split=14, n_estimators=200;, score=0.873 total time=   0.3s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=670, max_features=sqrt, min_samples_leaf=8, min_samples_split=14, n_estimators=200;, score=0.855 total time=   0.3s\n",
      "[CV 2/5] END criterion=absolute_error, max_depth=450, max_features=log2, min_samples_leaf=4, min_samples_split=3, n_estimators=1800;, score=0.888 total time=   7.6s\n",
      "[CV 3/5] END criterion=poisson, max_depth=670, max_features=sqrt, min_samples_leaf=4, min_samples_split=14, n_estimators=1600;, score=0.904 total time=   2.3s\n",
      "[CV 4/5] END criterion=absolute_error, max_depth=780, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=1600;, score=0.871 total time=   6.8s\n",
      "[CV 2/5] END criterion=absolute_error, max_depth=780, max_features=log2, min_samples_leaf=1, min_samples_split=14, n_estimators=1200;, score=0.896 total time=   5.5s\n",
      "[CV 2/5] END criterion=absolute_error, max_depth=780, max_features=sqrt, min_samples_leaf=1, min_samples_split=14, n_estimators=800;, score=0.895 total time=   3.6s\n",
      "[CV 3/5] END criterion=absolute_error, max_depth=450, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=800;, score=0.917 total time=   4.3s\n",
      "[CV 4/5] END criterion=absolute_error, max_depth=780, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=800;, score=0.888 total time=   4.2s\n",
      "[CV 1/5] END criterion=poisson, max_depth=1000, max_features=log2, min_samples_leaf=6, min_samples_split=3, n_estimators=1600;, score=0.861 total time=   2.1s\n",
      "[CV 4/5] END criterion=poisson, max_depth=1000, max_features=log2, min_samples_leaf=6, min_samples_split=3, n_estimators=1600;, score=0.869 total time=   2.3s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=450, max_features=sqrt, min_samples_leaf=6, min_samples_split=5, n_estimators=600;, score=0.866 total time=   0.8s\n",
      "RandomForestRegressor() RandomCV Best Params : {'n_estimators': 1200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 560, 'criterion': 'squared_error'}\n",
      "RandomForestRegressor() RandomCV Score: 0.9016557617707758\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Final score is  0.9027404283164311\n"
     ]
    }
   ],
   "source": [
    "hyperparameter_tuning(algo=\"RandomForestRegressor()\",param_grid=random_grid,n_iter=100,cv=5,verbose=3,random_state=42,X_train=X_train.loc[:,list(selected_features)],Y_train=Y_train,X_test=X_test.loc[:,list(selected_features)],Y_test=Y_test,evaluation_metric=\"r2_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "3581d505-719c-49af-bed3-2f855e4954f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "4c9c8ace-20d3-4918-83b0-d55e73d0e94d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  62 out of  62 | elapsed:    1.2s finished\n",
      "\n",
      "[2023-02-01 16:19:51] Features: 1/62 -- score: -0.03601832875996762[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  61 | elapsed:    1.2s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  61 out of  61 | elapsed:    1.3s finished\n",
      "\n",
      "[2023-02-01 16:19:53] Features: 2/62 -- score: -0.03691142544577834[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:    1.2s finished\n",
      "\n",
      "[2023-02-01 16:19:54] Features: 3/62 -- score: -0.037183690883610246[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  59 out of  59 | elapsed:    1.3s finished\n",
      "\n",
      "[2023-02-01 16:19:55] Features: 4/62 -- score: -0.037382159630301226[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done  58 out of  58 | elapsed:    1.2s finished\n",
      "\n",
      "[2023-02-01 16:19:56] Features: 5/62 -- score: -0.03754049935528721[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  46 out of  57 | elapsed:    1.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  57 out of  57 | elapsed:    1.3s finished\n",
      "\n",
      "[2023-02-01 16:19:58] Features: 6/62 -- score: -0.0376058371843794[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 out of  56 | elapsed:    1.2s finished\n",
      "\n",
      "[2023-02-01 16:19:59] Features: 7/62 -- score: -0.03772572098666105[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  44 out of  55 | elapsed:    1.0s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  55 out of  55 | elapsed:    1.2s finished\n",
      "\n",
      "[2023-02-01 16:20:00] Features: 8/62 -- score: -0.037838686930492214[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  54 out of  54 | elapsed:    1.3s finished\n",
      "\n",
      "[2023-02-01 16:20:01] Features: 9/62 -- score: -0.037943010905151064[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 out of  53 | elapsed:    1.0s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  53 out of  53 | elapsed:    1.2s finished\n",
      "\n",
      "[2023-02-01 16:20:03] Features: 10/62 -- score: -0.038015480678408056[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  52 out of  52 | elapsed:    1.2s finished\n",
      "\n",
      "[2023-02-01 16:20:04] Features: 11/62 -- score: -0.03809837641081395[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  51 | elapsed:    1.1s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  51 out of  51 | elapsed:    1.2s finished\n",
      "\n",
      "[2023-02-01 16:20:05] Features: 12/62 -- score: -0.038169929833261174[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    1.2s finished\n",
      "\n",
      "[2023-02-01 16:20:06] Features: 13/62 -- score: -0.03821905665337781[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  38 out of  49 | elapsed:    1.1s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  49 out of  49 | elapsed:    1.2s finished\n",
      "\n",
      "[2023-02-01 16:20:07] Features: 14/62 -- score: -0.03825794875861503[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:    1.2s finished\n",
      "\n",
      "[2023-02-01 16:20:09] Features: 15/62 -- score: -0.03829713264503263[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  47 out of  47 | elapsed:    1.1s finished\n",
      "\n",
      "[2023-02-01 16:20:10] Features: 16/62 -- score: -0.038328406887850705[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  46 out of  46 | elapsed:    1.2s finished\n",
      "\n",
      "[2023-02-01 16:20:11] Features: 17/62 -- score: -0.038364429788931974[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 out of  45 | elapsed:    0.9s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    1.1s finished\n",
      "\n",
      "[2023-02-01 16:20:12] Features: 18/62 -- score: -0.03839833871939815[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  44 out of  44 | elapsed:    1.1s finished\n",
      "\n",
      "[2023-02-01 16:20:13] Features: 19/62 -- score: -0.038432351370211615[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  32 out of  43 | elapsed:    0.8s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  43 out of  43 | elapsed:    1.1s finished\n",
      "\n",
      "[2023-02-01 16:20:14] Features: 20/62 -- score: -0.03846215014999928[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 out of  42 | elapsed:    1.0s finished\n",
      "\n",
      "[2023-02-01 16:20:15] Features: 21/62 -- score: -0.03849210909679659[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  41 | elapsed:    0.9s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  41 out of  41 | elapsed:    1.1s finished\n",
      "\n",
      "[2023-02-01 16:20:16] Features: 22/62 -- score: -0.03852109785536899[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    1.0s finished\n",
      "\n",
      "[2023-02-01 16:20:18] Features: 23/62 -- score: -0.03854875570903236[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  28 out of  39 | elapsed:    0.9s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  39 out of  39 | elapsed:    1.1s finished\n",
      "\n",
      "[2023-02-01 16:20:19] Features: 24/62 -- score: -0.03857898513295157[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  38 out of  38 | elapsed:    1.2s finished\n",
      "\n",
      "[2023-02-01 16:20:20] Features: 25/62 -- score: -0.038607856746674954[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 out of  37 | elapsed:    1.0s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  37 out of  37 | elapsed:    1.1s finished\n",
      "\n",
      "[2023-02-01 16:20:21] Features: 26/62 -- score: -0.03863631139632053[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  36 out of  36 | elapsed:    1.0s finished\n",
      "\n",
      "[2023-02-01 16:20:22] Features: 27/62 -- score: -0.03866455761109409[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  35 | elapsed:    1.1s finished\n",
      "\n",
      "[2023-02-01 16:20:23] Features: 28/62 -- score: -0.03868990954265783[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 out of  34 | elapsed:    1.0s finished\n",
      "\n",
      "[2023-02-01 16:20:24] Features: 29/62 -- score: -0.03871577910487809[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  22 out of  33 | elapsed:    0.9s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  33 out of  33 | elapsed:    1.2s finished\n",
      "\n",
      "[2023-02-01 16:20:25] Features: 30/62 -- score: -0.03874053765303502[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  32 out of  32 | elapsed:    1.0s finished\n",
      "\n",
      "[2023-02-01 16:20:26] Features: 31/62 -- score: -0.038766012131687864[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  31 | elapsed:    0.5s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  31 out of  31 | elapsed:    0.8s finished\n",
      "\n",
      "[2023-02-01 16:20:27] Features: 32/62 -- score: -0.038792177773823246[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    0.7s finished\n",
      "\n",
      "[2023-02-01 16:20:28] Features: 33/62 -- score: -0.038818387282212985[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  29 | elapsed:    0.6s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  29 out of  29 | elapsed:    0.7s finished\n",
      "\n",
      "[2023-02-01 16:20:28] Features: 34/62 -- score: -0.03884368940520453[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  28 out of  28 | elapsed:    0.7s finished\n",
      "\n",
      "[2023-02-01 16:20:29] Features: 35/62 -- score: -0.038871063765068437[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  27 | elapsed:    0.6s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:    0.7s finished\n",
      "\n",
      "[2023-02-01 16:20:30] Features: 36/62 -- score: -0.03889720774235115[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 out of  26 | elapsed:    0.8s finished\n",
      "\n",
      "[2023-02-01 16:20:31] Features: 37/62 -- score: -0.03892333207505949[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  14 out of  25 | elapsed:    0.6s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.7s finished\n",
      "\n",
      "[2023-02-01 16:20:31] Features: 38/62 -- score: -0.038949009225910915[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:    1.0s finished\n",
      "\n",
      "[2023-02-01 16:20:32] Features: 39/62 -- score: -0.03897716701892238[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  23 out of  23 | elapsed:    0.8s finished\n",
      "\n",
      "[2023-02-01 16:20:33] Features: 40/62 -- score: -0.03900450562362141[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  22 out of  22 | elapsed:    0.7s finished\n",
      "\n",
      "[2023-02-01 16:20:34] Features: 41/62 -- score: -0.039034787995089325[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  21 out of  21 | elapsed:    0.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  21 out of  21 | elapsed:    0.7s finished\n",
      "\n",
      "[2023-02-01 16:20:35] Features: 42/62 -- score: -0.03906335205293314[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    0.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    0.7s finished\n",
      "\n",
      "[2023-02-01 16:20:35] Features: 43/62 -- score: -0.03909280012310461[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  19 | elapsed:    0.7s finished\n",
      "\n",
      "[2023-02-01 16:20:36] Features: 44/62 -- score: -0.039121798860035285[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  18 | elapsed:    0.6s finished\n",
      "\n",
      "[2023-02-01 16:20:37] Features: 45/62 -- score: -0.03915048745105203[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  17 | elapsed:    0.6s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  17 out of  17 | elapsed:    0.6s finished\n",
      "\n",
      "[2023-02-01 16:20:37] Features: 46/62 -- score: -0.0391795399060062[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  14 out of  16 | elapsed:    0.6s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  16 | elapsed:    0.6s finished\n",
      "\n",
      "[2023-02-01 16:20:38] Features: 47/62 -- score: -0.03920927495931466[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  15 | elapsed:    0.3s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.5s finished\n",
      "\n",
      "[2023-02-01 16:20:38] Features: 48/62 -- score: -0.039239686363311675[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  14 | elapsed:    0.3s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  14 out of  14 | elapsed:    0.5s finished\n",
      "\n",
      "[2023-02-01 16:20:39] Features: 49/62 -- score: -0.03926882946660108[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of  13 | elapsed:    0.3s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  13 out of  13 | elapsed:    0.5s finished\n",
      "\n",
      "[2023-02-01 16:20:39] Features: 50/62 -- score: -0.03929717212407855[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  12 | elapsed:    0.3s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    0.5s finished\n",
      "\n",
      "[2023-02-01 16:20:40] Features: 51/62 -- score: -0.039325301277516544[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  11 | elapsed:    0.2s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  11 | elapsed:    0.4s finished\n",
      "\n",
      "[2023-02-01 16:20:40] Features: 52/62 -- score: -0.039353963287476826[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    0.2s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.3s finished\n",
      "\n",
      "[2023-02-01 16:20:40] Features: 53/62 -- score: -0.03938203472390187[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   9 | elapsed:    0.2s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    0.4s finished\n",
      "\n",
      "[2023-02-01 16:20:41] Features: 54/62 -- score: -0.03941438384918996[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   8 | elapsed:    0.2s remaining:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.4s finished\n",
      "\n",
      "[2023-02-01 16:20:41] Features: 55/62 -- score: -0.03944549149918215[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   7 | elapsed:    0.2s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of   7 | elapsed:    0.3s finished\n",
      "\n",
      "[2023-02-01 16:20:41] Features: 56/62 -- score: -0.0394785562772205[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    0.2s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.2s finished\n",
      "\n",
      "[2023-02-01 16:20:42] Features: 57/62 -- score: -0.039509294863694144[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    0.2s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "\n",
      "[2023-02-01 16:20:42] Features: 58/62 -- score: -0.039541765658160255[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   4 | elapsed:    0.2s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    0.2s finished\n",
      "\n",
      "[2023-02-01 16:20:42] Features: 59/62 -- score: -0.03957900459253274[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.2s finished\n",
      "\n",
      "[2023-02-01 16:20:42] Features: 60/62 -- score: -0.03961479519005486[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.2s finished\n",
      "\n",
      "[2023-02-01 16:20:43] Features: 61/62 -- score: -0.03964869538531155[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features ('OverallQual', 'YearBuilt', 'FullBath')\n",
      "Prediction using selected features using SVR() is : -0.021348942417104055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "\n",
      "[2023-02-01 16:20:43] Features: 62/62 -- score: -0.039698167559629516"
     ]
    }
   ],
   "source": [
    "selected_features=sf_selector(algo=\"SVR()\",forward=True,floating=False,scoring=\"r2\",X_train=X_train,Y_train=Y_train,X_test=X_test,Y_test=Y_test,min_featues=3,cv=5,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e0cbb101-a177-422e-a610-3cd05e7f493b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernel': ['linear', 'poly', 'sigmoid', 'poly'], 'degree': [1, 3, 5, 7, 9, 11, 13, 15, 17, 20], 'max_iter': [100], 'tol': [0.01], 'gamma': ['scale', 'auto']}\n"
     ]
    }
   ],
   "source": [
    "kernel = [\"linear\", \"poly\", \"sigmoid\",\"poly\"]\n",
    "degree = [int(x) for x in np.linspace(start = 1, stop = 20, num = 10)]\n",
    "gamma= [\"scale\", \"auto\"]\n",
    "\n",
    "tol=[1e-2]\n",
    "max_iter=[100]\n",
    "\n",
    "\n",
    "random_grid = {'kernel': kernel,\n",
    "               'degree':degree,\n",
    "               'max_iter':max_iter,\n",
    "               'tol':tol,\n",
    "               'gamma':gamma\n",
    "               \n",
    "               \n",
    "               }\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b66085a0-80bb-45ae-bcd6-28d5e4183968",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_search.py:306: UserWarning: The total space of parameters 80 is smaller than n_iter=100. Running 80 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n",
      "[CV 5/5] END criterion=absolute_error, max_depth=780, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=800;, score=0.889 total time=   4.1s\n",
      "[CV 5/5] END criterion=absolute_error, max_depth=890, max_features=sqrt, min_samples_leaf=6, min_samples_split=5, n_estimators=1400;, score=0.858 total time=   5.4s\n",
      "[CV 5/5] END criterion=poisson, max_depth=1000, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=1200;, score=0.891 total time=   1.9s\n",
      "[CV 1/5] END criterion=poisson, max_depth=670, max_features=sqrt, min_samples_leaf=8, min_samples_split=5, n_estimators=200;, score=0.856 total time=   0.3s\n",
      "[CV 2/5] END criterion=poisson, max_depth=670, max_features=sqrt, min_samples_leaf=8, min_samples_split=5, n_estimators=200;, score=0.873 total time=   0.3s\n",
      "[CV 3/5] END criterion=poisson, max_depth=670, max_features=sqrt, min_samples_leaf=8, min_samples_split=5, n_estimators=200;, score=0.892 total time=   0.3s\n",
      "[CV 4/5] END criterion=poisson, max_depth=670, max_features=sqrt, min_samples_leaf=8, min_samples_split=5, n_estimators=200;, score=0.860 total time=   0.3s\n",
      "[CV 5/5] END criterion=poisson, max_depth=670, max_features=sqrt, min_samples_leaf=8, min_samples_split=5, n_estimators=200;, score=0.852 total time=   0.3s\n",
      "[CV 2/5] END criterion=poisson, max_depth=1000, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=800;, score=0.908 total time=   1.2s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=670, max_features=sqrt, min_samples_leaf=6, min_samples_split=2, n_estimators=1600;, score=0.861 total time=   2.0s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=890, max_features=log2, min_samples_leaf=1, min_samples_split=14, n_estimators=2000;, score=0.897 total time=   2.8s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=10, max_features=sqrt, min_samples_leaf=6, min_samples_split=4, n_estimators=1400;, score=0.901 total time=   1.8s\n",
      "[CV 4/5] END criterion=absolute_error, max_depth=340, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=1400;, score=0.872 total time=   6.0s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=230, max_features=log2, min_samples_leaf=2, min_samples_split=4, n_estimators=1200;, score=0.884 total time=   1.8s\n",
      "[CV 2/5] END criterion=poisson, max_depth=1000, max_features=log2, min_samples_leaf=6, min_samples_split=14, n_estimators=2000;, score=0.881 total time=   2.7s\n",
      "[CV 3/5] END criterion=poisson, max_depth=230, max_features=sqrt, min_samples_leaf=8, min_samples_split=3, n_estimators=1600;, score=0.893 total time=   2.1s\n",
      "[CV 3/5] END criterion=absolute_error, max_depth=1000, max_features=sqrt, min_samples_leaf=8, min_samples_split=3, n_estimators=800;, score=0.892 total time=   2.9s\n",
      "[CV 3/5] END criterion=absolute_error, max_depth=890, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1200;, score=0.918 total time=   6.7s\n",
      "[CV 3/5] END criterion=poisson, max_depth=340, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=1600;, score=0.908 total time=   2.2s\n",
      "[CV 4/5] END criterion=absolute_error, max_depth=340, max_features=sqrt, min_samples_leaf=6, min_samples_split=2, n_estimators=2000;, score=0.859 total time=   7.6s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=120, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.871 total time=   0.3s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=120, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.887 total time=   0.3s\n",
      "[CV 2/5] END criterion=absolute_error, max_depth=120, max_features=sqrt, min_samples_leaf=8, min_samples_split=5, n_estimators=800;, score=0.865 total time=   2.9s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=1000, max_features=sqrt, min_samples_leaf=8, min_samples_split=5, n_estimators=1200;, score=0.872 total time=   1.5s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=400;, score=0.878 total time=   0.5s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=780, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1600;, score=0.888 total time=   2.3s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=120, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=1200;, score=0.882 total time=   1.7s\n",
      "[CV 1/5] END criterion=absolute_error, max_depth=230, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=2000;, score=0.859 total time=   8.2s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=120, max_features=log2, min_samples_leaf=2, min_samples_split=14, n_estimators=1400;, score=0.876 total time=   1.8s\n",
      "[CV 1/5] END criterion=poisson, max_depth=890, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=800;, score=0.873 total time=   1.3s\n",
      "[CV 4/5] END criterion=poisson, max_depth=890, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=800;, score=0.892 total time=   1.3s\n",
      "[CV 5/5] END criterion=poisson, max_depth=890, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=1600;, score=0.873 total time=   2.3s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=890, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=600;, score=0.864 total time=   0.8s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=890, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=600;, score=0.891 total time=   0.9s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=890, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=600;, score=0.906 total time=   1.2s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=890, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=600;, score=0.876 total time=   0.9s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=890, max_features=log2, min_samples_leaf=4, min_samples_split=10, n_estimators=600;, score=0.868 total time=   0.8s\n",
      "[CV 1/5] END criterion=absolute_error, max_depth=560, max_features=sqrt, min_samples_leaf=8, min_samples_split=4, n_estimators=1800;, score=0.846 total time=   6.8s\n",
      "[CV 5/5] END criterion=poisson, max_depth=560, max_features=sqrt, min_samples_leaf=8, min_samples_split=5, n_estimators=400;, score=0.856 total time=   0.7s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=10, max_features=sqrt, min_samples_leaf=6, min_samples_split=2, n_estimators=1200;, score=0.884 total time=   2.0s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=10, max_features=sqrt, min_samples_leaf=6, min_samples_split=2, n_estimators=1200;, score=0.863 total time=   1.7s\n",
      "[CV 2/5] END criterion=absolute_error, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=400;, score=0.907 total time=   2.1s\n",
      "[CV 3/5] END criterion=absolute_error, max_depth=450, max_features=sqrt, min_samples_leaf=4, min_samples_split=14, n_estimators=400;, score=0.902 total time=   1.6s\n",
      "[CV 4/5] END criterion=absolute_error, max_depth=230, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1800;, score=0.890 total time=  10.2s\n",
      "[CV 4/5] END criterion=poisson, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=1400;, score=0.876 total time=   1.9s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=780, max_features=sqrt, min_samples_leaf=8, min_samples_split=2, n_estimators=1800;, score=0.854 total time=   2.2s\n",
      "[CV 1/5] END criterion=absolute_error, max_depth=340, max_features=sqrt, min_samples_leaf=6, min_samples_split=4, n_estimators=1400;, score=0.851 total time=   5.5s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=450, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=1800;, score=0.908 total time=   2.4s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=560, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1200;, score=0.891 total time=   2.0s\n",
      "[CV 2/5] END degree=1, gamma=scale, kernel=linear, max_iter=100, tol=0.01;, score=-0.177 total time=   0.0s\n",
      "[CV 3/5] END degree=1, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-0.174 total time=   0.0s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=450, max_features=sqrt, min_samples_leaf=6, min_samples_split=5, n_estimators=600;, score=0.882 total time=   0.8s\n",
      "[CV 1/5] END criterion=poisson, max_depth=1000, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=1200;, score=0.876 total time=   1.9s\n",
      "[CV 2/5] END criterion=poisson, max_depth=780, max_features=log2, min_samples_leaf=2, min_samples_split=14, n_estimators=2000;, score=0.894 total time=   2.9s\n",
      "[CV 4/5] END criterion=poisson, max_depth=1000, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=800;, score=0.888 total time=   1.2s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=670, max_features=sqrt, min_samples_leaf=6, min_samples_split=2, n_estimators=1600;, score=0.863 total time=   2.1s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=890, max_features=log2, min_samples_leaf=1, min_samples_split=14, n_estimators=2000;, score=0.875 total time=   3.3s\n",
      "[CV 3/5] END criterion=absolute_error, max_depth=340, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=1400;, score=0.905 total time=   5.9s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=230, max_features=log2, min_samples_leaf=2, min_samples_split=4, n_estimators=1200;, score=0.917 total time=   1.8s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=670, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=800;, score=0.879 total time=   1.1s\n",
      "[CV 1/5] END criterion=poisson, max_depth=230, max_features=sqrt, min_samples_leaf=8, min_samples_split=3, n_estimators=1600;, score=0.855 total time=   2.1s\n",
      "[CV 4/5] END criterion=poisson, max_depth=230, max_features=sqrt, min_samples_leaf=8, min_samples_split=3, n_estimators=1600;, score=0.860 total time=   2.1s\n",
      "[CV 5/5] END criterion=absolute_error, max_depth=1000, max_features=sqrt, min_samples_leaf=8, min_samples_split=3, n_estimators=800;, score=0.848 total time=   3.4s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=230, max_features=sqrt, min_samples_leaf=6, min_samples_split=5, n_estimators=1600;, score=0.861 total time=   2.0s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=230, max_features=sqrt, min_samples_leaf=6, min_samples_split=5, n_estimators=1600;, score=0.883 total time=   2.0s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=230, max_features=sqrt, min_samples_leaf=6, min_samples_split=5, n_estimators=1600;, score=0.868 total time=   2.0s\n",
      "[CV 4/5] END criterion=poisson, max_depth=340, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=1600;, score=0.877 total time=   2.3s\n",
      "[CV 5/5] END criterion=absolute_error, max_depth=340, max_features=sqrt, min_samples_leaf=6, min_samples_split=2, n_estimators=2000;, score=0.860 total time=   7.6s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=120, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.915 total time=   0.3s\n",
      "[CV 1/5] END criterion=absolute_error, max_depth=120, max_features=sqrt, min_samples_leaf=8, min_samples_split=5, n_estimators=800;, score=0.846 total time=   3.0s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=1000, max_features=sqrt, min_samples_leaf=8, min_samples_split=5, n_estimators=1200;, score=0.895 total time=   1.5s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=400;, score=0.909 total time=   0.5s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=780, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1600;, score=0.883 total time=   2.6s\n",
      "[CV 2/5] END criterion=absolute_error, max_depth=1000, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=1000;, score=0.890 total time=   4.1s\n",
      "[CV 3/5] END criterion=absolute_error, max_depth=230, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=2000;, score=0.905 total time=   8.2s\n",
      "[CV 3/5] END criterion=poisson, max_depth=890, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=800;, score=0.919 total time=   1.3s\n",
      "[CV 4/5] END criterion=poisson, max_depth=890, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=1600;, score=0.877 total time=   2.4s\n",
      "[CV 5/5] END criterion=absolute_error, max_depth=450, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=2000;, score=0.869 total time=   9.7s\n",
      "[CV 1/5] END criterion=poisson, max_depth=560, max_features=sqrt, min_samples_leaf=8, min_samples_split=5, n_estimators=400;, score=0.855 total time=   0.5s\n",
      "[CV 2/5] END criterion=poisson, max_depth=560, max_features=sqrt, min_samples_leaf=8, min_samples_split=5, n_estimators=400;, score=0.870 total time=   0.5s\n",
      "[CV 3/5] END criterion=poisson, max_depth=560, max_features=sqrt, min_samples_leaf=8, min_samples_split=5, n_estimators=400;, score=0.896 total time=   0.5s\n",
      "[CV 4/5] END criterion=poisson, max_depth=560, max_features=sqrt, min_samples_leaf=8, min_samples_split=5, n_estimators=400;, score=0.859 total time=   0.5s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=10, max_features=sqrt, min_samples_leaf=6, min_samples_split=2, n_estimators=1200;, score=0.860 total time=   1.6s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=10, max_features=sqrt, min_samples_leaf=6, min_samples_split=2, n_estimators=1200;, score=0.868 total time=   1.5s\n",
      "[CV 3/5] END criterion=poisson, max_depth=560, max_features=sqrt, min_samples_leaf=8, min_samples_split=2, n_estimators=800;, score=0.893 total time=   1.4s\n",
      "[CV 4/5] END criterion=absolute_error, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=400;, score=0.886 total time=   2.0s\n",
      "[CV 5/5] END criterion=absolute_error, max_depth=450, max_features=sqrt, min_samples_leaf=4, min_samples_split=14, n_estimators=400;, score=0.863 total time=   1.6s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=890, max_features=log2, min_samples_leaf=4, min_samples_split=14, n_estimators=1400;, score=0.863 total time=   1.8s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=890, max_features=log2, min_samples_leaf=4, min_samples_split=14, n_estimators=1400;, score=0.888 total time=   2.0s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=890, max_features=log2, min_samples_leaf=4, min_samples_split=14, n_estimators=1400;, score=0.905 total time=   1.8s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=890, max_features=log2, min_samples_leaf=4, min_samples_split=14, n_estimators=1400;, score=0.869 total time=   2.0s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=890, max_features=log2, min_samples_leaf=4, min_samples_split=14, n_estimators=1400;, score=0.866 total time=   1.9s\n",
      "[CV 3/5] END criterion=poisson, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=1400;, score=0.907 total time=   1.9s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=780, max_features=sqrt, min_samples_leaf=8, min_samples_split=2, n_estimators=1800;, score=0.859 total time=   2.2s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=780, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=1400;, score=0.889 total time=   2.2s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=450, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=1800;, score=0.865 total time=   2.4s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=450, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=1800;, score=0.891 total time=   2.3s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=560, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1200;, score=0.912 total time=   2.0s\n",
      "[CV 1/5] END degree=1, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-0.333 total time=   0.0s\n",
      "[CV 2/5] END degree=1, gamma=scale, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.014 total time=   0.0s\n",
      "[CV 3/5] END degree=1, gamma=auto, kernel=linear, max_iter=100, tol=0.01;, score=-0.174 total time=   0.0s\n",
      "[CV 4/5] END degree=1, gamma=auto, kernel=linear, max_iter=100, tol=0.01;, score=-0.417 total time=   0.0s\n",
      "[CV 3/5] END degree=1, gamma=auto, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.174 total time=   0.0s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=1000, max_features=log2, min_samples_leaf=6, min_samples_split=5, n_estimators=600;, score=0.867 total time=   0.8s\n",
      "[CV 2/5] END criterion=absolute_error, max_depth=890, max_features=log2, min_samples_leaf=8, min_samples_split=14, n_estimators=1000;, score=0.865 total time=   3.7s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=560, max_features=log2, min_samples_leaf=8, min_samples_split=3, n_estimators=1400;, score=0.893 total time=   1.8s\n",
      "[CV 4/5] END criterion=absolute_error, max_depth=450, max_features=log2, min_samples_leaf=4, min_samples_split=3, n_estimators=1800;, score=0.870 total time=   7.8s\n",
      "[CV 1/5] END criterion=absolute_error, max_depth=780, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=1600;, score=0.860 total time=   7.0s\n",
      "[CV 3/5] END criterion=absolute_error, max_depth=450, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=600;, score=0.912 total time=   2.7s\n",
      "[CV 4/5] END criterion=absolute_error, max_depth=780, max_features=log2, min_samples_leaf=1, min_samples_split=14, n_estimators=1200;, score=0.875 total time=   5.5s\n",
      "[CV 1/5] END criterion=absolute_error, max_depth=450, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=800;, score=0.874 total time=   4.2s\n",
      "[CV 2/5] END criterion=absolute_error, max_depth=780, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=800;, score=0.911 total time=   4.1s\n",
      "[CV 3/5] END criterion=absolute_error, max_depth=890, max_features=sqrt, min_samples_leaf=6, min_samples_split=5, n_estimators=1400;, score=0.898 total time=   5.3s\n",
      "[CV 5/5] END criterion=poisson, max_depth=1000, max_features=log2, min_samples_leaf=6, min_samples_split=3, n_estimators=1600;, score=0.863 total time=   2.1s\n",
      "[CV 3/5] END criterion=poisson, max_depth=1000, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=1200;, score=0.918 total time=   1.9s\n",
      "[CV 4/5] END criterion=poisson, max_depth=780, max_features=log2, min_samples_leaf=2, min_samples_split=14, n_estimators=2000;, score=0.876 total time=   2.8s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=670, max_features=sqrt, min_samples_leaf=6, min_samples_split=2, n_estimators=1600;, score=0.881 total time=   2.0s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=890, max_features=log2, min_samples_leaf=1, min_samples_split=14, n_estimators=2000;, score=0.910 total time=   2.7s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=10, max_features=sqrt, min_samples_leaf=6, min_samples_split=4, n_estimators=1400;, score=0.868 total time=   1.8s\n",
      "[CV 5/5] END criterion=absolute_error, max_depth=340, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=1400;, score=0.869 total time=   5.9s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=230, max_features=log2, min_samples_leaf=2, min_samples_split=4, n_estimators=1200;, score=0.887 total time=   1.8s\n",
      "[CV 1/5] END criterion=poisson, max_depth=1000, max_features=log2, min_samples_leaf=6, min_samples_split=14, n_estimators=2000;, score=0.860 total time=   2.6s\n",
      "[CV 2/5] END criterion=poisson, max_depth=230, max_features=sqrt, min_samples_leaf=8, min_samples_split=3, n_estimators=1600;, score=0.873 total time=   2.1s\n",
      "[CV 2/5] END criterion=absolute_error, max_depth=1000, max_features=sqrt, min_samples_leaf=8, min_samples_split=3, n_estimators=800;, score=0.862 total time=   3.3s\n",
      "[CV 5/5] END criterion=absolute_error, max_depth=890, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1200;, score=0.890 total time=   6.7s\n",
      "[CV 5/5] END criterion=poisson, max_depth=340, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=1600;, score=0.871 total time=   2.3s\n",
      "[CV 1/5] END criterion=absolute_error, max_depth=670, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=600;, score=0.871 total time=   2.8s\n",
      "[CV 2/5] END criterion=absolute_error, max_depth=670, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=600;, score=0.905 total time=   2.7s\n",
      "[CV 3/5] END criterion=absolute_error, max_depth=670, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=600;, score=0.914 total time=   2.8s\n",
      "[CV 4/5] END criterion=absolute_error, max_depth=120, max_features=sqrt, min_samples_leaf=8, min_samples_split=5, n_estimators=800;, score=0.851 total time=   3.0s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=400;, score=0.864 total time=   0.5s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=400;, score=0.891 total time=   0.5s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=780, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1600;, score=0.906 total time=   2.6s\n",
      "[CV 1/5] END criterion=absolute_error, max_depth=1000, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=1000;, score=0.859 total time=   4.1s\n",
      "[CV 2/5] END criterion=absolute_error, max_depth=230, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=2000;, score=0.889 total time=   8.0s\n",
      "[CV 2/5] END criterion=poisson, max_depth=890, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=800;, score=0.910 total time=   1.3s\n",
      "[CV 1/5] END criterion=poisson, max_depth=890, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=1600;, score=0.867 total time=   2.3s\n",
      "[CV 2/5] END criterion=absolute_error, max_depth=450, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=2000;, score=0.887 total time=   8.6s\n",
      "[CV 4/5] END criterion=absolute_error, max_depth=560, max_features=sqrt, min_samples_leaf=8, min_samples_split=4, n_estimators=1800;, score=0.849 total time=   6.8s\n",
      "[CV 2/5] END criterion=poisson, max_depth=560, max_features=sqrt, min_samples_leaf=8, min_samples_split=2, n_estimators=800;, score=0.873 total time=   1.6s\n",
      "[CV 3/5] END criterion=absolute_error, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=400;, score=0.915 total time=   2.1s\n",
      "[CV 1/5] END criterion=absolute_error, max_depth=230, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1800;, score=0.876 total time=  10.1s\n",
      "[CV 1/5] END criterion=poisson, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=1400;, score=0.867 total time=   1.9s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=780, max_features=sqrt, min_samples_leaf=8, min_samples_split=2, n_estimators=1800;, score=0.855 total time=   2.2s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=780, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=1400;, score=0.913 total time=   2.2s\n",
      "[CV 3/5] END criterion=absolute_error, max_depth=340, max_features=sqrt, min_samples_leaf=6, min_samples_split=4, n_estimators=1400;, score=0.897 total time=   5.4s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=450, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=1800;, score=0.869 total time=   2.5s\n",
      "[CV 1/5] END degree=1, gamma=scale, kernel=linear, max_iter=100, tol=0.01;, score=-0.334 total time=   0.0s\n",
      "[CV 2/5] END degree=1, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-0.177 total time=   0.0s\n",
      "[CV 1/5] END degree=1, gamma=scale, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.001 total time=   0.0s\n",
      "[CV 1/5] END degree=1, gamma=auto, kernel=linear, max_iter=100, tol=0.01;, score=-0.334 total time=   0.0s\n",
      "[CV 2/5] END degree=1, gamma=auto, kernel=linear, max_iter=100, tol=0.01;, score=-0.177 total time=   0.0s\n",
      "[CV 1/5] END degree=1, gamma=auto, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.330 total time=   0.0s\n",
      "[CV 2/5] END degree=1, gamma=auto, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.177 total time=   0.0s\n",
      "[CV 4/5] END degree=3, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-0.197 total time=   0.0s\n",
      "[CV 5/5] END degree=3, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-0.045 total time=   0.0s\n",
      "[CV 4/5] END criterion=poisson, max_depth=1000, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=1200;, score=0.890 total time=   1.9s\n",
      "[CV 5/5] END criterion=poisson, max_depth=780, max_features=log2, min_samples_leaf=2, min_samples_split=14, n_estimators=2000;, score=0.872 total time=   2.8s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=670, max_features=sqrt, min_samples_leaf=6, min_samples_split=2, n_estimators=1600;, score=0.902 total time=   2.0s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=890, max_features=log2, min_samples_leaf=1, min_samples_split=14, n_estimators=2000;, score=0.878 total time=   2.7s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=10, max_features=sqrt, min_samples_leaf=6, min_samples_split=4, n_estimators=1400;, score=0.861 total time=   1.8s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=450, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=400;, score=0.865 total time=   0.5s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=450, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=400;, score=0.891 total time=   0.5s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=450, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=400;, score=0.907 total time=   0.5s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=450, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=400;, score=0.878 total time=   0.6s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=450, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, n_estimators=400;, score=0.871 total time=   0.6s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=560, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=600;, score=0.867 total time=   0.8s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=560, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=600;, score=0.893 total time=   0.8s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=560, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=600;, score=0.909 total time=   0.8s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=560, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=600;, score=0.871 total time=   0.8s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=670, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=800;, score=0.871 total time=   1.1s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=670, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=800;, score=0.914 total time=   1.1s\n",
      "[CV 4/5] END criterion=poisson, max_depth=1000, max_features=log2, min_samples_leaf=6, min_samples_split=14, n_estimators=2000;, score=0.867 total time=   2.7s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=120, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=400;, score=0.861 total time=   0.5s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=120, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=400;, score=0.908 total time=   0.5s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=120, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=400;, score=0.870 total time=   0.5s\n",
      "[CV 4/5] END criterion=absolute_error, max_depth=1000, max_features=sqrt, min_samples_leaf=8, min_samples_split=3, n_estimators=800;, score=0.850 total time=   2.9s\n",
      "[CV 4/5] END criterion=absolute_error, max_depth=890, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1200;, score=0.890 total time=   6.7s\n",
      "[CV 2/5] END criterion=poisson, max_depth=340, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=1600;, score=0.894 total time=   2.2s\n",
      "[CV 3/5] END criterion=absolute_error, max_depth=340, max_features=sqrt, min_samples_leaf=6, min_samples_split=2, n_estimators=2000;, score=0.898 total time=   7.8s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=120, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.908 total time=   0.3s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=120, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200;, score=0.883 total time=   0.3s\n",
      "[CV 3/5] END criterion=absolute_error, max_depth=120, max_features=sqrt, min_samples_leaf=8, min_samples_split=5, n_estimators=800;, score=0.891 total time=   2.9s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=1000, max_features=sqrt, min_samples_leaf=8, min_samples_split=5, n_estimators=1200;, score=0.859 total time=   1.5s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=10, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=400;, score=0.870 total time=   0.5s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=120, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=1200;, score=0.873 total time=   1.7s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=120, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=1200;, score=0.907 total time=   1.8s\n",
      "[CV 3/5] END criterion=absolute_error, max_depth=1000, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=1000;, score=0.906 total time=   4.2s\n",
      "[CV 4/5] END criterion=absolute_error, max_depth=230, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=2000;, score=0.871 total time=   8.1s\n",
      "[CV 2/5] END criterion=poisson, max_depth=890, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=1600;, score=0.893 total time=   2.2s\n",
      "[CV 3/5] END criterion=absolute_error, max_depth=450, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=2000;, score=0.906 total time=   8.4s\n",
      "[CV 3/5] END criterion=absolute_error, max_depth=560, max_features=sqrt, min_samples_leaf=8, min_samples_split=4, n_estimators=1800;, score=0.890 total time=   7.6s\n",
      "[CV 4/5] END criterion=poisson, max_depth=560, max_features=sqrt, min_samples_leaf=8, min_samples_split=2, n_estimators=800;, score=0.860 total time=   1.2s\n",
      "[CV 1/5] END criterion=absolute_error, max_depth=450, max_features=sqrt, min_samples_leaf=4, min_samples_split=14, n_estimators=400;, score=0.856 total time=   1.6s\n",
      "[CV 4/5] END criterion=absolute_error, max_depth=450, max_features=sqrt, min_samples_leaf=4, min_samples_split=14, n_estimators=400;, score=0.864 total time=   1.6s\n",
      "[CV 5/5] END criterion=absolute_error, max_depth=230, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1800;, score=0.892 total time=  10.8s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=780, max_features=sqrt, min_samples_leaf=8, min_samples_split=2, n_estimators=1800;, score=0.873 total time=   2.2s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=780, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=1400;, score=0.918 total time=   2.1s\n",
      "[CV 4/5] END criterion=absolute_error, max_depth=340, max_features=sqrt, min_samples_leaf=6, min_samples_split=4, n_estimators=1400;, score=0.857 total time=   5.4s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=560, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1200;, score=0.875 total time=   1.9s\n",
      "[CV 4/5] END degree=1, gamma=scale, kernel=linear, max_iter=100, tol=0.01;, score=-0.417 total time=   0.0s\n",
      "[CV 3/5] END degree=1, gamma=scale, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.009 total time=   0.0s\n",
      "[CV 4/5] END degree=1, gamma=scale, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.021 total time=   0.0s\n",
      "[CV 2/5] END degree=1, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.177 total time=   0.0s\n",
      "[CV 3/5] END degree=1, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.174 total time=   0.0s\n",
      "[CV 4/5] END degree=1, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.417 total time=   0.0s\n",
      "[CV 5/5] END degree=1, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.214 total time=   0.0s\n",
      "[CV 4/5] END degree=3, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.419 total time=   0.0s\n",
      "[CV 5/5] END degree=3, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.214 total time=   0.0s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=450, max_features=sqrt, min_samples_leaf=6, min_samples_split=5, n_estimators=600;, score=0.859 total time=   0.8s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=450, max_features=sqrt, min_samples_leaf=6, min_samples_split=5, n_estimators=600;, score=0.863 total time=   0.8s\n",
      "[CV 1/5] END criterion=poisson, max_depth=780, max_features=log2, min_samples_leaf=2, min_samples_split=14, n_estimators=2000;, score=0.868 total time=   2.8s\n",
      "[CV 1/5] END criterion=poisson, max_depth=1000, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=800;, score=0.873 total time=   1.3s\n",
      "[CV 3/5] END criterion=poisson, max_depth=1000, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=800;, score=0.915 total time=   1.2s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=670, max_features=sqrt, min_samples_leaf=6, min_samples_split=2, n_estimators=1600;, score=0.869 total time=   2.1s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=10, max_features=sqrt, min_samples_leaf=6, min_samples_split=4, n_estimators=1400;, score=0.860 total time=   1.9s\n",
      "[CV 1/5] END criterion=absolute_error, max_depth=340, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=1400;, score=0.860 total time=   6.0s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=560, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, n_estimators=600;, score=0.877 total time=   0.8s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=230, max_features=log2, min_samples_leaf=2, min_samples_split=4, n_estimators=1200;, score=0.873 total time=   1.7s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=670, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=800;, score=0.902 total time=   1.1s\n",
      "[CV 3/5] END criterion=poisson, max_depth=1000, max_features=log2, min_samples_leaf=6, min_samples_split=14, n_estimators=2000;, score=0.900 total time=   2.7s\n",
      "[CV 5/5] END criterion=poisson, max_depth=230, max_features=sqrt, min_samples_leaf=8, min_samples_split=3, n_estimators=1600;, score=0.856 total time=   2.1s\n",
      "[CV 1/5] END criterion=absolute_error, max_depth=890, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1200;, score=0.876 total time=   6.8s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=230, max_features=sqrt, min_samples_leaf=6, min_samples_split=5, n_estimators=1600;, score=0.901 total time=   2.0s\n",
      "[CV 1/5] END criterion=poisson, max_depth=340, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=1600;, score=0.866 total time=   2.3s\n",
      "[CV 2/5] END criterion=absolute_error, max_depth=340, max_features=sqrt, min_samples_leaf=6, min_samples_split=2, n_estimators=2000;, score=0.876 total time=   7.6s\n",
      "[CV 5/5] END criterion=absolute_error, max_depth=670, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=600;, score=0.880 total time=   2.8s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=1000, max_features=sqrt, min_samples_leaf=8, min_samples_split=5, n_estimators=1200;, score=0.856 total time=   1.5s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=1000, max_features=sqrt, min_samples_leaf=8, min_samples_split=5, n_estimators=1200;, score=0.855 total time=   1.5s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=780, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1600;, score=0.915 total time=   2.2s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=120, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=1200;, score=0.887 total time=   1.7s\n",
      "[CV 5/5] END criterion=absolute_error, max_depth=1000, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=1000;, score=0.870 total time=   4.2s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=120, max_features=log2, min_samples_leaf=2, min_samples_split=14, n_estimators=1400;, score=0.866 total time=   1.8s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=120, max_features=log2, min_samples_leaf=2, min_samples_split=14, n_estimators=1400;, score=0.893 total time=   1.8s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=120, max_features=log2, min_samples_leaf=2, min_samples_split=14, n_estimators=1400;, score=0.908 total time=   1.8s\n",
      "[CV 5/5] END criterion=squared_error, max_depth=120, max_features=log2, min_samples_leaf=2, min_samples_split=14, n_estimators=1400;, score=0.871 total time=   1.8s\n",
      "[CV 5/5] END criterion=poisson, max_depth=890, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=800;, score=0.890 total time=   1.3s\n",
      "[CV 1/5] END criterion=absolute_error, max_depth=450, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=2000;, score=0.859 total time=   8.5s\n",
      "[CV 2/5] END criterion=absolute_error, max_depth=560, max_features=sqrt, min_samples_leaf=8, min_samples_split=4, n_estimators=1800;, score=0.866 total time=   6.7s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=10, max_features=sqrt, min_samples_leaf=6, min_samples_split=2, n_estimators=1200;, score=0.901 total time=   1.6s\n",
      "[CV 1/5] END criterion=poisson, max_depth=560, max_features=sqrt, min_samples_leaf=8, min_samples_split=2, n_estimators=800;, score=0.855 total time=   1.1s\n",
      "[CV 1/5] END criterion=absolute_error, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=400;, score=0.872 total time=   2.1s\n",
      "[CV 2/5] END criterion=absolute_error, max_depth=450, max_features=sqrt, min_samples_leaf=4, min_samples_split=14, n_estimators=400;, score=0.883 total time=   1.6s\n",
      "[CV 3/5] END criterion=absolute_error, max_depth=230, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1800;, score=0.918 total time=  10.6s\n",
      "[CV 5/5] END criterion=poisson, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=1400;, score=0.873 total time=   2.0s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=780, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=1400;, score=0.875 total time=   2.2s\n",
      "[CV 2/5] END criterion=absolute_error, max_depth=340, max_features=sqrt, min_samples_leaf=6, min_samples_split=4, n_estimators=1400;, score=0.879 total time=   5.3s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=450, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=1800;, score=0.875 total time=   2.3s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=560, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1200;, score=0.891 total time=   2.0s\n",
      "[CV 3/5] END degree=1, gamma=scale, kernel=linear, max_iter=100, tol=0.01;, score=-0.174 total time=   0.0s\n",
      "[CV 4/5] END degree=1, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-0.417 total time=   0.0s\n",
      "[CV 5/5] END degree=1, gamma=scale, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.007 total time=   0.0s\n",
      "[CV 1/5] END degree=1, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-0.333 total time=   0.0s\n",
      "[CV 2/5] END degree=1, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.177 total time=   0.0s\n",
      "[CV 3/5] END degree=1, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.174 total time=   0.0s\n",
      "[CV 1/5] END degree=3, gamma=scale, kernel=linear, max_iter=100, tol=0.01;, score=-0.334 total time=   0.0s\n",
      "[CV 2/5] END degree=3, gamma=scale, kernel=linear, max_iter=100, tol=0.01;, score=-0.177 total time=   0.0s\n",
      "[CV 3/5] END degree=3, gamma=scale, kernel=linear, max_iter=100, tol=0.01;, score=-0.174 total time=   0.0s\n",
      "[CV 4/5] END degree=3, gamma=scale, kernel=linear, max_iter=100, tol=0.01;, score=-0.417 total time=   0.0s\n",
      "[CV 1/5] END degree=3, gamma=auto, kernel=linear, max_iter=100, tol=0.01;, score=-0.334 total time=   0.0s\n",
      "[CV 2/5] END degree=3, gamma=auto, kernel=linear, max_iter=100, tol=0.01;, score=-0.177 total time=   0.0s\n",
      "[CV 3/5] END degree=3, gamma=auto, kernel=linear, max_iter=100, tol=0.01;, score=-0.174 total time=   0.0s\n",
      "[CV 4/5] END degree=3, gamma=auto, kernel=linear, max_iter=100, tol=0.01;, score=-0.417 total time=   0.0s\n",
      "[CV 1/5] END degree=5, gamma=scale, kernel=linear, max_iter=100, tol=0.01;, score=-0.334 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END criterion=absolute_error, max_depth=890, max_features=sqrt, min_samples_leaf=6, min_samples_split=5, n_estimators=1400;, score=0.860 total time=   5.4s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=450, max_features=sqrt, min_samples_leaf=6, min_samples_split=5, n_estimators=600;, score=0.901 total time=   0.8s\n",
      "[CV 2/5] END criterion=poisson, max_depth=1000, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=1200;, score=0.913 total time=   1.9s\n",
      "[CV 3/5] END criterion=poisson, max_depth=780, max_features=log2, min_samples_leaf=2, min_samples_split=14, n_estimators=2000;, score=0.908 total time=   2.8s\n",
      "[CV 5/5] END criterion=poisson, max_depth=1000, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, n_estimators=800;, score=0.885 total time=   1.2s\n",
      "[CV 1/5] END criterion=friedman_mse, max_depth=890, max_features=log2, min_samples_leaf=1, min_samples_split=14, n_estimators=2000;, score=0.869 total time=   3.0s\n",
      "[CV 2/5] END criterion=friedman_mse, max_depth=10, max_features=sqrt, min_samples_leaf=6, min_samples_split=4, n_estimators=1400;, score=0.883 total time=   2.2s\n",
      "[CV 2/5] END criterion=absolute_error, max_depth=340, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=1400;, score=0.890 total time=   5.8s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=230, max_features=log2, min_samples_leaf=2, min_samples_split=4, n_estimators=1200;, score=0.907 total time=   1.8s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=670, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=800;, score=0.884 total time=   1.1s\n",
      "[CV 5/5] END criterion=poisson, max_depth=1000, max_features=log2, min_samples_leaf=6, min_samples_split=14, n_estimators=2000;, score=0.861 total time=   2.7s\n",
      "[CV 2/5] END criterion=squared_error, max_depth=120, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=400;, score=0.893 total time=   0.5s\n",
      "[CV 4/5] END criterion=squared_error, max_depth=120, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=400;, score=0.879 total time=   0.5s\n",
      "[CV 1/5] END criterion=absolute_error, max_depth=1000, max_features=sqrt, min_samples_leaf=8, min_samples_split=3, n_estimators=800;, score=0.846 total time=   2.9s\n",
      "[CV 2/5] END criterion=absolute_error, max_depth=890, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1200;, score=0.912 total time=   6.6s\n",
      "[CV 5/5] END criterion=friedman_mse, max_depth=230, max_features=sqrt, min_samples_leaf=6, min_samples_split=5, n_estimators=1600;, score=0.862 total time=   2.0s\n",
      "[CV 1/5] END criterion=absolute_error, max_depth=340, max_features=sqrt, min_samples_leaf=6, min_samples_split=2, n_estimators=2000;, score=0.851 total time=   7.7s\n",
      "[CV 4/5] END criterion=absolute_error, max_depth=670, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=600;, score=0.882 total time=   2.9s\n",
      "[CV 5/5] END criterion=absolute_error, max_depth=120, max_features=sqrt, min_samples_leaf=8, min_samples_split=5, n_estimators=800;, score=0.850 total time=   2.9s\n",
      "[CV 1/5] END criterion=squared_error, max_depth=780, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=1600;, score=0.873 total time=   2.3s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=120, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=1200;, score=0.916 total time=   1.8s\n",
      "[CV 4/5] END criterion=absolute_error, max_depth=1000, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, n_estimators=1000;, score=0.872 total time=   4.2s\n",
      "[CV 5/5] END criterion=absolute_error, max_depth=230, max_features=log2, min_samples_leaf=4, min_samples_split=2, n_estimators=2000;, score=0.870 total time=   8.3s\n",
      "[CV 3/5] END criterion=poisson, max_depth=890, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=1600;, score=0.908 total time=   2.3s\n",
      "[CV 4/5] END criterion=absolute_error, max_depth=450, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, n_estimators=2000;, score=0.870 total time=   9.2s\n",
      "[CV 5/5] END criterion=absolute_error, max_depth=560, max_features=sqrt, min_samples_leaf=8, min_samples_split=4, n_estimators=1800;, score=0.851 total time=   6.7s\n",
      "[CV 5/5] END criterion=poisson, max_depth=560, max_features=sqrt, min_samples_leaf=8, min_samples_split=2, n_estimators=800;, score=0.855 total time=   1.1s\n",
      "[CV 5/5] END criterion=absolute_error, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=400;, score=0.885 total time=   2.0s\n",
      "[CV 2/5] END criterion=absolute_error, max_depth=230, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1800;, score=0.913 total time=  10.7s\n",
      "[CV 2/5] END criterion=poisson, max_depth=10, max_features=log2, min_samples_leaf=4, min_samples_split=4, n_estimators=1400;, score=0.892 total time=   2.0s\n",
      "[CV 3/5] END criterion=friedman_mse, max_depth=780, max_features=sqrt, min_samples_leaf=8, min_samples_split=2, n_estimators=1800;, score=0.894 total time=   2.2s\n",
      "[CV 4/5] END criterion=friedman_mse, max_depth=780, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=1400;, score=0.891 total time=   2.2s\n",
      "[CV 5/5] END criterion=absolute_error, max_depth=340, max_features=sqrt, min_samples_leaf=6, min_samples_split=4, n_estimators=1400;, score=0.856 total time=   5.5s\n",
      "[CV 3/5] END criterion=squared_error, max_depth=560, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1200;, score=0.918 total time=   2.0s\n",
      "[CV 5/5] END degree=1, gamma=scale, kernel=linear, max_iter=100, tol=0.01;, score=-0.214 total time=   0.0s\n",
      "[CV 5/5] END degree=1, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-0.213 total time=   0.0s\n",
      "[CV 2/5] END degree=1, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-0.177 total time=   0.0s\n",
      "[CV 3/5] END degree=1, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-0.174 total time=   0.0s\n",
      "[CV 5/5] END degree=1, gamma=auto, kernel=linear, max_iter=100, tol=0.01;, score=-0.214 total time=   0.0s\n",
      "[CV 1/5] END degree=1, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.334 total time=   0.0s\n",
      "[CV 5/5] END degree=1, gamma=auto, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.214 total time=   0.0s\n",
      "[CV 1/5] END degree=1, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.334 total time=   0.0s\n",
      "[CV 2/5] END degree=3, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-0.023 total time=   0.0s\n",
      "[CV 3/5] END degree=3, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=0.029 total time=   0.0s\n",
      "[CV 4/5] END degree=3, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-0.197 total time=   0.0s\n",
      "[CV 5/5] END degree=3, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-0.045 total time=   0.0s\n",
      "[CV 3/5] END degree=3, gamma=auto, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.174 total time=   0.0s\n",
      "[CV 4/5] END degree=3, gamma=auto, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.417 total time=   0.0s\n",
      "[CV 5/5] END degree=3, gamma=auto, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.214 total time=   0.0s\n",
      "[CV 1/5] END degree=3, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.334 total time=   0.0s\n",
      "[CV 5/5] END degree=7, gamma=scale, kernel=linear, max_iter=100, tol=0.01;, score=-0.214 total time=   0.0s\n",
      "[CV 1/5] END degree=7, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-503.230 total time=   0.0s\n",
      "[CV 2/5] END degree=7, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-1699.664 total time=   0.0s\n",
      "[CV 3/5] END degree=7, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-413.756 total time=   0.0s\n",
      "[CV 4/5] END degree=7, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-1994.552 total time=   0.0s\n",
      "[CV 5/5] END degree=7, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-9.223 total time=   0.0s\n",
      "[CV 1/5] END degree=7, gamma=scale, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.001 total time=   0.0s\n",
      "[CV 2/5] END degree=7, gamma=scale, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.014 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR() RandomCV Best Params : {'tol': 0.01, 'max_iter': 100, 'kernel': 'poly', 'gamma': 'auto', 'degree': 20}\n",
      "SVR() RandomCV Score: -1.724446512385569e-05\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Final score is  -1.724446512385569e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:301: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "hyperparameter_tuning(algo=\"SVR()\",param_grid=random_grid,n_iter=100,cv=5,verbose=3,random_state=42,X_train=X_train.loc[:,list(selected_features)],Y_train=Y_train,X_test=X_test.loc[:,list(selected_features)],Y_test=Y_test,evaluation_metric=\"r2_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "13b4396d-9128-48b8-a9c7-71c9b61b533c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "d38c1368-978f-436c-b074-6b72d3bdf10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  62 out of  62 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:44] Features: 1/62 -- score: 0.7011779774549705[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  61 out of  61 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:44] Features: 2/62 -- score: 0.7602949981612708[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:44] Features: 3/62 -- score: 0.8270914779752742[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  59 out of  59 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:44] Features: 4/62 -- score: 0.8523049161504801[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  58 out of  58 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:44] Features: 5/62 -- score: 0.8669469937549803[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  57 out of  57 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:44] Features: 6/62 -- score: 0.8737958306173874[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  56 out of  56 | elapsed:    0.2s finished\n",
      "\n",
      "[2023-02-01 16:20:45] Features: 7/62 -- score: 0.8738940027698867[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  55 out of  55 | elapsed:    0.2s finished\n",
      "\n",
      "[2023-02-01 16:20:45] Features: 8/62 -- score: 0.8738940027698867[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  54 out of  54 | elapsed:    0.2s finished\n",
      "\n",
      "[2023-02-01 16:20:45] Features: 9/62 -- score: 0.8738203287217263[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  53 out of  53 | elapsed:    0.2s finished\n",
      "\n",
      "[2023-02-01 16:20:45] Features: 10/62 -- score: 0.8736940826394737[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  52 out of  52 | elapsed:    0.2s finished\n",
      "\n",
      "[2023-02-01 16:20:45] Features: 11/62 -- score: 0.8733612338212833[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  51 out of  51 | elapsed:    0.2s finished\n",
      "\n",
      "[2023-02-01 16:20:45] Features: 12/62 -- score: 0.8722824607959027[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.2s finished\n",
      "\n",
      "[2023-02-01 16:20:46] Features: 13/62 -- score: 0.8706864186171647[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  49 out of  49 | elapsed:    0.2s finished\n",
      "\n",
      "[2023-02-01 16:20:46] Features: 14/62 -- score: 0.8703138521370348[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  37 out of  48 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:    0.2s finished\n",
      "\n",
      "[2023-02-01 16:20:46] Features: 15/62 -- score: 0.8706495004890218[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  36 out of  47 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  47 out of  47 | elapsed:    0.2s finished\n",
      "\n",
      "[2023-02-01 16:20:46] Features: 16/62 -- score: 0.8701443296703477[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  46 out of  46 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:46] Features: 17/62 -- score: 0.8704017716090814[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:46] Features: 18/62 -- score: 0.8679724958745014[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 out of  44 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  44 out of  44 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:46] Features: 19/62 -- score: 0.8662078750339939[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  32 out of  43 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  43 out of  43 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:47] Features: 20/62 -- score: 0.8650984260148038[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 out of  42 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:47] Features: 21/62 -- score: 0.8635665487984362[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  41 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  41 out of  41 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:47] Features: 22/62 -- score: 0.8618572478932822[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:47] Features: 23/62 -- score: 0.8605796002728278[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  28 out of  39 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  39 out of  39 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:47] Features: 24/62 -- score: 0.8602072328563825[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  38 out of  38 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:47] Features: 25/62 -- score: 0.8586053213486948[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 out of  37 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  37 out of  37 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:47] Features: 26/62 -- score: 0.8573331092212154[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  36 out of  36 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:47] Features: 27/62 -- score: 0.8551635446717544[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  35 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  35 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:48] Features: 28/62 -- score: 0.8505551310634196[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  23 out of  34 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  34 out of  34 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:48] Features: 29/62 -- score: 0.849184635187132[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 out of  33 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:48] Features: 30/62 -- score: 0.8493897033013752[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  32 out of  32 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:48] Features: 31/62 -- score: 0.8523449877640565[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  31 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  31 out of  31 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:48] Features: 32/62 -- score: 0.853903932601027[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:48] Features: 33/62 -- score: 0.8526756880430273[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  29 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  29 out of  29 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:48] Features: 34/62 -- score: 0.8531372494873926[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  28 out of  28 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:48] Features: 35/62 -- score: 0.8551765529186252[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  27 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:48] Features: 36/62 -- score: 0.8572798489507895[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 out of  26 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:48] Features: 37/62 -- score: 0.8557715963838153[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  14 out of  25 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:48] Features: 38/62 -- score: 0.8589681009478254[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:48] Features: 39/62 -- score: 0.8581944239710925[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  23 out of  23 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:49] Features: 40/62 -- score: 0.8589619832028568[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  22 out of  22 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:49] Features: 41/62 -- score: 0.8601189186203089[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  21 out of  21 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  21 out of  21 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:49] Features: 42/62 -- score: 0.8596844618027966[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:49] Features: 43/62 -- score: 0.8581768247499266[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  19 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:49] Features: 44/62 -- score: 0.8585789581840064[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  18 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:49] Features: 45/62 -- score: 0.8589819367295961[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  17 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  17 out of  17 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:49] Features: 46/62 -- score: 0.8573198606952097[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  14 out of  16 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  16 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:49] Features: 47/62 -- score: 0.8558985341488385[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  15 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:49] Features: 48/62 -- score: 0.8532772386702655[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  14 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  14 out of  14 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:49] Features: 49/62 -- score: 0.8528562250924316[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of  13 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:49] Features: 50/62 -- score: 0.8514723502608931[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  12 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    0.0s finished\n",
      "\n",
      "[2023-02-01 16:20:49] Features: 51/62 -- score: 0.8514386520924322[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  11 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:49] Features: 52/62 -- score: 0.848512895161466[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "\n",
      "[2023-02-01 16:20:49] Features: 53/62 -- score: 0.8485701671325859[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "\n",
      "[2023-02-01 16:20:49] Features: 54/62 -- score: 0.8489798522332267[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   8 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.0s finished\n",
      "\n",
      "[2023-02-01 16:20:49] Features: 55/62 -- score: 0.8466354293085588[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "\n",
      "[2023-02-01 16:20:49] Features: 56/62 -- score: 0.841121675264889[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.0s finished\n",
      "\n",
      "[2023-02-01 16:20:49] Features: 57/62 -- score: 0.8417277249956584[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "\n",
      "[2023-02-01 16:20:50] Features: 58/62 -- score: 0.8409152355924603[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    0.0s finished\n",
      "\n",
      "[2023-02-01 16:20:50] Features: 59/62 -- score: 0.8462759554717433[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features ('OverallQual', 'YearBuilt', 'BsmtFinSF1', 'TotalBsmtSF', 'GrLivArea', 'Condition2', 'KitchenQual')\n",
      "Prediction using selected features using KNeighborsRegressor() is : 0.8712205629550169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "\n",
      "[2023-02-01 16:20:50] Features: 60/62 -- score: 0.842853820460655[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "\n",
      "[2023-02-01 16:20:50] Features: 61/62 -- score: 0.8437131950103266[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "\n",
      "[2023-02-01 16:20:50] Features: 62/62 -- score: 0.8332186315952939"
     ]
    }
   ],
   "source": [
    "selected_features=sf_selector(algo=\"KNeighborsRegressor()\",forward=True,floating=False,scoring=\"r2\",X_train=X_train,Y_train=Y_train,X_test=X_test,Y_test=Y_test,min_featues=3,cv=5,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "f799b445-697b-4da4-afec-a84a778c7fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'weights': ['uniform', 'distance'], 'n_neighbors': [5, 12, 19, 26, 33, 40, 47, 54, 61, 68, 75, 82, 89, 96, 103, 110, 117, 124, 131, 138, 145, 152, 159, 166, 173, 181, 188, 195, 202, 209, 216, 223, 230, 237, 244, 251, 258, 265, 272, 279, 286, 293, 300, 307, 314, 321, 328, 335, 342, 350], 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], 'leaf_size': [5, 6, 8, 10, 11, 13, 15, 16, 18, 20], 'p': [1, 2]}\n"
     ]
    }
   ],
   "source": [
    "weights=[\"uniform\", \"distance\"]\n",
    "n_neighbors = [int(x) for x in np.linspace(start = 5, stop = 350, num = 50)]\n",
    "algorithm= [\"auto\", \"ball_tree\",\"kd_tree\",\"brute\"]\n",
    "leaf_size=[int(x) for x in np.linspace(start = 5, stop = 20, num = 10)]\n",
    "p = [1,2]\n",
    "\n",
    "\n",
    "random_grid = {'weights': weights,\n",
    "               'n_neighbors': n_neighbors,\n",
    "               'algorithm': algorithm,\n",
    "               'leaf_size':leaf_size,\n",
    "               'p':p\n",
    "               }\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "443ff41c-96a7-4c43-950c-831d2159298f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "[CV 4/5] END degree=1, gamma=auto, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.417 total time=   0.0s\n",
      "[CV 3/5] END degree=3, gamma=scale, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.009 total time=   0.0s\n",
      "[CV 4/5] END degree=3, gamma=scale, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.021 total time=   0.0s\n",
      "[CV 5/5] END degree=3, gamma=scale, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.007 total time=   0.0s\n",
      "[CV 1/5] END degree=3, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-0.147 total time=   0.0s\n",
      "[CV 3/5] END degree=5, gamma=scale, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.009 total time=   0.0s\n",
      "[CV 4/5] END degree=5, gamma=scale, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.021 total time=   0.0s\n",
      "[CV 5/5] END degree=5, gamma=scale, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.007 total time=   0.0s\n",
      "[CV 1/5] END degree=5, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-1.654 total time=   0.0s\n",
      "[CV 2/5] END degree=5, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-1.406 total time=   0.0s\n",
      "[CV 3/5] END degree=5, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-1.335 total time=   0.0s\n",
      "[CV 4/5] END degree=5, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=0.111 total time=   0.0s\n",
      "[CV 5/5] END degree=5, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-0.424 total time=   0.0s\n",
      "[CV 2/5] END degree=7, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.022 total time=   0.0s\n",
      "[CV 3/5] END degree=7, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.041 total time=   0.0s\n",
      "[CV 4/5] END degree=7, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END degree=7, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.015 total time=   0.0s\n",
      "[CV 1/5] END degree=9, gamma=scale, kernel=linear, max_iter=100, tol=0.01;, score=-0.334 total time=   0.0s\n",
      "[CV 2/5] END degree=9, gamma=scale, kernel=linear, max_iter=100, tol=0.01;, score=-0.177 total time=   0.0s\n",
      "[CV 3/5] END degree=9, gamma=scale, kernel=linear, max_iter=100, tol=0.01;, score=-0.174 total time=   0.0s\n",
      "[CV 4/5] END degree=9, gamma=scale, kernel=linear, max_iter=100, tol=0.01;, score=-0.417 total time=   0.0s\n",
      "[CV 2/5] END degree=9, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.005 total time=   0.0s\n",
      "[CV 3/5] END degree=9, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.008 total time=   0.0s\n",
      "[CV 4/5] END degree=9, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.081 total time=   0.0s\n",
      "[CV 5/5] END degree=9, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.007 total time=   0.0s\n",
      "[CV 1/5] END degree=11, gamma=scale, kernel=linear, max_iter=100, tol=0.01;, score=-0.334 total time=   0.0s\n",
      "[CV 2/5] END degree=11, gamma=scale, kernel=linear, max_iter=100, tol=0.01;, score=-0.177 total time=   0.0s\n",
      "[CV 3/5] END degree=11, gamma=scale, kernel=linear, max_iter=100, tol=0.01;, score=-0.174 total time=   0.0s\n",
      "[CV 4/5] END degree=11, gamma=scale, kernel=linear, max_iter=100, tol=0.01;, score=-0.417 total time=   0.0s\n",
      "[CV 5/5] END degree=11, gamma=scale, kernel=linear, max_iter=100, tol=0.01;, score=-0.214 total time=   0.0s\n",
      "[CV 1/5] END degree=11, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-14.455 total time=   0.0s\n",
      "[CV 2/5] END degree=11, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-10694.671 total time=   0.0s\n",
      "[CV 3/5] END degree=11, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-848.503 total time=   0.0s\n",
      "[CV 4/5] END degree=11, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-5753.945 total time=   0.0s\n",
      "[CV 5/5] END degree=11, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-17805187.564 total time=   0.0s\n",
      "[CV 1/5] END degree=11, gamma=scale, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.001 total time=   0.0s\n",
      "[CV 2/5] END degree=11, gamma=scale, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.014 total time=   0.0s\n",
      "[CV 3/5] END degree=15, gamma=scale, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.009 total time=   0.0s\n",
      "[CV 4/5] END degree=15, gamma=scale, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.021 total time=   0.0s\n",
      "[CV 5/5] END degree=15, gamma=scale, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.007 total time=   0.0s\n",
      "[CV 1/5] END degree=15, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-4.840 total time=   0.0s\n",
      "[CV 2/5] END degree=15, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-0.361 total time=   0.0s\n",
      "[CV 3/5] END degree=15, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-6.465 total time=   0.0s\n",
      "[CV 4/5] END degree=15, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-4.258 total time=   0.0s\n",
      "[CV 5/5] END degree=15, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-0.646 total time=   0.0s\n",
      "[CV 1/5] END degree=15, gamma=auto, kernel=linear, max_iter=100, tol=0.01;, score=-0.334 total time=   0.0s\n",
      "[CV 2/5] END degree=15, gamma=auto, kernel=linear, max_iter=100, tol=0.01;, score=-0.177 total time=   0.0s\n",
      "[CV 3/5] END degree=15, gamma=auto, kernel=linear, max_iter=100, tol=0.01;, score=-0.174 total time=   0.0s\n",
      "[CV 4/5] END degree=15, gamma=auto, kernel=linear, max_iter=100, tol=0.01;, score=-0.417 total time=   0.0s\n",
      "[CV 5/5] END degree=15, gamma=auto, kernel=linear, max_iter=100, tol=0.01;, score=-0.214 total time=   0.0s\n",
      "[CV 1/5] END degree=15, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.021 total time=   0.0s\n",
      "[CV 2/5] END degree=15, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.000 total time=   0.0s\n",
      "[CV 3/5] END degree=15, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.000 total time=   0.0s\n",
      "[CV 2/5] END degree=17, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.002 total time=   0.0s\n",
      "[CV 3/5] END degree=17, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.000 total time=   0.0s\n",
      "[CV 4/5] END degree=17, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.033 total time=   0.0s\n",
      "[CV 5/5] END degree=17, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.001 total time=   0.0s\n",
      "[CV 1/5] END degree=20, gamma=scale, kernel=linear, max_iter=100, tol=0.01;, score=-0.334 total time=   0.0s\n",
      "[CV 2/5] END degree=20, gamma=scale, kernel=linear, max_iter=100, tol=0.01;, score=-0.177 total time=   0.0s\n",
      "[CV 3/5] END degree=20, gamma=scale, kernel=linear, max_iter=100, tol=0.01;, score=-0.174 total time=   0.0s\n",
      "[CV 4/5] END degree=20, gamma=scale, kernel=linear, max_iter=100, tol=0.01;, score=-0.417 total time=   0.0s\n",
      "[CV 5/5] END degree=20, gamma=scale, kernel=linear, max_iter=100, tol=0.01;, score=-0.214 total time=   0.0s\n",
      "[CV 1/5] END degree=20, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-4.840 total time=   0.0s\n",
      "[CV 2/5] END degree=20, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-30668.340 total time=   0.0s\n",
      "[CV 3/5] END degree=20, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-6.465 total time=   0.0s\n",
      "[CV 4/5] END degree=20, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-4.258 total time=   0.0s\n",
      "[CV 5/5] END degree=20, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-13908.536 total time=   0.0s\n",
      "[CV 1/5] END degree=20, gamma=scale, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.001 total time=   0.0s\n",
      "[CV 2/5] END degree=20, gamma=scale, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.014 total time=   0.0s\n",
      "[CV 5/5] END degree=20, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.001 total time=   0.0s\n",
      "[CV 1/5] END algorithm=ball_tree, leaf_size=8, n_neighbors=321, p=2, weights=uniform;, score=0.495 total time=   0.0s\n",
      "[CV 3/5] END algorithm=auto, leaf_size=18, n_neighbors=110, p=2, weights=uniform;, score=0.767 total time=   0.0s\n",
      "[CV 4/5] END algorithm=auto, leaf_size=18, n_neighbors=110, p=2, weights=uniform;, score=0.721 total time=   0.0s\n",
      "[CV 5/5] END algorithm=kd_tree, leaf_size=6, n_neighbors=251, p=2, weights=distance;, score=0.675 total time=   0.0s\n",
      "[CV 1/5] END algorithm=ball_tree, leaf_size=10, n_neighbors=145, p=1, weights=uniform;, score=0.708 total time=   0.0s\n",
      "[CV 1/5] END degree=3, gamma=scale, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.001 total time=   0.0s\n",
      "[CV 2/5] END degree=3, gamma=scale, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.014 total time=   0.0s\n",
      "[CV 2/5] END degree=3, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.189 total time=   0.0s\n",
      "[CV 3/5] END degree=3, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.174 total time=   0.0s\n",
      "[CV 4/5] END degree=3, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.419 total time=   0.0s\n",
      "[CV 5/5] END degree=3, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.214 total time=   0.0s\n",
      "[CV 2/5] END degree=5, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.047 total time=   0.0s\n",
      "[CV 3/5] END degree=5, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.089 total time=   0.0s\n",
      "[CV 4/5] END degree=5, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.268 total time=   0.0s\n",
      "[CV 5/5] END degree=5, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.076 total time=   0.0s\n",
      "[CV 1/5] END degree=7, gamma=scale, kernel=linear, max_iter=100, tol=0.01;, score=-0.334 total time=   0.0s\n",
      "[CV 2/5] END degree=7, gamma=scale, kernel=linear, max_iter=100, tol=0.01;, score=-0.177 total time=   0.0s\n",
      "[CV 3/5] END degree=7, gamma=scale, kernel=linear, max_iter=100, tol=0.01;, score=-0.174 total time=   0.0s\n",
      "[CV 4/5] END degree=7, gamma=scale, kernel=linear, max_iter=100, tol=0.01;, score=-0.417 total time=   0.0s\n",
      "[CV 1/5] END degree=7, gamma=auto, kernel=linear, max_iter=100, tol=0.01;, score=-0.334 total time=   0.0s\n",
      "[CV 2/5] END degree=7, gamma=auto, kernel=linear, max_iter=100, tol=0.01;, score=-0.177 total time=   0.0s\n",
      "[CV 3/5] END degree=7, gamma=auto, kernel=linear, max_iter=100, tol=0.01;, score=-0.174 total time=   0.0s\n",
      "[CV 4/5] END degree=7, gamma=auto, kernel=linear, max_iter=100, tol=0.01;, score=-0.417 total time=   0.0s\n",
      "[CV 5/5] END degree=7, gamma=auto, kernel=linear, max_iter=100, tol=0.01;, score=-0.214 total time=   0.0s\n",
      "[CV 1/5] END degree=7, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.055 total time=   0.0s\n",
      "[CV 2/5] END degree=7, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.022 total time=   0.0s\n",
      "[CV 3/5] END degree=7, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.041 total time=   0.0s\n",
      "[CV 1/5] END degree=9, gamma=auto, kernel=linear, max_iter=100, tol=0.01;, score=-0.334 total time=   0.0s\n",
      "[CV 2/5] END degree=9, gamma=auto, kernel=linear, max_iter=100, tol=0.01;, score=-0.177 total time=   0.0s\n",
      "[CV 3/5] END degree=9, gamma=auto, kernel=linear, max_iter=100, tol=0.01;, score=-0.174 total time=   0.0s\n",
      "[CV 4/5] END degree=9, gamma=auto, kernel=linear, max_iter=100, tol=0.01;, score=-0.417 total time=   0.0s\n",
      "[CV 5/5] END degree=9, gamma=auto, kernel=linear, max_iter=100, tol=0.01;, score=-0.214 total time=   0.0s\n",
      "[CV 1/5] END degree=9, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.041 total time=   0.0s\n",
      "[CV 2/5] END degree=9, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.005 total time=   0.0s\n",
      "[CV 3/5] END degree=9, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.008 total time=   0.0s\n",
      "[CV 4/5] END degree=9, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.081 total time=   0.0s\n",
      "[CV 5/5] END degree=9, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.007 total time=   0.0s\n",
      "[CV 1/5] END degree=9, gamma=auto, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.330 total time=   0.0s\n",
      "[CV 2/5] END degree=9, gamma=auto, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.177 total time=   0.0s\n",
      "[CV 3/5] END degree=9, gamma=auto, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.174 total time=   0.0s\n",
      "[CV 4/5] END degree=9, gamma=auto, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.417 total time=   0.0s\n",
      "[CV 5/5] END degree=9, gamma=auto, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.214 total time=   0.0s\n",
      "[CV 1/5] END degree=9, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.041 total time=   0.0s\n",
      "[CV 2/5] END degree=13, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.000 total time=   0.0s\n",
      "[CV 3/5] END degree=13, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.000 total time=   0.0s\n",
      "[CV 4/5] END degree=13, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.039 total time=   0.0s\n",
      "[CV 5/5] END degree=13, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.000 total time=   0.0s\n",
      "[CV 1/5] END degree=15, gamma=scale, kernel=linear, max_iter=100, tol=0.01;, score=-0.334 total time=   0.0s\n",
      "[CV 2/5] END degree=15, gamma=scale, kernel=linear, max_iter=100, tol=0.01;, score=-0.177 total time=   0.0s\n",
      "[CV 3/5] END degree=15, gamma=scale, kernel=linear, max_iter=100, tol=0.01;, score=-0.174 total time=   0.0s\n",
      "[CV 4/5] END degree=15, gamma=scale, kernel=linear, max_iter=100, tol=0.01;, score=-0.417 total time=   0.0s\n",
      "[CV 5/5] END degree=15, gamma=scale, kernel=linear, max_iter=100, tol=0.01;, score=-0.214 total time=   0.0s\n",
      "[CV 1/5] END degree=15, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-4.840 total time=   0.0s\n",
      "[CV 2/5] END degree=15, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-0.361 total time=   0.0s\n",
      "[CV 3/5] END degree=15, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-6.465 total time=   0.0s\n",
      "[CV 4/5] END degree=15, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-4.258 total time=   0.0s\n",
      "[CV 5/5] END degree=15, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-0.646 total time=   0.0s\n",
      "[CV 1/5] END degree=15, gamma=scale, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.001 total time=   0.0s\n",
      "[CV 2/5] END degree=15, gamma=scale, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.014 total time=   0.0s\n",
      "[CV 1/5] END degree=17, gamma=auto, kernel=linear, max_iter=100, tol=0.01;, score=-0.334 total time=   0.0s\n",
      "[CV 2/5] END degree=17, gamma=auto, kernel=linear, max_iter=100, tol=0.01;, score=-0.177 total time=   0.0s\n",
      "[CV 3/5] END degree=17, gamma=auto, kernel=linear, max_iter=100, tol=0.01;, score=-0.174 total time=   0.0s\n",
      "[CV 4/5] END degree=17, gamma=auto, kernel=linear, max_iter=100, tol=0.01;, score=-0.417 total time=   0.0s\n",
      "[CV 5/5] END degree=17, gamma=auto, kernel=linear, max_iter=100, tol=0.01;, score=-0.214 total time=   0.0s\n",
      "[CV 1/5] END degree=17, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.019 total time=   0.0s\n",
      "[CV 2/5] END degree=17, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.002 total time=   0.0s\n",
      "[CV 3/5] END degree=17, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.000 total time=   0.0s\n",
      "[CV 4/5] END degree=17, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.033 total time=   0.0s\n",
      "[CV 5/5] END degree=17, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.001 total time=   0.0s\n",
      "[CV 1/5] END degree=17, gamma=auto, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.330 total time=   0.0s\n",
      "[CV 2/5] END degree=17, gamma=auto, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.177 total time=   0.0s\n",
      "[CV 3/5] END degree=17, gamma=auto, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.174 total time=   0.0s\n",
      "[CV 4/5] END degree=17, gamma=auto, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.417 total time=   0.0s\n",
      "[CV 5/5] END degree=17, gamma=auto, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.214 total time=   0.0s\n",
      "[CV 1/5] END degree=17, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.019 total time=   0.0s\n",
      "[CV 1/5] END algorithm=ball_tree, leaf_size=6, n_neighbors=26, p=2, weights=distance;, score=0.842 total time=   0.0s\n",
      "[CV 3/5] END algorithm=ball_tree, leaf_size=8, n_neighbors=321, p=2, weights=uniform;, score=0.563 total time=   0.0s\n",
      "[CV 2/5] END algorithm=auto, leaf_size=18, n_neighbors=110, p=2, weights=uniform;, score=0.715 total time=   0.0s\n",
      "[CV 1/5] END algorithm=kd_tree, leaf_size=6, n_neighbors=251, p=2, weights=distance;, score=0.672 total time=   0.0s\n",
      "[CV 2/5] END algorithm=kd_tree, leaf_size=6, n_neighbors=251, p=2, weights=distance;, score=0.668 total time=   0.0s\n",
      "[CV 3/5] END algorithm=auto, leaf_size=18, n_neighbors=293, p=1, weights=distance;, score=0.712 total time=   0.0s\n",
      "[CV 2/5] END degree=5, gamma=scale, kernel=linear, max_iter=100, tol=0.01;, score=-0.177 total time=   0.0s\n",
      "[CV 3/5] END degree=5, gamma=scale, kernel=linear, max_iter=100, tol=0.01;, score=-0.174 total time=   0.0s\n",
      "[CV 4/5] END degree=5, gamma=scale, kernel=linear, max_iter=100, tol=0.01;, score=-0.417 total time=   0.0s\n",
      "[CV 4/5] END degree=5, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.268 total time=   0.0s\n",
      "[CV 5/5] END degree=5, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.076 total time=   0.0s\n",
      "[CV 1/5] END degree=5, gamma=auto, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.330 total time=   0.0s\n",
      "[CV 2/5] END degree=5, gamma=auto, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.177 total time=   0.0s\n",
      "[CV 3/5] END degree=5, gamma=auto, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.174 total time=   0.0s\n",
      "[CV 4/5] END degree=5, gamma=auto, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.417 total time=   0.0s\n",
      "[CV 5/5] END degree=5, gamma=auto, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.214 total time=   0.0s\n",
      "[CV 1/5] END degree=5, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.163 total time=   0.0s\n",
      "[CV 4/5] END degree=7, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END degree=7, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.015 total time=   0.0s\n",
      "[CV 1/5] END degree=7, gamma=auto, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.330 total time=   0.0s\n",
      "[CV 2/5] END degree=7, gamma=auto, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.177 total time=   0.0s\n",
      "[CV 3/5] END degree=7, gamma=auto, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.174 total time=   0.0s\n",
      "[CV 4/5] END degree=7, gamma=auto, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.417 total time=   0.0s\n",
      "[CV 5/5] END degree=7, gamma=auto, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.214 total time=   0.0s\n",
      "[CV 1/5] END degree=7, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.055 total time=   0.0s\n",
      "[CV 3/5] END degree=11, gamma=scale, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.009 total time=   0.0s\n",
      "[CV 4/5] END degree=11, gamma=scale, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.021 total time=   0.0s\n",
      "[CV 5/5] END degree=11, gamma=scale, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.007 total time=   0.0s\n",
      "[CV 1/5] END degree=11, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-14.455 total time=   0.0s\n",
      "[CV 2/5] END degree=11, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-10694.671 total time=   0.0s\n",
      "[CV 3/5] END degree=11, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-848.503 total time=   0.0s\n",
      "[CV 4/5] END degree=11, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-5753.945 total time=   0.0s\n",
      "[CV 5/5] END degree=11, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-17805187.564 total time=   0.0s\n",
      "[CV 1/5] END degree=11, gamma=auto, kernel=linear, max_iter=100, tol=0.01;, score=-0.334 total time=   0.0s\n",
      "[CV 2/5] END degree=11, gamma=auto, kernel=linear, max_iter=100, tol=0.01;, score=-0.177 total time=   0.0s\n",
      "[CV 3/5] END degree=11, gamma=auto, kernel=linear, max_iter=100, tol=0.01;, score=-0.174 total time=   0.0s\n",
      "[CV 4/5] END degree=11, gamma=auto, kernel=linear, max_iter=100, tol=0.01;, score=-0.417 total time=   0.0s\n",
      "[CV 5/5] END degree=11, gamma=auto, kernel=linear, max_iter=100, tol=0.01;, score=-0.214 total time=   0.0s\n",
      "[CV 1/5] END degree=11, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.032 total time=   0.0s\n",
      "[CV 2/5] END degree=11, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.002 total time=   0.0s\n",
      "[CV 3/5] END degree=11, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.001 total time=   0.0s\n",
      "[CV 4/5] END degree=15, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.033 total time=   0.0s\n",
      "[CV 5/5] END degree=15, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.000 total time=   0.0s\n",
      "[CV 1/5] END degree=15, gamma=auto, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.330 total time=   0.0s\n",
      "[CV 2/5] END degree=15, gamma=auto, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.177 total time=   0.0s\n",
      "[CV 3/5] END degree=15, gamma=auto, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.174 total time=   0.0s\n",
      "[CV 4/5] END degree=15, gamma=auto, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.417 total time=   0.0s\n",
      "[CV 5/5] END degree=15, gamma=auto, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.214 total time=   0.0s\n",
      "[CV 1/5] END degree=15, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.021 total time=   0.0s\n",
      "[CV 2/5] END degree=15, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.000 total time=   0.0s\n",
      "[CV 3/5] END degree=15, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.000 total time=   0.0s\n",
      "[CV 4/5] END degree=15, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.033 total time=   0.0s\n",
      "[CV 5/5] END degree=15, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.000 total time=   0.0s\n",
      "[CV 1/5] END degree=17, gamma=scale, kernel=linear, max_iter=100, tol=0.01;, score=-0.334 total time=   0.0s\n",
      "[CV 2/5] END degree=17, gamma=scale, kernel=linear, max_iter=100, tol=0.01;, score=-0.177 total time=   0.0s\n",
      "[CV 3/5] END degree=17, gamma=scale, kernel=linear, max_iter=100, tol=0.01;, score=-0.174 total time=   0.0s\n",
      "[CV 4/5] END degree=17, gamma=scale, kernel=linear, max_iter=100, tol=0.01;, score=-0.417 total time=   0.0s\n",
      "[CV 2/5] END degree=20, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-30668.340 total time=   0.0s\n",
      "[CV 4/5] END degree=20, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-4.258 total time=   0.0s\n",
      "[CV 1/5] END degree=20, gamma=auto, kernel=linear, max_iter=100, tol=0.01;, score=-0.334 total time=   0.0s\n",
      "[CV 3/5] END degree=20, gamma=auto, kernel=linear, max_iter=100, tol=0.01;, score=-0.174 total time=   0.0s\n",
      "[CV 1/5] END degree=20, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.014 total time=   0.0s\n",
      "[CV 4/5] END degree=20, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.028 total time=   0.0s\n",
      "[CV 1/5] END degree=20, gamma=auto, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.330 total time=   0.0s\n",
      "[CV 5/5] END degree=20, gamma=auto, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.214 total time=   0.0s\n",
      "[CV 3/5] END degree=20, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.001 total time=   0.0s\n",
      "[CV 3/5] END degree=20, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.001 total time=   0.0s\n",
      "[CV 3/5] END algorithm=ball_tree, leaf_size=6, n_neighbors=26, p=2, weights=distance;, score=0.864 total time=   0.0s\n",
      "[CV 4/5] END algorithm=ball_tree, leaf_size=8, n_neighbors=321, p=2, weights=uniform;, score=0.465 total time=   0.0s\n",
      "[CV 5/5] END algorithm=auto, leaf_size=18, n_neighbors=110, p=2, weights=uniform;, score=0.724 total time=   0.0s\n",
      "[CV 1/5] END algorithm=ball_tree, leaf_size=13, n_neighbors=47, p=2, weights=distance;, score=0.831 total time=   0.0s\n",
      "[CV 4/5] END algorithm=ball_tree, leaf_size=10, n_neighbors=145, p=1, weights=uniform;, score=0.695 total time=   0.0s\n",
      "[CV 5/5] END algorithm=ball_tree, leaf_size=10, n_neighbors=145, p=1, weights=uniform;, score=0.723 total time=   0.0s\n",
      "[CV 1/5] END algorithm=kd_tree, leaf_size=5, n_neighbors=96, p=2, weights=uniform;, score=0.743 total time=   0.0s\n",
      "[CV 2/5] END algorithm=kd_tree, leaf_size=5, n_neighbors=96, p=2, weights=uniform;, score=0.728 total time=   0.0s\n",
      "[CV 3/5] END algorithm=kd_tree, leaf_size=5, n_neighbors=96, p=2, weights=uniform;, score=0.782 total time=   0.0s\n",
      "[CV 4/5] END algorithm=kd_tree, leaf_size=5, n_neighbors=96, p=2, weights=uniform;, score=0.737 total time=   0.0s\n",
      "[CV 1/5] END algorithm=ball_tree, leaf_size=11, n_neighbors=328, p=2, weights=distance;, score=0.616 total time=   0.0s\n",
      "[CV 2/5] END algorithm=ball_tree, leaf_size=11, n_neighbors=328, p=2, weights=distance;, score=0.618 total time=   0.0s\n",
      "[CV 3/5] END algorithm=ball_tree, leaf_size=11, n_neighbors=328, p=2, weights=distance;, score=0.655 total time=   0.0s\n",
      "[CV 5/5] END degree=9, gamma=scale, kernel=linear, max_iter=100, tol=0.01;, score=-0.214 total time=   0.0s\n",
      "[CV 1/5] END degree=9, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-26482.837 total time=   0.0s\n",
      "[CV 2/5] END degree=9, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-958.640 total time=   0.0s\n",
      "[CV 3/5] END degree=9, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-6282.478 total time=   0.0s\n",
      "[CV 4/5] END degree=9, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-66656.852 total time=   0.0s\n",
      "[CV 5/5] END degree=9, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-130.443 total time=   0.0s\n",
      "[CV 1/5] END degree=9, gamma=scale, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.001 total time=   0.0s\n",
      "[CV 2/5] END degree=9, gamma=scale, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.014 total time=   0.0s\n",
      "[CV 5/5] END degree=13, gamma=scale, kernel=linear, max_iter=100, tol=0.01;, score=-0.214 total time=   0.0s\n",
      "[CV 1/5] END degree=13, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-4.840 total time=   0.0s\n",
      "[CV 2/5] END degree=13, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-0.602 total time=   0.0s\n",
      "[CV 3/5] END degree=13, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-5308561089.145 total time=   0.0s\n",
      "[CV 4/5] END degree=13, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-68.108 total time=   0.0s\n",
      "[CV 5/5] END degree=13, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=0.031 total time=   0.0s\n",
      "[CV 1/5] END degree=13, gamma=scale, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.001 total time=   0.0s\n",
      "[CV 2/5] END degree=13, gamma=scale, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.014 total time=   0.0s\n",
      "[CV 3/5] END degree=13, gamma=scale, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.009 total time=   0.0s\n",
      "[CV 4/5] END degree=13, gamma=scale, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.021 total time=   0.0s\n",
      "[CV 5/5] END degree=13, gamma=scale, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.007 total time=   0.0s\n",
      "[CV 1/5] END degree=13, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-4.840 total time=   0.0s\n",
      "[CV 2/5] END degree=13, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-0.602 total time=   0.0s\n",
      "[CV 3/5] END degree=13, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-5308561089.145 total time=   0.0s\n",
      "[CV 4/5] END degree=13, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-68.108 total time=   0.0s\n",
      "[CV 5/5] END degree=13, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=0.031 total time=   0.0s\n",
      "[CV 5/5] END degree=17, gamma=scale, kernel=linear, max_iter=100, tol=0.01;, score=-0.214 total time=   0.0s\n",
      "[CV 1/5] END degree=17, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=0.123 total time=   0.0s\n",
      "[CV 2/5] END degree=17, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-6.074 total time=   0.0s\n",
      "[CV 3/5] END degree=17, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-6.465 total time=   0.0s\n",
      "[CV 4/5] END degree=17, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-210.973 total time=   0.0s\n",
      "[CV 5/5] END degree=17, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-1.198 total time=   0.0s\n",
      "[CV 1/5] END degree=17, gamma=scale, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.001 total time=   0.0s\n",
      "[CV 2/5] END degree=17, gamma=scale, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.014 total time=   0.0s\n",
      "[CV 3/5] END degree=17, gamma=scale, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.009 total time=   0.0s\n",
      "[CV 4/5] END degree=17, gamma=scale, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.021 total time=   0.0s\n",
      "[CV 5/5] END degree=17, gamma=scale, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.007 total time=   0.0s\n",
      "[CV 1/5] END degree=17, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=0.123 total time=   0.0s\n",
      "[CV 2/5] END degree=17, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-6.074 total time=   0.0s\n",
      "[CV 3/5] END degree=17, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-6.465 total time=   0.0s\n",
      "[CV 4/5] END degree=17, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-210.973 total time=   0.0s\n",
      "[CV 5/5] END degree=17, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-1.198 total time=   0.0s\n",
      "[CV 4/5] END degree=20, gamma=scale, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.021 total time=   0.0s\n",
      "[CV 1/5] END degree=20, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-4.840 total time=   0.0s\n",
      "[CV 3/5] END degree=20, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-6.465 total time=   0.0s\n",
      "[CV 5/5] END degree=20, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-13908.536 total time=   0.0s\n",
      "[CV 2/5] END degree=20, gamma=auto, kernel=linear, max_iter=100, tol=0.01;, score=-0.177 total time=   0.0s\n",
      "[CV 5/5] END degree=20, gamma=auto, kernel=linear, max_iter=100, tol=0.01;, score=-0.214 total time=   0.0s\n",
      "[CV 2/5] END degree=20, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.003 total time=   0.0s\n",
      "[CV 5/5] END degree=20, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.001 total time=   0.0s\n",
      "[CV 4/5] END degree=20, gamma=auto, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.417 total time=   0.0s\n",
      "[CV 1/5] END degree=20, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.014 total time=   0.0s\n",
      "[CV 5/5] END degree=20, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.001 total time=   0.0s\n",
      "[CV 1/5] END degree=20, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.014 total time=   0.0s\n",
      "[CV 4/5] END algorithm=ball_tree, leaf_size=6, n_neighbors=26, p=2, weights=distance;, score=0.863 total time=   0.0s\n",
      "[CV 1/5] END algorithm=auto, leaf_size=18, n_neighbors=110, p=2, weights=uniform;, score=0.727 total time=   0.0s\n",
      "[CV 4/5] END algorithm=ball_tree, leaf_size=13, n_neighbors=47, p=2, weights=distance;, score=0.843 total time=   0.0s\n",
      "[CV 5/5] END algorithm=ball_tree, leaf_size=13, n_neighbors=47, p=2, weights=distance;, score=0.826 total time=   0.0s\n",
      "[CV 1/5] END algorithm=auto, leaf_size=18, n_neighbors=293, p=1, weights=distance;, score=0.685 total time=   0.0s\n",
      "[CV 2/5] END algorithm=auto, leaf_size=18, n_neighbors=293, p=1, weights=distance;, score=0.684 total time=   0.0s\n",
      "[CV 4/5] END algorithm=ball_tree, leaf_size=18, n_neighbors=286, p=1, weights=distance;, score=0.663 total time=   0.0s\n",
      "[CV 5/5] END algorithm=ball_tree, leaf_size=18, n_neighbors=286, p=1, weights=distance;, score=0.696 total time=   0.0s\n",
      "[CV 1/5] END algorithm=auto, leaf_size=16, n_neighbors=237, p=2, weights=distance;, score=0.681 total time=   0.0s\n",
      "[CV 2/5] END algorithm=auto, leaf_size=16, n_neighbors=237, p=2, weights=distance;, score=0.676 total time=   0.0s\n",
      "[CV 3/5] END algorithm=kd_tree, leaf_size=6, n_neighbors=251, p=2, weights=uniform;, score=0.644 total time=   0.0s\n",
      "[CV 4/5] END algorithm=kd_tree, leaf_size=6, n_neighbors=251, p=2, weights=uniform;, score=0.550 total time=   0.0s\n",
      "[CV 5/5] END algorithm=kd_tree, leaf_size=6, n_neighbors=251, p=2, weights=uniform;, score=0.590 total time=   0.0s\n",
      "[CV 1/5] END algorithm=kd_tree, leaf_size=8, n_neighbors=47, p=1, weights=uniform;, score=0.807 total time=   0.0s\n",
      "[CV 2/5] END algorithm=brute, leaf_size=16, n_neighbors=350, p=1, weights=uniform;, score=0.544 total time=   0.0s\n",
      "[CV 3/5] END algorithm=brute, leaf_size=16, n_neighbors=350, p=1, weights=uniform;, score=0.553 total time=   0.0s\n",
      "[CV 4/5] END algorithm=brute, leaf_size=16, n_neighbors=350, p=1, weights=uniform;, score=0.469 total time=   0.0s\n",
      "[CV 5/5] END algorithm=brute, leaf_size=16, n_neighbors=350, p=1, weights=uniform;, score=0.534 total time=   0.0s\n",
      "[CV 1/5] END algorithm=auto, leaf_size=10, n_neighbors=342, p=2, weights=uniform;, score=0.472 total time=   0.0s\n",
      "[CV 2/5] END algorithm=auto, leaf_size=10, n_neighbors=342, p=2, weights=uniform;, score=0.510 total time=   0.0s\n",
      "[CV 3/5] END algorithm=auto, leaf_size=10, n_neighbors=342, p=2, weights=uniform;, score=0.535 total time=   0.0s\n",
      "[CV 4/5] END algorithm=auto, leaf_size=10, n_neighbors=342, p=2, weights=uniform;, score=0.439 total time=   0.0s\n",
      "[CV 4/5] END degree=1, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-0.417 total time=   0.0s\n",
      "[CV 5/5] END degree=1, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-0.213 total time=   0.0s\n",
      "[CV 4/5] END degree=1, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.417 total time=   0.0s\n",
      "[CV 5/5] END degree=1, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.214 total time=   0.0s\n",
      "[CV 5/5] END degree=3, gamma=scale, kernel=linear, max_iter=100, tol=0.01;, score=-0.214 total time=   0.0s\n",
      "[CV 1/5] END degree=3, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-0.147 total time=   0.0s\n",
      "[CV 2/5] END degree=3, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-0.023 total time=   0.0s\n",
      "[CV 3/5] END degree=3, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=0.029 total time=   0.0s\n",
      "[CV 5/5] END degree=3, gamma=auto, kernel=linear, max_iter=100, tol=0.01;, score=-0.214 total time=   0.0s\n",
      "[CV 1/5] END degree=3, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.334 total time=   0.0s\n",
      "[CV 2/5] END degree=3, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.189 total time=   0.0s\n",
      "[CV 3/5] END degree=3, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.174 total time=   0.0s\n",
      "[CV 5/5] END degree=5, gamma=scale, kernel=linear, max_iter=100, tol=0.01;, score=-0.214 total time=   0.0s\n",
      "[CV 1/5] END degree=5, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-1.654 total time=   0.0s\n",
      "[CV 2/5] END degree=5, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-1.406 total time=   0.0s\n",
      "[CV 3/5] END degree=5, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-1.335 total time=   0.0s\n",
      "[CV 4/5] END degree=5, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=0.111 total time=   0.0s\n",
      "[CV 5/5] END degree=5, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-0.424 total time=   0.0s\n",
      "[CV 1/5] END degree=5, gamma=scale, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.001 total time=   0.0s\n",
      "[CV 2/5] END degree=5, gamma=scale, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.014 total time=   0.0s\n",
      "[CV 3/5] END degree=9, gamma=scale, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.009 total time=   0.0s\n",
      "[CV 4/5] END degree=9, gamma=scale, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.021 total time=   0.0s\n",
      "[CV 5/5] END degree=9, gamma=scale, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.007 total time=   0.0s\n",
      "[CV 1/5] END degree=9, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-26482.837 total time=   0.0s\n",
      "[CV 2/5] END degree=9, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-958.640 total time=   0.0s\n",
      "[CV 3/5] END degree=9, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-6282.478 total time=   0.0s\n",
      "[CV 4/5] END degree=9, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-66656.852 total time=   0.0s\n",
      "[CV 5/5] END degree=9, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-130.443 total time=   0.0s\n",
      "[CV 1/5] END degree=13, gamma=auto, kernel=linear, max_iter=100, tol=0.01;, score=-0.334 total time=   0.0s\n",
      "[CV 2/5] END degree=13, gamma=auto, kernel=linear, max_iter=100, tol=0.01;, score=-0.177 total time=   0.0s\n",
      "[CV 3/5] END degree=13, gamma=auto, kernel=linear, max_iter=100, tol=0.01;, score=-0.174 total time=   0.0s\n",
      "[CV 4/5] END degree=13, gamma=auto, kernel=linear, max_iter=100, tol=0.01;, score=-0.417 total time=   0.0s\n",
      "[CV 5/5] END degree=13, gamma=auto, kernel=linear, max_iter=100, tol=0.01;, score=-0.214 total time=   0.0s\n",
      "[CV 1/5] END degree=13, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.021 total time=   0.0s\n",
      "[CV 2/5] END degree=13, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.000 total time=   0.0s\n",
      "[CV 3/5] END degree=13, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.000 total time=   0.0s\n",
      "[CV 4/5] END degree=13, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.039 total time=   0.0s\n",
      "[CV 5/5] END degree=13, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.000 total time=   0.0s\n",
      "[CV 1/5] END degree=13, gamma=auto, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.330 total time=   0.0s\n",
      "[CV 2/5] END degree=13, gamma=auto, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.177 total time=   0.0s\n",
      "[CV 3/5] END degree=13, gamma=auto, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.174 total time=   0.0s\n",
      "[CV 4/5] END degree=13, gamma=auto, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.417 total time=   0.0s\n",
      "[CV 5/5] END degree=13, gamma=auto, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.214 total time=   0.0s\n",
      "[CV 1/5] END degree=13, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.021 total time=   0.0s\n",
      "[CV 2/5] END degree=20, gamma=auto, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.177 total time=   0.0s\n",
      "[CV 2/5] END degree=20, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.003 total time=   0.0s\n",
      "[CV 4/5] END degree=20, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.028 total time=   0.0s\n",
      "[CV 2/5] END algorithm=ball_tree, leaf_size=6, n_neighbors=26, p=2, weights=distance;, score=0.842 total time=   0.0s\n",
      "[CV 2/5] END algorithm=ball_tree, leaf_size=8, n_neighbors=321, p=2, weights=uniform;, score=0.530 total time=   0.0s\n",
      "[CV 3/5] END algorithm=kd_tree, leaf_size=6, n_neighbors=251, p=2, weights=distance;, score=0.716 total time=   0.0s\n",
      "[CV 4/5] END algorithm=kd_tree, leaf_size=6, n_neighbors=251, p=2, weights=distance;, score=0.658 total time=   0.0s\n",
      "[CV 5/5] END algorithm=kd_tree, leaf_size=5, n_neighbors=96, p=2, weights=uniform;, score=0.739 total time=   0.0s\n",
      "[CV 1/5] END algorithm=ball_tree, leaf_size=18, n_neighbors=286, p=1, weights=distance;, score=0.689 total time=   0.0s\n",
      "[CV 2/5] END algorithm=ball_tree, leaf_size=18, n_neighbors=286, p=1, weights=distance;, score=0.688 total time=   0.0s\n",
      "[CV 3/5] END algorithm=ball_tree, leaf_size=18, n_neighbors=286, p=1, weights=distance;, score=0.717 total time=   0.0s\n",
      "[CV 4/5] END algorithm=kd_tree, leaf_size=6, n_neighbors=159, p=2, weights=distance;, score=0.739 total time=   0.0s\n",
      "[CV 5/5] END algorithm=kd_tree, leaf_size=6, n_neighbors=159, p=2, weights=distance;, score=0.733 total time=   0.0s\n",
      "[CV 1/5] END algorithm=kd_tree, leaf_size=6, n_neighbors=251, p=2, weights=uniform;, score=0.571 total time=   0.0s\n",
      "[CV 2/5] END algorithm=kd_tree, leaf_size=6, n_neighbors=251, p=2, weights=uniform;, score=0.597 total time=   0.0s\n",
      "[CV 1/5] END algorithm=ball_tree, leaf_size=20, n_neighbors=237, p=1, weights=uniform;, score=0.634 total time=   0.0s\n",
      "[CV 2/5] END algorithm=ball_tree, leaf_size=20, n_neighbors=237, p=1, weights=uniform;, score=0.652 total time=   0.0s\n",
      "[CV 3/5] END algorithm=ball_tree, leaf_size=20, n_neighbors=237, p=1, weights=uniform;, score=0.673 total time=   0.0s\n",
      "[CV 4/5] END algorithm=ball_tree, leaf_size=20, n_neighbors=237, p=1, weights=uniform;, score=0.604 total time=   0.0s\n",
      "[CV 5/5] END algorithm=ball_tree, leaf_size=20, n_neighbors=237, p=1, weights=uniform;, score=0.656 total time=   0.0s\n",
      "[CV 1/5] END algorithm=kd_tree, leaf_size=20, n_neighbors=279, p=1, weights=uniform;, score=0.598 total time=   0.0s\n",
      "[CV 2/5] END algorithm=kd_tree, leaf_size=20, n_neighbors=279, p=1, weights=uniform;, score=0.620 total time=   0.0s\n",
      "[CV 3/5] END algorithm=kd_tree, leaf_size=20, n_neighbors=279, p=1, weights=uniform;, score=0.638 total time=   0.0s\n",
      "[CV 1/5] END algorithm=auto, leaf_size=10, n_neighbors=286, p=2, weights=distance;, score=0.647 total time=   0.0s\n",
      "[CV 2/5] END algorithm=auto, leaf_size=10, n_neighbors=286, p=2, weights=distance;, score=0.646 total time=   0.0s\n",
      "[CV 3/5] END algorithm=auto, leaf_size=10, n_neighbors=286, p=2, weights=distance;, score=0.689 total time=   0.0s\n",
      "[CV 4/5] END algorithm=auto, leaf_size=10, n_neighbors=286, p=2, weights=distance;, score=0.627 total time=   0.0s\n",
      "[CV 5/5] END algorithm=auto, leaf_size=10, n_neighbors=286, p=2, weights=distance;, score=0.654 total time=   0.0s\n",
      "[CV 1/5] END algorithm=ball_tree, leaf_size=13, n_neighbors=138, p=2, weights=uniform;, score=0.693 total time=   0.0s\n",
      "[CV 1/5] END degree=3, gamma=auto, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.330 total time=   0.0s\n",
      "[CV 2/5] END degree=3, gamma=auto, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.177 total time=   0.0s\n",
      "[CV 1/5] END degree=5, gamma=auto, kernel=linear, max_iter=100, tol=0.01;, score=-0.334 total time=   0.0s\n",
      "[CV 2/5] END degree=5, gamma=auto, kernel=linear, max_iter=100, tol=0.01;, score=-0.177 total time=   0.0s\n",
      "[CV 3/5] END degree=5, gamma=auto, kernel=linear, max_iter=100, tol=0.01;, score=-0.174 total time=   0.0s\n",
      "[CV 4/5] END degree=5, gamma=auto, kernel=linear, max_iter=100, tol=0.01;, score=-0.417 total time=   0.0s\n",
      "[CV 5/5] END degree=5, gamma=auto, kernel=linear, max_iter=100, tol=0.01;, score=-0.214 total time=   0.0s\n",
      "[CV 1/5] END degree=5, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.163 total time=   0.0s\n",
      "[CV 2/5] END degree=5, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.047 total time=   0.0s\n",
      "[CV 3/5] END degree=5, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.089 total time=   0.0s\n",
      "[CV 3/5] END degree=7, gamma=scale, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.009 total time=   0.0s\n",
      "[CV 4/5] END degree=7, gamma=scale, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.021 total time=   0.0s\n",
      "[CV 5/5] END degree=7, gamma=scale, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.007 total time=   0.0s\n",
      "[CV 1/5] END degree=7, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-503.230 total time=   0.0s\n",
      "[CV 2/5] END degree=7, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-1699.664 total time=   0.0s\n",
      "[CV 3/5] END degree=7, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-413.756 total time=   0.0s\n",
      "[CV 4/5] END degree=7, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-1994.552 total time=   0.0s\n",
      "[CV 5/5] END degree=7, gamma=scale, kernel=poly, max_iter=100, tol=0.01;, score=-9.223 total time=   0.0s\n",
      "[CV 4/5] END degree=11, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.065 total time=   0.0s\n",
      "[CV 5/5] END degree=11, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.003 total time=   0.0s\n",
      "[CV 1/5] END degree=11, gamma=auto, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.330 total time=   0.0s\n",
      "[CV 2/5] END degree=11, gamma=auto, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.177 total time=   0.0s\n",
      "[CV 3/5] END degree=11, gamma=auto, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.174 total time=   0.0s\n",
      "[CV 4/5] END degree=11, gamma=auto, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.417 total time=   0.0s\n",
      "[CV 5/5] END degree=11, gamma=auto, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.214 total time=   0.0s\n",
      "[CV 1/5] END degree=11, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.032 total time=   0.0s\n",
      "[CV 2/5] END degree=11, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.002 total time=   0.0s\n",
      "[CV 3/5] END degree=11, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.001 total time=   0.0s\n",
      "[CV 4/5] END degree=11, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.065 total time=   0.0s\n",
      "[CV 5/5] END degree=11, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.003 total time=   0.0s\n",
      "[CV 1/5] END degree=13, gamma=scale, kernel=linear, max_iter=100, tol=0.01;, score=-0.334 total time=   0.0s\n",
      "[CV 2/5] END degree=13, gamma=scale, kernel=linear, max_iter=100, tol=0.01;, score=-0.177 total time=   0.0s\n",
      "[CV 3/5] END degree=13, gamma=scale, kernel=linear, max_iter=100, tol=0.01;, score=-0.174 total time=   0.0s\n",
      "[CV 4/5] END degree=13, gamma=scale, kernel=linear, max_iter=100, tol=0.01;, score=-0.417 total time=   0.0s\n",
      "[CV 3/5] END degree=20, gamma=scale, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.009 total time=   0.0s\n",
      "[CV 5/5] END degree=20, gamma=scale, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.007 total time=   0.0s\n",
      "[CV 4/5] END degree=20, gamma=auto, kernel=linear, max_iter=100, tol=0.01;, score=-0.417 total time=   0.0s\n",
      "[CV 3/5] END degree=20, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.001 total time=   0.0s\n",
      "[CV 3/5] END degree=20, gamma=auto, kernel=sigmoid, max_iter=100, tol=0.01;, score=-0.174 total time=   0.0s\n",
      "[CV 4/5] END degree=20, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.028 total time=   0.0s\n",
      "[CV 2/5] END degree=20, gamma=auto, kernel=poly, max_iter=100, tol=0.01;, score=-0.003 total time=   0.0s\n",
      "[CV 5/5] END algorithm=ball_tree, leaf_size=6, n_neighbors=26, p=2, weights=distance;, score=0.843 total time=   0.0s\n",
      "[CV 5/5] END algorithm=ball_tree, leaf_size=8, n_neighbors=321, p=2, weights=uniform;, score=0.526 total time=   0.0s\n",
      "[CV 2/5] END algorithm=ball_tree, leaf_size=13, n_neighbors=47, p=2, weights=distance;, score=0.811 total time=   0.0s\n",
      "[CV 3/5] END algorithm=ball_tree, leaf_size=13, n_neighbors=47, p=2, weights=distance;, score=0.852 total time=   0.0s\n",
      "[CV 2/5] END algorithm=ball_tree, leaf_size=10, n_neighbors=145, p=1, weights=uniform;, score=0.708 total time=   0.0s\n",
      "[CV 3/5] END algorithm=ball_tree, leaf_size=10, n_neighbors=145, p=1, weights=uniform;, score=0.751 total time=   0.0s\n",
      "[CV 5/5] END algorithm=auto, leaf_size=18, n_neighbors=293, p=1, weights=distance;, score=0.692 total time=   0.0s\n",
      "[CV 1/5] END algorithm=auto, leaf_size=13, n_neighbors=216, p=2, weights=distance;, score=0.697 total time=   0.0s\n",
      "[CV 2/5] END algorithm=ball_tree, leaf_size=11, n_neighbors=258, p=1, weights=uniform;, score=0.640 total time=   0.0s\n",
      "[CV 3/5] END algorithm=ball_tree, leaf_size=11, n_neighbors=258, p=1, weights=uniform;, score=0.656 total time=   0.0s\n",
      "[CV 4/5] END algorithm=ball_tree, leaf_size=11, n_neighbors=258, p=1, weights=uniform;, score=0.582 total time=   0.0s\n",
      "[CV 5/5] END algorithm=ball_tree, leaf_size=11, n_neighbors=258, p=1, weights=uniform;, score=0.635 total time=   0.0s\n",
      "[CV 1/5] END algorithm=brute, leaf_size=20, n_neighbors=251, p=1, weights=distance;, score=0.710 total time=   0.0s\n",
      "[CV 2/5] END algorithm=brute, leaf_size=20, n_neighbors=251, p=1, weights=distance;, score=0.708 total time=   0.0s\n",
      "[CV 3/5] END algorithm=brute, leaf_size=20, n_neighbors=251, p=1, weights=distance;, score=0.738 total time=   0.0s\n",
      "[CV 4/5] END algorithm=brute, leaf_size=20, n_neighbors=251, p=1, weights=distance;, score=0.689 total time=   0.0s\n",
      "[CV 5/5] END algorithm=auto, leaf_size=10, n_neighbors=342, p=2, weights=uniform;, score=0.505 total time=   0.0s\n",
      "[CV 1/5] END algorithm=ball_tree, leaf_size=13, n_neighbors=286, p=2, weights=distance;, score=0.647 total time=   0.0s\n",
      "[CV 2/5] END algorithm=ball_tree, leaf_size=13, n_neighbors=286, p=2, weights=distance;, score=0.646 total time=   0.0s\n",
      "[CV 3/5] END algorithm=ball_tree, leaf_size=13, n_neighbors=286, p=2, weights=distance;, score=0.689 total time=   0.0s\n",
      "[CV 4/5] END algorithm=ball_tree, leaf_size=13, n_neighbors=286, p=2, weights=distance;, score=0.627 total time=   0.0s\n",
      "[CV 5/5] END algorithm=ball_tree, leaf_size=13, n_neighbors=286, p=2, weights=distance;, score=0.654 total time=   0.0s\n",
      "[CV 1/5] END algorithm=brute, leaf_size=20, n_neighbors=251, p=1, weights=uniform;, score=0.623 total time=   0.0s\n",
      "[CV 2/5] END algorithm=brute, leaf_size=20, n_neighbors=251, p=1, weights=uniform;, score=0.644 total time=   0.0s\n",
      "[CV 3/5] END algorithm=brute, leaf_size=11, n_neighbors=47, p=2, weights=uniform;, score=0.830 total time=   0.0s\n",
      "[CV 4/5] END algorithm=brute, leaf_size=11, n_neighbors=47, p=2, weights=uniform;, score=0.809 total time=   0.0s\n",
      "[CV 5/5] END algorithm=brute, leaf_size=11, n_neighbors=47, p=2, weights=uniform;, score=0.801 total time=   0.0s\n",
      "[CV 1/5] END algorithm=auto, leaf_size=13, n_neighbors=75, p=2, weights=uniform;, score=0.767 total time=   0.0s\n",
      "[CV 2/5] END algorithm=auto, leaf_size=13, n_neighbors=75, p=2, weights=uniform;, score=0.749 total time=   0.0s\n",
      "[CV 3/5] END algorithm=auto, leaf_size=13, n_neighbors=75, p=2, weights=uniform;, score=0.803 total time=   0.0s\n",
      "[CV 4/5] END algorithm=auto, leaf_size=13, n_neighbors=75, p=2, weights=uniform;, score=0.767 total time=   0.0s\n",
      "[CV 5/5] END algorithm=auto, leaf_size=13, n_neighbors=75, p=2, weights=uniform;, score=0.764 total time=   0.0s\n",
      "[CV 4/5] END algorithm=auto, leaf_size=18, n_neighbors=293, p=1, weights=distance;, score=0.657 total time=   0.0s\n",
      "[CV 3/5] END algorithm=auto, leaf_size=16, n_neighbors=237, p=2, weights=distance;, score=0.725 total time=   0.0s\n",
      "[CV 4/5] END algorithm=auto, leaf_size=16, n_neighbors=237, p=2, weights=distance;, score=0.670 total time=   0.0s\n",
      "[CV 5/5] END algorithm=auto, leaf_size=16, n_neighbors=237, p=2, weights=distance;, score=0.684 total time=   0.0s\n",
      "[CV 1/5] END algorithm=ball_tree, leaf_size=11, n_neighbors=258, p=1, weights=uniform;, score=0.617 total time=   0.0s\n",
      "[CV 2/5] END algorithm=kd_tree, leaf_size=8, n_neighbors=47, p=1, weights=uniform;, score=0.793 total time=   0.0s\n",
      "[CV 3/5] END algorithm=kd_tree, leaf_size=8, n_neighbors=47, p=1, weights=uniform;, score=0.840 total time=   0.0s\n",
      "[CV 4/5] END algorithm=kd_tree, leaf_size=8, n_neighbors=47, p=1, weights=uniform;, score=0.816 total time=   0.0s\n",
      "[CV 5/5] END algorithm=kd_tree, leaf_size=8, n_neighbors=47, p=1, weights=uniform;, score=0.826 total time=   0.0s\n",
      "[CV 4/5] END algorithm=kd_tree, leaf_size=20, n_neighbors=279, p=1, weights=uniform;, score=0.557 total time=   0.0s\n",
      "[CV 5/5] END algorithm=kd_tree, leaf_size=20, n_neighbors=279, p=1, weights=uniform;, score=0.612 total time=   0.0s\n",
      "[CV 1/5] END algorithm=brute, leaf_size=5, n_neighbors=230, p=2, weights=distance;, score=0.686 total time=   0.0s\n",
      "[CV 2/5] END algorithm=brute, leaf_size=5, n_neighbors=230, p=2, weights=distance;, score=0.680 total time=   0.0s\n",
      "[CV 3/5] END algorithm=brute, leaf_size=5, n_neighbors=230, p=2, weights=distance;, score=0.731 total time=   0.0s\n",
      "[CV 4/5] END algorithm=brute, leaf_size=5, n_neighbors=230, p=2, weights=distance;, score=0.676 total time=   0.0s\n",
      "[CV 5/5] END algorithm=brute, leaf_size=5, n_neighbors=230, p=2, weights=distance;, score=0.688 total time=   0.0s\n",
      "[CV 1/5] END algorithm=brute, leaf_size=16, n_neighbors=350, p=1, weights=uniform;, score=0.513 total time=   0.0s\n",
      "[CV 4/5] END algorithm=ball_tree, leaf_size=13, n_neighbors=138, p=2, weights=uniform;, score=0.689 total time=   0.0s\n",
      "[CV 5/5] END algorithm=ball_tree, leaf_size=13, n_neighbors=138, p=2, weights=uniform;, score=0.691 total time=   0.0s\n",
      "[CV 1/5] END algorithm=auto, leaf_size=11, n_neighbors=19, p=2, weights=distance;, score=0.849 total time=   0.0s\n",
      "[CV 2/5] END algorithm=auto, leaf_size=11, n_neighbors=19, p=2, weights=distance;, score=0.855 total time=   0.0s\n",
      "[CV 3/5] END algorithm=auto, leaf_size=11, n_neighbors=19, p=2, weights=distance;, score=0.867 total time=   0.0s\n",
      "[CV 4/5] END algorithm=auto, leaf_size=11, n_neighbors=19, p=2, weights=distance;, score=0.869 total time=   0.0s\n",
      "[CV 5/5] END algorithm=auto, leaf_size=11, n_neighbors=19, p=2, weights=distance;, score=0.850 total time=   0.0s\n",
      "[CV 1/5] END algorithm=brute, leaf_size=15, n_neighbors=103, p=2, weights=distance;, score=0.785 total time=   0.0s\n",
      "[CV 1/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=209, p=2, weights=uniform;, score=0.614 total time=   0.0s\n",
      "[CV 2/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=209, p=2, weights=uniform;, score=0.632 total time=   0.0s\n",
      "[CV 3/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=209, p=2, weights=uniform;, score=0.683 total time=   0.0s\n",
      "[CV 4/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=209, p=2, weights=uniform;, score=0.600 total time=   0.0s\n",
      "[CV 5/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=209, p=2, weights=uniform;, score=0.625 total time=   0.0s\n",
      "[CV 1/5] END algorithm=kd_tree, leaf_size=10, n_neighbors=342, p=2, weights=uniform;, score=0.472 total time=   0.0s\n",
      "[CV 2/5] END algorithm=kd_tree, leaf_size=10, n_neighbors=342, p=2, weights=uniform;, score=0.510 total time=   0.0s\n",
      "[CV 3/5] END algorithm=kd_tree, leaf_size=10, n_neighbors=342, p=2, weights=uniform;, score=0.535 total time=   0.0s\n",
      "[CV 4/5] END algorithm=kd_tree, leaf_size=10, n_neighbors=342, p=2, weights=uniform;, score=0.439 total time=   0.0s\n",
      "[CV 5/5] END algorithm=kd_tree, leaf_size=10, n_neighbors=342, p=2, weights=uniform;, score=0.505 total time=   0.0s\n",
      "[CV 1/5] END algorithm=auto, leaf_size=8, n_neighbors=152, p=2, weights=distance;, score=0.745 total time=   0.0s\n",
      "[CV 2/5] END algorithm=auto, leaf_size=8, n_neighbors=152, p=2, weights=distance;, score=0.726 total time=   0.0s\n",
      "[CV 3/5] END algorithm=auto, leaf_size=8, n_neighbors=152, p=2, weights=distance;, score=0.781 total time=   0.0s\n",
      "[CV 4/5] END algorithm=auto, leaf_size=8, n_neighbors=152, p=2, weights=distance;, score=0.746 total time=   0.0s\n",
      "[CV 5/5] END algorithm=auto, leaf_size=8, n_neighbors=152, p=2, weights=distance;, score=0.738 total time=   0.0s\n",
      "[CV 1/5] END algorithm=auto, leaf_size=13, n_neighbors=33, p=1, weights=distance;, score=0.844 total time=   0.0s\n",
      "[CV 5/5] END algorithm=kd_tree, leaf_size=11, n_neighbors=286, p=1, weights=distance;, score=0.696 total time=   0.0s\n",
      "[CV 1/5] END algorithm=brute, leaf_size=13, n_neighbors=75, p=2, weights=uniform;, score=0.767 total time=   0.0s\n",
      "[CV 2/5] END algorithm=brute, leaf_size=13, n_neighbors=75, p=2, weights=uniform;, score=0.749 total time=   0.0s\n",
      "[CV 3/5] END algorithm=brute, leaf_size=13, n_neighbors=75, p=2, weights=uniform;, score=0.803 total time=   0.0s\n",
      "[CV 4/5] END algorithm=brute, leaf_size=13, n_neighbors=75, p=2, weights=uniform;, score=0.767 total time=   0.0s\n",
      "[CV 5/5] END algorithm=brute, leaf_size=13, n_neighbors=75, p=2, weights=uniform;, score=0.764 total time=   0.0s\n",
      "[CV 1/5] END algorithm=brute, leaf_size=6, n_neighbors=75, p=1, weights=uniform;, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END algorithm=brute, leaf_size=6, n_neighbors=75, p=1, weights=uniform;, score=0.761 total time=   0.0s\n",
      "[CV 3/5] END algorithm=brute, leaf_size=6, n_neighbors=75, p=1, weights=uniform;, score=0.810 total time=   0.0s\n",
      "[CV 4/5] END algorithm=brute, leaf_size=6, n_neighbors=75, p=1, weights=uniform;, score=0.768 total time=   0.0s\n",
      "[CV 5/5] END algorithm=brute, leaf_size=6, n_neighbors=75, p=1, weights=uniform;, score=0.793 total time=   0.0s\n",
      "[CV 1/5] END algorithm=kd_tree, leaf_size=16, n_neighbors=82, p=2, weights=distance;, score=0.802 total time=   0.0s\n",
      "[CV 2/5] END algorithm=kd_tree, leaf_size=16, n_neighbors=82, p=2, weights=distance;, score=0.778 total time=   0.0s\n",
      "[CV 3/5] END algorithm=kd_tree, leaf_size=16, n_neighbors=82, p=2, weights=distance;, score=0.827 total time=   0.0s\n",
      "[CV 4/5] END algorithm=kd_tree, leaf_size=16, n_neighbors=82, p=2, weights=distance;, score=0.805 total time=   0.0s\n",
      "[CV 5/5] END algorithm=kd_tree, leaf_size=16, n_neighbors=82, p=2, weights=distance;, score=0.793 total time=   0.0s\n",
      "[CV 1/5] END algorithm=auto, leaf_size=13, n_neighbors=258, p=1, weights=uniform;, score=0.617 total time=   0.0s\n",
      "[CV 2/5] END algorithm=auto, leaf_size=13, n_neighbors=258, p=1, weights=uniform;, score=0.640 total time=   0.0s\n",
      "[CV 5/5] END algorithm=ball_tree, leaf_size=5, n_neighbors=265, p=1, weights=distance;, score=0.711 total time=   0.0s\n",
      "[CV 1/5] END algorithm=ball_tree, leaf_size=20, n_neighbors=230, p=1, weights=distance;, score=0.721 total time=   0.0s\n",
      "[CV 4/5] END algorithm=ball_tree, leaf_size=15, n_neighbors=159, p=2, weights=uniform;, score=0.664 total time=   0.0s\n",
      "[CV 5/5] END algorithm=ball_tree, leaf_size=15, n_neighbors=159, p=2, weights=uniform;, score=0.670 total time=   0.0s\n",
      "[CV 4/5] END algorithm=ball_tree, leaf_size=11, n_neighbors=75, p=1, weights=uniform;, score=0.768 total time=   0.0s\n",
      "[CV 5/5] END algorithm=ball_tree, leaf_size=11, n_neighbors=75, p=1, weights=uniform;, score=0.793 total time=   0.0s\n",
      "[CV 5/5] END algorithm=kd_tree, leaf_size=13, n_neighbors=230, p=1, weights=distance;, score=0.733 total time=   0.0s\n",
      "[CV 1/5] END algorithm=kd_tree, leaf_size=6, n_neighbors=159, p=2, weights=uniform;, score=0.670 total time=   0.0s\n",
      "[CV 3/5] END algorithm=ball_tree, leaf_size=5, n_neighbors=307, p=1, weights=distance;, score=0.702 total time=   0.0s\n",
      "[CV 4/5] END algorithm=ball_tree, leaf_size=5, n_neighbors=307, p=1, weights=distance;, score=0.647 total time=   0.0s\n",
      "[CV 2/5] END algorithm=kd_tree, leaf_size=8, n_neighbors=26, p=2, weights=uniform;, score=0.821 total time=   0.0s\n",
      "[CV 2/5] END algorithm=auto, leaf_size=13, n_neighbors=216, p=2, weights=distance;, score=0.688 total time=   0.0s\n",
      "[CV 3/5] END algorithm=auto, leaf_size=13, n_neighbors=216, p=2, weights=distance;, score=0.740 total time=   0.0s\n",
      "[CV 4/5] END algorithm=auto, leaf_size=13, n_neighbors=216, p=2, weights=distance;, score=0.689 total time=   0.0s\n",
      "[CV 5/5] END algorithm=auto, leaf_size=13, n_neighbors=216, p=2, weights=distance;, score=0.696 total time=   0.0s\n",
      "[CV 5/5] END algorithm=ball_tree, leaf_size=11, n_neighbors=328, p=2, weights=distance;, score=0.626 total time=   0.0s\n",
      "[CV 1/5] END algorithm=kd_tree, leaf_size=6, n_neighbors=159, p=2, weights=distance;, score=0.740 total time=   0.0s\n",
      "[CV 2/5] END algorithm=kd_tree, leaf_size=6, n_neighbors=159, p=2, weights=distance;, score=0.722 total time=   0.0s\n",
      "[CV 3/5] END algorithm=kd_tree, leaf_size=6, n_neighbors=159, p=2, weights=distance;, score=0.778 total time=   0.0s\n",
      "[CV 3/5] END algorithm=ball_tree, leaf_size=10, n_neighbors=265, p=1, weights=uniform;, score=0.649 total time=   0.0s\n",
      "[CV 4/5] END algorithm=ball_tree, leaf_size=10, n_neighbors=265, p=1, weights=uniform;, score=0.573 total time=   0.0s\n",
      "[CV 5/5] END algorithm=ball_tree, leaf_size=10, n_neighbors=265, p=1, weights=uniform;, score=0.629 total time=   0.0s\n",
      "[CV 1/5] END algorithm=ball_tree, leaf_size=6, n_neighbors=181, p=2, weights=uniform;, score=0.644 total time=   0.0s\n",
      "[CV 2/5] END algorithm=ball_tree, leaf_size=6, n_neighbors=181, p=2, weights=uniform;, score=0.648 total time=   0.0s\n",
      "[CV 3/5] END algorithm=ball_tree, leaf_size=6, n_neighbors=181, p=2, weights=uniform;, score=0.709 total time=   0.0s\n",
      "[CV 4/5] END algorithm=ball_tree, leaf_size=6, n_neighbors=181, p=2, weights=uniform;, score=0.636 total time=   0.0s\n",
      "[CV 5/5] END algorithm=ball_tree, leaf_size=6, n_neighbors=181, p=2, weights=uniform;, score=0.650 total time=   0.0s\n",
      "[CV 3/5] END algorithm=brute, leaf_size=20, n_neighbors=251, p=1, weights=uniform;, score=0.662 total time=   0.0s\n",
      "[CV 4/5] END algorithm=brute, leaf_size=20, n_neighbors=251, p=1, weights=uniform;, score=0.590 total time=   0.0s\n",
      "[CV 5/5] END algorithm=brute, leaf_size=20, n_neighbors=251, p=1, weights=uniform;, score=0.643 total time=   0.0s\n",
      "[CV 1/5] END algorithm=ball_tree, leaf_size=13, n_neighbors=321, p=1, weights=distance;, score=0.666 total time=   0.0s\n",
      "[CV 2/5] END algorithm=ball_tree, leaf_size=13, n_neighbors=321, p=1, weights=distance;, score=0.667 total time=   0.0s\n",
      "[CV 3/5] END algorithm=ball_tree, leaf_size=13, n_neighbors=321, p=1, weights=distance;, score=0.692 total time=   0.0s\n",
      "[CV 4/5] END algorithm=ball_tree, leaf_size=13, n_neighbors=321, p=1, weights=distance;, score=0.636 total time=   0.0s\n",
      "[CV 5/5] END algorithm=ball_tree, leaf_size=13, n_neighbors=321, p=1, weights=distance;, score=0.673 total time=   0.0s\n",
      "[CV 4/5] END algorithm=kd_tree, leaf_size=13, n_neighbors=293, p=1, weights=distance;, score=0.657 total time=   0.0s\n",
      "[CV 5/5] END algorithm=kd_tree, leaf_size=13, n_neighbors=293, p=1, weights=distance;, score=0.692 total time=   0.0s\n",
      "[CV 1/5] END algorithm=auto, leaf_size=13, n_neighbors=131, p=2, weights=distance;, score=0.761 total time=   0.0s\n",
      "[CV 2/5] END algorithm=auto, leaf_size=13, n_neighbors=131, p=2, weights=distance;, score=0.741 total time=   0.0s\n",
      "[CV 3/5] END algorithm=auto, leaf_size=13, n_neighbors=131, p=2, weights=distance;, score=0.795 total time=   0.0s\n",
      "[CV 4/5] END algorithm=auto, leaf_size=13, n_neighbors=131, p=2, weights=distance;, score=0.763 total time=   0.0s\n",
      "[CV 5/5] END algorithm=auto, leaf_size=13, n_neighbors=131, p=2, weights=distance;, score=0.753 total time=   0.0s\n",
      "[CV 1/5] END algorithm=brute, leaf_size=6, n_neighbors=350, p=2, weights=uniform;, score=0.464 total time=   0.0s\n",
      "[CV 2/5] END algorithm=brute, leaf_size=6, n_neighbors=350, p=2, weights=uniform;, score=0.500 total time=   0.0s\n",
      "[CV 3/5] END algorithm=brute, leaf_size=6, n_neighbors=350, p=2, weights=uniform;, score=0.525 total time=   0.0s\n",
      "[CV 4/5] END algorithm=brute, leaf_size=6, n_neighbors=350, p=2, weights=uniform;, score=0.430 total time=   0.0s\n",
      "[CV 5/5] END algorithm=brute, leaf_size=6, n_neighbors=350, p=2, weights=uniform;, score=0.497 total time=   0.0s\n",
      "[CV 1/5] END algorithm=kd_tree, leaf_size=11, n_neighbors=321, p=1, weights=distance;, score=0.666 total time=   0.0s\n",
      "[CV 2/5] END algorithm=kd_tree, leaf_size=11, n_neighbors=321, p=1, weights=distance;, score=0.667 total time=   0.0s\n",
      "[CV 3/5] END algorithm=kd_tree, leaf_size=11, n_neighbors=321, p=1, weights=distance;, score=0.692 total time=   0.0s\n",
      "[CV 4/5] END algorithm=kd_tree, leaf_size=11, n_neighbors=321, p=1, weights=distance;, score=0.636 total time=   0.0s\n",
      "[CV 1/5] END algorithm=auto, leaf_size=16, n_neighbors=181, p=2, weights=uniform;, score=0.644 total time=   0.0s\n",
      "[CV 2/5] END algorithm=auto, leaf_size=16, n_neighbors=181, p=2, weights=uniform;, score=0.648 total time=   0.0s\n",
      "[CV 3/5] END algorithm=auto, leaf_size=16, n_neighbors=181, p=2, weights=uniform;, score=0.709 total time=   0.0s\n",
      "[CV 4/5] END algorithm=auto, leaf_size=16, n_neighbors=181, p=2, weights=uniform;, score=0.636 total time=   0.0s\n",
      "[CV 5/5] END algorithm=auto, leaf_size=16, n_neighbors=181, p=2, weights=uniform;, score=0.650 total time=   0.0s\n",
      "[CV 1/5] END algorithm=ball_tree, leaf_size=20, n_neighbors=202, p=2, weights=distance;, score=0.707 total time=   0.0s\n",
      "[CV 2/5] END algorithm=ball_tree, leaf_size=20, n_neighbors=202, p=2, weights=distance;, score=0.697 total time=   0.0s\n",
      "[CV 3/5] END algorithm=ball_tree, leaf_size=20, n_neighbors=202, p=2, weights=distance;, score=0.750 total time=   0.0s\n",
      "[CV 4/5] END algorithm=ball_tree, leaf_size=20, n_neighbors=202, p=2, weights=distance;, score=0.702 total time=   0.0s\n",
      "[CV 5/5] END algorithm=ball_tree, leaf_size=20, n_neighbors=202, p=2, weights=distance;, score=0.706 total time=   0.0s\n",
      "[CV 1/5] END algorithm=ball_tree, leaf_size=15, n_neighbors=110, p=2, weights=uniform;, score=0.727 total time=   0.0s\n",
      "[CV 2/5] END algorithm=ball_tree, leaf_size=15, n_neighbors=110, p=2, weights=uniform;, score=0.715 total time=   0.0s\n",
      "[CV 3/5] END algorithm=ball_tree, leaf_size=15, n_neighbors=110, p=2, weights=uniform;, score=0.767 total time=   0.0s\n",
      "[CV 4/5] END algorithm=ball_tree, leaf_size=15, n_neighbors=110, p=2, weights=uniform;, score=0.721 total time=   0.0s\n",
      "[CV 5/5] END algorithm=ball_tree, leaf_size=15, n_neighbors=110, p=2, weights=uniform;, score=0.724 total time=   0.0s\n",
      "[CV 1/5] END algorithm=auto, leaf_size=6, n_neighbors=110, p=2, weights=distance;, score=0.779 total time=   0.0s\n",
      "[CV 4/5] END algorithm=kd_tree, leaf_size=20, n_neighbors=47, p=2, weights=distance;, score=0.843 total time=   0.0s\n",
      "[CV 5/5] END algorithm=kd_tree, leaf_size=20, n_neighbors=47, p=2, weights=distance;, score=0.826 total time=   0.0s\n",
      "[CV 4/5] END algorithm=ball_tree, leaf_size=20, n_neighbors=230, p=1, weights=distance;, score=0.704 total time=   0.0s\n",
      "[CV 5/5] END algorithm=ball_tree, leaf_size=20, n_neighbors=230, p=1, weights=distance;, score=0.733 total time=   0.0s\n",
      "[CV 5/5] END algorithm=brute, leaf_size=6, n_neighbors=209, p=2, weights=distance;, score=0.701 total time=   0.0s\n",
      "[CV 1/5] END algorithm=ball_tree, leaf_size=15, n_neighbors=159, p=2, weights=uniform;, score=0.670 total time=   0.0s\n",
      "[CV 1/5] END algorithm=auto, leaf_size=13, n_neighbors=5, p=2, weights=uniform;, score=0.858 total time=   0.0s\n",
      "[CV 2/5] END algorithm=auto, leaf_size=13, n_neighbors=5, p=2, weights=uniform;, score=0.874 total time=   0.0s\n",
      "[CV 4/5] END algorithm=brute, leaf_size=10, n_neighbors=272, p=2, weights=distance;, score=0.639 total time=   0.0s\n",
      "[CV 5/5] END algorithm=brute, leaf_size=10, n_neighbors=272, p=2, weights=distance;, score=0.663 total time=   0.0s\n",
      "[CV 1/5] END algorithm=ball_tree, leaf_size=5, n_neighbors=307, p=1, weights=distance;, score=0.675 total time=   0.0s\n",
      "[CV 2/5] END algorithm=ball_tree, leaf_size=5, n_neighbors=307, p=1, weights=distance;, score=0.675 total time=   0.0s\n",
      "[CV 5/5] END algorithm=ball_tree, leaf_size=20, n_neighbors=26, p=1, weights=distance;, score=0.857 total time=   0.0s\n",
      "[CV 1/5] END algorithm=kd_tree, leaf_size=8, n_neighbors=26, p=2, weights=uniform;, score=0.819 total time=   0.0s\n",
      "KNeighborsRegressor() RandomCV Best Params : {'weights': 'uniform', 'p': 2, 'n_neighbors': 5, 'leaf_size': 13, 'algorithm': 'auto'}\n",
      "KNeighborsRegressor() RandomCV Score: 0.8713196886668324\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 4/5] END algorithm=ball_tree, leaf_size=11, n_neighbors=328, p=2, weights=distance;, score=0.592 total time=   0.0s\n",
      "[CV 5/5] END algorithm=brute, leaf_size=20, n_neighbors=251, p=1, weights=distance;, score=0.720 total time=   0.0s\n",
      "[CV 1/5] END algorithm=kd_tree, leaf_size=11, n_neighbors=350, p=1, weights=distance;, score=0.646 total time=   0.0s\n",
      "[CV 2/5] END algorithm=kd_tree, leaf_size=11, n_neighbors=350, p=1, weights=distance;, score=0.647 total time=   0.0s\n",
      "[CV 3/5] END algorithm=kd_tree, leaf_size=11, n_neighbors=350, p=1, weights=distance;, score=0.670 total time=   0.0s\n",
      "[CV 4/5] END algorithm=kd_tree, leaf_size=11, n_neighbors=350, p=1, weights=distance;, score=0.615 total time=   0.0s\n",
      "[CV 5/5] END algorithm=kd_tree, leaf_size=11, n_neighbors=350, p=1, weights=distance;, score=0.654 total time=   0.0s\n",
      "[CV 1/5] END algorithm=ball_tree, leaf_size=10, n_neighbors=265, p=1, weights=uniform;, score=0.611 total time=   0.0s\n",
      "[CV 2/5] END algorithm=ball_tree, leaf_size=10, n_neighbors=265, p=1, weights=uniform;, score=0.634 total time=   0.0s\n",
      "[CV 2/5] END algorithm=brute, leaf_size=15, n_neighbors=103, p=2, weights=distance;, score=0.763 total time=   0.0s\n",
      "[CV 3/5] END algorithm=brute, leaf_size=15, n_neighbors=103, p=2, weights=distance;, score=0.812 total time=   0.0s\n",
      "[CV 4/5] END algorithm=brute, leaf_size=15, n_neighbors=103, p=2, weights=distance;, score=0.785 total time=   0.0s\n",
      "[CV 5/5] END algorithm=brute, leaf_size=15, n_neighbors=103, p=2, weights=distance;, score=0.777 total time=   0.0s\n",
      "[CV 1/5] END algorithm=brute, leaf_size=11, n_neighbors=230, p=2, weights=distance;, score=0.686 total time=   0.0s\n",
      "[CV 2/5] END algorithm=brute, leaf_size=11, n_neighbors=230, p=2, weights=distance;, score=0.680 total time=   0.0s\n",
      "[CV 3/5] END algorithm=brute, leaf_size=11, n_neighbors=230, p=2, weights=distance;, score=0.731 total time=   0.0s\n",
      "[CV 4/5] END algorithm=brute, leaf_size=11, n_neighbors=230, p=2, weights=distance;, score=0.676 total time=   0.0s\n",
      "[CV 3/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=286, p=2, weights=distance;, score=0.689 total time=   0.0s\n",
      "[CV 4/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=286, p=2, weights=distance;, score=0.627 total time=   0.0s\n",
      "[CV 5/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=286, p=2, weights=distance;, score=0.654 total time=   0.0s\n",
      "[CV 1/5] END algorithm=ball_tree, leaf_size=11, n_neighbors=230, p=1, weights=distance;, score=0.721 total time=   0.0s\n",
      "[CV 2/5] END algorithm=ball_tree, leaf_size=11, n_neighbors=230, p=1, weights=distance;, score=0.718 total time=   0.0s\n",
      "[CV 3/5] END algorithm=ball_tree, leaf_size=11, n_neighbors=230, p=1, weights=distance;, score=0.750 total time=   0.0s\n",
      "[CV 4/5] END algorithm=ball_tree, leaf_size=11, n_neighbors=230, p=1, weights=distance;, score=0.704 total time=   0.0s\n",
      "[CV 5/5] END algorithm=ball_tree, leaf_size=11, n_neighbors=230, p=1, weights=distance;, score=0.733 total time=   0.0s\n",
      "[CV 1/5] END algorithm=ball_tree, leaf_size=15, n_neighbors=286, p=2, weights=uniform;, score=0.535 total time=   0.0s\n",
      "[CV 2/5] END algorithm=ball_tree, leaf_size=15, n_neighbors=286, p=2, weights=uniform;, score=0.566 total time=   0.0s\n",
      "[CV 3/5] END algorithm=ball_tree, leaf_size=15, n_neighbors=286, p=2, weights=uniform;, score=0.606 total time=   0.0s\n",
      "[CV 4/5] END algorithm=ball_tree, leaf_size=15, n_neighbors=286, p=2, weights=uniform;, score=0.507 total time=   0.0s\n",
      "[CV 5/5] END algorithm=ball_tree, leaf_size=15, n_neighbors=286, p=2, weights=uniform;, score=0.560 total time=   0.0s\n",
      "[CV 1/5] END algorithm=kd_tree, leaf_size=13, n_neighbors=293, p=1, weights=distance;, score=0.685 total time=   0.0s\n",
      "[CV 2/5] END algorithm=kd_tree, leaf_size=13, n_neighbors=293, p=1, weights=distance;, score=0.684 total time=   0.0s\n",
      "[CV 3/5] END algorithm=kd_tree, leaf_size=13, n_neighbors=293, p=1, weights=distance;, score=0.712 total time=   0.0s\n",
      "[CV 4/5] END algorithm=ball_tree, leaf_size=8, n_neighbors=117, p=1, weights=distance;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END algorithm=ball_tree, leaf_size=8, n_neighbors=117, p=1, weights=distance;, score=0.796 total time=   0.0s\n",
      "[CV 1/5] END algorithm=auto, leaf_size=8, n_neighbors=117, p=1, weights=distance;, score=0.789 total time=   0.0s\n",
      "[CV 2/5] END algorithm=auto, leaf_size=8, n_neighbors=117, p=1, weights=distance;, score=0.772 total time=   0.0s\n",
      "[CV 3/5] END algorithm=auto, leaf_size=8, n_neighbors=117, p=1, weights=distance;, score=0.819 total time=   0.0s\n",
      "[CV 4/5] END algorithm=auto, leaf_size=8, n_neighbors=117, p=1, weights=distance;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END algorithm=auto, leaf_size=8, n_neighbors=117, p=1, weights=distance;, score=0.796 total time=   0.0s\n",
      "[CV 1/5] END algorithm=ball_tree, leaf_size=11, n_neighbors=145, p=2, weights=uniform;, score=0.686 total time=   0.0s\n",
      "[CV 2/5] END algorithm=ball_tree, leaf_size=11, n_neighbors=145, p=2, weights=uniform;, score=0.682 total time=   0.0s\n",
      "[CV 3/5] END algorithm=ball_tree, leaf_size=11, n_neighbors=145, p=2, weights=uniform;, score=0.737 total time=   0.0s\n",
      "[CV 4/5] END algorithm=ball_tree, leaf_size=11, n_neighbors=145, p=2, weights=uniform;, score=0.681 total time=   0.0s\n",
      "[CV 5/5] END algorithm=ball_tree, leaf_size=11, n_neighbors=145, p=2, weights=uniform;, score=0.683 total time=   0.0s\n",
      "[CV 1/5] END algorithm=kd_tree, leaf_size=11, n_neighbors=286, p=1, weights=distance;, score=0.689 total time=   0.0s\n",
      "[CV 2/5] END algorithm=kd_tree, leaf_size=11, n_neighbors=286, p=1, weights=distance;, score=0.688 total time=   0.0s\n",
      "[CV 3/5] END algorithm=kd_tree, leaf_size=11, n_neighbors=286, p=1, weights=distance;, score=0.717 total time=   0.0s\n",
      "[CV 4/5] END algorithm=kd_tree, leaf_size=11, n_neighbors=286, p=1, weights=distance;, score=0.663 total time=   0.0s\n",
      "[CV 3/5] END algorithm=ball_tree, leaf_size=5, n_neighbors=265, p=1, weights=distance;, score=0.729 total time=   0.0s\n",
      "[CV 4/5] END algorithm=ball_tree, leaf_size=5, n_neighbors=265, p=1, weights=distance;, score=0.678 total time=   0.0s\n",
      "[CV 2/5] END algorithm=ball_tree, leaf_size=15, n_neighbors=159, p=2, weights=uniform;, score=0.669 total time=   0.0s\n",
      "[CV 3/5] END algorithm=ball_tree, leaf_size=15, n_neighbors=159, p=2, weights=uniform;, score=0.728 total time=   0.0s\n",
      "[CV 2/5] END algorithm=ball_tree, leaf_size=11, n_neighbors=75, p=1, weights=uniform;, score=0.761 total time=   0.0s\n",
      "[CV 3/5] END algorithm=ball_tree, leaf_size=11, n_neighbors=75, p=1, weights=uniform;, score=0.810 total time=   0.0s\n",
      "[CV 1/5] END algorithm=kd_tree, leaf_size=13, n_neighbors=230, p=1, weights=distance;, score=0.721 total time=   0.0s\n",
      "[CV 2/5] END algorithm=kd_tree, leaf_size=13, n_neighbors=230, p=1, weights=distance;, score=0.718 total time=   0.0s\n",
      "[CV 4/5] END algorithm=kd_tree, leaf_size=6, n_neighbors=159, p=2, weights=uniform;, score=0.664 total time=   0.0s\n",
      "[CV 5/5] END algorithm=kd_tree, leaf_size=6, n_neighbors=159, p=2, weights=uniform;, score=0.670 total time=   0.0s\n",
      "[CV 1/5] END algorithm=ball_tree, leaf_size=20, n_neighbors=26, p=1, weights=distance;, score=0.848 total time=   0.0s\n",
      "[CV 2/5] END algorithm=ball_tree, leaf_size=20, n_neighbors=26, p=1, weights=distance;, score=0.853 total time=   0.0s\n",
      "[CV 3/5] END algorithm=auto, leaf_size=8, n_neighbors=209, p=2, weights=uniform;, score=0.683 total time=   0.0s\n",
      "[CV 4/5] END algorithm=auto, leaf_size=8, n_neighbors=209, p=2, weights=uniform;, score=0.600 total time=   0.0s\n",
      "[CV 5/5] END algorithm=auto, leaf_size=15, n_neighbors=258, p=1, weights=distance;, score=0.715 total time=   0.0s\n",
      "[CV 1/5] END algorithm=auto, leaf_size=10, n_neighbors=173, p=1, weights=uniform;, score=0.686 total time=   0.0s\n",
      "[CV 5/5] END algorithm=auto, leaf_size=13, n_neighbors=19, p=1, weights=distance;, score=0.861 total time=   0.0s\n",
      "[CV 1/5] END algorithm=brute, leaf_size=6, n_neighbors=209, p=1, weights=distance;, score=0.732 total time=   0.0s\n",
      "[CV 2/5] END algorithm=ball_tree, leaf_size=10, n_neighbors=300, p=2, weights=uniform;, score=0.552 total time=   0.0s\n",
      "[CV 3/5] END algorithm=ball_tree, leaf_size=10, n_neighbors=300, p=2, weights=uniform;, score=0.588 total time=   0.0s\n",
      "Final score is  0.8713196886668324\n"
     ]
    }
   ],
   "source": [
    "hyperparameter_tuning(algo=\"KNeighborsRegressor()\",param_grid=random_grid,n_iter=100,cv=5,verbose=3,random_state=42,X_train=X_train.loc[:,list(selected_features)],Y_train=Y_train,X_test=X_test.loc[:,list(selected_features)],Y_test=Y_test,evaluation_metric=\"r2_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "069ec833-a925-419a-8248-08f94fe26d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "7a37b1b9-6464-4966-aec2-1f211e86fd59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  62 out of  62 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:51] Features: 1/62 -- score: 0.70646095151178[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  61 out of  61 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:51] Features: 2/62 -- score: 0.7502704460998386[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:51] Features: 3/62 -- score: 0.7637317537896153[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  59 out of  59 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:51] Features: 4/62 -- score: 0.7708405236196857[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  58 out of  58 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:51] Features: 5/62 -- score: 0.7752312346581502[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  57 out of  57 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:51] Features: 6/62 -- score: 0.7754236017996939[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  56 out of  56 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:51] Features: 7/62 -- score: 0.7776762525722061[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  55 out of  55 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:51] Features: 8/62 -- score: 0.779656421690951[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  54 out of  54 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:52] Features: 9/62 -- score: 0.7787915765543214[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  53 out of  53 | elapsed:    0.2s finished\n",
      "\n",
      "[2023-02-01 16:20:52] Features: 10/62 -- score: 0.778802854935685[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  52 out of  52 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:52] Features: 11/62 -- score: 0.7684619021702052[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  51 out of  51 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:52] Features: 12/62 -- score: 0.7745905669030577[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:52] Features: 13/62 -- score: 0.7760660084603714[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  38 out of  49 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  49 out of  49 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:52] Features: 14/62 -- score: 0.7743588058058639[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  37 out of  48 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:52] Features: 15/62 -- score: 0.7710430712613089[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  36 out of  47 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  47 out of  47 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:53] Features: 16/62 -- score: 0.7694897103620443[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  46 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  46 out of  46 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:53] Features: 17/62 -- score: 0.763568878160141[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:53] Features: 18/62 -- score: 0.763639394493306[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  44 out of  44 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:53] Features: 19/62 -- score: 0.7591215353186455[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  32 out of  43 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  43 out of  43 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:53] Features: 20/62 -- score: 0.750852574542924[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 out of  42 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:53] Features: 21/62 -- score: 0.7534430519527385[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  41 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  41 out of  41 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:53] Features: 22/62 -- score: 0.7622429086572503[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:54] Features: 23/62 -- score: 0.7660650185175358[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  28 out of  39 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  39 out of  39 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:54] Features: 24/62 -- score: 0.7536450369439252[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  38 out of  38 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:54] Features: 25/62 -- score: 0.752315952831325[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 out of  37 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  37 out of  37 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:54] Features: 26/62 -- score: 0.7459197932363791[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  36 out of  36 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:54] Features: 27/62 -- score: 0.7429233228001744[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  35 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:54] Features: 28/62 -- score: 0.742551246769343[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 out of  34 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:54] Features: 29/62 -- score: 0.7491858473896482[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  22 out of  33 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  33 out of  33 | elapsed:    0.2s finished\n",
      "\n",
      "[2023-02-01 16:20:55] Features: 30/62 -- score: 0.7443173455527836[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  32 out of  32 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:55] Features: 31/62 -- score: 0.7430162923140496[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  31 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  31 out of  31 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:55] Features: 32/62 -- score: 0.747207191489154[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:55] Features: 33/62 -- score: 0.7406937926257864[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  29 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  29 out of  29 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:55] Features: 34/62 -- score: 0.7435468371264986[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  28 out of  28 | elapsed:    0.2s finished\n",
      "\n",
      "[2023-02-01 16:20:55] Features: 35/62 -- score: 0.7719089397779234[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  27 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:    0.2s finished\n",
      "\n",
      "[2023-02-01 16:20:55] Features: 36/62 -- score: 0.7790732265159764[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 out of  26 | elapsed:    0.2s finished\n",
      "\n",
      "[2023-02-01 16:20:56] Features: 37/62 -- score: 0.7935502469319303[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  14 out of  25 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.2s finished\n",
      "\n",
      "[2023-02-01 16:20:56] Features: 38/62 -- score: 0.7960532682269836[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:56] Features: 39/62 -- score: 0.7975306791352337[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  23 out of  23 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:56] Features: 40/62 -- score: 0.8045317635994099[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  22 out of  22 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:56] Features: 41/62 -- score: 0.8047763763470771[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  21 out of  21 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  21 out of  21 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:56] Features: 42/62 -- score: 0.7944971456425346[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    0.2s finished\n",
      "\n",
      "[2023-02-01 16:20:56] Features: 43/62 -- score: 0.7991554792833334[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  19 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:57] Features: 44/62 -- score: 0.7901587571471369[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  18 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:57] Features: 45/62 -- score: 0.8001751194745849[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  17 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  17 out of  17 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:57] Features: 46/62 -- score: 0.7890713903037133[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  14 out of  16 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  16 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:57] Features: 47/62 -- score: 0.7857955759484838[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  15 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:57] Features: 48/62 -- score: 0.8015338356329893[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  14 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  14 out of  14 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:57] Features: 49/62 -- score: 0.8032193388393518[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of  13 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:57] Features: 50/62 -- score: 0.8090252807684484[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  12 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:57] Features: 51/62 -- score: 0.8033333601702664[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  11 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:58] Features: 52/62 -- score: 0.8112530888818832[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:58] Features: 53/62 -- score: 0.7988745421847565[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   9 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:58] Features: 54/62 -- score: 0.7969792156440235[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   8 | elapsed:    0.1s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:58] Features: 55/62 -- score: 0.7886239224323304[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   7 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:58] Features: 56/62 -- score: 0.7898209359395757[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:58] Features: 57/62 -- score: 0.7835556802739407[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:58] Features: 58/62 -- score: 0.7807570936164946[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   4 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:58] Features: 59/62 -- score: 0.7752255912848524[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features ('MSSubClass', 'LotArea', 'OverallQual', 'OverallCond', 'YearBuilt', 'BsmtFinSF1', 'TotalBsmtSF', 'GrLivArea', 'FullBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageYrBlt', 'GarageCars', 'GarageArea', 'YrSold', 'MSZoning', 'Street', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'MasVnrType', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtFinType1', 'BsmtFinType2', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual', 'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PavedDrive', 'SaleType', 'SaleCondition')\n",
      "Prediction using selected features using DecisionTreeRegressor() is : 0.6965560365416512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:58] Features: 60/62 -- score: 0.778249944219682[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:58] Features: 61/62 -- score: 0.7587019219645514[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:20:59] Features: 62/62 -- score: 0.7476039444964682"
     ]
    }
   ],
   "source": [
    "selected_features=sf_selector(algo=\"DecisionTreeRegressor()\",forward=True,floating=False,scoring=\"r2\",X_train=X_train,Y_train=Y_train,X_test=X_test,Y_test=Y_test,min_featues=3,cv=5,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "c872c965-0b16-4779-ad4e-2ca19d88165a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'splitter': ['best', 'random'], 'ccp_alpha': [1, 0], 'max_features': ['sqrt', 'log2'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190, 200, 210, 220, 230, 240, 250, 260, 270, 280, 290, 300, 310, 320, 330, 340, 350, 360, 370, 380, 390, 400, 410, 420, 430, 440, 450, 460, 470, 480, 490, 500, 510, 520, 530, 540, 550, 560, 570, 580, 590, 600, 610, 620, 630, 640, 650, 660, 670, 680, 690, 700, 710, 720, 730, 740, 750, 760, 770, 780, 790, 800, 810, 820, 830, 840, 850, 860, 870, 880, 890, 900, 910, 920, 930, 940, 950, 960, 970, 980, 990, 1000], 'min_samples_split': [2, 3, 4, 5, 10, 14], 'min_samples_leaf': [1, 2, 4, 6, 8], 'criterion': ['squared_error', 'absolute_error', 'friedman_mse', 'poisson']}\n"
     ]
    }
   ],
   "source": [
    "splitter=[\"best\", \"random\"]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['sqrt','log2']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 1000,100)]\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2,3,4, 5, 10,14]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1,2, 4,6,8]\n",
    "# Create the random grid\n",
    "random_grid = {'splitter':splitter,\n",
    "               'ccp_alpha':[1,0],\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "              'criterion':['squared_error','absolute_error','friedman_mse','poisson']}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "984c650c-943d-467d-a7bf-e43135b3b038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "[CV 2/5] END algorithm=ball_tree, leaf_size=13, n_neighbors=138, p=2, weights=uniform;, score=0.687 total time=   0.0s\n",
      "[CV 3/5] END algorithm=ball_tree, leaf_size=13, n_neighbors=138, p=2, weights=uniform;, score=0.745 total time=   0.0s\n",
      "[CV 2/5] END algorithm=auto, leaf_size=13, n_neighbors=33, p=1, weights=distance;, score=0.845 total time=   0.0s\n",
      "[CV 3/5] END algorithm=auto, leaf_size=13, n_neighbors=33, p=1, weights=distance;, score=0.869 total time=   0.0s\n",
      "[CV 4/5] END algorithm=auto, leaf_size=13, n_neighbors=33, p=1, weights=distance;, score=0.863 total time=   0.0s\n",
      "[CV 5/5] END algorithm=auto, leaf_size=13, n_neighbors=33, p=1, weights=distance;, score=0.853 total time=   0.0s\n",
      "[CV 1/5] END algorithm=ball_tree, leaf_size=11, n_neighbors=26, p=2, weights=distance;, score=0.842 total time=   0.0s\n",
      "[CV 2/5] END algorithm=ball_tree, leaf_size=11, n_neighbors=26, p=2, weights=distance;, score=0.842 total time=   0.0s\n",
      "[CV 3/5] END algorithm=ball_tree, leaf_size=11, n_neighbors=26, p=2, weights=distance;, score=0.864 total time=   0.0s\n",
      "[CV 4/5] END algorithm=ball_tree, leaf_size=11, n_neighbors=26, p=2, weights=distance;, score=0.863 total time=   0.0s\n",
      "[CV 5/5] END algorithm=ball_tree, leaf_size=11, n_neighbors=26, p=2, weights=distance;, score=0.843 total time=   0.0s\n",
      "[CV 1/5] END algorithm=ball_tree, leaf_size=10, n_neighbors=209, p=1, weights=uniform;, score=0.655 total time=   0.0s\n",
      "[CV 2/5] END algorithm=ball_tree, leaf_size=10, n_neighbors=209, p=1, weights=uniform;, score=0.668 total time=   0.0s\n",
      "[CV 3/5] END algorithm=ball_tree, leaf_size=10, n_neighbors=209, p=1, weights=uniform;, score=0.697 total time=   0.0s\n",
      "[CV 4/5] END algorithm=ball_tree, leaf_size=10, n_neighbors=209, p=1, weights=uniform;, score=0.632 total time=   0.0s\n",
      "[CV 5/5] END algorithm=ball_tree, leaf_size=10, n_neighbors=209, p=1, weights=uniform;, score=0.677 total time=   0.0s\n",
      "[CV 1/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=286, p=2, weights=distance;, score=0.647 total time=   0.0s\n",
      "[CV 2/5] END algorithm=kd_tree, leaf_size=15, n_neighbors=286, p=2, weights=distance;, score=0.646 total time=   0.0s\n",
      "[CV 2/5] END algorithm=brute, leaf_size=18, n_neighbors=230, p=2, weights=distance;, score=0.680 total time=   0.0s\n",
      "[CV 3/5] END algorithm=brute, leaf_size=18, n_neighbors=230, p=2, weights=distance;, score=0.731 total time=   0.0s\n",
      "[CV 4/5] END algorithm=brute, leaf_size=18, n_neighbors=230, p=2, weights=distance;, score=0.676 total time=   0.0s\n",
      "[CV 5/5] END algorithm=brute, leaf_size=18, n_neighbors=230, p=2, weights=distance;, score=0.688 total time=   0.0s\n",
      "[CV 1/5] END algorithm=ball_tree, leaf_size=6, n_neighbors=96, p=1, weights=uniform;, score=0.754 total time=   0.0s\n",
      "[CV 2/5] END algorithm=ball_tree, leaf_size=6, n_neighbors=96, p=1, weights=uniform;, score=0.741 total time=   0.0s\n",
      "[CV 3/5] END algorithm=ball_tree, leaf_size=6, n_neighbors=96, p=1, weights=uniform;, score=0.791 total time=   0.0s\n",
      "[CV 4/5] END algorithm=ball_tree, leaf_size=6, n_neighbors=96, p=1, weights=uniform;, score=0.748 total time=   0.0s\n",
      "[CV 5/5] END algorithm=ball_tree, leaf_size=6, n_neighbors=96, p=1, weights=uniform;, score=0.770 total time=   0.0s\n",
      "[CV 1/5] END algorithm=brute, leaf_size=10, n_neighbors=96, p=2, weights=uniform;, score=0.743 total time=   0.0s\n",
      "[CV 2/5] END algorithm=brute, leaf_size=10, n_neighbors=96, p=2, weights=uniform;, score=0.728 total time=   0.0s\n",
      "[CV 3/5] END algorithm=brute, leaf_size=10, n_neighbors=96, p=2, weights=uniform;, score=0.782 total time=   0.0s\n",
      "[CV 4/5] END algorithm=brute, leaf_size=10, n_neighbors=96, p=2, weights=uniform;, score=0.737 total time=   0.0s\n",
      "[CV 5/5] END algorithm=brute, leaf_size=10, n_neighbors=96, p=2, weights=uniform;, score=0.739 total time=   0.0s\n",
      "[CV 1/5] END algorithm=brute, leaf_size=15, n_neighbors=82, p=1, weights=uniform;, score=0.765 total time=   0.0s\n",
      "[CV 2/5] END algorithm=brute, leaf_size=15, n_neighbors=82, p=1, weights=uniform;, score=0.750 total time=   0.0s\n",
      "[CV 3/5] END algorithm=brute, leaf_size=20, n_neighbors=68, p=2, weights=distance;, score=0.836 total time=   0.0s\n",
      "[CV 4/5] END algorithm=brute, leaf_size=20, n_neighbors=68, p=2, weights=distance;, score=0.821 total time=   0.0s\n",
      "[CV 5/5] END algorithm=brute, leaf_size=20, n_neighbors=68, p=2, weights=distance;, score=0.805 total time=   0.0s\n",
      "[CV 1/5] END algorithm=auto, leaf_size=20, n_neighbors=19, p=2, weights=distance;, score=0.849 total time=   0.0s\n",
      "[CV 2/5] END algorithm=auto, leaf_size=20, n_neighbors=19, p=2, weights=distance;, score=0.855 total time=   0.0s\n",
      "[CV 3/5] END algorithm=auto, leaf_size=20, n_neighbors=19, p=2, weights=distance;, score=0.867 total time=   0.0s\n",
      "[CV 4/5] END algorithm=auto, leaf_size=20, n_neighbors=19, p=2, weights=distance;, score=0.869 total time=   0.0s\n",
      "[CV 5/5] END algorithm=auto, leaf_size=20, n_neighbors=19, p=2, weights=distance;, score=0.850 total time=   0.0s\n",
      "[CV 3/5] END algorithm=auto, leaf_size=13, n_neighbors=258, p=1, weights=uniform;, score=0.656 total time=   0.0s\n",
      "[CV 4/5] END algorithm=auto, leaf_size=13, n_neighbors=258, p=1, weights=uniform;, score=0.582 total time=   0.0s\n",
      "[CV 1/5] END algorithm=ball_tree, leaf_size=5, n_neighbors=265, p=1, weights=distance;, score=0.702 total time=   0.0s\n",
      "[CV 2/5] END algorithm=ball_tree, leaf_size=5, n_neighbors=265, p=1, weights=distance;, score=0.701 total time=   0.0s\n",
      "[CV 3/5] END algorithm=brute, leaf_size=6, n_neighbors=209, p=2, weights=distance;, score=0.745 total time=   0.0s\n",
      "[CV 4/5] END algorithm=brute, leaf_size=6, n_neighbors=209, p=2, weights=distance;, score=0.695 total time=   0.0s\n",
      "[CV 5/5] END algorithm=auto, leaf_size=10, n_neighbors=145, p=2, weights=uniform;, score=0.683 total time=   0.0s\n",
      "[CV 1/5] END algorithm=ball_tree, leaf_size=11, n_neighbors=75, p=1, weights=uniform;, score=0.771 total time=   0.0s\n",
      "[CV 3/5] END algorithm=kd_tree, leaf_size=13, n_neighbors=230, p=1, weights=distance;, score=0.750 total time=   0.0s\n",
      "[CV 4/5] END algorithm=kd_tree, leaf_size=13, n_neighbors=230, p=1, weights=distance;, score=0.704 total time=   0.0s\n",
      "[CV 5/5] END algorithm=ball_tree, leaf_size=5, n_neighbors=307, p=1, weights=distance;, score=0.683 total time=   0.0s\n",
      "[CV 1/5] END algorithm=auto, leaf_size=8, n_neighbors=145, p=2, weights=distance;, score=0.751 total time=   0.0s\n",
      "[CV 4/5] END algorithm=kd_tree, leaf_size=8, n_neighbors=26, p=2, weights=uniform;, score=0.842 total time=   0.0s\n",
      "[CV 5/5] END algorithm=kd_tree, leaf_size=8, n_neighbors=26, p=2, weights=uniform;, score=0.826 total time=   0.0s\n",
      "[CV 1/5] END algorithm=auto, leaf_size=15, n_neighbors=258, p=1, weights=distance;, score=0.706 total time=   0.0s\n",
      "[CV 2/5] END algorithm=auto, leaf_size=15, n_neighbors=258, p=1, weights=distance;, score=0.705 total time=   0.0s\n",
      "[CV 1/5] END algorithm=auto, leaf_size=13, n_neighbors=19, p=1, weights=distance;, score=0.853 total time=   0.0s\n",
      "[CV 2/5] END algorithm=auto, leaf_size=13, n_neighbors=19, p=1, weights=distance;, score=0.862 total time=   0.0s\n",
      "[CV 4/5] END algorithm=brute, leaf_size=6, n_neighbors=209, p=1, weights=distance;, score=0.719 total time=   0.0s\n",
      "[CV 5/5] END algorithm=brute, leaf_size=6, n_neighbors=209, p=1, weights=distance;, score=0.744 total time=   0.0s\n",
      "[CV 1/5] END algorithm=auto, leaf_size=13, n_neighbors=5, p=2, weights=uniform;, score=0.858 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=1, criterion=absolute_error, max_depth=320, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.625 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=1, criterion=squared_error, max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, splitter=best;, score=0.721 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0, criterion=friedman_mse, max_depth=410, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, splitter=best;, score=0.781 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0, criterion=squared_error, max_depth=580, max_features=sqrt, min_samples_leaf=6, min_samples_split=14, splitter=best;, score=0.796 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0, criterion=squared_error, max_depth=580, max_features=sqrt, min_samples_leaf=6, min_samples_split=14, splitter=best;, score=0.822 total time=   0.0s\n",
      "[CV 5/5] END algorithm=brute, leaf_size=11, n_neighbors=230, p=2, weights=distance;, score=0.688 total time=   0.0s\n",
      "[CV 1/5] END algorithm=auto, leaf_size=18, n_neighbors=33, p=2, weights=uniform;, score=0.815 total time=   0.0s\n",
      "[CV 2/5] END algorithm=auto, leaf_size=18, n_neighbors=33, p=2, weights=uniform;, score=0.804 total time=   0.0s\n",
      "[CV 3/5] END algorithm=auto, leaf_size=18, n_neighbors=33, p=2, weights=uniform;, score=0.842 total time=   0.0s\n",
      "[CV 4/5] END algorithm=auto, leaf_size=18, n_neighbors=33, p=2, weights=uniform;, score=0.834 total time=   0.0s\n",
      "[CV 5/5] END algorithm=auto, leaf_size=18, n_neighbors=33, p=2, weights=uniform;, score=0.822 total time=   0.0s\n",
      "[CV 1/5] END algorithm=brute, leaf_size=11, n_neighbors=47, p=2, weights=uniform;, score=0.802 total time=   0.0s\n",
      "[CV 2/5] END algorithm=brute, leaf_size=11, n_neighbors=47, p=2, weights=uniform;, score=0.778 total time=   0.0s\n",
      "[CV 5/5] END algorithm=kd_tree, leaf_size=11, n_neighbors=321, p=1, weights=distance;, score=0.673 total time=   0.0s\n",
      "[CV 1/5] END algorithm=brute, leaf_size=6, n_neighbors=54, p=1, weights=uniform;, score=0.796 total time=   0.0s\n",
      "[CV 2/5] END algorithm=brute, leaf_size=6, n_neighbors=54, p=1, weights=uniform;, score=0.790 total time=   0.0s\n",
      "[CV 3/5] END algorithm=brute, leaf_size=6, n_neighbors=54, p=1, weights=uniform;, score=0.837 total time=   0.0s\n",
      "[CV 4/5] END algorithm=brute, leaf_size=6, n_neighbors=54, p=1, weights=uniform;, score=0.803 total time=   0.0s\n",
      "[CV 5/5] END algorithm=brute, leaf_size=6, n_neighbors=54, p=1, weights=uniform;, score=0.818 total time=   0.0s\n",
      "[CV 1/5] END algorithm=ball_tree, leaf_size=11, n_neighbors=216, p=1, weights=distance;, score=0.729 total time=   0.0s\n",
      "[CV 2/5] END algorithm=ball_tree, leaf_size=11, n_neighbors=216, p=1, weights=distance;, score=0.724 total time=   0.0s\n",
      "[CV 3/5] END algorithm=ball_tree, leaf_size=11, n_neighbors=216, p=1, weights=distance;, score=0.758 total time=   0.0s\n",
      "[CV 4/5] END algorithm=ball_tree, leaf_size=11, n_neighbors=216, p=1, weights=distance;, score=0.714 total time=   0.0s\n",
      "[CV 5/5] END algorithm=ball_tree, leaf_size=11, n_neighbors=216, p=1, weights=distance;, score=0.741 total time=   0.0s\n",
      "[CV 1/5] END algorithm=kd_tree, leaf_size=5, n_neighbors=33, p=2, weights=distance;, score=0.840 total time=   0.0s\n",
      "[CV 2/5] END algorithm=kd_tree, leaf_size=5, n_neighbors=33, p=2, weights=distance;, score=0.830 total time=   0.0s\n",
      "[CV 3/5] END algorithm=kd_tree, leaf_size=5, n_neighbors=33, p=2, weights=distance;, score=0.859 total time=   0.0s\n",
      "[CV 4/5] END algorithm=kd_tree, leaf_size=5, n_neighbors=33, p=2, weights=distance;, score=0.859 total time=   0.0s\n",
      "[CV 5/5] END algorithm=kd_tree, leaf_size=5, n_neighbors=33, p=2, weights=distance;, score=0.839 total time=   0.0s\n",
      "[CV 3/5] END algorithm=brute, leaf_size=15, n_neighbors=82, p=1, weights=uniform;, score=0.802 total time=   0.0s\n",
      "[CV 4/5] END algorithm=brute, leaf_size=15, n_neighbors=82, p=1, weights=uniform;, score=0.760 total time=   0.0s\n",
      "[CV 5/5] END algorithm=brute, leaf_size=15, n_neighbors=82, p=1, weights=uniform;, score=0.786 total time=   0.0s\n",
      "[CV 1/5] END algorithm=auto, leaf_size=11, n_neighbors=117, p=2, weights=uniform;, score=0.719 total time=   0.0s\n",
      "[CV 2/5] END algorithm=auto, leaf_size=11, n_neighbors=117, p=2, weights=uniform;, score=0.707 total time=   0.0s\n",
      "[CV 3/5] END algorithm=auto, leaf_size=11, n_neighbors=117, p=2, weights=uniform;, score=0.761 total time=   0.0s\n",
      "[CV 4/5] END algorithm=auto, leaf_size=11, n_neighbors=117, p=2, weights=uniform;, score=0.712 total time=   0.0s\n",
      "[CV 5/5] END algorithm=auto, leaf_size=11, n_neighbors=117, p=2, weights=uniform;, score=0.713 total time=   0.0s\n",
      "[CV 1/5] END algorithm=kd_tree, leaf_size=16, n_neighbors=335, p=2, weights=distance;, score=0.610 total time=   0.0s\n",
      "[CV 2/5] END algorithm=kd_tree, leaf_size=16, n_neighbors=335, p=2, weights=distance;, score=0.613 total time=   0.0s\n",
      "[CV 3/5] END algorithm=kd_tree, leaf_size=16, n_neighbors=335, p=2, weights=distance;, score=0.648 total time=   0.0s\n",
      "[CV 4/5] END algorithm=kd_tree, leaf_size=16, n_neighbors=335, p=2, weights=distance;, score=0.586 total time=   0.0s\n",
      "[CV 5/5] END algorithm=kd_tree, leaf_size=16, n_neighbors=335, p=2, weights=distance;, score=0.621 total time=   0.0s\n",
      "[CV 1/5] END algorithm=ball_tree, leaf_size=8, n_neighbors=117, p=1, weights=distance;, score=0.789 total time=   0.0s\n",
      "[CV 2/5] END algorithm=ball_tree, leaf_size=8, n_neighbors=117, p=1, weights=distance;, score=0.772 total time=   0.0s\n",
      "[CV 3/5] END algorithm=ball_tree, leaf_size=8, n_neighbors=117, p=1, weights=distance;, score=0.819 total time=   0.0s\n",
      "[CV 2/5] END algorithm=kd_tree, leaf_size=20, n_neighbors=47, p=2, weights=distance;, score=0.811 total time=   0.0s\n",
      "[CV 3/5] END algorithm=kd_tree, leaf_size=20, n_neighbors=47, p=2, weights=distance;, score=0.852 total time=   0.0s\n",
      "[CV 2/5] END algorithm=ball_tree, leaf_size=20, n_neighbors=230, p=1, weights=distance;, score=0.718 total time=   0.0s\n",
      "[CV 3/5] END algorithm=ball_tree, leaf_size=20, n_neighbors=230, p=1, weights=distance;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END algorithm=auto, leaf_size=10, n_neighbors=145, p=2, weights=uniform;, score=0.686 total time=   0.0s\n",
      "[CV 2/5] END algorithm=auto, leaf_size=10, n_neighbors=145, p=2, weights=uniform;, score=0.682 total time=   0.0s\n",
      "[CV 3/5] END algorithm=auto, leaf_size=13, n_neighbors=5, p=2, weights=uniform;, score=0.880 total time=   0.0s\n",
      "[CV 4/5] END algorithm=auto, leaf_size=13, n_neighbors=5, p=2, weights=uniform;, score=0.878 total time=   0.0s\n",
      "[CV 2/5] END algorithm=brute, leaf_size=10, n_neighbors=272, p=2, weights=distance;, score=0.656 total time=   0.0s\n",
      "[CV 3/5] END algorithm=brute, leaf_size=10, n_neighbors=272, p=2, weights=distance;, score=0.700 total time=   0.0s\n",
      "[CV 2/5] END algorithm=auto, leaf_size=8, n_neighbors=145, p=2, weights=distance;, score=0.731 total time=   0.0s\n",
      "[CV 3/5] END algorithm=auto, leaf_size=8, n_neighbors=145, p=2, weights=distance;, score=0.785 total time=   0.0s\n",
      "[CV 3/5] END algorithm=ball_tree, leaf_size=20, n_neighbors=26, p=1, weights=distance;, score=0.870 total time=   0.0s\n",
      "[CV 4/5] END algorithm=ball_tree, leaf_size=20, n_neighbors=26, p=1, weights=distance;, score=0.866 total time=   0.0s\n",
      "[CV 5/5] END algorithm=auto, leaf_size=8, n_neighbors=209, p=2, weights=uniform;, score=0.625 total time=   0.0s\n",
      "[CV 1/5] END algorithm=brute, leaf_size=11, n_neighbors=335, p=1, weights=uniform;, score=0.533 total time=   0.0s\n",
      "[CV 2/5] END algorithm=auto, leaf_size=10, n_neighbors=173, p=1, weights=uniform;, score=0.692 total time=   0.0s\n",
      "[CV 3/5] END algorithm=auto, leaf_size=10, n_neighbors=173, p=1, weights=uniform;, score=0.726 total time=   0.0s\n",
      "[CV 3/5] END algorithm=brute, leaf_size=8, n_neighbors=342, p=2, weights=distance;, score=0.643 total time=   0.0s\n",
      "[CV 4/5] END algorithm=brute, leaf_size=8, n_neighbors=342, p=2, weights=distance;, score=0.580 total time=   0.0s\n",
      "[CV 3/5] END algorithm=auto, leaf_size=13, n_neighbors=5, p=2, weights=uniform;, score=0.880 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=1, criterion=absolute_error, max_depth=320, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.554 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=1, criterion=squared_error, max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, splitter=best;, score=0.752 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0, criterion=friedman_mse, max_depth=410, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, splitter=best;, score=0.769 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0, criterion=friedman_mse, max_depth=410, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, splitter=best;, score=0.722 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=1, criterion=squared_error, max_depth=530, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=random;, score=0.584 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0, criterion=friedman_mse, max_depth=870, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=best;, score=0.706 total time=   0.0s\n",
      "[CV 1/5] END algorithm=kd_tree, leaf_size=6, n_neighbors=230, p=2, weights=distance;, score=0.686 total time=   0.0s\n",
      "[CV 2/5] END algorithm=kd_tree, leaf_size=6, n_neighbors=230, p=2, weights=distance;, score=0.680 total time=   0.0s\n",
      "[CV 3/5] END algorithm=kd_tree, leaf_size=6, n_neighbors=230, p=2, weights=distance;, score=0.731 total time=   0.0s\n",
      "[CV 4/5] END algorithm=kd_tree, leaf_size=6, n_neighbors=230, p=2, weights=distance;, score=0.676 total time=   0.0s\n",
      "[CV 5/5] END algorithm=kd_tree, leaf_size=6, n_neighbors=230, p=2, weights=distance;, score=0.688 total time=   0.0s\n",
      "[CV 1/5] END algorithm=brute, leaf_size=11, n_neighbors=350, p=2, weights=distance;, score=0.599 total time=   0.0s\n",
      "[CV 2/5] END algorithm=brute, leaf_size=11, n_neighbors=350, p=2, weights=distance;, score=0.601 total time=   0.0s\n",
      "[CV 3/5] END algorithm=brute, leaf_size=11, n_neighbors=350, p=2, weights=distance;, score=0.636 total time=   0.0s\n",
      "[CV 4/5] END algorithm=brute, leaf_size=11, n_neighbors=350, p=2, weights=distance;, score=0.573 total time=   0.0s\n",
      "[CV 5/5] END algorithm=brute, leaf_size=11, n_neighbors=350, p=2, weights=distance;, score=0.611 total time=   0.0s\n",
      "[CV 1/5] END algorithm=auto, leaf_size=15, n_neighbors=216, p=2, weights=uniform;, score=0.606 total time=   0.0s\n",
      "[CV 2/5] END algorithm=auto, leaf_size=15, n_neighbors=216, p=2, weights=uniform;, score=0.625 total time=   0.0s\n",
      "[CV 3/5] END algorithm=auto, leaf_size=15, n_neighbors=216, p=2, weights=uniform;, score=0.676 total time=   0.0s\n",
      "[CV 4/5] END algorithm=auto, leaf_size=15, n_neighbors=216, p=2, weights=uniform;, score=0.592 total time=   0.0s\n",
      "[CV 5/5] END algorithm=auto, leaf_size=15, n_neighbors=216, p=2, weights=uniform;, score=0.619 total time=   0.0s\n",
      "[CV 1/5] END algorithm=brute, leaf_size=18, n_neighbors=230, p=2, weights=distance;, score=0.686 total time=   0.0s\n",
      "[CV 2/5] END algorithm=auto, leaf_size=6, n_neighbors=110, p=2, weights=distance;, score=0.758 total time=   0.0s\n",
      "[CV 3/5] END algorithm=auto, leaf_size=6, n_neighbors=110, p=2, weights=distance;, score=0.807 total time=   0.0s\n",
      "[CV 4/5] END algorithm=auto, leaf_size=6, n_neighbors=110, p=2, weights=distance;, score=0.779 total time=   0.0s\n",
      "[CV 5/5] END algorithm=auto, leaf_size=6, n_neighbors=110, p=2, weights=distance;, score=0.771 total time=   0.0s\n",
      "[CV 1/5] END algorithm=ball_tree, leaf_size=20, n_neighbors=12, p=2, weights=uniform;, score=0.842 total time=   0.0s\n",
      "[CV 2/5] END algorithm=ball_tree, leaf_size=20, n_neighbors=12, p=2, weights=uniform;, score=0.859 total time=   0.0s\n",
      "[CV 3/5] END algorithm=ball_tree, leaf_size=20, n_neighbors=12, p=2, weights=uniform;, score=0.865 total time=   0.0s\n",
      "[CV 4/5] END algorithm=ball_tree, leaf_size=20, n_neighbors=12, p=2, weights=uniform;, score=0.861 total time=   0.0s\n",
      "[CV 5/5] END algorithm=ball_tree, leaf_size=20, n_neighbors=12, p=2, weights=uniform;, score=0.853 total time=   0.0s\n",
      "[CV 1/5] END algorithm=kd_tree, leaf_size=5, n_neighbors=152, p=1, weights=uniform;, score=0.704 total time=   0.0s\n",
      "[CV 2/5] END algorithm=kd_tree, leaf_size=5, n_neighbors=152, p=1, weights=uniform;, score=0.703 total time=   0.0s\n",
      "[CV 3/5] END algorithm=kd_tree, leaf_size=5, n_neighbors=152, p=1, weights=uniform;, score=0.745 total time=   0.0s\n",
      "[CV 4/5] END algorithm=kd_tree, leaf_size=5, n_neighbors=152, p=1, weights=uniform;, score=0.688 total time=   0.0s\n",
      "[CV 5/5] END algorithm=kd_tree, leaf_size=5, n_neighbors=152, p=1, weights=uniform;, score=0.717 total time=   0.0s\n",
      "[CV 1/5] END algorithm=brute, leaf_size=20, n_neighbors=68, p=2, weights=distance;, score=0.812 total time=   0.0s\n",
      "[CV 2/5] END algorithm=brute, leaf_size=20, n_neighbors=68, p=2, weights=distance;, score=0.790 total time=   0.0s\n",
      "[CV 5/5] END algorithm=auto, leaf_size=13, n_neighbors=258, p=1, weights=uniform;, score=0.635 total time=   0.0s\n",
      "[CV 1/5] END algorithm=kd_tree, leaf_size=20, n_neighbors=47, p=2, weights=distance;, score=0.831 total time=   0.0s\n",
      "[CV 1/5] END algorithm=brute, leaf_size=6, n_neighbors=209, p=2, weights=distance;, score=0.702 total time=   0.0s\n",
      "[CV 2/5] END algorithm=brute, leaf_size=6, n_neighbors=209, p=2, weights=distance;, score=0.693 total time=   0.0s\n",
      "[CV 3/5] END algorithm=auto, leaf_size=10, n_neighbors=145, p=2, weights=uniform;, score=0.737 total time=   0.0s\n",
      "[CV 4/5] END algorithm=auto, leaf_size=10, n_neighbors=145, p=2, weights=uniform;, score=0.681 total time=   0.0s\n",
      "[CV 5/5] END algorithm=auto, leaf_size=13, n_neighbors=5, p=2, weights=uniform;, score=0.879 total time=   0.0s\n",
      "[CV 1/5] END algorithm=brute, leaf_size=10, n_neighbors=272, p=2, weights=distance;, score=0.657 total time=   0.0s\n",
      "[CV 2/5] END algorithm=kd_tree, leaf_size=6, n_neighbors=159, p=2, weights=uniform;, score=0.669 total time=   0.0s\n",
      "[CV 3/5] END algorithm=kd_tree, leaf_size=6, n_neighbors=159, p=2, weights=uniform;, score=0.728 total time=   0.0s\n",
      "[CV 4/5] END algorithm=auto, leaf_size=8, n_neighbors=145, p=2, weights=distance;, score=0.751 total time=   0.0s\n",
      "[CV 5/5] END algorithm=auto, leaf_size=8, n_neighbors=145, p=2, weights=distance;, score=0.742 total time=   0.0s\n",
      "[CV 1/5] END algorithm=auto, leaf_size=8, n_neighbors=209, p=2, weights=uniform;, score=0.614 total time=   0.0s\n",
      "[CV 2/5] END algorithm=auto, leaf_size=8, n_neighbors=209, p=2, weights=uniform;, score=0.632 total time=   0.0s\n",
      "[CV 3/5] END algorithm=auto, leaf_size=15, n_neighbors=258, p=1, weights=distance;, score=0.734 total time=   0.0s\n",
      "[CV 4/5] END algorithm=auto, leaf_size=15, n_neighbors=258, p=1, weights=distance;, score=0.684 total time=   0.0s\n",
      "[CV 2/5] END algorithm=brute, leaf_size=6, n_neighbors=209, p=1, weights=distance;, score=0.727 total time=   0.0s\n",
      "[CV 3/5] END algorithm=brute, leaf_size=6, n_neighbors=209, p=1, weights=distance;, score=0.763 total time=   0.0s\n",
      "[CV 4/5] END algorithm=ball_tree, leaf_size=10, n_neighbors=300, p=2, weights=uniform;, score=0.491 total time=   0.0s\n",
      "[CV 5/5] END algorithm=ball_tree, leaf_size=10, n_neighbors=300, p=2, weights=uniform;, score=0.547 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=1, criterion=absolute_error, max_depth=320, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.614 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0, criterion=friedman_mse, max_depth=410, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, splitter=best;, score=0.824 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=1, criterion=squared_error, max_depth=530, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=random;, score=0.803 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=1, criterion=squared_error, max_depth=530, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=random;, score=0.681 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=1, criterion=poisson, max_depth=100, max_features=log2, min_samples_leaf=8, min_samples_split=5, splitter=best;, score=0.702 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0, criterion=poisson, max_depth=300, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=best;, score=0.745 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=1, criterion=poisson, max_depth=680, max_features=log2, min_samples_leaf=4, min_samples_split=5, splitter=random;, score=0.651 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0, criterion=absolute_error, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=14, splitter=random;, score=0.683 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0, criterion=absolute_error, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=14, splitter=random;, score=0.740 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0, criterion=absolute_error, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=14, splitter=random;, score=0.815 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=1, criterion=squared_error, max_depth=70, max_features=sqrt, min_samples_leaf=8, min_samples_split=2, splitter=random;, score=0.743 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=1, criterion=squared_error, max_depth=70, max_features=sqrt, min_samples_leaf=8, min_samples_split=2, splitter=random;, score=0.727 total time=   0.0s\n",
      "[CV 3/5] END algorithm=kd_tree, leaf_size=8, n_neighbors=26, p=2, weights=uniform;, score=0.852 total time=   0.0s\n",
      "[CV 4/5] END algorithm=brute, leaf_size=11, n_neighbors=335, p=1, weights=uniform;, score=0.489 total time=   0.0s\n",
      "[CV 5/5] END algorithm=brute, leaf_size=11, n_neighbors=335, p=1, weights=uniform;, score=0.550 total time=   0.0s\n",
      "[CV 3/5] END algorithm=auto, leaf_size=13, n_neighbors=19, p=1, weights=distance;, score=0.878 total time=   0.0s\n",
      "[CV 4/5] END algorithm=auto, leaf_size=13, n_neighbors=19, p=1, weights=distance;, score=0.872 total time=   0.0s\n",
      "[CV 1/5] END algorithm=brute, leaf_size=8, n_neighbors=342, p=2, weights=distance;, score=0.605 total time=   0.0s\n",
      "[CV 2/5] END algorithm=brute, leaf_size=8, n_neighbors=342, p=2, weights=distance;, score=0.608 total time=   0.0s\n",
      "[CV 2/5] END algorithm=auto, leaf_size=13, n_neighbors=5, p=2, weights=uniform;, score=0.874 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=1, criterion=absolute_error, max_depth=320, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.589 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=1, criterion=squared_error, max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, splitter=best;, score=0.777 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0, criterion=friedman_mse, max_depth=410, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, splitter=best;, score=0.741 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0, criterion=squared_error, max_depth=580, max_features=sqrt, min_samples_leaf=6, min_samples_split=14, splitter=best;, score=0.698 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0, criterion=friedman_mse, max_depth=870, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=best;, score=0.765 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0, criterion=friedman_mse, max_depth=870, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=best;, score=0.822 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0, criterion=poisson, max_depth=300, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=best;, score=0.792 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0, criterion=poisson, max_depth=300, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=best;, score=0.767 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0, criterion=poisson, max_depth=300, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=best;, score=0.737 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0, criterion=poisson, max_depth=300, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=best;, score=0.661 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0, criterion=absolute_error, max_depth=610, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, splitter=random;, score=0.760 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0, criterion=absolute_error, max_depth=610, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, splitter=random;, score=0.735 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0, criterion=absolute_error, max_depth=610, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, splitter=random;, score=0.724 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0, criterion=absolute_error, max_depth=610, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, splitter=random;, score=0.700 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0, criterion=absolute_error, max_depth=670, max_features=sqrt, min_samples_leaf=8, min_samples_split=2, splitter=random;, score=0.735 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0, criterion=absolute_error, max_depth=670, max_features=sqrt, min_samples_leaf=8, min_samples_split=2, splitter=random;, score=0.688 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0, criterion=absolute_error, max_depth=670, max_features=sqrt, min_samples_leaf=8, min_samples_split=2, splitter=random;, score=0.539 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=1, criterion=squared_error, max_depth=450, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=random;, score=0.683 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=1, criterion=squared_error, max_depth=450, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=random;, score=0.800 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=1, criterion=squared_error, max_depth=450, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=random;, score=0.827 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=1, criterion=squared_error, max_depth=450, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=random;, score=0.738 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=1, criterion=squared_error, max_depth=450, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=random;, score=0.683 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=1, criterion=squared_error, max_depth=230, max_features=log2, min_samples_leaf=6, min_samples_split=14, splitter=random;, score=0.669 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=1, criterion=squared_error, max_depth=230, max_features=log2, min_samples_leaf=6, min_samples_split=14, splitter=random;, score=0.466 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0, criterion=squared_error, max_depth=930, max_features=log2, min_samples_leaf=8, min_samples_split=3, splitter=best;, score=0.762 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0, criterion=squared_error, max_depth=930, max_features=log2, min_samples_leaf=8, min_samples_split=3, splitter=best;, score=0.751 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0, criterion=squared_error, max_depth=930, max_features=log2, min_samples_leaf=8, min_samples_split=3, splitter=best;, score=0.810 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0, criterion=squared_error, max_depth=930, max_features=log2, min_samples_leaf=8, min_samples_split=3, splitter=best;, score=0.644 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0, criterion=squared_error, max_depth=930, max_features=log2, min_samples_leaf=8, min_samples_split=3, splitter=best;, score=0.707 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0, criterion=absolute_error, max_depth=480, max_features=log2, min_samples_leaf=4, min_samples_split=2, splitter=random;, score=0.693 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0, criterion=absolute_error, max_depth=570, max_features=log2, min_samples_leaf=2, min_samples_split=14, splitter=random;, score=0.576 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0, criterion=absolute_error, max_depth=570, max_features=log2, min_samples_leaf=2, min_samples_split=14, splitter=random;, score=0.784 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0, criterion=absolute_error, max_depth=570, max_features=log2, min_samples_leaf=2, min_samples_split=14, splitter=random;, score=0.642 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0, criterion=absolute_error, max_depth=570, max_features=log2, min_samples_leaf=2, min_samples_split=14, splitter=random;, score=0.736 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0, criterion=absolute_error, max_depth=570, max_features=log2, min_samples_leaf=2, min_samples_split=14, splitter=random;, score=0.563 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=1, criterion=friedman_mse, max_depth=630, max_features=log2, min_samples_leaf=8, min_samples_split=3, splitter=random;, score=0.514 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=1, criterion=friedman_mse, max_depth=630, max_features=log2, min_samples_leaf=8, min_samples_split=3, splitter=random;, score=0.604 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=1, criterion=friedman_mse, max_depth=630, max_features=log2, min_samples_leaf=8, min_samples_split=3, splitter=random;, score=0.725 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=1, criterion=friedman_mse, max_depth=630, max_features=log2, min_samples_leaf=8, min_samples_split=3, splitter=random;, score=0.632 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=1, criterion=friedman_mse, max_depth=630, max_features=log2, min_samples_leaf=8, min_samples_split=3, splitter=random;, score=0.639 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=1, criterion=squared_error, max_depth=950, max_features=log2, min_samples_leaf=8, min_samples_split=5, splitter=best;, score=0.762 total time=   0.0s\n",
      "[CV 2/5] END algorithm=brute, leaf_size=11, n_neighbors=335, p=1, weights=uniform;, score=0.562 total time=   0.0s\n",
      "[CV 3/5] END algorithm=brute, leaf_size=11, n_neighbors=335, p=1, weights=uniform;, score=0.571 total time=   0.0s\n",
      "[CV 4/5] END algorithm=auto, leaf_size=10, n_neighbors=173, p=1, weights=uniform;, score=0.669 total time=   0.0s\n",
      "[CV 5/5] END algorithm=auto, leaf_size=10, n_neighbors=173, p=1, weights=uniform;, score=0.703 total time=   0.0s\n",
      "[CV 5/5] END algorithm=brute, leaf_size=8, n_neighbors=342, p=2, weights=distance;, score=0.616 total time=   0.0s\n",
      "[CV 1/5] END algorithm=ball_tree, leaf_size=10, n_neighbors=300, p=2, weights=uniform;, score=0.520 total time=   0.0s\n",
      "[CV 4/5] END algorithm=auto, leaf_size=13, n_neighbors=5, p=2, weights=uniform;, score=0.878 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=1, criterion=squared_error, max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, splitter=best;, score=0.701 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=1, criterion=squared_error, max_depth=530, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=random;, score=0.670 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=1, criterion=squared_error, max_depth=530, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=random;, score=0.768 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0, criterion=friedman_mse, max_depth=870, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=best;, score=0.690 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0, criterion=friedman_mse, max_depth=870, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=best;, score=0.777 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0, criterion=absolute_error, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=14, splitter=random;, score=0.648 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0, criterion=absolute_error, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=14, splitter=random;, score=0.567 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=1, criterion=absolute_error, max_depth=340, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.748 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=1, criterion=absolute_error, max_depth=340, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.587 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0, criterion=squared_error, max_depth=980, max_features=log2, min_samples_leaf=4, min_samples_split=14, splitter=random;, score=0.672 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0, criterion=squared_error, max_depth=980, max_features=log2, min_samples_leaf=4, min_samples_split=14, splitter=random;, score=0.780 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0, criterion=squared_error, max_depth=980, max_features=log2, min_samples_leaf=4, min_samples_split=14, splitter=random;, score=0.584 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0, criterion=squared_error, max_depth=980, max_features=log2, min_samples_leaf=4, min_samples_split=14, splitter=random;, score=0.662 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0, criterion=squared_error, max_depth=480, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=random;, score=0.683 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0, criterion=squared_error, max_depth=480, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=random;, score=0.694 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0, criterion=poisson, max_depth=110, max_features=log2, min_samples_leaf=6, min_samples_split=10, splitter=random;, score=0.575 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0, criterion=poisson, max_depth=110, max_features=log2, min_samples_leaf=6, min_samples_split=10, splitter=random;, score=0.741 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0, criterion=poisson, max_depth=110, max_features=log2, min_samples_leaf=6, min_samples_split=10, splitter=random;, score=0.659 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0, criterion=poisson, max_depth=110, max_features=log2, min_samples_leaf=6, min_samples_split=10, splitter=random;, score=0.628 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0, criterion=poisson, max_depth=110, max_features=log2, min_samples_leaf=6, min_samples_split=10, splitter=random;, score=0.546 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=1, criterion=friedman_mse, max_depth=400, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.743 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=1, criterion=absolute_error, max_depth=540, max_features=log2, min_samples_leaf=1, min_samples_split=14, splitter=random;, score=0.734 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=1, criterion=absolute_error, max_depth=540, max_features=log2, min_samples_leaf=1, min_samples_split=14, splitter=random;, score=0.697 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=1, criterion=absolute_error, max_depth=540, max_features=log2, min_samples_leaf=1, min_samples_split=14, splitter=random;, score=0.661 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=1, criterion=absolute_error, max_depth=540, max_features=log2, min_samples_leaf=1, min_samples_split=14, splitter=random;, score=0.687 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=1, criterion=absolute_error, max_depth=540, max_features=log2, min_samples_leaf=1, min_samples_split=14, splitter=random;, score=0.636 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=1, criterion=squared_error, max_depth=230, max_features=log2, min_samples_leaf=6, min_samples_split=14, splitter=random;, score=0.642 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=1, criterion=squared_error, max_depth=230, max_features=log2, min_samples_leaf=6, min_samples_split=14, splitter=random;, score=0.644 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=1, criterion=squared_error, max_depth=230, max_features=log2, min_samples_leaf=6, min_samples_split=14, splitter=random;, score=0.715 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0, criterion=friedman_mse, max_depth=670, max_features=log2, min_samples_leaf=8, min_samples_split=14, splitter=best;, score=0.692 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0, criterion=friedman_mse, max_depth=670, max_features=log2, min_samples_leaf=8, min_samples_split=14, splitter=best;, score=0.735 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0, criterion=friedman_mse, max_depth=670, max_features=log2, min_samples_leaf=8, min_samples_split=14, splitter=best;, score=0.750 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0, criterion=poisson, max_depth=280, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.680 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0, criterion=poisson, max_depth=280, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.630 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0, criterion=poisson, max_depth=280, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.724 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0, criterion=poisson, max_depth=280, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.651 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0, criterion=poisson, max_depth=280, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.561 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=1, criterion=squared_error, max_depth=890, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=random;, score=0.588 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=1, criterion=squared_error, max_depth=890, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=1, criterion=squared_error, max_depth=890, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=random;, score=0.592 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=1, criterion=squared_error, max_depth=890, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=random;, score=0.726 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=1, criterion=squared_error, max_depth=890, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=random;, score=0.548 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=1, criterion=poisson, max_depth=100, max_features=log2, min_samples_leaf=8, min_samples_split=5, splitter=best;, score=0.812 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=1, criterion=poisson, max_depth=100, max_features=log2, min_samples_leaf=8, min_samples_split=5, splitter=best;, score=0.714 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=1, criterion=poisson, max_depth=430, max_features=sqrt, min_samples_leaf=8, min_samples_split=3, splitter=best;, score=0.804 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=1, criterion=poisson, max_depth=430, max_features=sqrt, min_samples_leaf=8, min_samples_split=3, splitter=best;, score=0.730 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=1, criterion=poisson, max_depth=430, max_features=sqrt, min_samples_leaf=8, min_samples_split=3, splitter=best;, score=0.694 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=1, criterion=poisson, max_depth=430, max_features=sqrt, min_samples_leaf=8, min_samples_split=3, splitter=best;, score=0.662 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0, criterion=absolute_error, max_depth=410, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, splitter=best;, score=0.776 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0, criterion=absolute_error, max_depth=410, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, splitter=best;, score=0.654 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=1, criterion=squared_error, max_depth=70, max_features=sqrt, min_samples_leaf=8, min_samples_split=2, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=1, criterion=squared_error, max_depth=70, max_features=sqrt, min_samples_leaf=8, min_samples_split=2, splitter=random;, score=0.794 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0, criterion=friedman_mse, max_depth=930, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.681 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0, criterion=friedman_mse, max_depth=930, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.614 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0, criterion=friedman_mse, max_depth=930, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.632 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0, criterion=friedman_mse, max_depth=930, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.689 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0, criterion=friedman_mse, max_depth=930, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.628 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0, criterion=squared_error, max_depth=480, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=random;, score=0.693 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0, criterion=squared_error, max_depth=480, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=random;, score=0.685 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0, criterion=squared_error, max_depth=480, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=random;, score=0.723 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=1, criterion=friedman_mse, max_depth=140, max_features=log2, min_samples_leaf=6, min_samples_split=3, splitter=best;, score=0.737 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=1, criterion=friedman_mse, max_depth=140, max_features=log2, min_samples_leaf=6, min_samples_split=3, splitter=best;, score=0.675 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=1, criterion=friedman_mse, max_depth=140, max_features=log2, min_samples_leaf=6, min_samples_split=3, splitter=best;, score=0.639 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0, criterion=poisson, max_depth=40, max_features=log2, min_samples_leaf=8, min_samples_split=14, splitter=best;, score=0.693 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0, criterion=poisson, max_depth=40, max_features=log2, min_samples_leaf=8, min_samples_split=14, splitter=best;, score=0.764 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0, criterion=poisson, max_depth=40, max_features=log2, min_samples_leaf=8, min_samples_split=14, splitter=best;, score=0.701 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0, criterion=poisson, max_depth=40, max_features=log2, min_samples_leaf=8, min_samples_split=14, splitter=best;, score=0.723 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0, criterion=poisson, max_depth=40, max_features=log2, min_samples_leaf=8, min_samples_split=14, splitter=best;, score=0.631 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0, criterion=absolute_error, max_depth=480, max_features=log2, min_samples_leaf=4, min_samples_split=2, splitter=random;, score=0.755 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0, criterion=absolute_error, max_depth=480, max_features=log2, min_samples_leaf=4, min_samples_split=2, splitter=random;, score=0.719 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0, criterion=absolute_error, max_depth=480, max_features=log2, min_samples_leaf=4, min_samples_split=2, splitter=random;, score=0.619 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0, criterion=absolute_error, max_depth=480, max_features=log2, min_samples_leaf=4, min_samples_split=2, splitter=random;, score=0.350 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0, criterion=poisson, max_depth=60, max_features=sqrt, min_samples_leaf=8, min_samples_split=5, splitter=best;, score=0.684 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0, criterion=poisson, max_depth=60, max_features=sqrt, min_samples_leaf=8, min_samples_split=5, splitter=best;, score=0.788 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0, criterion=poisson, max_depth=60, max_features=sqrt, min_samples_leaf=8, min_samples_split=5, splitter=best;, score=0.802 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0, criterion=poisson, max_depth=60, max_features=sqrt, min_samples_leaf=8, min_samples_split=5, splitter=best;, score=0.684 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=1, criterion=squared_error, max_depth=740, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, splitter=best;, score=0.681 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=1, criterion=squared_error, max_depth=740, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, splitter=best;, score=0.709 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0, criterion=friedman_mse, max_depth=170, max_features=sqrt, min_samples_leaf=8, min_samples_split=2, splitter=random;, score=0.718 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0, criterion=friedman_mse, max_depth=170, max_features=sqrt, min_samples_leaf=8, min_samples_split=2, splitter=random;, score=0.639 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0, criterion=friedman_mse, max_depth=170, max_features=sqrt, min_samples_leaf=8, min_samples_split=2, splitter=random;, score=0.680 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0, criterion=friedman_mse, max_depth=170, max_features=sqrt, min_samples_leaf=8, min_samples_split=2, splitter=random;, score=0.670 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0, criterion=friedman_mse, max_depth=170, max_features=sqrt, min_samples_leaf=8, min_samples_split=2, splitter=random;, score=0.566 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=1, criterion=poisson, max_depth=590, max_features=sqrt, min_samples_leaf=6, min_samples_split=4, splitter=random;, score=0.669 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=1, criterion=poisson, max_depth=590, max_features=sqrt, min_samples_leaf=6, min_samples_split=4, splitter=random;, score=0.713 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=1, criterion=poisson, max_depth=590, max_features=sqrt, min_samples_leaf=6, min_samples_split=4, splitter=random;, score=0.740 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=1, criterion=poisson, max_depth=590, max_features=sqrt, min_samples_leaf=6, min_samples_split=4, splitter=random;, score=0.670 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=1, criterion=poisson, max_depth=590, max_features=sqrt, min_samples_leaf=6, min_samples_split=4, splitter=random;, score=0.615 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0, criterion=friedman_mse, max_depth=380, max_features=log2, min_samples_leaf=8, min_samples_split=4, splitter=best;, score=0.698 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=1, criterion=poisson, max_depth=680, max_features=log2, min_samples_leaf=4, min_samples_split=5, splitter=random;, score=0.582 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=1, criterion=poisson, max_depth=680, max_features=log2, min_samples_leaf=4, min_samples_split=5, splitter=random;, score=0.664 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=1, criterion=poisson, max_depth=680, max_features=log2, min_samples_leaf=4, min_samples_split=5, splitter=random;, score=0.767 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=1, criterion=poisson, max_depth=680, max_features=log2, min_samples_leaf=4, min_samples_split=5, splitter=random;, score=0.587 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0, criterion=absolute_error, max_depth=610, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, splitter=random;, score=0.665 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0, criterion=absolute_error, max_depth=410, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, splitter=best;, score=0.744 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0, criterion=absolute_error, max_depth=410, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, splitter=best;, score=0.743 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0, criterion=absolute_error, max_depth=410, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, splitter=best;, score=0.835 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=1, criterion=friedman_mse, max_depth=400, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.740 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=1, criterion=friedman_mse, max_depth=400, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.785 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=1, criterion=friedman_mse, max_depth=400, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.734 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=1, criterion=friedman_mse, max_depth=400, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.621 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0, criterion=absolute_error, max_depth=1000, max_features=sqrt, min_samples_leaf=8, min_samples_split=4, splitter=best;, score=0.584 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0, criterion=absolute_error, max_depth=1000, max_features=sqrt, min_samples_leaf=8, min_samples_split=4, splitter=best;, score=0.740 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0, criterion=absolute_error, max_depth=1000, max_features=sqrt, min_samples_leaf=8, min_samples_split=4, splitter=best;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0, criterion=absolute_error, max_depth=1000, max_features=sqrt, min_samples_leaf=8, min_samples_split=4, splitter=best;, score=0.765 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0, criterion=absolute_error, max_depth=620, max_features=log2, min_samples_leaf=8, min_samples_split=5, splitter=random;, score=0.609 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0, criterion=absolute_error, max_depth=620, max_features=log2, min_samples_leaf=8, min_samples_split=5, splitter=random;, score=0.716 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0, criterion=absolute_error, max_depth=620, max_features=log2, min_samples_leaf=8, min_samples_split=5, splitter=random;, score=0.359 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0, criterion=squared_error, max_depth=750, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, splitter=best;, score=0.780 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0, criterion=squared_error, max_depth=750, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, splitter=best;, score=0.788 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0, criterion=squared_error, max_depth=750, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, splitter=best;, score=0.734 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0, criterion=squared_error, max_depth=750, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, splitter=best;, score=0.667 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0, criterion=squared_error, max_depth=750, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, splitter=best;, score=0.756 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0, criterion=squared_error, max_depth=50, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.698 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0, criterion=squared_error, max_depth=50, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.708 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0, criterion=squared_error, max_depth=50, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.753 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0, criterion=squared_error, max_depth=50, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.675 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0, criterion=squared_error, max_depth=50, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.659 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=1, criterion=absolute_error, max_depth=430, max_features=log2, min_samples_leaf=8, min_samples_split=14, splitter=random;, score=0.411 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=1, criterion=absolute_error, max_depth=430, max_features=log2, min_samples_leaf=8, min_samples_split=14, splitter=random;, score=0.702 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=1, criterion=absolute_error, max_depth=430, max_features=log2, min_samples_leaf=8, min_samples_split=14, splitter=random;, score=0.745 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=1, criterion=absolute_error, max_depth=430, max_features=log2, min_samples_leaf=8, min_samples_split=14, splitter=random;, score=0.615 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=1, criterion=absolute_error, max_depth=430, max_features=log2, min_samples_leaf=8, min_samples_split=14, splitter=random;, score=0.648 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0, criterion=friedman_mse, max_depth=680, max_features=sqrt, min_samples_leaf=6, min_samples_split=2, splitter=random;, score=0.638 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0, criterion=friedman_mse, max_depth=680, max_features=sqrt, min_samples_leaf=6, min_samples_split=2, splitter=random;, score=0.746 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0, criterion=friedman_mse, max_depth=680, max_features=sqrt, min_samples_leaf=6, min_samples_split=2, splitter=random;, score=0.731 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0, criterion=friedman_mse, max_depth=680, max_features=sqrt, min_samples_leaf=6, min_samples_split=2, splitter=random;, score=0.726 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0, criterion=friedman_mse, max_depth=680, max_features=sqrt, min_samples_leaf=6, min_samples_split=2, splitter=random;, score=0.722 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=1, criterion=friedman_mse, max_depth=1000, max_features=sqrt, min_samples_leaf=6, min_samples_split=4, splitter=best;, score=0.741 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0, criterion=squared_error, max_depth=420, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.589 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=1, criterion=poisson, max_depth=400, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.738 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=1, criterion=poisson, max_depth=400, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.687 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=1, criterion=poisson, max_depth=400, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.761 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=1, criterion=poisson, max_depth=400, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.766 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=1, criterion=poisson, max_depth=400, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.671 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=1, criterion=squared_error, max_depth=810, max_features=log2, min_samples_leaf=4, min_samples_split=10, splitter=best;, score=0.771 total time=   0.0s\n",
      "[CV 5/5] END algorithm=auto, leaf_size=13, n_neighbors=5, p=2, weights=uniform;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=1, criterion=absolute_error, max_depth=320, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.775 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=1, criterion=squared_error, max_depth=80, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, splitter=best;, score=0.746 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0, criterion=squared_error, max_depth=580, max_features=sqrt, min_samples_leaf=6, min_samples_split=14, splitter=best;, score=0.762 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0, criterion=squared_error, max_depth=580, max_features=sqrt, min_samples_leaf=6, min_samples_split=14, splitter=best;, score=0.705 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=1, criterion=poisson, max_depth=100, max_features=log2, min_samples_leaf=8, min_samples_split=5, splitter=best;, score=0.799 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=1, criterion=poisson, max_depth=100, max_features=log2, min_samples_leaf=8, min_samples_split=5, splitter=best;, score=0.799 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=1, criterion=absolute_error, max_depth=340, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.634 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=1, criterion=absolute_error, max_depth=340, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.634 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=1, criterion=absolute_error, max_depth=340, max_features=log2, min_samples_leaf=1, min_samples_split=3, splitter=random;, score=0.558 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=1, criterion=poisson, max_depth=430, max_features=sqrt, min_samples_leaf=8, min_samples_split=3, splitter=best;, score=0.731 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0, criterion=absolute_error, max_depth=250, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.684 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0, criterion=absolute_error, max_depth=250, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.741 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0, criterion=absolute_error, max_depth=250, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.641 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0, criterion=absolute_error, max_depth=250, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.679 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0, criterion=absolute_error, max_depth=1000, max_features=sqrt, min_samples_leaf=8, min_samples_split=4, splitter=best;, score=0.687 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0, criterion=poisson, max_depth=760, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.759 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0, criterion=poisson, max_depth=760, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.808 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0, criterion=poisson, max_depth=760, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.754 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0, criterion=poisson, max_depth=760, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.751 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0, criterion=poisson, max_depth=760, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=best;, score=0.658 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=1, criterion=friedman_mse, max_depth=140, max_features=log2, min_samples_leaf=6, min_samples_split=3, splitter=best;, score=0.772 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=1, criterion=friedman_mse, max_depth=140, max_features=log2, min_samples_leaf=6, min_samples_split=3, splitter=best;, score=0.808 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0, criterion=poisson, max_depth=60, max_features=sqrt, min_samples_leaf=8, min_samples_split=5, splitter=best;, score=0.769 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=1, criterion=friedman_mse, max_depth=990, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.699 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=1, criterion=friedman_mse, max_depth=990, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.768 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=1, criterion=friedman_mse, max_depth=990, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.736 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=1, criterion=friedman_mse, max_depth=990, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.755 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=1, criterion=friedman_mse, max_depth=990, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, splitter=random;, score=0.732 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0, criterion=absolute_error, max_depth=620, max_features=log2, min_samples_leaf=8, min_samples_split=5, splitter=random;, score=0.641 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0, criterion=absolute_error, max_depth=620, max_features=log2, min_samples_leaf=8, min_samples_split=5, splitter=random;, score=0.627 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0, criterion=friedman_mse, max_depth=380, max_features=log2, min_samples_leaf=8, min_samples_split=4, splitter=best;, score=0.676 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=1, criterion=absolute_error, max_depth=1000, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.655 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=1, criterion=absolute_error, max_depth=1000, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.671 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=1, criterion=absolute_error, max_depth=1000, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.737 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=1, criterion=absolute_error, max_depth=1000, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.709 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=1, criterion=absolute_error, max_depth=1000, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.538 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0, criterion=absolute_error, max_depth=680, max_features=log2, min_samples_leaf=8, min_samples_split=2, splitter=best;, score=0.708 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0, criterion=absolute_error, max_depth=680, max_features=log2, min_samples_leaf=8, min_samples_split=2, splitter=best;, score=0.780 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0, criterion=absolute_error, max_depth=680, max_features=log2, min_samples_leaf=8, min_samples_split=2, splitter=best;, score=0.748 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0, criterion=absolute_error, max_depth=680, max_features=log2, min_samples_leaf=8, min_samples_split=2, splitter=best;, score=0.702 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0, criterion=absolute_error, max_depth=680, max_features=log2, min_samples_leaf=8, min_samples_split=2, splitter=best;, score=0.650 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=1, criterion=absolute_error, max_depth=960, max_features=log2, min_samples_leaf=2, min_samples_split=14, splitter=random;, score=0.672 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=1, criterion=absolute_error, max_depth=960, max_features=log2, min_samples_leaf=2, min_samples_split=14, splitter=random;, score=0.636 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=1, criterion=absolute_error, max_depth=960, max_features=log2, min_samples_leaf=2, min_samples_split=14, splitter=random;, score=0.741 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=1, criterion=absolute_error, max_depth=960, max_features=log2, min_samples_leaf=2, min_samples_split=14, splitter=random;, score=0.597 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=1, criterion=absolute_error, max_depth=960, max_features=log2, min_samples_leaf=2, min_samples_split=14, splitter=random;, score=0.661 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=1, criterion=squared_error, max_depth=70, max_features=sqrt, min_samples_leaf=8, min_samples_split=2, splitter=random;, score=0.577 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0, criterion=squared_error, max_depth=980, max_features=log2, min_samples_leaf=4, min_samples_split=14, splitter=random;, score=0.745 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0, criterion=absolute_error, max_depth=250, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.519 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0, criterion=absolute_error, max_depth=420, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.713 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0, criterion=absolute_error, max_depth=420, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.740 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0, criterion=absolute_error, max_depth=420, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.715 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0, criterion=absolute_error, max_depth=420, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.687 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0, criterion=absolute_error, max_depth=420, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.583 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0, criterion=absolute_error, max_depth=670, max_features=sqrt, min_samples_leaf=8, min_samples_split=2, splitter=random;, score=0.494 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0, criterion=absolute_error, max_depth=670, max_features=sqrt, min_samples_leaf=8, min_samples_split=2, splitter=random;, score=0.716 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0, criterion=absolute_error, max_depth=760, max_features=log2, min_samples_leaf=4, min_samples_split=10, splitter=best;, score=0.808 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0, criterion=absolute_error, max_depth=760, max_features=log2, min_samples_leaf=4, min_samples_split=10, splitter=best;, score=0.765 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0, criterion=absolute_error, max_depth=760, max_features=log2, min_samples_leaf=4, min_samples_split=10, splitter=best;, score=0.784 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0, criterion=absolute_error, max_depth=760, max_features=log2, min_samples_leaf=4, min_samples_split=10, splitter=best;, score=0.702 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=1, criterion=squared_error, max_depth=330, max_features=sqrt, min_samples_leaf=8, min_samples_split=3, splitter=best;, score=0.761 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=1, criterion=squared_error, max_depth=330, max_features=sqrt, min_samples_leaf=8, min_samples_split=3, splitter=best;, score=0.780 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=1, criterion=squared_error, max_depth=330, max_features=sqrt, min_samples_leaf=8, min_samples_split=3, splitter=best;, score=0.750 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=1, criterion=squared_error, max_depth=330, max_features=sqrt, min_samples_leaf=8, min_samples_split=3, splitter=best;, score=0.728 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=1, criterion=squared_error, max_depth=330, max_features=sqrt, min_samples_leaf=8, min_samples_split=3, splitter=best;, score=0.742 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=1, criterion=poisson, max_depth=470, max_features=log2, min_samples_leaf=4, min_samples_split=3, splitter=best;, score=0.694 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=1, criterion=poisson, max_depth=470, max_features=log2, min_samples_leaf=4, min_samples_split=3, splitter=best;, score=0.588 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=1, criterion=poisson, max_depth=470, max_features=log2, min_samples_leaf=4, min_samples_split=3, splitter=best;, score=0.724 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=1, criterion=poisson, max_depth=470, max_features=log2, min_samples_leaf=4, min_samples_split=3, splitter=best;, score=0.741 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=1, criterion=poisson, max_depth=470, max_features=log2, min_samples_leaf=4, min_samples_split=3, splitter=best;, score=0.720 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0, criterion=friedman_mse, max_depth=670, max_features=log2, min_samples_leaf=8, min_samples_split=14, splitter=best;, score=0.727 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0, criterion=friedman_mse, max_depth=670, max_features=log2, min_samples_leaf=8, min_samples_split=14, splitter=best;, score=0.749 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0, criterion=friedman_mse, max_depth=40, max_features=sqrt, min_samples_leaf=8, min_samples_split=2, splitter=random;, score=0.737 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0, criterion=friedman_mse, max_depth=40, max_features=sqrt, min_samples_leaf=8, min_samples_split=2, splitter=random;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0, criterion=friedman_mse, max_depth=40, max_features=sqrt, min_samples_leaf=8, min_samples_split=2, splitter=random;, score=0.713 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0, criterion=friedman_mse, max_depth=40, max_features=sqrt, min_samples_leaf=8, min_samples_split=2, splitter=random;, score=0.720 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0, criterion=friedman_mse, max_depth=40, max_features=sqrt, min_samples_leaf=8, min_samples_split=2, splitter=random;, score=0.588 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0, criterion=absolute_error, max_depth=940, max_features=sqrt, min_samples_leaf=8, min_samples_split=3, splitter=random;, score=0.691 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0, criterion=absolute_error, max_depth=940, max_features=sqrt, min_samples_leaf=8, min_samples_split=3, splitter=random;, score=0.769 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0, criterion=absolute_error, max_depth=940, max_features=sqrt, min_samples_leaf=8, min_samples_split=3, splitter=random;, score=0.788 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0, criterion=absolute_error, max_depth=940, max_features=sqrt, min_samples_leaf=8, min_samples_split=3, splitter=random;, score=0.605 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0, criterion=absolute_error, max_depth=940, max_features=sqrt, min_samples_leaf=8, min_samples_split=3, splitter=random;, score=0.546 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0, criterion=absolute_error, max_depth=480, max_features=sqrt, min_samples_leaf=8, min_samples_split=10, splitter=random;, score=0.621 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0, criterion=absolute_error, max_depth=480, max_features=sqrt, min_samples_leaf=8, min_samples_split=10, splitter=random;, score=0.752 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0, criterion=absolute_error, max_depth=480, max_features=sqrt, min_samples_leaf=8, min_samples_split=10, splitter=random;, score=0.753 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0, criterion=absolute_error, max_depth=480, max_features=sqrt, min_samples_leaf=8, min_samples_split=10, splitter=random;, score=0.555 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0, criterion=absolute_error, max_depth=480, max_features=sqrt, min_samples_leaf=8, min_samples_split=10, splitter=random;, score=0.530 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=1, criterion=poisson, max_depth=90, max_features=log2, min_samples_leaf=6, min_samples_split=10, splitter=random;, score=0.716 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=1, criterion=absolute_error, max_depth=940, max_features=log2, min_samples_leaf=4, min_samples_split=3, splitter=random;, score=0.642 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=1, criterion=friedman_mse, max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.735 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0, criterion=friedman_mse, max_depth=900, max_features=log2, min_samples_leaf=8, min_samples_split=14, splitter=best;, score=0.796 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0, criterion=friedman_mse, max_depth=900, max_features=log2, min_samples_leaf=8, min_samples_split=14, splitter=best;, score=0.687 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0, criterion=poisson, max_depth=240, max_features=sqrt, min_samples_leaf=6, min_samples_split=14, splitter=random;, score=0.673 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0, criterion=friedman_mse, max_depth=380, max_features=log2, min_samples_leaf=8, min_samples_split=4, splitter=best;, score=0.715 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0, criterion=friedman_mse, max_depth=380, max_features=log2, min_samples_leaf=8, min_samples_split=4, splitter=best;, score=0.715 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0, criterion=friedman_mse, max_depth=380, max_features=log2, min_samples_leaf=8, min_samples_split=4, splitter=best;, score=0.670 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0, criterion=absolute_error, max_depth=550, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.636 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0, criterion=absolute_error, max_depth=550, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.584 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0, criterion=friedman_mse, max_depth=440, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=random;, score=0.786 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0, criterion=friedman_mse, max_depth=440, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=random;, score=0.746 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0, criterion=friedman_mse, max_depth=440, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=random;, score=0.711 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0, criterion=friedman_mse, max_depth=440, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=random;, score=0.672 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0, criterion=friedman_mse, max_depth=440, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=random;, score=0.658 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0, criterion=friedman_mse, max_depth=580, max_features=log2, min_samples_leaf=8, min_samples_split=4, splitter=random;, score=0.688 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0, criterion=friedman_mse, max_depth=580, max_features=log2, min_samples_leaf=8, min_samples_split=4, splitter=random;, score=0.767 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0, criterion=friedman_mse, max_depth=580, max_features=log2, min_samples_leaf=8, min_samples_split=4, splitter=random;, score=0.644 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0, criterion=friedman_mse, max_depth=580, max_features=log2, min_samples_leaf=8, min_samples_split=4, splitter=random;, score=0.660 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0, criterion=friedman_mse, max_depth=580, max_features=log2, min_samples_leaf=8, min_samples_split=4, splitter=random;, score=0.656 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0, criterion=squared_error, max_depth=420, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.580 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0, criterion=squared_error, max_depth=420, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.665 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0, criterion=squared_error, max_depth=420, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.740 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0, criterion=squared_error, max_depth=420, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.617 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=1, criterion=poisson, max_depth=90, max_features=log2, min_samples_leaf=6, min_samples_split=10, splitter=random;, score=0.639 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=1, criterion=poisson, max_depth=90, max_features=log2, min_samples_leaf=6, min_samples_split=10, splitter=random;, score=0.689 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=1, criterion=poisson, max_depth=90, max_features=log2, min_samples_leaf=6, min_samples_split=10, splitter=random;, score=0.542 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=1, criterion=poisson, max_depth=90, max_features=log2, min_samples_leaf=6, min_samples_split=10, splitter=random;, score=0.434 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0, criterion=poisson, max_depth=680, max_features=sqrt, min_samples_leaf=8, min_samples_split=4, splitter=random;, score=0.538 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0, criterion=poisson, max_depth=680, max_features=sqrt, min_samples_leaf=8, min_samples_split=4, splitter=random;, score=0.788 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0, criterion=poisson, max_depth=680, max_features=sqrt, min_samples_leaf=8, min_samples_split=4, splitter=random;, score=0.575 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0, criterion=poisson, max_depth=680, max_features=sqrt, min_samples_leaf=8, min_samples_split=4, splitter=random;, score=0.681 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0, criterion=poisson, max_depth=680, max_features=sqrt, min_samples_leaf=8, min_samples_split=4, splitter=random;, score=0.577 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=1, criterion=friedman_mse, max_depth=720, max_features=log2, min_samples_leaf=4, min_samples_split=3, splitter=best;, score=0.789 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=1, criterion=friedman_mse, max_depth=720, max_features=log2, min_samples_leaf=4, min_samples_split=3, splitter=best;, score=0.710 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=1, criterion=friedman_mse, max_depth=720, max_features=log2, min_samples_leaf=4, min_samples_split=3, splitter=best;, score=0.760 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=1, criterion=friedman_mse, max_depth=720, max_features=log2, min_samples_leaf=4, min_samples_split=3, splitter=best;, score=0.714 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=1, criterion=friedman_mse, max_depth=720, max_features=log2, min_samples_leaf=4, min_samples_split=3, splitter=best;, score=0.705 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=1, criterion=squared_error, max_depth=970, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.770 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=1, criterion=squared_error, max_depth=970, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.777 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0, criterion=friedman_mse, max_depth=180, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=random;, score=0.702 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0, criterion=friedman_mse, max_depth=180, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=random;, score=0.736 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=1, criterion=squared_error, max_depth=780, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=best;, score=0.749 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0, criterion=poisson, max_depth=240, max_features=sqrt, min_samples_leaf=6, min_samples_split=14, splitter=random;, score=0.683 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0, criterion=absolute_error, max_depth=310, max_features=log2, min_samples_leaf=6, min_samples_split=10, splitter=best;, score=0.724 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0, criterion=absolute_error, max_depth=310, max_features=log2, min_samples_leaf=6, min_samples_split=10, splitter=best;, score=0.700 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=1, criterion=squared_error, max_depth=720, max_features=sqrt, min_samples_leaf=8, min_samples_split=3, splitter=random;, score=0.625 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=1, criterion=squared_error, max_depth=720, max_features=sqrt, min_samples_leaf=8, min_samples_split=3, splitter=random;, score=0.712 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0, criterion=squared_error, max_depth=270, max_features=log2, min_samples_leaf=4, min_samples_split=14, splitter=best;, score=0.776 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0, criterion=squared_error, max_depth=270, max_features=log2, min_samples_leaf=4, min_samples_split=14, splitter=best;, score=0.701 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0, criterion=squared_error, max_depth=90, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=best;, score=0.678 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=1, criterion=poisson, max_depth=400, max_features=log2, min_samples_leaf=4, min_samples_split=14, splitter=best;, score=0.711 total time=   0.0s\n",
      "DecisionTreeRegressor() RandomCV Best Params : {'splitter': 'best', 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 780, 'criterion': 'squared_error', 'ccp_alpha': 1}\n",
      "DecisionTreeRegressor() RandomCV Score: 0.7083064981365933\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Final score is  0.7306322588578171\n"
     ]
    }
   ],
   "source": [
    "hyperparameter_tuning(algo=\"DecisionTreeRegressor()\",param_grid=random_grid,n_iter=100,cv=5,verbose=3,random_state=42,X_train=X_train.loc[:,list(selected_features)],Y_train=Y_train,X_test=X_test.loc[:,list(selected_features)],Y_test=Y_test,evaluation_metric=\"r2_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "13b82c26-f243-4463-adc7-74730a517632",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "28d5dfb5-2ed0-46ed-8c2e-fb39e8f7af67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  62 out of  62 | elapsed:    0.4s finished\n",
      "\n",
      "[2023-02-01 16:21:00] Features: 1/62 -- score: 0.6795332925095348[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  61 | elapsed:    1.2s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  61 out of  61 | elapsed:    1.3s finished\n",
      "\n",
      "[2023-02-01 16:21:01] Features: 2/62 -- score: 0.7542980811710336[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:    1.2s finished\n",
      "\n",
      "[2023-02-01 16:21:02] Features: 3/62 -- score: 0.8173373065555415[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  48 out of  59 | elapsed:    1.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  59 out of  59 | elapsed:    1.1s finished\n",
      "\n",
      "[2023-02-01 16:21:03] Features: 4/62 -- score: 0.8406585300931317[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done  58 out of  58 | elapsed:    0.9s finished\n",
      "\n",
      "[2023-02-01 16:21:04] Features: 5/62 -- score: 0.8564197964459744[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  46 out of  57 | elapsed:    0.8s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  57 out of  57 | elapsed:    0.9s finished\n",
      "\n",
      "[2023-02-01 16:21:05] Features: 6/62 -- score: 0.8640116730511437[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  56 | elapsed:    0.7s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  56 out of  56 | elapsed:    0.9s finished\n",
      "\n",
      "[2023-02-01 16:21:06] Features: 7/62 -- score: 0.8700872338970317[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  44 out of  55 | elapsed:    0.7s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  55 out of  55 | elapsed:    0.8s finished\n",
      "\n",
      "[2023-02-01 16:21:07] Features: 8/62 -- score: 0.8750722999173683[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  54 out of  54 | elapsed:    0.9s finished\n",
      "\n",
      "[2023-02-01 16:21:08] Features: 9/62 -- score: 0.8783701419954942[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 out of  53 | elapsed:    0.8s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  53 out of  53 | elapsed:    0.9s finished\n",
      "\n",
      "[2023-02-01 16:21:09] Features: 10/62 -- score: 0.8825074763916975[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  52 out of  52 | elapsed:    0.9s finished\n",
      "\n",
      "[2023-02-01 16:21:10] Features: 11/62 -- score: 0.8856801622518995[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  51 | elapsed:    0.8s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  51 out of  51 | elapsed:    0.9s finished\n",
      "\n",
      "[2023-02-01 16:21:10] Features: 12/62 -- score: 0.8879272987331562[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.9s finished\n",
      "\n",
      "[2023-02-01 16:21:11] Features: 13/62 -- score: 0.8900610989421841[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  38 out of  49 | elapsed:    0.8s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  49 out of  49 | elapsed:    1.0s finished\n",
      "\n",
      "[2023-02-01 16:21:12] Features: 14/62 -- score: 0.8920339934560436[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:    0.9s finished\n",
      "\n",
      "[2023-02-01 16:21:13] Features: 15/62 -- score: 0.8930694097681549[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  47 out of  47 | elapsed:    0.8s finished\n",
      "\n",
      "[2023-02-01 16:21:14] Features: 16/62 -- score: 0.8932988877079703[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  46 out of  46 | elapsed:    0.7s finished\n",
      "\n",
      "[2023-02-01 16:21:15] Features: 17/62 -- score: 0.893700926293921[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 out of  45 | elapsed:    0.6s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    0.8s finished\n",
      "\n",
      "[2023-02-01 16:21:15] Features: 18/62 -- score: 0.8944157549580789[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 out of  44 | elapsed:    0.6s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  44 out of  44 | elapsed:    0.8s finished\n",
      "\n",
      "[2023-02-01 16:21:16] Features: 19/62 -- score: 0.8948904684150654[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  32 out of  43 | elapsed:    0.6s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  43 out of  43 | elapsed:    0.8s finished\n",
      "\n",
      "[2023-02-01 16:21:17] Features: 20/62 -- score: 0.8958435577660204[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 out of  42 | elapsed:    0.8s finished\n",
      "\n",
      "[2023-02-01 16:21:18] Features: 21/62 -- score: 0.8962182545972659[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  41 | elapsed:    0.6s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  41 out of  41 | elapsed:    0.8s finished\n",
      "\n",
      "[2023-02-01 16:21:19] Features: 22/62 -- score: 0.8963846367740486[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    0.9s finished\n",
      "\n",
      "[2023-02-01 16:21:20] Features: 23/62 -- score: 0.8961853458048565[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  28 out of  39 | elapsed:    0.7s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  39 out of  39 | elapsed:    0.9s finished\n",
      "\n",
      "[2023-02-01 16:21:20] Features: 24/62 -- score: 0.8961600529367526[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  38 out of  38 | elapsed:    0.9s finished\n",
      "\n",
      "[2023-02-01 16:21:21] Features: 25/62 -- score: 0.8960987215360611[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 out of  37 | elapsed:    0.6s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  37 out of  37 | elapsed:    0.8s finished\n",
      "\n",
      "[2023-02-01 16:21:22] Features: 26/62 -- score: 0.8962910355514323[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  36 out of  36 | elapsed:    0.8s finished\n",
      "\n",
      "[2023-02-01 16:21:23] Features: 27/62 -- score: 0.8963433088817624[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  35 | elapsed:    0.7s finished\n",
      "\n",
      "[2023-02-01 16:21:24] Features: 28/62 -- score: 0.8960317005154262[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 out of  34 | elapsed:    0.7s finished\n",
      "\n",
      "[2023-02-01 16:21:24] Features: 29/62 -- score: 0.8963227447229096[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  22 out of  33 | elapsed:    0.6s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  33 out of  33 | elapsed:    0.8s finished\n",
      "\n",
      "[2023-02-01 16:21:25] Features: 30/62 -- score: 0.8957654656345662[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  21 out of  32 | elapsed:    0.6s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  32 out of  32 | elapsed:    0.7s finished\n",
      "\n",
      "[2023-02-01 16:21:26] Features: 31/62 -- score: 0.8956303076233525[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  31 | elapsed:    0.5s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  31 out of  31 | elapsed:    0.7s finished\n",
      "\n",
      "[2023-02-01 16:21:27] Features: 32/62 -- score: 0.8955514994350426[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    0.7s finished\n",
      "\n",
      "[2023-02-01 16:21:27] Features: 33/62 -- score: 0.8953398439837127[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  29 | elapsed:    0.5s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  29 out of  29 | elapsed:    0.7s finished\n",
      "\n",
      "[2023-02-01 16:21:28] Features: 34/62 -- score: 0.8950498118099374[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  28 out of  28 | elapsed:    0.6s finished\n",
      "\n",
      "[2023-02-01 16:21:29] Features: 35/62 -- score: 0.894964431545746[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  27 | elapsed:    0.5s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:    0.6s finished\n",
      "\n",
      "[2023-02-01 16:21:29] Features: 36/62 -- score: 0.895157444184011[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 out of  26 | elapsed:    0.7s finished\n",
      "\n",
      "[2023-02-01 16:21:30] Features: 37/62 -- score: 0.8944439827773902[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  14 out of  25 | elapsed:    0.5s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.6s finished\n",
      "\n",
      "[2023-02-01 16:21:31] Features: 38/62 -- score: 0.8943651359348863[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:    0.7s finished\n",
      "\n",
      "[2023-02-01 16:21:31] Features: 39/62 -- score: 0.8943307710802362[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  23 out of  23 | elapsed:    0.6s finished\n",
      "\n",
      "[2023-02-01 16:21:32] Features: 40/62 -- score: 0.8946631306406161[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  22 out of  22 | elapsed:    0.5s finished\n",
      "\n",
      "[2023-02-01 16:21:32] Features: 41/62 -- score: 0.8945290069989289[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  21 out of  21 | elapsed:    0.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  21 out of  21 | elapsed:    0.6s finished\n",
      "\n",
      "[2023-02-01 16:21:33] Features: 42/62 -- score: 0.8942884685891231[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    0.5s finished\n",
      "\n",
      "[2023-02-01 16:21:33] Features: 43/62 -- score: 0.8942734580744949[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  19 | elapsed:    0.5s finished\n",
      "\n",
      "[2023-02-01 16:21:34] Features: 44/62 -- score: 0.8937890232742622[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  18 | elapsed:    0.4s finished\n",
      "\n",
      "[2023-02-01 16:21:34] Features: 45/62 -- score: 0.8931362596655363[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  17 | elapsed:    0.4s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  17 out of  17 | elapsed:    0.4s finished\n",
      "\n",
      "[2023-02-01 16:21:35] Features: 46/62 -- score: 0.892832349763707[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  14 out of  16 | elapsed:    0.4s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  16 | elapsed:    0.5s finished\n",
      "\n",
      "[2023-02-01 16:21:35] Features: 47/62 -- score: 0.8927848034817945[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  15 | elapsed:    0.3s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.4s finished\n",
      "\n",
      "[2023-02-01 16:21:36] Features: 48/62 -- score: 0.8925313536600168[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  14 | elapsed:    0.3s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  14 out of  14 | elapsed:    0.4s finished\n",
      "\n",
      "[2023-02-01 16:21:36] Features: 49/62 -- score: 0.8927975254030767[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of  13 | elapsed:    0.3s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  13 out of  13 | elapsed:    0.4s finished\n",
      "\n",
      "[2023-02-01 16:21:37] Features: 50/62 -- score: 0.8917292938037058[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  12 | elapsed:    0.3s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    0.3s finished\n",
      "\n",
      "[2023-02-01 16:21:37] Features: 51/62 -- score: 0.8919528489428693[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  11 | elapsed:    0.4s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  11 | elapsed:    0.5s finished\n",
      "\n",
      "[2023-02-01 16:21:38] Features: 52/62 -- score: 0.891371950306751[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    0.2s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.3s finished\n",
      "\n",
      "[2023-02-01 16:21:38] Features: 53/62 -- score: 0.8906786053718239[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   9 | elapsed:    0.1s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    0.3s finished\n",
      "\n",
      "[2023-02-01 16:21:38] Features: 54/62 -- score: 0.8905168035034021[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   8 | elapsed:    0.1s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.3s finished\n",
      "\n",
      "[2023-02-01 16:21:38] Features: 55/62 -- score: 0.8902790800175202[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   7 | elapsed:    0.2s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of   7 | elapsed:    0.2s finished\n",
      "\n",
      "[2023-02-01 16:21:39] Features: 56/62 -- score: 0.8893143951845909[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.2s finished\n",
      "\n",
      "[2023-02-01 16:21:39] Features: 57/62 -- score: 0.888115480362982[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    0.2s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "\n",
      "[2023-02-01 16:21:39] Features: 58/62 -- score: 0.888184244010171[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   4 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    0.2s finished\n",
      "\n",
      "[2023-02-01 16:21:39] Features: 59/62 -- score: 0.8864239890134188[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.2s finished\n",
      "\n",
      "[2023-02-01 16:21:39] Features: 60/62 -- score: 0.883843255163985[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.2s finished\n",
      "\n",
      "[2023-02-01 16:21:39] Features: 61/62 -- score: 0.8824586645905146[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features ('LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'BsmtFinSF1', 'TotalBsmtSF', 'GrLivArea', 'GarageCars', 'Street', 'LandContour', 'Neighborhood', 'Condition1', 'ExterQual', 'Foundation', 'BsmtQual', 'BsmtExposure', 'Heating', 'KitchenQual', 'Functional', 'SaleType')\n",
      "Prediction using selected features using SGDRegressor() is : 0.8724641699458564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:21:40] Features: 62/62 -- score: 0.8807834212589402"
     ]
    }
   ],
   "source": [
    "selected_features=sf_selector(algo=\"SGDRegressor()\",forward=True,floating=False,scoring=\"r2\",X_train=X_train,Y_train=Y_train,X_test=X_test,Y_test=Y_test,min_featues=3,cv=5,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "765f34d2-8d58-465e-a612-266e1f7a872c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': ['squared_error', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'], 'penalty': ['l2', 'l1', 'elasticnet', 'None'], 'alpha': [0.0, 2.0408163265306123e-05, 4.0816326530612245e-05, 6.122448979591836e-05, 8.163265306122449e-05, 0.00010204081632653062, 0.00012244897959183673, 0.00014285714285714287, 0.00016326530612244898, 0.0001836734693877551, 0.00020408163265306123, 0.00022448979591836734, 0.00024489795918367346, 0.0002653061224489796, 0.00028571428571428574, 0.0003061224489795918, 0.00032653061224489796, 0.0003469387755102041, 0.0003673469387755102, 0.0003877551020408163, 0.00040816326530612246, 0.00042857142857142855, 0.0004489795918367347, 0.00046938775510204083, 0.0004897959183673469, 0.0005102040816326531, 0.0005306122448979592, 0.0005510204081632653, 0.0005714285714285715, 0.0005918367346938776, 0.0006122448979591836, 0.0006326530612244898, 0.0006530612244897959, 0.000673469387755102, 0.0006938775510204082, 0.0007142857142857143, 0.0007346938775510204, 0.0007551020408163266, 0.0007755102040816326, 0.0007959183673469387, 0.0008163265306122449, 0.000836734693877551, 0.0008571428571428571, 0.0008775510204081633, 0.0008979591836734694, 0.0009183673469387755, 0.0009387755102040817, 0.0009591836734693877, 0.0009795918367346938, 0.001], 'l1_ratio': [0.0, 0.01020408163265306, 0.02040816326530612, 0.030612244897959183, 0.04081632653061224, 0.0510204081632653, 0.061224489795918366, 0.07142857142857142, 0.08163265306122448, 0.09183673469387754, 0.1020408163265306, 0.11224489795918366, 0.12244897959183673, 0.13265306122448978, 0.14285714285714285, 0.1530612244897959, 0.16326530612244897, 0.17346938775510204, 0.18367346938775508, 0.19387755102040816, 0.2040816326530612, 0.21428571428571427, 0.22448979591836732, 0.2346938775510204, 0.24489795918367346, 0.25510204081632654, 0.26530612244897955, 0.2755102040816326, 0.2857142857142857, 0.29591836734693877, 0.3061224489795918, 0.31632653061224486, 0.32653061224489793, 0.336734693877551, 0.3469387755102041, 0.3571428571428571, 0.36734693877551017, 0.37755102040816324, 0.3877551020408163, 0.39795918367346933, 0.4081632653061224, 0.4183673469387755, 0.42857142857142855, 0.4387755102040816, 0.44897959183673464, 0.4591836734693877, 0.4693877551020408, 0.47959183673469385, 0.4897959183673469, 0.5], 'max_iter': [8000, 8121, 8242, 8363, 8484, 8606, 8727, 8848, 8969, 9090, 9212, 9333, 9454, 9575, 9696, 9818, 9939, 10060, 10181, 10303, 10424, 10545, 10666, 10787, 10909, 11030, 11151, 11272, 11393, 11515, 11636, 11757, 11878, 12000, 12121, 12242, 12363, 12484, 12606, 12727, 12848, 12969, 13090, 13212, 13333, 13454, 13575, 13696, 13818, 13939, 14060, 14181, 14303, 14424, 14545, 14666, 14787, 14909, 15030, 15151, 15272, 15393, 15515, 15636, 15757, 15878, 16000, 16121, 16242, 16363, 16484, 16606, 16727, 16848, 16969, 17090, 17212, 17333, 17454, 17575, 17696, 17818, 17939, 18060, 18181, 18303, 18424, 18545, 18666, 18787, 18909, 19030, 19151, 19272, 19393, 19515, 19636, 19757, 19878, 20000], 'tol': [0.01, 0.009909090909090909, 0.009818181818181818, 0.009727272727272727, 0.009636363636363637, 0.009545454545454546, 0.009454545454545455, 0.009363636363636364, 0.009272727272727273, 0.009181818181818182, 0.00909090909090909, 0.009000000000000001, 0.00890909090909091, 0.008818181818181819, 0.008727272727272728, 0.008636363636363636, 0.008545454545454545, 0.008454545454545454, 0.008363636363636363, 0.008272727272727272, 0.008181818181818182, 0.008090909090909091, 0.008, 0.007909090909090909, 0.007818181818181818, 0.007727272727272727, 0.0076363636363636364, 0.007545454545454545, 0.007454545454545455, 0.007363636363636364, 0.007272727272727273, 0.007181818181818182, 0.00709090909090909, 0.007, 0.006909090909090909, 0.006818181818181819, 0.006727272727272728, 0.006636363636363636, 0.006545454545454545, 0.006454545454545454, 0.006363636363636363, 0.006272727272727273, 0.0061818181818181816, 0.00609090909090909, 0.006, 0.005909090909090909, 0.005818181818181818, 0.005727272727272727, 0.005636363636363636, 0.005545454545454545, 0.005454545454545454, 0.005363636363636364, 0.005272727272727273, 0.0051818181818181815, 0.00509090909090909, 0.005, 0.004909090909090909, 0.004818181818181818, 0.004727272727272727, 0.004636363636363636, 0.004545454545454545, 0.004454545454545454, 0.004363636363636363, 0.004272727272727273, 0.0041818181818181815, 0.00409090909090909, 0.004, 0.003909090909090909, 0.003818181818181818, 0.0037272727272727266, 0.0036363636363636364, 0.003545454545454545, 0.003454545454545454, 0.003363636363636363, 0.0032727272727272726, 0.0031818181818181815, 0.0030909090909090903, 0.002999999999999999, 0.002909090909090909, 0.0028181818181818178, 0.0027272727272727266, 0.0026363636363636363, 0.002545454545454545, 0.002454545454545454, 0.002363636363636363, 0.0022727272727272726, 0.0021818181818181806, 0.002090909090909091, 0.002, 0.001909090909090909, 0.0018181818181818177, 0.0017272727272727266, 0.0016363636363636355, 0.0015454545454545443, 0.0014545454545454532, 0.0013636363636363637, 0.0012727272727272726, 0.0011818181818181814, 0.0010909090909090903, 0.001], 'learning_rate': ['constant', 'optimal', 'invscaling', 'adaptive'], 'eta0': [0.1, 0.0994949494949495, 0.09898989898989899, 0.0984848484848485, 0.09797979797979799, 0.09747474747474748, 0.09696969696969697, 0.09646464646464648, 0.09595959595959597, 0.09545454545454546, 0.09494949494949495, 0.09444444444444446, 0.09393939393939395, 0.09343434343434344, 0.09292929292929293, 0.09242424242424244, 0.09191919191919193, 0.09141414141414142, 0.09090909090909091, 0.0904040404040404, 0.08989898989898991, 0.0893939393939394, 0.08888888888888889, 0.08838383838383838, 0.08787878787878789, 0.08737373737373738, 0.08686868686868687, 0.08636363636363636, 0.08585858585858586, 0.08535353535353536, 0.08484848484848485, 0.08434343434343435, 0.08383838383838385, 0.08333333333333334, 0.08282828282828283, 0.08232323232323233, 0.08181818181818182, 0.08131313131313132, 0.08080808080808081, 0.0803030303030303, 0.07979797979797981, 0.0792929292929293, 0.0787878787878788, 0.07828282828282829, 0.07777777777777778, 0.07727272727272727, 0.07676767676767678, 0.07626262626262627, 0.07575757575757576, 0.07525252525252527, 0.07474747474747476, 0.07424242424242425, 0.07373737373737374, 0.07323232323232323, 0.07272727272727274, 0.07222222222222223, 0.07171717171717172, 0.07121212121212121, 0.07070707070707072, 0.07020202020202021, 0.0696969696969697, 0.0691919191919192, 0.06868686868686869, 0.06818181818181819, 0.06767676767676768, 0.06717171717171717, 0.06666666666666668, 0.06616161616161617, 0.06565656565656566, 0.06515151515151515, 0.06464646464646465, 0.06414141414141414, 0.06363636363636364, 0.06313131313131314, 0.06262626262626264, 0.062121212121212126, 0.061616161616161624, 0.061111111111111116, 0.060606060606060615, 0.060101010101010106, 0.059595959595959605, 0.0590909090909091, 0.05858585858585859, 0.05808080808080809, 0.05757575757575758, 0.05707070707070708, 0.05656565656565657, 0.05606060606060607, 0.05555555555555556, 0.05505050505050506, 0.05454545454545455, 0.05404040404040405, 0.05353535353535354, 0.05303030303030304, 0.05252525252525253, 0.05202020202020203, 0.05151515151515152, 0.05101010101010101, 0.05050505050505051, 0.05], 'validation_fraction': [0.1, 0.1163265306122449, 0.1326530612244898, 0.1489795918367347, 0.1653061224489796, 0.1816326530612245, 0.1979591836734694, 0.2142857142857143, 0.2306122448979592, 0.2469387755102041, 0.263265306122449, 0.2795918367346939, 0.29591836734693877, 0.3122448979591837, 0.3285714285714286, 0.3448979591836735, 0.36122448979591837, 0.37755102040816324, 0.3938775510204082, 0.4102040816326531, 0.42653061224489797, 0.44285714285714284, 0.4591836734693878, 0.4755102040816327, 0.49183673469387756, 0.5081632653061224, 0.5244897959183674, 0.5408163265306123, 0.5571428571428572, 0.573469387755102, 0.589795918367347, 0.6061224489795919, 0.6224489795918368, 0.6387755102040816, 0.6551020408163265, 0.6714285714285715, 0.6877551020408164, 0.7040816326530612, 0.7204081632653062, 0.7367346938775511, 0.753061224489796, 0.7693877551020408, 0.7857142857142857, 0.8020408163265307, 0.8183673469387756, 0.8346938775510204, 0.8510204081632654, 0.8673469387755103, 0.8836734693877552, 0.9], 'n_iter_no_change': [1, 2, 4, 6, 8, 5, 10]}\n"
     ]
    }
   ],
   "source": [
    "loss = ['squared_error','huber','epsilon_insensitive','squared_epsilon_insensitive']\n",
    "penalty=['l2','l1','elasticnet','None']\n",
    "alpha = [float(x) for x in np.linspace(0, 0.001,50)]\n",
    "l1_ratio=[float(x) for x in np.linspace(0, 0.5,50)]\n",
    "max_iter=[int(x) for x in np.linspace(8000, 20000,100)]\n",
    "tol=[float(x) for x in np.linspace(0.01, 0.001,100)]\n",
    "learning_rate=['constant','optimal','invscaling','adaptive']\n",
    "eta0=[float(x) for x in np.linspace(0.1, 0.05,100)]\n",
    "early_stopping = ['True','False']\n",
    "validation_fraction=[float(x) for x in np.linspace(0.1, 0.9,50)]\n",
    "n_iter_no_change = [1,2, 4,6,8,5,10]\n",
    "average=['bool','int']\n",
    "random_grid = {\n",
    "               'loss': loss,\n",
    "               'penalty': penalty,\n",
    "               'alpha': alpha,\n",
    "               'l1_ratio': l1_ratio,\n",
    "              'max_iter':max_iter,\n",
    "               'tol':tol,\n",
    "                'learning_rate':learning_rate,\n",
    "                'eta0':eta0,\n",
    "               \n",
    "                'validation_fraction':validation_fraction,\n",
    "                'n_iter_no_change':n_iter_no_change\n",
    "                }\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "6649496d-0fe8-4ade-a51a-8721771ea9ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "[CV 2/5] END ccp_alpha=1, criterion=squared_error, max_depth=950, max_features=log2, min_samples_leaf=8, min_samples_split=5, splitter=best;, score=0.699 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=1, criterion=squared_error, max_depth=950, max_features=log2, min_samples_leaf=8, min_samples_split=5, splitter=best;, score=0.737 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=1, criterion=squared_error, max_depth=950, max_features=log2, min_samples_leaf=8, min_samples_split=5, splitter=best;, score=0.611 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=1, criterion=squared_error, max_depth=950, max_features=log2, min_samples_leaf=8, min_samples_split=5, splitter=best;, score=0.691 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0, criterion=absolute_error, max_depth=760, max_features=log2, min_samples_leaf=4, min_samples_split=10, splitter=best;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0, criterion=absolute_error, max_depth=790, max_features=log2, min_samples_leaf=8, min_samples_split=14, splitter=random;, score=0.581 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0, criterion=absolute_error, max_depth=790, max_features=log2, min_samples_leaf=8, min_samples_split=14, splitter=random;, score=0.582 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0, criterion=absolute_error, max_depth=790, max_features=log2, min_samples_leaf=8, min_samples_split=14, splitter=random;, score=0.541 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0, criterion=poisson, max_depth=460, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.728 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0, criterion=poisson, max_depth=460, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.655 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0, criterion=poisson, max_depth=460, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.780 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0, criterion=poisson, max_depth=460, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.717 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0, criterion=poisson, max_depth=460, max_features=log2, min_samples_leaf=2, min_samples_split=3, splitter=random;, score=0.659 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=1, criterion=absolute_error, max_depth=630, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.679 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=1, criterion=absolute_error, max_depth=630, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.796 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=1, criterion=absolute_error, max_depth=630, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.783 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=1, criterion=absolute_error, max_depth=630, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.676 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=1, criterion=absolute_error, max_depth=630, max_features=sqrt, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.656 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0, criterion=absolute_error, max_depth=550, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.677 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0, criterion=absolute_error, max_depth=550, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.721 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0, criterion=absolute_error, max_depth=550, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.737 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0, criterion=poisson, max_depth=620, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=random;, score=0.752 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0, criterion=poisson, max_depth=620, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=random;, score=0.699 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=1, criterion=squared_error, max_depth=90, max_features=sqrt, min_samples_leaf=8, min_samples_split=10, splitter=best;, score=0.709 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0, criterion=poisson, max_depth=490, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=random;, score=0.644 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0, criterion=squared_error, max_depth=640, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=random;, score=0.764 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0, criterion=squared_error, max_depth=640, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=random;, score=0.671 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0, criterion=poisson, max_depth=490, max_features=sqrt, min_samples_leaf=8, min_samples_split=4, splitter=best;, score=0.720 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0, criterion=poisson, max_depth=490, max_features=sqrt, min_samples_leaf=8, min_samples_split=4, splitter=best;, score=0.684 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=1, criterion=friedman_mse, max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.663 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=1, criterion=friedman_mse, max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.664 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0, criterion=friedman_mse, max_depth=900, max_features=log2, min_samples_leaf=8, min_samples_split=14, splitter=best;, score=0.763 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0, criterion=friedman_mse, max_depth=900, max_features=log2, min_samples_leaf=8, min_samples_split=14, splitter=best;, score=0.662 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=1, criterion=absolute_error, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.638 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=1, criterion=absolute_error, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.701 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0, criterion=poisson, max_depth=240, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=random;, score=0.761 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0, criterion=poisson, max_depth=240, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=random;, score=0.720 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=1, criterion=squared_error, max_depth=720, max_features=sqrt, min_samples_leaf=8, min_samples_split=3, splitter=random;, score=0.700 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=1, criterion=squared_error, max_depth=720, max_features=sqrt, min_samples_leaf=8, min_samples_split=3, splitter=random;, score=0.583 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0, criterion=squared_error, max_depth=270, max_features=log2, min_samples_leaf=4, min_samples_split=14, splitter=best;, score=0.690 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0, criterion=absolute_error, max_depth=110, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=best;, score=0.753 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=1, criterion=poisson, max_depth=400, max_features=log2, min_samples_leaf=4, min_samples_split=14, splitter=best;, score=0.743 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=1, criterion=poisson, max_depth=400, max_features=log2, min_samples_leaf=4, min_samples_split=14, splitter=best;, score=0.712 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=1, criterion=squared_error, max_depth=220, max_features=sqrt, min_samples_leaf=8, min_samples_split=2, splitter=best;, score=0.568 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0, criterion=absolute_error, max_depth=220, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.729 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=1, criterion=squared_error, max_depth=780, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=best;, score=0.680 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0, criterion=poisson, max_depth=620, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=random;, score=0.700 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0, criterion=poisson, max_depth=620, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=random;, score=0.575 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0, criterion=squared_error, max_depth=640, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=random;, score=0.767 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0, criterion=squared_error, max_depth=640, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=random;, score=0.703 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=1, criterion=absolute_error, max_depth=940, max_features=log2, min_samples_leaf=4, min_samples_split=3, splitter=random;, score=0.351 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=1, criterion=absolute_error, max_depth=940, max_features=log2, min_samples_leaf=4, min_samples_split=3, splitter=random;, score=0.698 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0, criterion=friedman_mse, max_depth=180, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=random;, score=0.703 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0, criterion=friedman_mse, max_depth=180, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=random;, score=0.745 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0, criterion=poisson, max_depth=240, max_features=sqrt, min_samples_leaf=6, min_samples_split=14, splitter=random;, score=0.711 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0, criterion=poisson, max_depth=240, max_features=sqrt, min_samples_leaf=6, min_samples_split=14, splitter=random;, score=0.714 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0, criterion=poisson, max_depth=240, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=random;, score=0.657 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0, criterion=poisson, max_depth=240, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=random;, score=0.721 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=1, criterion=poisson, max_depth=260, max_features=log2, min_samples_leaf=6, min_samples_split=3, splitter=random;, score=0.540 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=1, criterion=poisson, max_depth=260, max_features=log2, min_samples_leaf=6, min_samples_split=3, splitter=random;, score=0.665 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0, criterion=squared_error, max_depth=270, max_features=log2, min_samples_leaf=4, min_samples_split=14, splitter=best;, score=0.707 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0, criterion=squared_error, max_depth=270, max_features=log2, min_samples_leaf=4, min_samples_split=14, splitter=best;, score=0.831 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0, criterion=squared_error, max_depth=90, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=best;, score=0.826 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0, criterion=squared_error, max_depth=90, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=best;, score=0.712 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=1, criterion=squared_error, max_depth=220, max_features=sqrt, min_samples_leaf=8, min_samples_split=2, splitter=best;, score=0.754 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=1, criterion=squared_error, max_depth=220, max_features=sqrt, min_samples_leaf=8, min_samples_split=2, splitter=best;, score=0.783 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=1, criterion=squared_error, max_depth=780, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=best;, score=0.743 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.0005510204081632653, eta0=0.05555555555555556, l1_ratio=0.09183673469387754, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=14303, n_iter_no_change=8, penalty=l1, tol=0.004636363636363636, validation_fraction=0.7040816326530612;, score=0.893 total time=   0.5s\n",
      "[CV 1/5] END alpha=0.0009183673469387755, eta0=0.05555555555555556, l1_ratio=0.08163265306122448, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=13333, n_iter_no_change=2, penalty=l2, tol=0.007727272727272727, validation_fraction=0.3938775510204082;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.0009183673469387755, eta0=0.05555555555555556, l1_ratio=0.08163265306122448, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=13333, n_iter_no_change=2, penalty=l2, tol=0.007727272727272727, validation_fraction=0.3938775510204082;, score=0.904 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.0009183673469387755, eta0=0.05555555555555556, l1_ratio=0.08163265306122448, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=13333, n_iter_no_change=2, penalty=l2, tol=0.007727272727272727, validation_fraction=0.3938775510204082;, score=0.926 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.0009183673469387755, eta0=0.05555555555555556, l1_ratio=0.08163265306122448, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=13333, n_iter_no_change=2, penalty=l2, tol=0.007727272727272727, validation_fraction=0.3938775510204082;, score=0.896 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.0009183673469387755, eta0=0.05555555555555556, l1_ratio=0.08163265306122448, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=13333, n_iter_no_change=2, penalty=l2, tol=0.007727272727272727, validation_fraction=0.3938775510204082;, score=0.879 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.00042857142857142855, eta0=0.05, l1_ratio=0.02040816326530612, learning_rate=constant, loss=squared_error, max_iter=16000, n_iter_no_change=6, penalty=elasticnet, tol=0.005727272727272727, validation_fraction=0.5408163265306123;, score=0.880 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.00042857142857142855, eta0=0.05, l1_ratio=0.02040816326530612, learning_rate=constant, loss=squared_error, max_iter=16000, n_iter_no_change=6, penalty=elasticnet, tol=0.005727272727272727, validation_fraction=0.5408163265306123;, score=0.904 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.00042857142857142855, eta0=0.05, l1_ratio=0.02040816326530612, learning_rate=constant, loss=squared_error, max_iter=16000, n_iter_no_change=6, penalty=elasticnet, tol=0.005727272727272727, validation_fraction=0.5408163265306123;, score=0.923 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.00042857142857142855, eta0=0.05, l1_ratio=0.02040816326530612, learning_rate=constant, loss=squared_error, max_iter=16000, n_iter_no_change=6, penalty=elasticnet, tol=0.005727272727272727, validation_fraction=0.5408163265306123;, score=0.891 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.00042857142857142855, eta0=0.05, l1_ratio=0.02040816326530612, learning_rate=constant, loss=squared_error, max_iter=16000, n_iter_no_change=6, penalty=elasticnet, tol=0.005727272727272727, validation_fraction=0.5408163265306123;, score=0.874 total time=   0.0s\n",
      "[CV 1/5] END alpha=2.0408163265306123e-05, eta0=0.060606060606060615, l1_ratio=0.36734693877551017, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=16727, n_iter_no_change=6, penalty=l1, tol=0.0028181818181818178, validation_fraction=0.1;, score=0.878 total time=   0.2s\n",
      "[CV 2/5] END alpha=2.0408163265306123e-05, eta0=0.060606060606060615, l1_ratio=0.36734693877551017, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=16727, n_iter_no_change=6, penalty=l1, tol=0.0028181818181818178, validation_fraction=0.1;, score=0.903 total time=   0.0s\n",
      "[CV 3/5] END alpha=2.0408163265306123e-05, eta0=0.060606060606060615, l1_ratio=0.36734693877551017, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=16727, n_iter_no_change=6, penalty=l1, tol=0.0028181818181818178, validation_fraction=0.1;, score=0.926 total time=   0.1s\n",
      "[CV 4/5] END alpha=2.0408163265306123e-05, eta0=0.060606060606060615, l1_ratio=0.36734693877551017, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=16727, n_iter_no_change=6, penalty=l1, tol=0.0028181818181818178, validation_fraction=0.1;, score=0.893 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=1, criterion=squared_error, max_depth=740, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, splitter=best;, score=0.767 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=1, criterion=squared_error, max_depth=740, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, splitter=best;, score=0.799 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=1, criterion=squared_error, max_depth=740, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, splitter=best;, score=0.771 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=1, criterion=friedman_mse, max_depth=1000, max_features=sqrt, min_samples_leaf=6, min_samples_split=4, splitter=best;, score=0.775 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=1, criterion=friedman_mse, max_depth=1000, max_features=sqrt, min_samples_leaf=6, min_samples_split=4, splitter=best;, score=0.767 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=1, criterion=friedman_mse, max_depth=1000, max_features=sqrt, min_samples_leaf=6, min_samples_split=4, splitter=best;, score=0.737 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=1, criterion=friedman_mse, max_depth=1000, max_features=sqrt, min_samples_leaf=6, min_samples_split=4, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0, criterion=poisson, max_depth=680, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, splitter=random;, score=0.715 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0, criterion=poisson, max_depth=680, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, splitter=random;, score=0.804 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0, criterion=poisson, max_depth=680, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, splitter=random;, score=0.785 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0, criterion=poisson, max_depth=680, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, splitter=random;, score=0.736 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0, criterion=poisson, max_depth=680, max_features=sqrt, min_samples_leaf=4, min_samples_split=3, splitter=random;, score=0.668 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0, criterion=absolute_error, max_depth=600, max_features=sqrt, min_samples_leaf=6, min_samples_split=4, splitter=random;, score=0.672 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0, criterion=absolute_error, max_depth=600, max_features=sqrt, min_samples_leaf=6, min_samples_split=4, splitter=random;, score=0.657 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0, criterion=absolute_error, max_depth=600, max_features=sqrt, min_samples_leaf=6, min_samples_split=4, splitter=random;, score=0.680 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0, criterion=absolute_error, max_depth=600, max_features=sqrt, min_samples_leaf=6, min_samples_split=4, splitter=random;, score=0.745 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0, criterion=absolute_error, max_depth=600, max_features=sqrt, min_samples_leaf=6, min_samples_split=4, splitter=random;, score=0.548 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0, criterion=absolute_error, max_depth=790, max_features=log2, min_samples_leaf=8, min_samples_split=14, splitter=random;, score=0.628 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0, criterion=absolute_error, max_depth=790, max_features=log2, min_samples_leaf=8, min_samples_split=14, splitter=random;, score=0.718 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=1, criterion=squared_error, max_depth=970, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.764 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=1, criterion=squared_error, max_depth=970, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.795 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0, criterion=poisson, max_depth=890, max_features=log2, min_samples_leaf=6, min_samples_split=5, splitter=random;, score=0.688 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0, criterion=poisson, max_depth=890, max_features=log2, min_samples_leaf=6, min_samples_split=5, splitter=random;, score=0.700 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=1, criterion=poisson, max_depth=370, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.673 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=1, criterion=poisson, max_depth=370, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.711 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=1, criterion=poisson, max_depth=370, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.612 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0, criterion=poisson, max_depth=620, max_features=log2, min_samples_leaf=1, min_samples_split=5, splitter=random;, score=0.618 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=1, criterion=squared_error, max_depth=90, max_features=sqrt, min_samples_leaf=8, min_samples_split=10, splitter=best;, score=0.817 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=1, criterion=squared_error, max_depth=90, max_features=sqrt, min_samples_leaf=8, min_samples_split=10, splitter=best;, score=0.703 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0, criterion=poisson, max_depth=490, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=random;, score=0.731 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0, criterion=poisson, max_depth=490, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=random;, score=0.683 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0, criterion=poisson, max_depth=490, max_features=sqrt, min_samples_leaf=8, min_samples_split=4, splitter=best;, score=0.803 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0, criterion=poisson, max_depth=490, max_features=sqrt, min_samples_leaf=8, min_samples_split=4, splitter=best;, score=0.763 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=1, criterion=friedman_mse, max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.741 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=1, criterion=friedman_mse, max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=2, splitter=best;, score=0.698 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=1, criterion=squared_error, max_depth=780, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=best;, score=0.795 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=1, criterion=squared_error, max_depth=780, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=best;, score=0.806 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=1, criterion=absolute_error, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.674 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=1, criterion=absolute_error, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.657 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0, criterion=poisson, max_depth=240, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, splitter=random;, score=0.594 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=1, criterion=poisson, max_depth=260, max_features=log2, min_samples_leaf=6, min_samples_split=3, splitter=random;, score=0.633 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=1, criterion=squared_error, max_depth=720, max_features=sqrt, min_samples_leaf=8, min_samples_split=3, splitter=random;, score=0.618 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=1, criterion=poisson, max_depth=180, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.768 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0, criterion=absolute_error, max_depth=110, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=best;, score=0.781 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0, criterion=absolute_error, max_depth=110, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=best;, score=0.787 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0, criterion=absolute_error, max_depth=220, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.686 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0, criterion=absolute_error, max_depth=220, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.662 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ccp_alpha=1, criterion=squared_error, max_depth=810, max_features=log2, min_samples_leaf=4, min_samples_split=10, splitter=best;, score=0.744 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=1, criterion=squared_error, max_depth=810, max_features=log2, min_samples_leaf=4, min_samples_split=10, splitter=best;, score=0.746 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=1, criterion=squared_error, max_depth=810, max_features=log2, min_samples_leaf=4, min_samples_split=10, splitter=best;, score=0.757 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=1, criterion=squared_error, max_depth=810, max_features=log2, min_samples_leaf=4, min_samples_split=10, splitter=best;, score=0.677 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=1, criterion=poisson, max_depth=820, max_features=sqrt, min_samples_leaf=6, min_samples_split=3, splitter=best;, score=0.727 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=1, criterion=poisson, max_depth=820, max_features=sqrt, min_samples_leaf=6, min_samples_split=3, splitter=best;, score=0.762 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=1, criterion=poisson, max_depth=820, max_features=sqrt, min_samples_leaf=6, min_samples_split=3, splitter=best;, score=0.777 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=1, criterion=poisson, max_depth=820, max_features=sqrt, min_samples_leaf=6, min_samples_split=3, splitter=best;, score=0.720 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=1, criterion=poisson, max_depth=820, max_features=sqrt, min_samples_leaf=6, min_samples_split=3, splitter=best;, score=0.691 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=1, criterion=squared_error, max_depth=970, max_features=sqrt, min_samples_leaf=2, min_samples_split=3, splitter=best;, score=0.689 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0, criterion=poisson, max_depth=890, max_features=log2, min_samples_leaf=6, min_samples_split=5, splitter=random;, score=0.544 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0, criterion=poisson, max_depth=890, max_features=log2, min_samples_leaf=6, min_samples_split=5, splitter=random;, score=0.629 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0, criterion=poisson, max_depth=890, max_features=log2, min_samples_leaf=6, min_samples_split=5, splitter=random;, score=0.391 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=1, criterion=poisson, max_depth=370, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.673 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=1, criterion=poisson, max_depth=370, max_features=log2, min_samples_leaf=2, min_samples_split=4, splitter=random;, score=0.643 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=1, criterion=squared_error, max_depth=90, max_features=sqrt, min_samples_leaf=8, min_samples_split=10, splitter=best;, score=0.650 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=1, criterion=squared_error, max_depth=90, max_features=sqrt, min_samples_leaf=8, min_samples_split=10, splitter=best;, score=0.715 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0, criterion=poisson, max_depth=490, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=random;, score=0.798 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0, criterion=poisson, max_depth=490, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=random;, score=0.607 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0, criterion=squared_error, max_depth=640, max_features=sqrt, min_samples_leaf=4, min_samples_split=5, splitter=random;, score=0.724 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0, criterion=poisson, max_depth=490, max_features=sqrt, min_samples_leaf=8, min_samples_split=4, splitter=best;, score=0.689 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=1, criterion=absolute_error, max_depth=940, max_features=log2, min_samples_leaf=4, min_samples_split=3, splitter=random;, score=0.665 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=1, criterion=absolute_error, max_depth=940, max_features=log2, min_samples_leaf=4, min_samples_split=3, splitter=random;, score=0.462 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0, criterion=friedman_mse, max_depth=180, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=random;, score=0.721 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0, criterion=friedman_mse, max_depth=900, max_features=log2, min_samples_leaf=8, min_samples_split=14, splitter=best;, score=0.713 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=1, criterion=squared_error, max_depth=780, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=best;, score=0.774 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=1, criterion=squared_error, max_depth=780, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=best;, score=0.775 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=1, criterion=absolute_error, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=4, splitter=random;, score=0.650 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0, criterion=absolute_error, max_depth=310, max_features=log2, min_samples_leaf=6, min_samples_split=10, splitter=best;, score=0.801 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=1, criterion=poisson, max_depth=260, max_features=log2, min_samples_leaf=6, min_samples_split=3, splitter=random;, score=0.650 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=1, criterion=poisson, max_depth=260, max_features=log2, min_samples_leaf=6, min_samples_split=3, splitter=random;, score=0.725 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=1, criterion=poisson, max_depth=180, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.756 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=1, criterion=poisson, max_depth=180, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.762 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0, criterion=absolute_error, max_depth=110, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=best;, score=0.720 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0, criterion=absolute_error, max_depth=110, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=best;, score=0.723 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=1, criterion=squared_error, max_depth=780, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=best;, score=0.766 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.0005510204081632653, eta0=0.05555555555555556, l1_ratio=0.09183673469387754, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=14303, n_iter_no_change=8, penalty=l1, tol=0.004636363636363636, validation_fraction=0.7040816326530612;, score=0.903 total time=   0.0s\n",
      "[CV 3/5] END alpha=6.122448979591836e-05, eta0=0.08535353535353536, l1_ratio=0.4387755102040816, learning_rate=constant, loss=huber, max_iter=19878, n_iter_no_change=1, penalty=l2, tol=0.008272727272727272, validation_fraction=0.49183673469387756;, score=-1.076 total time=   1.1s\n",
      "[CV 1/5] END alpha=4.0816326530612245e-05, eta0=0.05202020202020203, l1_ratio=0.08163265306122448, learning_rate=invscaling, loss=huber, max_iter=19030, n_iter_no_change=6, penalty=elasticnet, tol=0.006909090909090909, validation_fraction=0.6714285714285715;, score=-7.207 total time=   1.9s\n",
      "[CV 2/5] END alpha=4.0816326530612245e-05, eta0=0.05202020202020203, l1_ratio=0.08163265306122448, learning_rate=invscaling, loss=huber, max_iter=19030, n_iter_no_change=6, penalty=elasticnet, tol=0.006909090909090909, validation_fraction=0.6714285714285715;, score=-7.441 total time=   2.0s\n",
      "[CV 3/5] END alpha=0.0003469387755102041, eta0=0.07676767676767678, l1_ratio=0.5, learning_rate=constant, loss=huber, max_iter=19272, n_iter_no_change=4, penalty=l2, tol=0.003454545454545454, validation_fraction=0.2469387755102041;, score=-1.663 total time=   1.0s\n",
      "[CV 4/5] END alpha=0.0003469387755102041, eta0=0.07676767676767678, l1_ratio=0.5, learning_rate=constant, loss=huber, max_iter=19272, n_iter_no_change=4, penalty=l2, tol=0.003454545454545454, validation_fraction=0.2469387755102041;, score=-2.043 total time=   1.0s\n",
      "[CV 3/5] END alpha=0.0006122448979591836, eta0=0.09545454545454546, l1_ratio=0.47959183673469385, learning_rate=optimal, loss=huber, max_iter=8606, n_iter_no_change=2, penalty=elasticnet, tol=0.0030909090909090903, validation_fraction=0.4755102040816327;, score=-7.121 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=2.0408163265306123e-05, eta0=0.060606060606060615, l1_ratio=0.36734693877551017, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=16727, n_iter_no_change=6, penalty=l1, tol=0.0028181818181818178, validation_fraction=0.1;, score=0.886 total time=   0.1s\n",
      "[CV 1/5] END alpha=0.00032653061224489796, eta0=0.05101010101010101, l1_ratio=0.22448979591836732, learning_rate=adaptive, loss=squared_error, max_iter=9454, n_iter_no_change=2, penalty=elasticnet, tol=0.008090909090909091, validation_fraction=0.1;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.00032653061224489796, eta0=0.05101010101010101, l1_ratio=0.22448979591836732, learning_rate=adaptive, loss=squared_error, max_iter=9454, n_iter_no_change=2, penalty=elasticnet, tol=0.008090909090909091, validation_fraction=0.1;, score=0.904 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.00032653061224489796, eta0=0.05101010101010101, l1_ratio=0.22448979591836732, learning_rate=adaptive, loss=squared_error, max_iter=9454, n_iter_no_change=2, penalty=elasticnet, tol=0.008090909090909091, validation_fraction=0.1;, score=0.926 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.00032653061224489796, eta0=0.05101010101010101, l1_ratio=0.22448979591836732, learning_rate=adaptive, loss=squared_error, max_iter=9454, n_iter_no_change=2, penalty=elasticnet, tol=0.008090909090909091, validation_fraction=0.1;, score=0.894 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.00032653061224489796, eta0=0.05101010101010101, l1_ratio=0.22448979591836732, learning_rate=adaptive, loss=squared_error, max_iter=9454, n_iter_no_change=2, penalty=elasticnet, tol=0.008090909090909091, validation_fraction=0.1;, score=0.884 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.0008775510204081633, eta0=0.07121212121212121, l1_ratio=0.26530612244897955, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=12242, n_iter_no_change=8, penalty=elasticnet, tol=0.00509090909090909, validation_fraction=0.8020408163265307;, score=0.871 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.0008775510204081633, eta0=0.07121212121212121, l1_ratio=0.26530612244897955, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=12242, n_iter_no_change=8, penalty=elasticnet, tol=0.00509090909090909, validation_fraction=0.8020408163265307;, score=0.864 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.0008775510204081633, eta0=0.07121212121212121, l1_ratio=0.26530612244897955, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=12242, n_iter_no_change=8, penalty=elasticnet, tol=0.00509090909090909, validation_fraction=0.8020408163265307;, score=0.910 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.0008775510204081633, eta0=0.07121212121212121, l1_ratio=0.26530612244897955, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=12242, n_iter_no_change=8, penalty=elasticnet, tol=0.00509090909090909, validation_fraction=0.8020408163265307;, score=0.891 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.00012244897959183673, eta0=0.07676767676767678, l1_ratio=0.09183673469387754, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=11515, n_iter_no_change=5, penalty=None, tol=0.0016363636363636355, validation_fraction=0.6877551020408164;, score=0.891 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.00012244897959183673, eta0=0.07676767676767678, l1_ratio=0.09183673469387754, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=11515, n_iter_no_change=5, penalty=None, tol=0.0016363636363636355, validation_fraction=0.6877551020408164;, score=0.818 total time=   0.0s\n",
      "[CV 3/5] END alpha=4.0816326530612245e-05, eta0=0.05202020202020203, l1_ratio=0.08163265306122448, learning_rate=invscaling, loss=huber, max_iter=19030, n_iter_no_change=6, penalty=elasticnet, tol=0.006909090909090909, validation_fraction=0.6714285714285715;, score=-6.937 total time=   1.9s\n",
      "[CV 4/5] END alpha=4.0816326530612245e-05, eta0=0.05202020202020203, l1_ratio=0.08163265306122448, learning_rate=invscaling, loss=huber, max_iter=19030, n_iter_no_change=6, penalty=elasticnet, tol=0.006909090909090909, validation_fraction=0.6714285714285715;, score=-7.356 total time=   1.9s\n",
      "[CV 1/5] END alpha=0.0003469387755102041, eta0=0.07676767676767678, l1_ratio=0.5, learning_rate=constant, loss=huber, max_iter=19272, n_iter_no_change=4, penalty=l2, tol=0.003454545454545454, validation_fraction=0.2469387755102041;, score=-1.887 total time=   1.0s\n",
      "[CV 2/5] END alpha=0.0003469387755102041, eta0=0.07676767676767678, l1_ratio=0.5, learning_rate=constant, loss=huber, max_iter=19272, n_iter_no_change=4, penalty=l2, tol=0.003454545454545454, validation_fraction=0.2469387755102041;, score=-1.766 total time=   1.0s\n",
      "[CV 1/5] END alpha=0.001, eta0=0.05050505050505051, l1_ratio=0.336734693877551, learning_rate=constant, loss=squared_error, max_iter=12969, n_iter_no_change=1, penalty=None, tol=0.008727272727272728, validation_fraction=0.6877551020408164;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.001, eta0=0.05050505050505051, l1_ratio=0.336734693877551, learning_rate=constant, loss=squared_error, max_iter=12969, n_iter_no_change=1, penalty=None, tol=0.008727272727272728, validation_fraction=0.6877551020408164;, score=0.898 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.001, eta0=0.05050505050505051, l1_ratio=0.336734693877551, learning_rate=constant, loss=squared_error, max_iter=12969, n_iter_no_change=1, penalty=None, tol=0.008727272727272728, validation_fraction=0.6877551020408164;, score=0.922 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.001, eta0=0.05050505050505051, l1_ratio=0.336734693877551, learning_rate=constant, loss=squared_error, max_iter=12969, n_iter_no_change=1, penalty=None, tol=0.008727272727272728, validation_fraction=0.6877551020408164;, score=0.889 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.001, eta0=0.05050505050505051, l1_ratio=0.336734693877551, learning_rate=constant, loss=squared_error, max_iter=12969, n_iter_no_change=1, penalty=None, tol=0.008727272727272728, validation_fraction=0.6877551020408164;, score=0.858 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.0007142857142857143, eta0=0.07171717171717172, l1_ratio=0.26530612244897955, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=16727, n_iter_no_change=1, penalty=elasticnet, tol=0.004727272727272727, validation_fraction=0.5244897959183674;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.0007142857142857143, eta0=0.07171717171717172, l1_ratio=0.26530612244897955, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=16727, n_iter_no_change=1, penalty=elasticnet, tol=0.004727272727272727, validation_fraction=0.5244897959183674;, score=0.903 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.0007142857142857143, eta0=0.07171717171717172, l1_ratio=0.26530612244897955, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=16727, n_iter_no_change=1, penalty=elasticnet, tol=0.004727272727272727, validation_fraction=0.5244897959183674;, score=0.926 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.0007142857142857143, eta0=0.07171717171717172, l1_ratio=0.26530612244897955, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=16727, n_iter_no_change=1, penalty=elasticnet, tol=0.004727272727272727, validation_fraction=0.5244897959183674;, score=0.896 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.0007142857142857143, eta0=0.07171717171717172, l1_ratio=0.26530612244897955, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=16727, n_iter_no_change=1, penalty=elasticnet, tol=0.004727272727272727, validation_fraction=0.5244897959183674;, score=0.886 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.0006122448979591836, eta0=0.09545454545454546, l1_ratio=0.47959183673469385, learning_rate=optimal, loss=huber, max_iter=8606, n_iter_no_change=2, penalty=elasticnet, tol=0.0030909090909090903, validation_fraction=0.4755102040816327;, score=-7.391 total time=   0.5s\n",
      "[CV 4/5] END alpha=0.0006122448979591836, eta0=0.09545454545454546, l1_ratio=0.47959183673469385, learning_rate=optimal, loss=huber, max_iter=8606, n_iter_no_change=2, penalty=elasticnet, tol=0.0030909090909090903, validation_fraction=0.4755102040816327;, score=-7.542 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=0.0005510204081632653, eta0=0.05555555555555556, l1_ratio=0.09183673469387754, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=14303, n_iter_no_change=8, penalty=l1, tol=0.004636363636363636, validation_fraction=0.7040816326530612;, score=0.926 total time=   0.0s\n",
      "[CV 4/5] END alpha=6.122448979591836e-05, eta0=0.08535353535353536, l1_ratio=0.4387755102040816, learning_rate=constant, loss=huber, max_iter=19878, n_iter_no_change=1, penalty=l2, tol=0.008272727272727272, validation_fraction=0.49183673469387756;, score=-1.419 total time=   1.1s\n",
      "[CV 4/5] END alpha=0.0005306122448979592, eta0=0.06767676767676768, l1_ratio=0.39795918367346933, learning_rate=adaptive, loss=huber, max_iter=19272, n_iter_no_change=6, penalty=l2, tol=0.0015454545454545443, validation_fraction=0.4755102040816327;, score=-2.513 total time=   1.0s\n",
      "[CV 5/5] END alpha=0.0005306122448979592, eta0=0.06767676767676768, l1_ratio=0.39795918367346933, learning_rate=adaptive, loss=huber, max_iter=19272, n_iter_no_change=6, penalty=l2, tol=0.0015454545454545443, validation_fraction=0.4755102040816327;, score=-2.561 total time=   1.0s\n",
      "[CV 5/5] END alpha=0.00040816326530612246, eta0=0.08131313131313132, l1_ratio=0.01020408163265306, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=19030, n_iter_no_change=8, penalty=l1, tol=0.009545454545454546, validation_fraction=0.5081632653061224;, score=0.833 total time=   1.8s\n",
      "[CV 1/5] END alpha=0.0004897959183673469, eta0=0.06868686868686869, l1_ratio=0.08163265306122448, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=16727, n_iter_no_change=2, penalty=l2, tol=0.0041818181818181815, validation_fraction=0.1;, score=-5.780 total time=   1.1s\n",
      "[CV 5/5] END alpha=0.0003469387755102041, eta0=0.07676767676767678, l1_ratio=0.5, learning_rate=constant, loss=huber, max_iter=19272, n_iter_no_change=4, penalty=l2, tol=0.003454545454545454, validation_fraction=0.2469387755102041;, score=-2.035 total time=   1.0s\n",
      "[CV 1/5] END alpha=0.0009591836734693877, eta0=0.08989898989898991, l1_ratio=0.12244897959183673, learning_rate=optimal, loss=epsilon_insensitive, max_iter=17333, n_iter_no_change=1, penalty=None, tol=0.008181818181818182, validation_fraction=0.5571428571428572;, score=-4.101 total time=   0.9s\n",
      "[CV 2/5] END alpha=0.0007142857142857143, eta0=0.09242424242424244, l1_ratio=0.22448979591836732, learning_rate=constant, loss=epsilon_insensitive, max_iter=15636, n_iter_no_change=10, penalty=l1, tol=0.00509090909090909, validation_fraction=0.5244897959183674;, score=0.862 total time=   1.5s\n",
      "[CV 3/5] END alpha=0.0, eta0=0.06363636363636364, l1_ratio=0.25510204081632654, learning_rate=invscaling, loss=huber, max_iter=18303, n_iter_no_change=6, penalty=elasticnet, tol=0.00890909090909091, validation_fraction=0.44285714285714284;, score=-6.773 total time=   1.9s\n",
      "[CV 5/5] END alpha=0.0003469387755102041, eta0=0.05656565656565657, l1_ratio=0.19387755102040816, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=11636, n_iter_no_change=10, penalty=l1, tol=0.007272727272727273, validation_fraction=0.2142857142857143;, score=-4.959 total time=   1.2s\n",
      "[CV 1/5] END alpha=0.00028571428571428574, eta0=0.05404040404040405, l1_ratio=0.5, learning_rate=adaptive, loss=squared_error, max_iter=8484, n_iter_no_change=10, penalty=l2, tol=0.009909090909090909, validation_fraction=0.42653061224489797;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.00028571428571428574, eta0=0.05404040404040405, l1_ratio=0.5, learning_rate=adaptive, loss=squared_error, max_iter=8484, n_iter_no_change=10, penalty=l2, tol=0.009909090909090909, validation_fraction=0.42653061224489797;, score=0.903 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.00028571428571428574, eta0=0.05404040404040405, l1_ratio=0.5, learning_rate=adaptive, loss=squared_error, max_iter=8484, n_iter_no_change=10, penalty=l2, tol=0.009909090909090909, validation_fraction=0.42653061224489797;, score=0.926 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.00028571428571428574, eta0=0.05404040404040405, l1_ratio=0.5, learning_rate=adaptive, loss=squared_error, max_iter=8484, n_iter_no_change=10, penalty=l2, tol=0.009909090909090909, validation_fraction=0.42653061224489797;, score=0.894 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.00028571428571428574, eta0=0.05404040404040405, l1_ratio=0.5, learning_rate=adaptive, loss=squared_error, max_iter=8484, n_iter_no_change=10, penalty=l2, tol=0.009909090909090909, validation_fraction=0.42653061224489797;, score=0.885 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.0008163265306122449, eta0=0.062121212121212126, l1_ratio=0.29591836734693877, learning_rate=adaptive, loss=squared_error, max_iter=8121, n_iter_no_change=4, penalty=l2, tol=0.009454545454545455, validation_fraction=0.29591836734693877;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.0008163265306122449, eta0=0.062121212121212126, l1_ratio=0.29591836734693877, learning_rate=adaptive, loss=squared_error, max_iter=8121, n_iter_no_change=4, penalty=l2, tol=0.009454545454545455, validation_fraction=0.29591836734693877;, score=0.904 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.0008163265306122449, eta0=0.062121212121212126, l1_ratio=0.29591836734693877, learning_rate=adaptive, loss=squared_error, max_iter=8121, n_iter_no_change=4, penalty=l2, tol=0.009454545454545455, validation_fraction=0.29591836734693877;, score=0.926 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.0008163265306122449, eta0=0.062121212121212126, l1_ratio=0.29591836734693877, learning_rate=adaptive, loss=squared_error, max_iter=8121, n_iter_no_change=4, penalty=l2, tol=0.009454545454545455, validation_fraction=0.29591836734693877;, score=0.895 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.0008163265306122449, eta0=0.062121212121212126, l1_ratio=0.29591836734693877, learning_rate=adaptive, loss=squared_error, max_iter=8121, n_iter_no_change=4, penalty=l2, tol=0.009454545454545455, validation_fraction=0.29591836734693877;, score=0.885 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.0008163265306122449, eta0=0.07626262626262627, l1_ratio=0.4183673469387755, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=12363, n_iter_no_change=6, penalty=elasticnet, tol=0.0032727272727272726, validation_fraction=0.7693877551020408;, score=0.878 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.0008163265306122449, eta0=0.07626262626262627, l1_ratio=0.4183673469387755, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=12363, n_iter_no_change=6, penalty=elasticnet, tol=0.0032727272727272726, validation_fraction=0.7693877551020408;, score=0.903 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.0008163265306122449, eta0=0.07626262626262627, l1_ratio=0.4183673469387755, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=12363, n_iter_no_change=6, penalty=elasticnet, tol=0.0032727272727272726, validation_fraction=0.7693877551020408;, score=0.926 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.0008163265306122449, eta0=0.07626262626262627, l1_ratio=0.4183673469387755, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=12363, n_iter_no_change=6, penalty=elasticnet, tol=0.0032727272727272726, validation_fraction=0.7693877551020408;, score=0.894 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.0008163265306122449, eta0=0.07626262626262627, l1_ratio=0.4183673469387755, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=12363, n_iter_no_change=6, penalty=elasticnet, tol=0.0032727272727272726, validation_fraction=0.7693877551020408;, score=0.885 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.0006530612244897959, eta0=0.08282828282828283, l1_ratio=0.01020408163265306, learning_rate=optimal, loss=epsilon_insensitive, max_iter=13575, n_iter_no_change=5, penalty=None, tol=0.0037272727272727266, validation_fraction=0.2142857142857143;, score=-2.977 total time=   0.7s\n",
      "[CV 5/5] END alpha=0.0006530612244897959, eta0=0.08282828282828283, l1_ratio=0.01020408163265306, learning_rate=optimal, loss=epsilon_insensitive, max_iter=13575, n_iter_no_change=5, penalty=None, tol=0.0037272727272727266, validation_fraction=0.2142857142857143;, score=-3.340 total time=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=6.122448979591836e-05, eta0=0.08535353535353536, l1_ratio=0.4387755102040816, learning_rate=constant, loss=huber, max_iter=19878, n_iter_no_change=1, penalty=l2, tol=0.008272727272727272, validation_fraction=0.49183673469387756;, score=-1.276 total time=   1.1s\n",
      "[CV 5/5] END alpha=0.0008775510204081633, eta0=0.07121212121212121, l1_ratio=0.26530612244897955, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=12242, n_iter_no_change=8, penalty=elasticnet, tol=0.00509090909090909, validation_fraction=0.8020408163265307;, score=0.885 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.00012244897959183673, eta0=0.07676767676767678, l1_ratio=0.09183673469387754, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=11515, n_iter_no_change=5, penalty=None, tol=0.0016363636363636355, validation_fraction=0.6877551020408164;, score=0.825 total time=   0.0s\n",
      "[CV 5/5] END alpha=4.0816326530612245e-05, eta0=0.05202020202020203, l1_ratio=0.08163265306122448, learning_rate=invscaling, loss=huber, max_iter=19030, n_iter_no_change=6, penalty=elasticnet, tol=0.006909090909090909, validation_fraction=0.6714285714285715;, score=-8.223 total time=   2.0s\n",
      "[CV 1/5] END alpha=0.0005306122448979592, eta0=0.06767676767676768, l1_ratio=0.39795918367346933, learning_rate=adaptive, loss=huber, max_iter=19272, n_iter_no_change=6, penalty=l2, tol=0.0015454545454545443, validation_fraction=0.4755102040816327;, score=-2.349 total time=   1.0s\n",
      "[CV 2/5] END alpha=0.0004897959183673469, eta0=0.06868686868686869, l1_ratio=0.08163265306122448, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=16727, n_iter_no_change=2, penalty=l2, tol=0.0041818181818181815, validation_fraction=0.1;, score=-5.910 total time=   1.2s\n",
      "[CV 3/5] END alpha=0.0004897959183673469, eta0=0.06868686868686869, l1_ratio=0.08163265306122448, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=16727, n_iter_no_change=2, penalty=l2, tol=0.0041818181818181815, validation_fraction=0.1;, score=-5.511 total time=   1.1s\n",
      "[CV 2/5] END alpha=0.0009591836734693877, eta0=0.08989898989898991, l1_ratio=0.12244897959183673, learning_rate=optimal, loss=epsilon_insensitive, max_iter=17333, n_iter_no_change=1, penalty=None, tol=0.008181818181818182, validation_fraction=0.5571428571428572;, score=-4.163 total time=   0.9s\n",
      "[CV 3/5] END alpha=0.0009591836734693877, eta0=0.08989898989898991, l1_ratio=0.12244897959183673, learning_rate=optimal, loss=epsilon_insensitive, max_iter=17333, n_iter_no_change=1, penalty=None, tol=0.008181818181818182, validation_fraction=0.5571428571428572;, score=-3.851 total time=   0.9s\n",
      "[CV 5/5] END alpha=0.0007142857142857143, eta0=0.09242424242424244, l1_ratio=0.22448979591836732, learning_rate=constant, loss=epsilon_insensitive, max_iter=15636, n_iter_no_change=10, penalty=l1, tol=0.00509090909090909, validation_fraction=0.5244897959183674;, score=0.828 total time=   1.5s\n",
      "[CV 1/5] END alpha=0.00020408163265306123, eta0=0.07575757575757576, l1_ratio=0.336734693877551, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=13575, n_iter_no_change=8, penalty=elasticnet, tol=0.001, validation_fraction=0.4755102040816327;, score=0.853 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.00020408163265306123, eta0=0.07575757575757576, l1_ratio=0.336734693877551, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=13575, n_iter_no_change=8, penalty=elasticnet, tol=0.001, validation_fraction=0.4755102040816327;, score=0.879 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.00020408163265306123, eta0=0.07575757575757576, l1_ratio=0.336734693877551, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=13575, n_iter_no_change=8, penalty=elasticnet, tol=0.001, validation_fraction=0.4755102040816327;, score=0.920 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.00020408163265306123, eta0=0.07575757575757576, l1_ratio=0.336734693877551, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=13575, n_iter_no_change=8, penalty=elasticnet, tol=0.001, validation_fraction=0.4755102040816327;, score=0.861 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.00020408163265306123, eta0=0.07575757575757576, l1_ratio=0.336734693877551, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=13575, n_iter_no_change=8, penalty=elasticnet, tol=0.001, validation_fraction=0.4755102040816327;, score=0.878 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.0003469387755102041, eta0=0.05656565656565657, l1_ratio=0.19387755102040816, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=11636, n_iter_no_change=10, penalty=l1, tol=0.007272727272727273, validation_fraction=0.2142857142857143;, score=-4.390 total time=   1.2s\n",
      "[CV 3/5] END alpha=0.0003469387755102041, eta0=0.05656565656565657, l1_ratio=0.19387755102040816, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=11636, n_iter_no_change=10, penalty=l1, tol=0.007272727272727273, validation_fraction=0.2142857142857143;, score=-4.134 total time=   1.2s\n",
      "[CV 4/5] END alpha=0.0008775510204081633, eta0=0.06515151515151515, l1_ratio=0.3469387755102041, learning_rate=invscaling, loss=huber, max_iter=15515, n_iter_no_change=5, penalty=l1, tol=0.007272727272727273, validation_fraction=0.6224489795918368;, score=-7.250 total time=   1.5s\n",
      "[CV 1/5] END alpha=0.0008571428571428571, eta0=0.08787878787878789, l1_ratio=0.2040816326530612, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=15151, n_iter_no_change=4, penalty=l1, tol=0.005909090909090909, validation_fraction=0.7367346938775511;, score=-2.193 total time=   1.5s\n",
      "[CV 5/5] END alpha=0.00020408163265306123, eta0=0.0994949494949495, l1_ratio=0.36734693877551017, learning_rate=adaptive, loss=huber, max_iter=8121, n_iter_no_change=5, penalty=None, tol=0.003545454545454545, validation_fraction=0.2795918367346939;, score=0.553 total time=   0.4s\n",
      "[CV 1/5] END alpha=0.00042857142857142855, eta0=0.09797979797979799, l1_ratio=0.01020408163265306, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=10666, n_iter_no_change=5, penalty=l2, tol=0.009454545454545455, validation_fraction=0.8673469387755103;, score=0.848 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.00042857142857142855, eta0=0.09797979797979799, l1_ratio=0.01020408163265306, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=10666, n_iter_no_change=5, penalty=l2, tol=0.009454545454545455, validation_fraction=0.8673469387755103;, score=0.882 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.00042857142857142855, eta0=0.09797979797979799, l1_ratio=0.01020408163265306, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=10666, n_iter_no_change=5, penalty=l2, tol=0.009454545454545455, validation_fraction=0.8673469387755103;, score=0.923 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.00042857142857142855, eta0=0.09797979797979799, l1_ratio=0.01020408163265306, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=10666, n_iter_no_change=5, penalty=l2, tol=0.009454545454545455, validation_fraction=0.8673469387755103;, score=0.878 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.00042857142857142855, eta0=0.09797979797979799, l1_ratio=0.01020408163265306, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=10666, n_iter_no_change=5, penalty=l2, tol=0.009454545454545455, validation_fraction=0.8673469387755103;, score=0.879 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.0007551020408163266, eta0=0.09595959595959597, l1_ratio=0.2346938775510204, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=12848, n_iter_no_change=6, penalty=l1, tol=0.004545454545454545, validation_fraction=0.2795918367346939;, score=0.822 total time=   1.2s\n",
      "[CV 2/5] END alpha=0.0007755102040816326, eta0=0.05404040404040405, l1_ratio=0.11224489795918366, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=18181, n_iter_no_change=8, penalty=elasticnet, tol=0.00909090909090909, validation_fraction=0.8346938775510204;, score=-6.273 total time=   1.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END alpha=0.0007142857142857143, eta0=0.09242424242424244, l1_ratio=0.22448979591836732, learning_rate=constant, loss=epsilon_insensitive, max_iter=15636, n_iter_no_change=10, penalty=l1, tol=0.00509090909090909, validation_fraction=0.5244897959183674;, score=0.896 total time=   1.5s\n",
      "[CV 4/5] END alpha=0.0, eta0=0.06363636363636364, l1_ratio=0.25510204081632654, learning_rate=invscaling, loss=huber, max_iter=18303, n_iter_no_change=6, penalty=elasticnet, tol=0.00890909090909091, validation_fraction=0.44285714285714284;, score=-7.190 total time=   1.9s\n",
      "[CV 1/5] END alpha=0.0005918367346938776, eta0=0.06666666666666668, l1_ratio=0.1020408163265306, learning_rate=optimal, loss=squared_error, max_iter=11393, n_iter_no_change=8, penalty=elasticnet, tol=0.006818181818181819, validation_fraction=0.3122448979591837;, score=0.872 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.0005918367346938776, eta0=0.06666666666666668, l1_ratio=0.1020408163265306, learning_rate=optimal, loss=squared_error, max_iter=11393, n_iter_no_change=8, penalty=elasticnet, tol=0.006818181818181819, validation_fraction=0.3122448979591837;, score=0.898 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.0005918367346938776, eta0=0.06666666666666668, l1_ratio=0.1020408163265306, learning_rate=optimal, loss=squared_error, max_iter=11393, n_iter_no_change=8, penalty=elasticnet, tol=0.006818181818181819, validation_fraction=0.3122448979591837;, score=0.927 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.0005918367346938776, eta0=0.06666666666666668, l1_ratio=0.1020408163265306, learning_rate=optimal, loss=squared_error, max_iter=11393, n_iter_no_change=8, penalty=elasticnet, tol=0.006818181818181819, validation_fraction=0.3122448979591837;, score=0.884 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.0008775510204081633, eta0=0.06515151515151515, l1_ratio=0.3469387755102041, learning_rate=invscaling, loss=huber, max_iter=15515, n_iter_no_change=5, penalty=l1, tol=0.007272727272727273, validation_fraction=0.6224489795918368;, score=-7.330 total time=   1.5s\n",
      "[CV 2/5] END alpha=0.0006530612244897959, eta0=0.08282828282828283, l1_ratio=0.01020408163265306, learning_rate=optimal, loss=epsilon_insensitive, max_iter=13575, n_iter_no_change=5, penalty=None, tol=0.0037272727272727266, validation_fraction=0.2142857142857143;, score=-2.988 total time=   0.7s\n",
      "[CV 3/5] END alpha=0.0008571428571428571, eta0=0.08787878787878789, l1_ratio=0.2040816326530612, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=15151, n_iter_no_change=4, penalty=l1, tol=0.005909090909090909, validation_fraction=0.7367346938775511;, score=-1.969 total time=   1.5s\n",
      "[CV 4/5] END alpha=0.00020408163265306123, eta0=0.0994949494949495, l1_ratio=0.36734693877551017, learning_rate=adaptive, loss=huber, max_iter=8121, n_iter_no_change=5, penalty=None, tol=0.003545454545454545, validation_fraction=0.2795918367346939;, score=0.517 total time=   0.4s\n",
      "[CV 5/5] END alpha=0.0007346938775510204, eta0=0.06767676767676768, l1_ratio=0.11224489795918366, learning_rate=adaptive, loss=huber, max_iter=9454, n_iter_no_change=2, penalty=l1, tol=0.0013636363636363637, validation_fraction=0.7040816326530612;, score=0.270 total time=   0.8s\n",
      "[CV 1/5] END alpha=0.000836734693877551, eta0=0.0893939393939394, l1_ratio=0.47959183673469385, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=12363, n_iter_no_change=1, penalty=l2, tol=0.005818181818181818, validation_fraction=0.2795918367346939;, score=0.882 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.000836734693877551, eta0=0.0893939393939394, l1_ratio=0.47959183673469385, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=12363, n_iter_no_change=1, penalty=l2, tol=0.005818181818181818, validation_fraction=0.2795918367346939;, score=0.893 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.000836734693877551, eta0=0.0893939393939394, l1_ratio=0.47959183673469385, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=12363, n_iter_no_change=1, penalty=l2, tol=0.005818181818181818, validation_fraction=0.2795918367346939;, score=0.922 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.000836734693877551, eta0=0.0893939393939394, l1_ratio=0.47959183673469385, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=12363, n_iter_no_change=1, penalty=l2, tol=0.005818181818181818, validation_fraction=0.2795918367346939;, score=0.896 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.000836734693877551, eta0=0.0893939393939394, l1_ratio=0.47959183673469385, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=12363, n_iter_no_change=1, penalty=l2, tol=0.005818181818181818, validation_fraction=0.2795918367346939;, score=0.878 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.0009387755102040817, eta0=0.059595959595959605, l1_ratio=0.4081632653061224, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=9212, n_iter_no_change=1, penalty=elasticnet, tol=0.009181818181818182, validation_fraction=0.36122448979591837;, score=0.876 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.0009387755102040817, eta0=0.059595959595959605, l1_ratio=0.4081632653061224, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=9212, n_iter_no_change=1, penalty=elasticnet, tol=0.009181818181818182, validation_fraction=0.36122448979591837;, score=0.904 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.0009387755102040817, eta0=0.059595959595959605, l1_ratio=0.4081632653061224, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=9212, n_iter_no_change=1, penalty=elasticnet, tol=0.009181818181818182, validation_fraction=0.36122448979591837;, score=0.925 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.0009387755102040817, eta0=0.059595959595959605, l1_ratio=0.4081632653061224, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=9212, n_iter_no_change=1, penalty=elasticnet, tol=0.009181818181818182, validation_fraction=0.36122448979591837;, score=0.885 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.0009387755102040817, eta0=0.059595959595959605, l1_ratio=0.4081632653061224, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=9212, n_iter_no_change=1, penalty=elasticnet, tol=0.009181818181818182, validation_fraction=0.36122448979591837;, score=0.875 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.0007755102040816326, eta0=0.05404040404040405, l1_ratio=0.11224489795918366, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=18181, n_iter_no_change=8, penalty=elasticnet, tol=0.00909090909090909, validation_fraction=0.8346938775510204;, score=-6.121 total time=   1.9s\n",
      "[CV 3/5] END alpha=0.0003061224489795918, eta0=0.09393939393939395, l1_ratio=0.17346938775510204, learning_rate=optimal, loss=epsilon_insensitive, max_iter=15151, n_iter_no_change=4, penalty=l2, tol=0.008818181818181819, validation_fraction=0.5081632653061224;, score=-4.133 total time=   0.8s\n",
      "[CV 4/5] END alpha=0.00022448979591836734, eta0=0.060606060606060615, l1_ratio=0.29591836734693877, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=17090, n_iter_no_change=2, penalty=elasticnet, tol=0.007909090909090909, validation_fraction=0.8673469387755103;, score=0.895 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.0008979591836734694, eta0=0.06565656565656566, l1_ratio=0.3877551020408163, learning_rate=constant, loss=epsilon_insensitive, max_iter=14060, n_iter_no_change=1, penalty=l2, tol=0.004727272727272727, validation_fraction=0.6387755102040816;, score=-0.146 total time=   0.3s\n",
      "[CV 5/5] END alpha=0.0008979591836734694, eta0=0.06565656565656566, l1_ratio=0.3877551020408163, learning_rate=constant, loss=epsilon_insensitive, max_iter=14060, n_iter_no_change=1, penalty=l2, tol=0.004727272727272727, validation_fraction=0.6387755102040816;, score=-0.218 total time=   0.3s\n",
      "[CV 5/5] END alpha=0.0006122448979591836, eta0=0.06818181818181819, l1_ratio=0.31632653061224486, learning_rate=optimal, loss=epsilon_insensitive, max_iter=8121, n_iter_no_change=6, penalty=None, tol=0.005818181818181818, validation_fraction=0.2306122448979592;, score=-3.300 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ccp_alpha=0, criterion=poisson, max_depth=240, max_features=sqrt, min_samples_leaf=6, min_samples_split=14, splitter=random;, score=0.684 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=0, criterion=absolute_error, max_depth=310, max_features=log2, min_samples_leaf=6, min_samples_split=10, splitter=best;, score=0.680 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=0, criterion=absolute_error, max_depth=310, max_features=log2, min_samples_leaf=6, min_samples_split=10, splitter=best;, score=0.676 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=1, criterion=poisson, max_depth=180, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.698 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=1, criterion=poisson, max_depth=180, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, splitter=best;, score=0.651 total time=   0.0s\n",
      "[CV 1/5] END ccp_alpha=0, criterion=squared_error, max_depth=90, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=best;, score=0.756 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0, criterion=squared_error, max_depth=90, max_features=sqrt, min_samples_leaf=4, min_samples_split=2, splitter=best;, score=0.824 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=1, criterion=poisson, max_depth=400, max_features=log2, min_samples_leaf=4, min_samples_split=14, splitter=best;, score=0.740 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=1, criterion=poisson, max_depth=400, max_features=log2, min_samples_leaf=4, min_samples_split=14, splitter=best;, score=0.642 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=0, criterion=absolute_error, max_depth=220, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.712 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=0, criterion=absolute_error, max_depth=220, max_features=log2, min_samples_leaf=2, min_samples_split=2, splitter=best;, score=0.762 total time=   0.0s\n",
      "[CV 5/5] END ccp_alpha=1, criterion=squared_error, max_depth=780, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=best;, score=0.792 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.0005510204081632653, eta0=0.05555555555555556, l1_ratio=0.09183673469387754, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=14303, n_iter_no_change=8, penalty=l1, tol=0.004636363636363636, validation_fraction=0.7040816326530612;, score=0.878 total time=   0.0s\n",
      "[CV 2/5] END alpha=6.122448979591836e-05, eta0=0.08535353535353536, l1_ratio=0.4387755102040816, learning_rate=constant, loss=huber, max_iter=19878, n_iter_no_change=1, penalty=l2, tol=0.008272727272727272, validation_fraction=0.49183673469387756;, score=-1.147 total time=   1.1s\n",
      "[CV 4/5] END alpha=0.00012244897959183673, eta0=0.07676767676767678, l1_ratio=0.09183673469387754, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=11515, n_iter_no_change=5, penalty=None, tol=0.0016363636363636355, validation_fraction=0.6877551020408164;, score=0.875 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.00012244897959183673, eta0=0.07676767676767678, l1_ratio=0.09183673469387754, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=11515, n_iter_no_change=5, penalty=None, tol=0.0016363636363636355, validation_fraction=0.6877551020408164;, score=0.822 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.0005306122448979592, eta0=0.06767676767676768, l1_ratio=0.39795918367346933, learning_rate=adaptive, loss=huber, max_iter=19272, n_iter_no_change=6, penalty=l2, tol=0.0015454545454545443, validation_fraction=0.4755102040816327;, score=-2.245 total time=   1.0s\n",
      "[CV 3/5] END alpha=0.0005306122448979592, eta0=0.06767676767676768, l1_ratio=0.39795918367346933, learning_rate=adaptive, loss=huber, max_iter=19272, n_iter_no_change=6, penalty=l2, tol=0.0015454545454545443, validation_fraction=0.4755102040816327;, score=-2.111 total time=   1.0s\n",
      "[CV 3/5] END alpha=0.00040816326530612246, eta0=0.08131313131313132, l1_ratio=0.01020408163265306, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=19030, n_iter_no_change=8, penalty=l1, tol=0.009545454545454546, validation_fraction=0.5081632653061224;, score=0.900 total time=   1.8s\n",
      "[CV 4/5] END alpha=0.00040816326530612246, eta0=0.08131313131313132, l1_ratio=0.01020408163265306, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=19030, n_iter_no_change=8, penalty=l1, tol=0.009545454545454546, validation_fraction=0.5081632653061224;, score=0.850 total time=   1.8s\n",
      "[CV 4/5] END alpha=0.0009591836734693877, eta0=0.08989898989898991, l1_ratio=0.12244897959183673, learning_rate=optimal, loss=epsilon_insensitive, max_iter=17333, n_iter_no_change=1, penalty=None, tol=0.008181818181818182, validation_fraction=0.5571428571428572;, score=-4.233 total time=   0.9s\n",
      "[CV 5/5] END alpha=0.0009591836734693877, eta0=0.08989898989898991, l1_ratio=0.12244897959183673, learning_rate=optimal, loss=epsilon_insensitive, max_iter=17333, n_iter_no_change=1, penalty=None, tol=0.008181818181818182, validation_fraction=0.5571428571428572;, score=-4.628 total time=   0.9s\n",
      "[CV 1/5] END alpha=0.0, eta0=0.06363636363636364, l1_ratio=0.25510204081632654, learning_rate=invscaling, loss=huber, max_iter=18303, n_iter_no_change=6, penalty=elasticnet, tol=0.00890909090909091, validation_fraction=0.44285714285714284;, score=-7.042 total time=   1.9s\n",
      "[CV 2/5] END alpha=0.0003469387755102041, eta0=0.05656565656565657, l1_ratio=0.19387755102040816, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=11636, n_iter_no_change=10, penalty=l1, tol=0.007272727272727273, validation_fraction=0.2142857142857143;, score=-4.468 total time=   1.1s\n",
      "[CV 3/5] END alpha=0.0008775510204081633, eta0=0.06515151515151515, l1_ratio=0.3469387755102041, learning_rate=invscaling, loss=huber, max_iter=15515, n_iter_no_change=5, penalty=l1, tol=0.007272727272727273, validation_fraction=0.6224489795918368;, score=-6.832 total time=   1.5s\n",
      "[CV 4/5] END alpha=0.0006530612244897959, eta0=0.08282828282828283, l1_ratio=0.01020408163265306, learning_rate=optimal, loss=epsilon_insensitive, max_iter=13575, n_iter_no_change=5, penalty=None, tol=0.0037272727272727266, validation_fraction=0.2142857142857143;, score=-3.100 total time=   0.7s\n",
      "[CV 5/5] END alpha=0.0008571428571428571, eta0=0.08787878787878789, l1_ratio=0.2040816326530612, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=15151, n_iter_no_change=4, penalty=l1, tol=0.005909090909090909, validation_fraction=0.7367346938775511;, score=-2.439 total time=   1.5s\n",
      "[CV 3/5] END alpha=0.0007346938775510204, eta0=0.06767676767676768, l1_ratio=0.11224489795918366, learning_rate=adaptive, loss=huber, max_iter=9454, n_iter_no_change=2, penalty=l1, tol=0.0013636363636363637, validation_fraction=0.7040816326530612;, score=0.369 total time=   0.9s\n",
      "[CV 4/5] END alpha=0.0007551020408163266, eta0=0.09595959595959597, l1_ratio=0.2346938775510204, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=12848, n_iter_no_change=6, penalty=l1, tol=0.004545454545454545, validation_fraction=0.2795918367346939;, score=0.833 total time=   1.2s\n",
      "[CV 5/5] END alpha=0.0007755102040816326, eta0=0.05404040404040405, l1_ratio=0.11224489795918366, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=18181, n_iter_no_change=8, penalty=elasticnet, tol=0.00909090909090909, validation_fraction=0.8346938775510204;, score=-6.953 total time=   1.9s\n",
      "[CV 4/5] END alpha=0.0008979591836734694, eta0=0.06565656565656566, l1_ratio=0.3877551020408163, learning_rate=constant, loss=epsilon_insensitive, max_iter=14060, n_iter_no_change=1, penalty=l2, tol=0.004727272727272727, validation_fraction=0.6387755102040816;, score=-0.346 total time=   0.3s\n",
      "[CV 3/5] END alpha=0.0006122448979591836, eta0=0.06818181818181819, l1_ratio=0.31632653061224486, learning_rate=optimal, loss=epsilon_insensitive, max_iter=8121, n_iter_no_change=6, penalty=None, tol=0.005818181818181818, validation_fraction=0.2306122448979592;, score=-2.710 total time=   0.4s\n",
      "[CV 4/5] END alpha=0.001, eta0=0.0590909090909091, l1_ratio=0.3571428571428571, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=13818, n_iter_no_change=4, penalty=l2, tol=0.009000000000000001, validation_fraction=0.8020408163265307;, score=-0.178 total time=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=0.0007142857142857143, eta0=0.09242424242424244, l1_ratio=0.22448979591836732, learning_rate=constant, loss=epsilon_insensitive, max_iter=15636, n_iter_no_change=10, penalty=l1, tol=0.00509090909090909, validation_fraction=0.5244897959183674;, score=0.832 total time=   1.5s\n",
      "[CV 2/5] END alpha=0.0, eta0=0.06363636363636364, l1_ratio=0.25510204081632654, learning_rate=invscaling, loss=huber, max_iter=18303, n_iter_no_change=6, penalty=elasticnet, tol=0.00890909090909091, validation_fraction=0.44285714285714284;, score=-7.267 total time=   1.9s\n",
      "[CV 4/5] END alpha=0.0003469387755102041, eta0=0.05656565656565657, l1_ratio=0.19387755102040816, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=11636, n_iter_no_change=10, penalty=l1, tol=0.007272727272727273, validation_fraction=0.2142857142857143;, score=-4.523 total time=   1.1s\n",
      "[CV 5/5] END alpha=0.0008775510204081633, eta0=0.06515151515151515, l1_ratio=0.3469387755102041, learning_rate=invscaling, loss=huber, max_iter=15515, n_iter_no_change=5, penalty=l1, tol=0.007272727272727273, validation_fraction=0.6224489795918368;, score=-8.101 total time=   1.5s\n",
      "[CV 2/5] END alpha=0.0008571428571428571, eta0=0.08787878787878789, l1_ratio=0.2040816326530612, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=15151, n_iter_no_change=4, penalty=l1, tol=0.005909090909090909, validation_fraction=0.7367346938775511;, score=-2.170 total time=   1.5s\n",
      "[CV 2/5] END alpha=0.0007346938775510204, eta0=0.06767676767676768, l1_ratio=0.11224489795918366, learning_rate=adaptive, loss=huber, max_iter=9454, n_iter_no_change=2, penalty=l1, tol=0.0013636363636363637, validation_fraction=0.7040816326530612;, score=0.313 total time=   0.8s\n",
      "[CV 3/5] END alpha=0.0007551020408163266, eta0=0.09595959595959597, l1_ratio=0.2346938775510204, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=12848, n_iter_no_change=6, penalty=l1, tol=0.004545454545454545, validation_fraction=0.2795918367346939;, score=0.886 total time=   1.2s\n",
      "[CV 4/5] END alpha=0.0007755102040816326, eta0=0.05404040404040405, l1_ratio=0.11224489795918366, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=18181, n_iter_no_change=8, penalty=elasticnet, tol=0.00909090909090909, validation_fraction=0.8346938775510204;, score=-6.279 total time=   1.8s\n",
      "[CV 1/5] END alpha=0.00022448979591836734, eta0=0.060606060606060615, l1_ratio=0.29591836734693877, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=17090, n_iter_no_change=2, penalty=elasticnet, tol=0.007909090909090909, validation_fraction=0.8673469387755103;, score=0.885 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.00022448979591836734, eta0=0.060606060606060615, l1_ratio=0.29591836734693877, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=17090, n_iter_no_change=2, penalty=elasticnet, tol=0.007909090909090909, validation_fraction=0.8673469387755103;, score=0.903 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.00022448979591836734, eta0=0.060606060606060615, l1_ratio=0.29591836734693877, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=17090, n_iter_no_change=2, penalty=elasticnet, tol=0.007909090909090909, validation_fraction=0.8673469387755103;, score=0.919 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.00022448979591836734, eta0=0.060606060606060615, l1_ratio=0.29591836734693877, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=17090, n_iter_no_change=2, penalty=elasticnet, tol=0.007909090909090909, validation_fraction=0.8673469387755103;, score=0.884 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.0008979591836734694, eta0=0.06565656565656566, l1_ratio=0.3877551020408163, learning_rate=constant, loss=epsilon_insensitive, max_iter=14060, n_iter_no_change=1, penalty=l2, tol=0.004727272727272727, validation_fraction=0.6387755102040816;, score=-0.141 total time=   0.3s\n",
      "[CV 1/5] END alpha=0.0006122448979591836, eta0=0.06818181818181819, l1_ratio=0.31632653061224486, learning_rate=optimal, loss=epsilon_insensitive, max_iter=8121, n_iter_no_change=6, penalty=None, tol=0.005818181818181818, validation_fraction=0.2306122448979592;, score=-2.942 total time=   0.4s\n",
      "[CV 1/5] END alpha=0.001, eta0=0.0590909090909091, l1_ratio=0.3571428571428571, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=13818, n_iter_no_change=4, penalty=l2, tol=0.009000000000000001, validation_fraction=0.8020408163265307;, score=-0.106 total time=   0.4s\n",
      "[CV 2/5] END alpha=0.0, eta0=0.0691919191919192, l1_ratio=0.44897959183673464, learning_rate=invscaling, loss=huber, max_iter=12121, n_iter_no_change=10, penalty=elasticnet, tol=0.006454545454545454, validation_fraction=0.5408163265306123;, score=-7.385 total time=   1.4s\n",
      "[CV 1/5] END alpha=6.122448979591836e-05, eta0=0.05505050505050506, l1_ratio=0.5, learning_rate=constant, loss=epsilon_insensitive, max_iter=17454, n_iter_no_change=4, penalty=None, tol=0.009727272727272727, validation_fraction=0.3448979591836735;, score=0.808 total time=   1.0s\n",
      "[CV 1/5] END alpha=0.0004897959183673469, eta0=0.06515151515151515, l1_ratio=0.2755102040816326, learning_rate=optimal, loss=huber, max_iter=11151, n_iter_no_change=2, penalty=l2, tol=0.002363636363636363, validation_fraction=0.29591836734693877;, score=-7.381 total time=   0.5s\n",
      "[CV 2/5] END alpha=0.0004897959183673469, eta0=0.06515151515151515, l1_ratio=0.2755102040816326, learning_rate=optimal, loss=huber, max_iter=11151, n_iter_no_change=2, penalty=l2, tol=0.002363636363636363, validation_fraction=0.29591836734693877;, score=-7.622 total time=   0.4s\n",
      "[CV 2/5] END alpha=0.0007142857142857143, eta0=0.07272727272727274, l1_ratio=0.1530612244897959, learning_rate=invscaling, loss=squared_error, max_iter=12242, n_iter_no_change=6, penalty=None, tol=0.007454545454545455, validation_fraction=0.2142857142857143;, score=0.903 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.0007142857142857143, eta0=0.07272727272727274, l1_ratio=0.1530612244897959, learning_rate=invscaling, loss=squared_error, max_iter=12242, n_iter_no_change=6, penalty=None, tol=0.007454545454545455, validation_fraction=0.2142857142857143;, score=0.926 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.0007142857142857143, eta0=0.07272727272727274, l1_ratio=0.1530612244897959, learning_rate=invscaling, loss=squared_error, max_iter=12242, n_iter_no_change=6, penalty=None, tol=0.007454545454545455, validation_fraction=0.2142857142857143;, score=0.886 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.0007142857142857143, eta0=0.07272727272727274, l1_ratio=0.1530612244897959, learning_rate=invscaling, loss=squared_error, max_iter=12242, n_iter_no_change=6, penalty=None, tol=0.007454545454545455, validation_fraction=0.2142857142857143;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.0009387755102040817, eta0=0.06313131313131314, l1_ratio=0.030612244897959183, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=15030, n_iter_no_change=10, penalty=l2, tol=0.006818181818181819, validation_fraction=0.1326530612244898;, score=0.876 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.0009387755102040817, eta0=0.06313131313131314, l1_ratio=0.030612244897959183, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=15030, n_iter_no_change=10, penalty=l2, tol=0.006818181818181819, validation_fraction=0.1326530612244898;, score=0.882 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.0009387755102040817, eta0=0.06313131313131314, l1_ratio=0.030612244897959183, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=15030, n_iter_no_change=10, penalty=l2, tol=0.006818181818181819, validation_fraction=0.1326530612244898;, score=0.900 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.0009387755102040817, eta0=0.06313131313131314, l1_ratio=0.030612244897959183, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=15030, n_iter_no_change=10, penalty=l2, tol=0.006818181818181819, validation_fraction=0.1326530612244898;, score=0.567 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=0.00020408163265306123, eta0=0.0994949494949495, l1_ratio=0.36734693877551017, learning_rate=adaptive, loss=huber, max_iter=8121, n_iter_no_change=5, penalty=None, tol=0.003545454545454545, validation_fraction=0.2795918367346939;, score=0.549 total time=   0.4s\n",
      "[CV 2/5] END alpha=0.00020408163265306123, eta0=0.0994949494949495, l1_ratio=0.36734693877551017, learning_rate=adaptive, loss=huber, max_iter=8121, n_iter_no_change=5, penalty=None, tol=0.003545454545454545, validation_fraction=0.2795918367346939;, score=0.578 total time=   0.4s\n",
      "[CV 3/5] END alpha=0.00020408163265306123, eta0=0.0994949494949495, l1_ratio=0.36734693877551017, learning_rate=adaptive, loss=huber, max_iter=8121, n_iter_no_change=5, penalty=None, tol=0.003545454545454545, validation_fraction=0.2795918367346939;, score=0.620 total time=   0.4s\n",
      "[CV 4/5] END alpha=0.0007346938775510204, eta0=0.06767676767676768, l1_ratio=0.11224489795918366, learning_rate=adaptive, loss=huber, max_iter=9454, n_iter_no_change=2, penalty=l1, tol=0.0013636363636363637, validation_fraction=0.7040816326530612;, score=0.204 total time=   0.8s\n",
      "[CV 5/5] END alpha=0.0007551020408163266, eta0=0.09595959595959597, l1_ratio=0.2346938775510204, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=12848, n_iter_no_change=6, penalty=l1, tol=0.004545454545454545, validation_fraction=0.2795918367346939;, score=0.819 total time=   1.2s\n",
      "[CV 1/5] END alpha=0.0003061224489795918, eta0=0.09393939393939395, l1_ratio=0.17346938775510204, learning_rate=optimal, loss=epsilon_insensitive, max_iter=15151, n_iter_no_change=4, penalty=l2, tol=0.008818181818181819, validation_fraction=0.5081632653061224;, score=-4.391 total time=   0.8s\n",
      "[CV 2/5] END alpha=0.0003061224489795918, eta0=0.09393939393939395, l1_ratio=0.17346938775510204, learning_rate=optimal, loss=epsilon_insensitive, max_iter=15151, n_iter_no_change=4, penalty=l2, tol=0.008818181818181819, validation_fraction=0.5081632653061224;, score=-4.430 total time=   0.8s\n",
      "[CV 1/5] END alpha=0.0008979591836734694, eta0=0.06565656565656566, l1_ratio=0.3877551020408163, learning_rate=constant, loss=epsilon_insensitive, max_iter=14060, n_iter_no_change=1, penalty=l2, tol=0.004727272727272727, validation_fraction=0.6387755102040816;, score=-0.209 total time=   0.3s\n",
      "[CV 2/5] END alpha=0.0006122448979591836, eta0=0.06818181818181819, l1_ratio=0.31632653061224486, learning_rate=optimal, loss=epsilon_insensitive, max_iter=8121, n_iter_no_change=6, penalty=None, tol=0.005818181818181818, validation_fraction=0.2306122448979592;, score=-2.952 total time=   0.4s\n",
      "[CV 2/5] END alpha=0.001, eta0=0.0590909090909091, l1_ratio=0.3571428571428571, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=13818, n_iter_no_change=4, penalty=l2, tol=0.009000000000000001, validation_fraction=0.8020408163265307;, score=-0.030 total time=   0.4s\n",
      "[CV 3/5] END alpha=0.0, eta0=0.0691919191919192, l1_ratio=0.44897959183673464, learning_rate=invscaling, loss=huber, max_iter=12121, n_iter_no_change=10, penalty=elasticnet, tol=0.006454545454545454, validation_fraction=0.5408163265306123;, score=-6.884 total time=   1.4s\n",
      "[CV 3/5] END alpha=6.122448979591836e-05, eta0=0.05505050505050506, l1_ratio=0.5, learning_rate=constant, loss=epsilon_insensitive, max_iter=17454, n_iter_no_change=4, penalty=None, tol=0.009727272727272727, validation_fraction=0.3448979591836735;, score=0.872 total time=   1.0s\n",
      "[CV 5/5] END alpha=0.0004897959183673469, eta0=0.06515151515151515, l1_ratio=0.2755102040816326, learning_rate=optimal, loss=huber, max_iter=11151, n_iter_no_change=2, penalty=l2, tol=0.002363636363636363, validation_fraction=0.29591836734693877;, score=-8.425 total time=   0.5s\n",
      "[CV 1/5] END alpha=0.0005306122448979592, eta0=0.08383838383838385, l1_ratio=0.0510204081632653, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=15151, n_iter_no_change=1, penalty=l1, tol=0.004818181818181818, validation_fraction=0.6551020408163265;, score=0.839 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.0006530612244897959, eta0=0.06464646464646465, l1_ratio=0.4591836734693877, learning_rate=constant, loss=huber, max_iter=8000, n_iter_no_change=2, penalty=l1, tol=0.005272727272727273, validation_fraction=0.589795918367347;, score=-0.378 total time=   0.7s\n",
      "[CV 1/5] END alpha=0.0007142857142857143, eta0=0.07272727272727274, l1_ratio=0.1530612244897959, learning_rate=invscaling, loss=squared_error, max_iter=12242, n_iter_no_change=6, penalty=None, tol=0.007454545454545455, validation_fraction=0.2142857142857143;, score=0.878 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.0006530612244897959, eta0=0.05656565656565657, l1_ratio=0.4591836734693877, learning_rate=optimal, loss=huber, max_iter=8000, n_iter_no_change=5, penalty=l2, tol=0.007363636363636364, validation_fraction=0.6551020408163265;, score=-7.452 total time=   0.1s\n",
      "[CV 2/5] END alpha=0.0006530612244897959, eta0=0.05656565656565657, l1_ratio=0.4591836734693877, learning_rate=optimal, loss=huber, max_iter=8000, n_iter_no_change=5, penalty=l2, tol=0.007363636363636364, validation_fraction=0.6551020408163265;, score=-7.698 total time=   0.1s\n",
      "[CV 5/5] END alpha=0.0006530612244897959, eta0=0.05656565656565657, l1_ratio=0.4591836734693877, learning_rate=optimal, loss=huber, max_iter=8000, n_iter_no_change=5, penalty=l2, tol=0.007363636363636364, validation_fraction=0.6551020408163265;, score=-8.507 total time=   0.1s\n",
      "[CV 1/5] END alpha=0.0005510204081632653, eta0=0.06767676767676768, l1_ratio=0.11224489795918366, learning_rate=invscaling, loss=huber, max_iter=13818, n_iter_no_change=2, penalty=elasticnet, tol=0.0017272727272727266, validation_fraction=0.7204081632653062;, score=-7.430 total time=   1.4s\n",
      "[CV 2/5] END alpha=0.00040816326530612246, eta0=0.05202020202020203, l1_ratio=0.04081632653061224, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=16848, n_iter_no_change=10, penalty=l2, tol=0.007818181818181818, validation_fraction=0.8836734693877552;, score=-0.016 total time=   0.5s\n",
      "[CV 3/5] END alpha=0.00040816326530612246, eta0=0.05202020202020203, l1_ratio=0.04081632653061224, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=16848, n_iter_no_change=10, penalty=l2, tol=0.007818181818181818, validation_fraction=0.8836734693877552;, score=-0.018 total time=   0.5s\n",
      "[CV 4/5] END alpha=0.00040816326530612246, eta0=0.05202020202020203, l1_ratio=0.04081632653061224, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=16848, n_iter_no_change=10, penalty=l2, tol=0.007818181818181818, validation_fraction=0.8836734693877552;, score=-0.174 total time=   0.5s\n",
      "[CV 5/5] END alpha=0.00040816326530612246, eta0=0.05202020202020203, l1_ratio=0.04081632653061224, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=16848, n_iter_no_change=10, penalty=l2, tol=0.007818181818181818, validation_fraction=0.8836734693877552;, score=-0.083 total time=   0.5s\n",
      "[CV 3/5] END alpha=0.00040816326530612246, eta0=0.09191919191919193, l1_ratio=0.2040816326530612, learning_rate=invscaling, loss=squared_error, max_iter=8000, n_iter_no_change=6, penalty=l2, tol=0.0028181818181818178, validation_fraction=0.6877551020408164;, score=0.926 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.00040816326530612246, eta0=0.09191919191919193, l1_ratio=0.2040816326530612, learning_rate=invscaling, loss=squared_error, max_iter=8000, n_iter_no_change=6, penalty=l2, tol=0.0028181818181818178, validation_fraction=0.6877551020408164;, score=0.896 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.0005102040816326531, eta0=0.05808080808080809, l1_ratio=0.19387755102040816, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=8727, n_iter_no_change=4, penalty=None, tol=0.007727272727272727, validation_fraction=0.3122448979591837;, score=0.864 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.0005102040816326531, eta0=0.05808080808080809, l1_ratio=0.19387755102040816, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=8727, n_iter_no_change=4, penalty=None, tol=0.007727272727272727, validation_fraction=0.3122448979591837;, score=0.859 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.0005306122448979592, eta0=0.08232323232323233, l1_ratio=0.4183673469387755, learning_rate=optimal, loss=squared_error, max_iter=9575, n_iter_no_change=8, penalty=l2, tol=0.0015454545454545443, validation_fraction=0.6387755102040816;, score=0.873 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.0005306122448979592, eta0=0.08232323232323233, l1_ratio=0.4183673469387755, learning_rate=optimal, loss=squared_error, max_iter=9575, n_iter_no_change=8, penalty=l2, tol=0.0015454545454545443, validation_fraction=0.6387755102040816;, score=0.901 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.0005306122448979592, eta0=0.08232323232323233, l1_ratio=0.4183673469387755, learning_rate=optimal, loss=squared_error, max_iter=9575, n_iter_no_change=8, penalty=l2, tol=0.0015454545454545443, validation_fraction=0.6387755102040816;, score=0.923 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.0005306122448979592, eta0=0.08232323232323233, l1_ratio=0.4183673469387755, learning_rate=optimal, loss=squared_error, max_iter=9575, n_iter_no_change=8, penalty=l2, tol=0.0015454545454545443, validation_fraction=0.6387755102040816;, score=0.893 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.0005306122448979592, eta0=0.08232323232323233, l1_ratio=0.4183673469387755, learning_rate=optimal, loss=squared_error, max_iter=9575, n_iter_no_change=8, penalty=l2, tol=0.0015454545454545443, validation_fraction=0.6387755102040816;, score=0.888 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.0, eta0=0.0691919191919192, l1_ratio=0.44897959183673464, learning_rate=invscaling, loss=huber, max_iter=12121, n_iter_no_change=10, penalty=elasticnet, tol=0.006454545454545454, validation_fraction=0.5408163265306123;, score=-7.154 total time=   1.4s\n",
      "[CV 2/5] END alpha=0.0009183673469387755, eta0=0.05050505050505051, l1_ratio=0.0510204081632653, learning_rate=adaptive, loss=squared_error, max_iter=13818, n_iter_no_change=10, penalty=l1, tol=0.009727272727272727, validation_fraction=0.573469387755102;, score=0.903 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.0009183673469387755, eta0=0.05050505050505051, l1_ratio=0.0510204081632653, learning_rate=adaptive, loss=squared_error, max_iter=13818, n_iter_no_change=10, penalty=l1, tol=0.009727272727272727, validation_fraction=0.573469387755102;, score=0.886 total time=   0.0s\n",
      "[CV 2/5] END alpha=6.122448979591836e-05, eta0=0.05505050505050506, l1_ratio=0.5, learning_rate=constant, loss=epsilon_insensitive, max_iter=17454, n_iter_no_change=4, penalty=None, tol=0.009727272727272727, validation_fraction=0.3448979591836735;, score=0.836 total time=   1.0s\n",
      "[CV 3/5] END alpha=0.0004897959183673469, eta0=0.06515151515151515, l1_ratio=0.2755102040816326, learning_rate=optimal, loss=huber, max_iter=11151, n_iter_no_change=2, penalty=l2, tol=0.002363636363636363, validation_fraction=0.29591836734693877;, score=-7.110 total time=   0.5s\n",
      "[CV 4/5] END alpha=0.0004897959183673469, eta0=0.06515151515151515, l1_ratio=0.2755102040816326, learning_rate=optimal, loss=huber, max_iter=11151, n_iter_no_change=2, penalty=l2, tol=0.002363636363636363, validation_fraction=0.29591836734693877;, score=-7.532 total time=   0.5s\n",
      "[CV 2/5] END alpha=0.0003673469387755102, eta0=0.06818181818181819, l1_ratio=0.2755102040816326, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=16000, n_iter_no_change=4, penalty=l2, tol=0.0036363636363636364, validation_fraction=0.3448979591836735;, score=-0.033 total time=   0.4s\n",
      "[CV 3/5] END alpha=0.0003673469387755102, eta0=0.06818181818181819, l1_ratio=0.2755102040816326, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=16000, n_iter_no_change=4, penalty=l2, tol=0.0036363636363636364, validation_fraction=0.3448979591836735;, score=-0.020 total time=   0.5s\n",
      "[CV 5/5] END alpha=0.00014285714285714287, eta0=0.05454545454545455, l1_ratio=0.39795918367346933, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=8242, n_iter_no_change=5, penalty=l2, tol=0.009181818181818182, validation_fraction=0.263265306122449;, score=-0.058 total time=   0.4s\n",
      "[CV 1/5] END alpha=0.0, eta0=0.08787878787878789, l1_ratio=0.2755102040816326, learning_rate=optimal, loss=epsilon_insensitive, max_iter=19272, n_iter_no_change=4, penalty=l2, tol=0.0013636363636363637, validation_fraction=0.7857142857142857;, score=nan total time=   0.0s\n",
      "[CV 2/5] END alpha=0.0, eta0=0.08787878787878789, l1_ratio=0.2755102040816326, learning_rate=optimal, loss=epsilon_insensitive, max_iter=19272, n_iter_no_change=4, penalty=l2, tol=0.0013636363636363637, validation_fraction=0.7857142857142857;, score=nan total time=   0.0s\n",
      "[CV 3/5] END alpha=0.0, eta0=0.08787878787878789, l1_ratio=0.2755102040816326, learning_rate=optimal, loss=epsilon_insensitive, max_iter=19272, n_iter_no_change=4, penalty=l2, tol=0.0013636363636363637, validation_fraction=0.7857142857142857;, score=nan total time=   0.0s\n",
      "[CV 4/5] END alpha=0.0, eta0=0.08787878787878789, l1_ratio=0.2755102040816326, learning_rate=optimal, loss=epsilon_insensitive, max_iter=19272, n_iter_no_change=4, penalty=l2, tol=0.0013636363636363637, validation_fraction=0.7857142857142857;, score=nan total time=   0.0s\n",
      "[CV 5/5] END alpha=0.0, eta0=0.08787878787878789, l1_ratio=0.2755102040816326, learning_rate=optimal, loss=epsilon_insensitive, max_iter=19272, n_iter_no_change=4, penalty=l2, tol=0.0013636363636363637, validation_fraction=0.7857142857142857;, score=nan total time=   0.0s\n",
      "[CV 1/5] END alpha=0.0006122448979591836, eta0=0.06464646464646465, l1_ratio=0.14285714285714285, learning_rate=adaptive, loss=huber, max_iter=15393, n_iter_no_change=10, penalty=l1, tol=0.005909090909090909, validation_fraction=0.4591836734693878;, score=0.610 total time=   1.3s\n",
      "[CV 2/5] END alpha=0.0006122448979591836, eta0=0.06464646464646465, l1_ratio=0.14285714285714285, learning_rate=adaptive, loss=huber, max_iter=15393, n_iter_no_change=10, penalty=l1, tol=0.005909090909090909, validation_fraction=0.4591836734693878;, score=0.636 total time=   1.4s\n",
      "[CV 1/5] END alpha=0.00040816326530612246, eta0=0.09191919191919193, l1_ratio=0.2040816326530612, learning_rate=invscaling, loss=squared_error, max_iter=8000, n_iter_no_change=6, penalty=l2, tol=0.0028181818181818178, validation_fraction=0.6877551020408164;, score=0.874 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.00040816326530612246, eta0=0.09191919191919193, l1_ratio=0.2040816326530612, learning_rate=invscaling, loss=squared_error, max_iter=8000, n_iter_no_change=6, penalty=l2, tol=0.0028181818181818178, validation_fraction=0.6877551020408164;, score=0.904 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.00040816326530612246, eta0=0.09191919191919193, l1_ratio=0.2040816326530612, learning_rate=invscaling, loss=squared_error, max_iter=8000, n_iter_no_change=6, penalty=l2, tol=0.0028181818181818178, validation_fraction=0.6877551020408164;, score=0.876 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.0005102040816326531, eta0=0.05808080808080809, l1_ratio=0.19387755102040816, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=8727, n_iter_no_change=4, penalty=None, tol=0.007727272727272727, validation_fraction=0.3122448979591837;, score=0.880 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.0005102040816326531, eta0=0.05808080808080809, l1_ratio=0.19387755102040816, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=8727, n_iter_no_change=4, penalty=None, tol=0.007727272727272727, validation_fraction=0.3122448979591837;, score=0.888 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.0005102040816326531, eta0=0.05808080808080809, l1_ratio=0.19387755102040816, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=8727, n_iter_no_change=4, penalty=None, tol=0.007727272727272727, validation_fraction=0.3122448979591837;, score=0.728 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.0004489795918367347, eta0=0.07020202020202021, l1_ratio=0.4081632653061224, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=18060, n_iter_no_change=10, penalty=l2, tol=0.01, validation_fraction=0.2469387755102041;, score=0.925 total time=   0.0s\n",
      "[CV 3/5] END ccp_alpha=1, criterion=squared_error, max_depth=220, max_features=sqrt, min_samples_leaf=8, min_samples_split=2, splitter=best;, score=0.791 total time=   0.0s\n",
      "[CV 4/5] END ccp_alpha=1, criterion=squared_error, max_depth=220, max_features=sqrt, min_samples_leaf=8, min_samples_split=2, splitter=best;, score=0.675 total time=   0.0s\n",
      "[CV 2/5] END ccp_alpha=1, criterion=squared_error, max_depth=780, max_features=sqrt, min_samples_leaf=4, min_samples_split=4, splitter=best;, score=0.738 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.0005510204081632653, eta0=0.05555555555555556, l1_ratio=0.09183673469387754, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=14303, n_iter_no_change=8, penalty=l1, tol=0.004636363636363636, validation_fraction=0.7040816326530612;, score=0.886 total time=   0.3s\n",
      "[CV 5/5] END alpha=6.122448979591836e-05, eta0=0.08535353535353536, l1_ratio=0.4387755102040816, learning_rate=constant, loss=huber, max_iter=19878, n_iter_no_change=1, penalty=l2, tol=0.008272727272727272, validation_fraction=0.49183673469387756;, score=-1.347 total time=   1.0s\n",
      "[CV 1/5] END alpha=0.00040816326530612246, eta0=0.08131313131313132, l1_ratio=0.01020408163265306, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=19030, n_iter_no_change=8, penalty=l1, tol=0.009545454545454546, validation_fraction=0.5081632653061224;, score=0.836 total time=   1.8s\n",
      "[CV 2/5] END alpha=0.00040816326530612246, eta0=0.08131313131313132, l1_ratio=0.01020408163265306, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=19030, n_iter_no_change=8, penalty=l1, tol=0.009545454545454546, validation_fraction=0.5081632653061224;, score=0.865 total time=   1.8s\n",
      "[CV 4/5] END alpha=0.0004897959183673469, eta0=0.06868686868686869, l1_ratio=0.08163265306122448, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=16727, n_iter_no_change=2, penalty=l2, tol=0.0041818181818181815, validation_fraction=0.1;, score=-5.938 total time=   1.1s\n",
      "[CV 5/5] END alpha=0.0004897959183673469, eta0=0.06868686868686869, l1_ratio=0.08163265306122448, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=16727, n_iter_no_change=2, penalty=l2, tol=0.0041818181818181815, validation_fraction=0.1;, score=-6.557 total time=   1.1s\n",
      "[CV 2/5] END alpha=0.0006122448979591836, eta0=0.09545454545454546, l1_ratio=0.47959183673469385, learning_rate=optimal, loss=huber, max_iter=8606, n_iter_no_change=2, penalty=elasticnet, tol=0.0030909090909090903, validation_fraction=0.4755102040816327;, score=-7.634 total time=   0.5s\n",
      "[CV 5/5] END alpha=0.0006122448979591836, eta0=0.09545454545454546, l1_ratio=0.47959183673469385, learning_rate=optimal, loss=huber, max_iter=8606, n_iter_no_change=2, penalty=elasticnet, tol=0.0030909090909090903, validation_fraction=0.4755102040816327;, score=-8.437 total time=   0.5s\n",
      "[CV 4/5] END alpha=0.0007142857142857143, eta0=0.09242424242424244, l1_ratio=0.22448979591836732, learning_rate=constant, loss=epsilon_insensitive, max_iter=15636, n_iter_no_change=10, penalty=l1, tol=0.00509090909090909, validation_fraction=0.5244897959183674;, score=0.845 total time=   1.6s\n",
      "[CV 5/5] END alpha=0.0, eta0=0.06363636363636364, l1_ratio=0.25510204081632654, learning_rate=invscaling, loss=huber, max_iter=18303, n_iter_no_change=6, penalty=elasticnet, tol=0.00890909090909091, validation_fraction=0.44285714285714284;, score=-8.032 total time=   1.8s\n",
      "[CV 4/5] END alpha=0.0005918367346938776, eta0=0.06666666666666668, l1_ratio=0.1020408163265306, learning_rate=optimal, loss=squared_error, max_iter=11393, n_iter_no_change=8, penalty=elasticnet, tol=0.006818181818181819, validation_fraction=0.3122448979591837;, score=0.888 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.0008775510204081633, eta0=0.06515151515151515, l1_ratio=0.3469387755102041, learning_rate=invscaling, loss=huber, max_iter=15515, n_iter_no_change=5, penalty=l1, tol=0.007272727272727273, validation_fraction=0.6224489795918368;, score=-7.102 total time=   1.5s\n",
      "[CV 3/5] END alpha=0.0006530612244897959, eta0=0.08282828282828283, l1_ratio=0.01020408163265306, learning_rate=optimal, loss=epsilon_insensitive, max_iter=13575, n_iter_no_change=5, penalty=None, tol=0.0037272727272727266, validation_fraction=0.2142857142857143;, score=-2.740 total time=   0.7s\n",
      "[CV 4/5] END alpha=0.0008571428571428571, eta0=0.08787878787878789, l1_ratio=0.2040816326530612, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=15151, n_iter_no_change=4, penalty=l1, tol=0.005909090909090909, validation_fraction=0.7367346938775511;, score=-2.305 total time=   1.5s\n",
      "[CV 1/5] END alpha=0.0007346938775510204, eta0=0.06767676767676768, l1_ratio=0.11224489795918366, learning_rate=adaptive, loss=huber, max_iter=9454, n_iter_no_change=2, penalty=l1, tol=0.0013636363636363637, validation_fraction=0.7040816326530612;, score=0.256 total time=   0.8s\n",
      "[CV 2/5] END alpha=0.0007551020408163266, eta0=0.09595959595959597, l1_ratio=0.2346938775510204, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=12848, n_iter_no_change=6, penalty=l1, tol=0.004545454545454545, validation_fraction=0.2795918367346939;, score=0.852 total time=   1.2s\n",
      "[CV 3/5] END alpha=0.0007755102040816326, eta0=0.05404040404040405, l1_ratio=0.11224489795918366, learning_rate=invscaling, loss=epsilon_insensitive, max_iter=18181, n_iter_no_change=8, penalty=elasticnet, tol=0.00909090909090909, validation_fraction=0.8346938775510204;, score=-5.851 total time=   1.9s\n",
      "[CV 5/5] END alpha=0.0003061224489795918, eta0=0.09393939393939395, l1_ratio=0.17346938775510204, learning_rate=optimal, loss=epsilon_insensitive, max_iter=15151, n_iter_no_change=4, penalty=l2, tol=0.008818181818181819, validation_fraction=0.5081632653061224;, score=-4.945 total time=   0.8s\n",
      "[CV 3/5] END alpha=0.001, eta0=0.0590909090909091, l1_ratio=0.3571428571428571, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=13818, n_iter_no_change=4, penalty=l2, tol=0.009000000000000001, validation_fraction=0.8020408163265307;, score=-0.030 total time=   0.4s\n",
      "[CV 4/5] END alpha=0.0, eta0=0.0691919191919192, l1_ratio=0.44897959183673464, learning_rate=invscaling, loss=huber, max_iter=12121, n_iter_no_change=10, penalty=elasticnet, tol=0.006454545454545454, validation_fraction=0.5408163265306123;, score=-7.302 total time=   1.3s\n",
      "[CV 4/5] END alpha=0.0009183673469387755, eta0=0.05050505050505051, l1_ratio=0.0510204081632653, learning_rate=adaptive, loss=squared_error, max_iter=13818, n_iter_no_change=10, penalty=l1, tol=0.009727272727272727, validation_fraction=0.573469387755102;, score=0.894 total time=   1.3s\n",
      "[CV 3/5] END alpha=0.0006530612244897959, eta0=0.06464646464646465, l1_ratio=0.4591836734693877, learning_rate=constant, loss=huber, max_iter=8000, n_iter_no_change=2, penalty=l1, tol=0.005272727272727273, validation_fraction=0.589795918367347;, score=-0.194 total time=   0.7s\n",
      "[CV 4/5] END alpha=0.0006530612244897959, eta0=0.06464646464646465, l1_ratio=0.4591836734693877, learning_rate=constant, loss=huber, max_iter=8000, n_iter_no_change=2, penalty=l1, tol=0.005272727272727273, validation_fraction=0.589795918367347;, score=-0.429 total time=   0.8s\n",
      "[CV 1/5] END alpha=0.00014285714285714287, eta0=0.05454545454545455, l1_ratio=0.39795918367346933, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=8242, n_iter_no_change=5, penalty=l2, tol=0.009181818181818182, validation_fraction=0.263265306122449;, score=-0.077 total time=   0.4s\n",
      "[CV 2/5] END alpha=0.00014285714285714287, eta0=0.05454545454545455, l1_ratio=0.39795918367346933, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=8242, n_iter_no_change=5, penalty=l2, tol=0.009181818181818182, validation_fraction=0.263265306122449;, score=-0.012 total time=   0.4s\n",
      "[CV 3/5] END alpha=0.0006122448979591836, eta0=0.06464646464646465, l1_ratio=0.14285714285714285, learning_rate=adaptive, loss=huber, max_iter=15393, n_iter_no_change=10, penalty=l1, tol=0.005909090909090909, validation_fraction=0.4591836734693878;, score=0.673 total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=0.0003061224489795918, eta0=0.09393939393939395, l1_ratio=0.17346938775510204, learning_rate=optimal, loss=epsilon_insensitive, max_iter=15151, n_iter_no_change=4, penalty=l2, tol=0.008818181818181819, validation_fraction=0.5081632653061224;, score=-4.555 total time=   0.8s\n",
      "[CV 4/5] END alpha=0.0006122448979591836, eta0=0.06818181818181819, l1_ratio=0.31632653061224486, learning_rate=optimal, loss=epsilon_insensitive, max_iter=8121, n_iter_no_change=6, penalty=None, tol=0.005818181818181818, validation_fraction=0.2306122448979592;, score=-3.066 total time=   0.4s\n",
      "[CV 5/5] END alpha=0.001, eta0=0.0590909090909091, l1_ratio=0.3571428571428571, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=13818, n_iter_no_change=4, penalty=l2, tol=0.009000000000000001, validation_fraction=0.8020408163265307;, score=-0.096 total time=   0.4s\n",
      "[CV 1/5] END alpha=0.0007959183673469387, eta0=0.0994949494949495, l1_ratio=0.24489795918367346, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=15151, n_iter_no_change=1, penalty=elasticnet, tol=0.006909090909090909, validation_fraction=0.3448979591836735;, score=0.834 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.0007959183673469387, eta0=0.0994949494949495, l1_ratio=0.24489795918367346, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=15151, n_iter_no_change=1, penalty=elasticnet, tol=0.006909090909090909, validation_fraction=0.3448979591836735;, score=0.887 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.0007959183673469387, eta0=0.0994949494949495, l1_ratio=0.24489795918367346, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=15151, n_iter_no_change=1, penalty=elasticnet, tol=0.006909090909090909, validation_fraction=0.3448979591836735;, score=0.909 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.0007959183673469387, eta0=0.0994949494949495, l1_ratio=0.24489795918367346, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=15151, n_iter_no_change=1, penalty=elasticnet, tol=0.006909090909090909, validation_fraction=0.3448979591836735;, score=0.897 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.0007959183673469387, eta0=0.0994949494949495, l1_ratio=0.24489795918367346, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=15151, n_iter_no_change=1, penalty=elasticnet, tol=0.006909090909090909, validation_fraction=0.3448979591836735;, score=0.870 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.0009795918367346938, eta0=0.05656565656565657, l1_ratio=0.44897959183673464, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=15151, n_iter_no_change=2, penalty=elasticnet, tol=0.008, validation_fraction=0.9;, score=0.883 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.0009795918367346938, eta0=0.05656565656565657, l1_ratio=0.44897959183673464, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=15151, n_iter_no_change=2, penalty=elasticnet, tol=0.008, validation_fraction=0.9;, score=0.896 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.0009795918367346938, eta0=0.05656565656565657, l1_ratio=0.44897959183673464, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=15151, n_iter_no_change=2, penalty=elasticnet, tol=0.008, validation_fraction=0.9;, score=0.926 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.0009795918367346938, eta0=0.05656565656565657, l1_ratio=0.44897959183673464, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=15151, n_iter_no_change=2, penalty=elasticnet, tol=0.008, validation_fraction=0.9;, score=0.895 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.0009795918367346938, eta0=0.05656565656565657, l1_ratio=0.44897959183673464, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=15151, n_iter_no_change=2, penalty=elasticnet, tol=0.008, validation_fraction=0.9;, score=0.882 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.0009183673469387755, eta0=0.05050505050505051, l1_ratio=0.0510204081632653, learning_rate=adaptive, loss=squared_error, max_iter=13818, n_iter_no_change=10, penalty=l1, tol=0.009727272727272727, validation_fraction=0.573469387755102;, score=0.878 total time=   1.3s\n",
      "[CV 4/5] END alpha=6.122448979591836e-05, eta0=0.05505050505050506, l1_ratio=0.5, learning_rate=constant, loss=epsilon_insensitive, max_iter=17454, n_iter_no_change=4, penalty=None, tol=0.009727272727272727, validation_fraction=0.3448979591836735;, score=0.815 total time=   1.0s\n",
      "[CV 5/5] END alpha=6.122448979591836e-05, eta0=0.05505050505050506, l1_ratio=0.5, learning_rate=constant, loss=epsilon_insensitive, max_iter=17454, n_iter_no_change=4, penalty=None, tol=0.009727272727272727, validation_fraction=0.3448979591836735;, score=0.804 total time=   1.0s\n",
      "[CV 4/5] END alpha=0.0003673469387755102, eta0=0.06818181818181819, l1_ratio=0.2755102040816326, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=16000, n_iter_no_change=4, penalty=l2, tol=0.0036363636363636364, validation_fraction=0.3448979591836735;, score=-0.174 total time=   0.4s\n",
      "[CV 5/5] END alpha=0.0003673469387755102, eta0=0.06818181818181819, l1_ratio=0.2755102040816326, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=16000, n_iter_no_change=4, penalty=l2, tol=0.0036363636363636364, validation_fraction=0.3448979591836735;, score=-0.081 total time=   0.3s\n",
      "[CV 3/5] END alpha=0.00014285714285714287, eta0=0.05454545454545455, l1_ratio=0.39795918367346933, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=8242, n_iter_no_change=5, penalty=l2, tol=0.009181818181818182, validation_fraction=0.263265306122449;, score=-0.002 total time=   0.4s\n",
      "[CV 4/5] END alpha=0.00014285714285714287, eta0=0.05454545454545455, l1_ratio=0.39795918367346933, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=8242, n_iter_no_change=5, penalty=l2, tol=0.009181818181818182, validation_fraction=0.263265306122449;, score=-0.150 total time=   0.4s\n",
      "[CV 5/5] END alpha=0.0006122448979591836, eta0=0.06464646464646465, l1_ratio=0.14285714285714285, learning_rate=adaptive, loss=huber, max_iter=15393, n_iter_no_change=10, penalty=l1, tol=0.005909090909090909, validation_fraction=0.4591836734693878;, score=0.609 total time=   1.3s\n",
      "[CV 1/5] END alpha=0.00040816326530612246, eta0=0.05202020202020203, l1_ratio=0.04081632653061224, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=16848, n_iter_no_change=10, penalty=l2, tol=0.007818181818181818, validation_fraction=0.8836734693877552;, score=-0.072 total time=   0.5s\n",
      "[CV 4/5] END alpha=0.0007551020408163266, eta0=0.09292929292929293, l1_ratio=0.3877551020408163, learning_rate=optimal, loss=epsilon_insensitive, max_iter=18909, n_iter_no_change=6, penalty=l1, tol=0.0032727272727272726, validation_fraction=0.6551020408163265;, score=-3.484 total time=   1.6s\n",
      "[CV 5/5] END alpha=0.0007551020408163266, eta0=0.09292929292929293, l1_ratio=0.3877551020408163, learning_rate=optimal, loss=epsilon_insensitive, max_iter=18909, n_iter_no_change=6, penalty=l1, tol=0.0032727272727272726, validation_fraction=0.6551020408163265;, score=-3.773 total time=   1.6s\n",
      "[CV 1/5] END alpha=0.0005510204081632653, eta0=0.06666666666666668, l1_ratio=0.47959183673469385, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=18060, n_iter_no_change=6, penalty=elasticnet, tol=0.004727272727272727, validation_fraction=0.3938775510204082;, score=0.872 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.0005510204081632653, eta0=0.06666666666666668, l1_ratio=0.47959183673469385, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=18060, n_iter_no_change=6, penalty=elasticnet, tol=0.004727272727272727, validation_fraction=0.3938775510204082;, score=0.877 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.0005510204081632653, eta0=0.06666666666666668, l1_ratio=0.47959183673469385, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=18060, n_iter_no_change=6, penalty=elasticnet, tol=0.004727272727272727, validation_fraction=0.3938775510204082;, score=0.888 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=0.0009387755102040817, eta0=0.06313131313131314, l1_ratio=0.030612244897959183, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=15030, n_iter_no_change=10, penalty=l2, tol=0.006818181818181819, validation_fraction=0.1326530612244898;, score=0.871 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.0003673469387755102, eta0=0.06818181818181819, l1_ratio=0.2755102040816326, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=16000, n_iter_no_change=4, penalty=l2, tol=0.0036363636363636364, validation_fraction=0.3448979591836735;, score=-0.117 total time=   0.3s\n",
      "[CV 3/5] END alpha=0.0006530612244897959, eta0=0.05656565656565657, l1_ratio=0.4591836734693877, learning_rate=optimal, loss=huber, max_iter=8000, n_iter_no_change=5, penalty=l2, tol=0.007363636363636364, validation_fraction=0.6551020408163265;, score=-7.181 total time=   0.1s\n",
      "[CV 4/5] END alpha=0.0006530612244897959, eta0=0.05656565656565657, l1_ratio=0.4591836734693877, learning_rate=optimal, loss=huber, max_iter=8000, n_iter_no_change=5, penalty=l2, tol=0.007363636363636364, validation_fraction=0.6551020408163265;, score=-7.602 total time=   0.1s\n",
      "[CV 2/5] END alpha=0.0005510204081632653, eta0=0.06767676767676768, l1_ratio=0.11224489795918366, learning_rate=invscaling, loss=huber, max_iter=13818, n_iter_no_change=2, penalty=elasticnet, tol=0.0017272727272727266, validation_fraction=0.7204081632653062;, score=-7.675 total time=   1.4s\n",
      "[CV 3/5] END alpha=0.0005510204081632653, eta0=0.06767676767676768, l1_ratio=0.11224489795918366, learning_rate=invscaling, loss=huber, max_iter=13818, n_iter_no_change=2, penalty=elasticnet, tol=0.0017272727272727266, validation_fraction=0.7204081632653062;, score=-7.159 total time=   1.4s\n",
      "[CV 1/5] END alpha=0.00014285714285714287, eta0=0.061111111111111116, l1_ratio=0.21428571428571427, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=19393, n_iter_no_change=6, penalty=elasticnet, tol=0.008, validation_fraction=0.2795918367346939;, score=0.840 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.00014285714285714287, eta0=0.061111111111111116, l1_ratio=0.21428571428571427, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=19393, n_iter_no_change=6, penalty=elasticnet, tol=0.008, validation_fraction=0.2795918367346939;, score=0.897 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.00014285714285714287, eta0=0.061111111111111116, l1_ratio=0.21428571428571427, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=19393, n_iter_no_change=6, penalty=elasticnet, tol=0.008, validation_fraction=0.2795918367346939;, score=0.895 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.00014285714285714287, eta0=0.061111111111111116, l1_ratio=0.21428571428571427, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=19393, n_iter_no_change=6, penalty=elasticnet, tol=0.008, validation_fraction=0.2795918367346939;, score=0.870 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.00014285714285714287, eta0=0.061111111111111116, l1_ratio=0.21428571428571427, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=19393, n_iter_no_change=6, penalty=elasticnet, tol=0.008, validation_fraction=0.2795918367346939;, score=0.709 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.0007551020408163266, eta0=0.09292929292929293, l1_ratio=0.3877551020408163, learning_rate=optimal, loss=epsilon_insensitive, max_iter=18909, n_iter_no_change=6, penalty=l1, tol=0.0032727272727272726, validation_fraction=0.6551020408163265;, score=-3.352 total time=   1.6s\n",
      "[CV 1/5] END alpha=0.00046938775510204083, eta0=0.06414141414141414, l1_ratio=0.39795918367346933, learning_rate=optimal, loss=huber, max_iter=9212, n_iter_no_change=8, penalty=l2, tol=0.009454545454545455, validation_fraction=0.8673469387755103;, score=-7.396 total time=   0.1s\n",
      "[CV 3/5] END alpha=0.00046938775510204083, eta0=0.06414141414141414, l1_ratio=0.39795918367346933, learning_rate=optimal, loss=huber, max_iter=9212, n_iter_no_change=8, penalty=l2, tol=0.009454545454545455, validation_fraction=0.8673469387755103;, score=-7.125 total time=   0.1s\n",
      "[CV 5/5] END alpha=0.00046938775510204083, eta0=0.06414141414141414, l1_ratio=0.39795918367346933, learning_rate=optimal, loss=huber, max_iter=9212, n_iter_no_change=8, penalty=l2, tol=0.009454545454545455, validation_fraction=0.8673469387755103;, score=-8.442 total time=   0.1s\n",
      "[CV 2/5] END alpha=0.0004897959183673469, eta0=0.09646464646464648, l1_ratio=0.4081632653061224, learning_rate=optimal, loss=epsilon_insensitive, max_iter=17939, n_iter_no_change=8, penalty=elasticnet, tol=0.00609090909090909, validation_fraction=0.3938775510204082;, score=-5.198 total time=   1.6s\n",
      "[CV 2/5] END alpha=0.0003877551020408163, eta0=0.0803030303030303, l1_ratio=0.0, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=10787, n_iter_no_change=8, penalty=l1, tol=0.006454545454545454, validation_fraction=0.5571428571428572;, score=0.828 total time=   1.0s\n",
      "[CV 2/5] END alpha=0.00028571428571428574, eta0=0.06363636363636364, l1_ratio=0.4183673469387755, learning_rate=adaptive, loss=huber, max_iter=15030, n_iter_no_change=5, penalty=l2, tol=0.0076363636363636364, validation_fraction=0.36122448979591837;, score=-3.356 total time=   0.8s\n",
      "[CV 5/5] END alpha=0.0003469387755102041, eta0=0.0893939393939394, l1_ratio=0.16326530612244897, learning_rate=optimal, loss=huber, max_iter=17939, n_iter_no_change=1, penalty=None, tol=0.004, validation_fraction=0.3938775510204082;, score=-7.527 total time=   1.0s\n",
      "[CV 1/5] END alpha=0.0003877551020408163, eta0=0.06565656565656566, l1_ratio=0.4183673469387755, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=18666, n_iter_no_change=4, penalty=elasticnet, tol=0.009818181818181818, validation_fraction=0.7040816326530612;, score=0.865 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.00010204081632653062, eta0=0.06515151515151515, l1_ratio=0.08163265306122448, learning_rate=constant, loss=squared_error, max_iter=12969, n_iter_no_change=5, penalty=l2, tol=0.0015454545454545443, validation_fraction=0.2306122448979592;, score=0.885 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.00010204081632653062, eta0=0.06515151515151515, l1_ratio=0.08163265306122448, learning_rate=constant, loss=squared_error, max_iter=12969, n_iter_no_change=5, penalty=l2, tol=0.0015454545454545443, validation_fraction=0.2306122448979592;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.00010204081632653062, eta0=0.06515151515151515, l1_ratio=0.08163265306122448, learning_rate=constant, loss=squared_error, max_iter=12969, n_iter_no_change=5, penalty=l2, tol=0.0015454545454545443, validation_fraction=0.2306122448979592;, score=0.869 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.00010204081632653062, eta0=0.06515151515151515, l1_ratio=0.08163265306122448, learning_rate=constant, loss=squared_error, max_iter=12969, n_iter_no_change=5, penalty=l2, tol=0.0015454545454545443, validation_fraction=0.2306122448979592;, score=0.867 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.00020408163265306123, eta0=0.06464646464646465, l1_ratio=0.04081632653061224, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=13575, n_iter_no_change=1, penalty=None, tol=0.009272727272727273, validation_fraction=0.2306122448979592;, score=-12821535112921.215 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.00020408163265306123, eta0=0.06464646464646465, l1_ratio=0.04081632653061224, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=13575, n_iter_no_change=1, penalty=None, tol=0.009272727272727273, validation_fraction=0.2306122448979592;, score=0.870 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.00020408163265306123, eta0=0.06464646464646465, l1_ratio=0.04081632653061224, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=13575, n_iter_no_change=1, penalty=None, tol=0.009272727272727273, validation_fraction=0.2306122448979592;, score=0.879 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=0.0005510204081632653, eta0=0.06666666666666668, l1_ratio=0.47959183673469385, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=18060, n_iter_no_change=6, penalty=elasticnet, tol=0.004727272727272727, validation_fraction=0.3938775510204082;, score=0.878 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.0005510204081632653, eta0=0.06666666666666668, l1_ratio=0.47959183673469385, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=18060, n_iter_no_change=6, penalty=elasticnet, tol=0.004727272727272727, validation_fraction=0.3938775510204082;, score=0.874 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.0001836734693877551, eta0=0.0792929292929293, l1_ratio=0.1530612244897959, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=15151, n_iter_no_change=10, penalty=None, tol=0.008727272727272728, validation_fraction=0.2469387755102041;, score=0.859 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.0001836734693877551, eta0=0.0792929292929293, l1_ratio=0.1530612244897959, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=15151, n_iter_no_change=10, penalty=None, tol=0.008727272727272728, validation_fraction=0.2469387755102041;, score=0.896 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.0001836734693877551, eta0=0.0792929292929293, l1_ratio=0.1530612244897959, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=15151, n_iter_no_change=10, penalty=None, tol=0.008727272727272728, validation_fraction=0.2469387755102041;, score=0.926 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.0001836734693877551, eta0=0.0792929292929293, l1_ratio=0.1530612244897959, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=15151, n_iter_no_change=10, penalty=None, tol=0.008727272727272728, validation_fraction=0.2469387755102041;, score=0.893 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.0001836734693877551, eta0=0.0792929292929293, l1_ratio=0.1530612244897959, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=15151, n_iter_no_change=10, penalty=None, tol=0.008727272727272728, validation_fraction=0.2469387755102041;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.0006326530612244898, eta0=0.08636363636363636, l1_ratio=0.0510204081632653, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=18181, n_iter_no_change=8, penalty=elasticnet, tol=0.0032727272727272726, validation_fraction=0.589795918367347;, score=0.596 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.0006326530612244898, eta0=0.08636363636363636, l1_ratio=0.0510204081632653, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=18181, n_iter_no_change=8, penalty=elasticnet, tol=0.0032727272727272726, validation_fraction=0.589795918367347;, score=0.870 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.0006326530612244898, eta0=0.08636363636363636, l1_ratio=0.0510204081632653, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=18181, n_iter_no_change=8, penalty=elasticnet, tol=0.0032727272727272726, validation_fraction=0.589795918367347;, score=0.814 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.0006326530612244898, eta0=0.08636363636363636, l1_ratio=0.0510204081632653, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=18181, n_iter_no_change=8, penalty=elasticnet, tol=0.0032727272727272726, validation_fraction=0.589795918367347;, score=0.862 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.0006326530612244898, eta0=0.08636363636363636, l1_ratio=0.0510204081632653, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=18181, n_iter_no_change=8, penalty=elasticnet, tol=0.0032727272727272726, validation_fraction=0.589795918367347;, score=0.592 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.0003877551020408163, eta0=0.0803030303030303, l1_ratio=0.0, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=10787, n_iter_no_change=8, penalty=l1, tol=0.006454545454545454, validation_fraction=0.5571428571428572;, score=0.800 total time=   1.0s\n",
      "[CV 1/5] END alpha=0.00028571428571428574, eta0=0.06363636363636364, l1_ratio=0.4183673469387755, learning_rate=adaptive, loss=huber, max_iter=15030, n_iter_no_change=5, penalty=l2, tol=0.0076363636363636364, validation_fraction=0.36122448979591837;, score=-3.399 total time=   0.8s\n",
      "[CV 3/5] END alpha=0.0003469387755102041, eta0=0.0893939393939394, l1_ratio=0.16326530612244897, learning_rate=optimal, loss=huber, max_iter=17939, n_iter_no_change=1, penalty=None, tol=0.004, validation_fraction=0.3938775510204082;, score=-6.339 total time=   0.9s\n",
      "[CV 4/5] END alpha=0.0003469387755102041, eta0=0.0893939393939394, l1_ratio=0.16326530612244897, learning_rate=optimal, loss=huber, max_iter=17939, n_iter_no_change=1, penalty=None, tol=0.004, validation_fraction=0.3938775510204082;, score=-6.754 total time=   0.9s\n",
      "[CV 1/5] END alpha=0.0009591836734693877, eta0=0.07575757575757576, l1_ratio=0.44897959183673464, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=19393, n_iter_no_change=8, penalty=l1, tol=0.009727272727272727, validation_fraction=0.7040816326530612;, score=0.877 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.0009591836734693877, eta0=0.07575757575757576, l1_ratio=0.44897959183673464, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=19393, n_iter_no_change=8, penalty=l1, tol=0.009727272727272727, validation_fraction=0.7040816326530612;, score=0.836 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.0009591836734693877, eta0=0.07575757575757576, l1_ratio=0.44897959183673464, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=19393, n_iter_no_change=8, penalty=l1, tol=0.009727272727272727, validation_fraction=0.7040816326530612;, score=0.924 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.0009591836734693877, eta0=0.07575757575757576, l1_ratio=0.44897959183673464, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=19393, n_iter_no_change=8, penalty=l1, tol=0.009727272727272727, validation_fraction=0.7040816326530612;, score=0.891 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.0009591836734693877, eta0=0.07575757575757576, l1_ratio=0.44897959183673464, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=19393, n_iter_no_change=8, penalty=l1, tol=0.009727272727272727, validation_fraction=0.7040816326530612;, score=0.882 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.00012244897959183673, eta0=0.06313131313131314, l1_ratio=0.4183673469387755, learning_rate=optimal, loss=huber, max_iter=9696, n_iter_no_change=1, penalty=l2, tol=0.004363636363636363, validation_fraction=0.2306122448979592;, score=-6.795 total time=   0.5s\n",
      "[CV 1/5] END alpha=0.0005918367346938776, eta0=0.09797979797979799, l1_ratio=0.3571428571428571, learning_rate=constant, loss=epsilon_insensitive, max_iter=16848, n_iter_no_change=2, penalty=elasticnet, tol=0.005, validation_fraction=0.49183673469387756;, score=-0.168 total time=   0.3s\n",
      "[CV 2/5] END alpha=0.0005918367346938776, eta0=0.09797979797979799, l1_ratio=0.3571428571428571, learning_rate=constant, loss=epsilon_insensitive, max_iter=16848, n_iter_no_change=2, penalty=elasticnet, tol=0.005, validation_fraction=0.49183673469387756;, score=-0.045 total time=   0.4s\n",
      "[CV 5/5] END alpha=0.0005918367346938776, eta0=0.09797979797979799, l1_ratio=0.3571428571428571, learning_rate=constant, loss=epsilon_insensitive, max_iter=16848, n_iter_no_change=2, penalty=elasticnet, tol=0.005, validation_fraction=0.49183673469387756;, score=-0.105 total time=   0.4s\n",
      "[CV 1/5] END alpha=0.0005306122448979592, eta0=0.07828282828282829, l1_ratio=0.07142857142857142, learning_rate=optimal, loss=squared_error, max_iter=15878, n_iter_no_change=5, penalty=l2, tol=0.002999999999999999, validation_fraction=0.1653061224489796;, score=0.864 total time=   0.0s\n",
      "[CV 2/5] END alpha=8.163265306122449e-05, eta0=0.09696969696969697, l1_ratio=0.2346938775510204, learning_rate=optimal, loss=squared_error, max_iter=18181, n_iter_no_change=10, penalty=elasticnet, tol=0.006909090909090909, validation_fraction=0.49183673469387756;, score=0.883 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END alpha=0.0006122448979591836, eta0=0.06464646464646465, l1_ratio=0.14285714285714285, learning_rate=adaptive, loss=huber, max_iter=15393, n_iter_no_change=10, penalty=l1, tol=0.005909090909090909, validation_fraction=0.4591836734693878;, score=0.587 total time=   1.4s\n",
      "[CV 3/5] END alpha=0.0008163265306122449, eta0=0.09242424242424244, l1_ratio=0.13265306122448978, learning_rate=adaptive, loss=huber, max_iter=16606, n_iter_no_change=1, penalty=l2, tol=0.003363636363636363, validation_fraction=0.4755102040816327;, score=-1.558 total time=   0.9s\n",
      "[CV 2/5] END alpha=0.00046938775510204083, eta0=0.06414141414141414, l1_ratio=0.39795918367346933, learning_rate=optimal, loss=huber, max_iter=9212, n_iter_no_change=8, penalty=l2, tol=0.009454545454545455, validation_fraction=0.8673469387755103;, score=-7.638 total time=   0.1s\n",
      "[CV 4/5] END alpha=0.00046938775510204083, eta0=0.06414141414141414, l1_ratio=0.39795918367346933, learning_rate=optimal, loss=huber, max_iter=9212, n_iter_no_change=8, penalty=l2, tol=0.009454545454545455, validation_fraction=0.8673469387755103;, score=-7.547 total time=   0.1s\n",
      "[CV 1/5] END alpha=0.0004897959183673469, eta0=0.09646464646464648, l1_ratio=0.4081632653061224, learning_rate=optimal, loss=epsilon_insensitive, max_iter=17939, n_iter_no_change=8, penalty=elasticnet, tol=0.00609090909090909, validation_fraction=0.3938775510204082;, score=-5.108 total time=   1.6s\n",
      "[CV 3/5] END alpha=0.0003877551020408163, eta0=0.0803030303030303, l1_ratio=0.0, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=10787, n_iter_no_change=8, penalty=l1, tol=0.006454545454545454, validation_fraction=0.5571428571428572;, score=0.864 total time=   1.0s\n",
      "[CV 3/5] END alpha=0.00028571428571428574, eta0=0.06363636363636364, l1_ratio=0.4183673469387755, learning_rate=adaptive, loss=huber, max_iter=15030, n_iter_no_change=5, penalty=l2, tol=0.0076363636363636364, validation_fraction=0.36122448979591837;, score=-3.144 total time=   0.8s\n",
      "[CV 2/5] END alpha=0.0003877551020408163, eta0=0.06565656565656566, l1_ratio=0.4183673469387755, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=18666, n_iter_no_change=4, penalty=elasticnet, tol=0.009818181818181818, validation_fraction=0.7040816326530612;, score=0.900 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.0003877551020408163, eta0=0.06565656565656566, l1_ratio=0.4183673469387755, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=18666, n_iter_no_change=4, penalty=elasticnet, tol=0.009818181818181818, validation_fraction=0.7040816326530612;, score=0.823 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.0003877551020408163, eta0=0.06565656565656566, l1_ratio=0.4183673469387755, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=18666, n_iter_no_change=4, penalty=elasticnet, tol=0.009818181818181818, validation_fraction=0.7040816326530612;, score=0.838 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.0003877551020408163, eta0=0.06565656565656566, l1_ratio=0.4183673469387755, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=18666, n_iter_no_change=4, penalty=elasticnet, tol=0.009818181818181818, validation_fraction=0.7040816326530612;, score=0.859 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.0005918367346938776, eta0=0.0691919191919192, l1_ratio=0.0, learning_rate=invscaling, loss=huber, max_iter=10909, n_iter_no_change=6, penalty=l1, tol=0.004, validation_fraction=0.8673469387755103;, score=-7.191 total time=   1.2s\n",
      "[CV 2/5] END alpha=0.0005918367346938776, eta0=0.0691919191919192, l1_ratio=0.0, learning_rate=invscaling, loss=huber, max_iter=10909, n_iter_no_change=6, penalty=l1, tol=0.004, validation_fraction=0.8673469387755103;, score=-7.425 total time=   1.1s\n",
      "[CV 4/5] END alpha=0.00012244897959183673, eta0=0.06313131313131314, l1_ratio=0.4183673469387755, learning_rate=optimal, loss=huber, max_iter=9696, n_iter_no_change=1, penalty=l2, tol=0.004363636363636363, validation_fraction=0.2306122448979592;, score=-6.950 total time=   0.5s\n",
      "[CV 5/5] END alpha=0.00012244897959183673, eta0=0.06313131313131314, l1_ratio=0.4183673469387755, learning_rate=optimal, loss=huber, max_iter=9696, n_iter_no_change=1, penalty=l2, tol=0.004363636363636363, validation_fraction=0.2306122448979592;, score=-7.741 total time=   0.5s\n",
      "[CV 5/5] END alpha=0.00024489795918367346, eta0=0.07828282828282829, l1_ratio=0.1530612244897959, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=8000, n_iter_no_change=5, penalty=elasticnet, tol=0.001, validation_fraction=0.4591836734693878;, score=-0.071 total time=   0.5s\n",
      "[CV 1/5] END alpha=8.163265306122449e-05, eta0=0.09696969696969697, l1_ratio=0.2346938775510204, learning_rate=optimal, loss=squared_error, max_iter=18181, n_iter_no_change=10, penalty=elasticnet, tol=0.006909090909090909, validation_fraction=0.49183673469387756;, score=0.734 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.000836734693877551, eta0=0.07575757575757576, l1_ratio=0.16326530612244897, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=12121, n_iter_no_change=6, penalty=l2, tol=0.008181818181818182, validation_fraction=0.6387755102040816;, score=0.884 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.000836734693877551, eta0=0.07575757575757576, l1_ratio=0.16326530612244897, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=12121, n_iter_no_change=6, penalty=l2, tol=0.008181818181818182, validation_fraction=0.6387755102040816;, score=0.903 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.000836734693877551, eta0=0.07575757575757576, l1_ratio=0.16326530612244897, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=12121, n_iter_no_change=6, penalty=l2, tol=0.008181818181818182, validation_fraction=0.6387755102040816;, score=0.921 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.000836734693877551, eta0=0.07575757575757576, l1_ratio=0.16326530612244897, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=12121, n_iter_no_change=6, penalty=l2, tol=0.008181818181818182, validation_fraction=0.6387755102040816;, score=0.895 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.000836734693877551, eta0=0.07575757575757576, l1_ratio=0.16326530612244897, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=12121, n_iter_no_change=6, penalty=l2, tol=0.008181818181818182, validation_fraction=0.6387755102040816;, score=0.876 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.00020408163265306123, eta0=0.08383838383838385, l1_ratio=0.44897959183673464, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=16363, n_iter_no_change=6, penalty=l1, tol=0.002454545454545454, validation_fraction=0.573469387755102;, score=0.865 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.00020408163265306123, eta0=0.08383838383838385, l1_ratio=0.44897959183673464, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=16363, n_iter_no_change=6, penalty=l1, tol=0.002454545454545454, validation_fraction=0.573469387755102;, score=0.875 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.00020408163265306123, eta0=0.08383838383838385, l1_ratio=0.44897959183673464, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=16363, n_iter_no_change=6, penalty=l1, tol=0.002454545454545454, validation_fraction=0.573469387755102;, score=0.870 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.00020408163265306123, eta0=0.08383838383838385, l1_ratio=0.44897959183673464, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=16363, n_iter_no_change=6, penalty=l1, tol=0.002454545454545454, validation_fraction=0.573469387755102;, score=0.874 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.00020408163265306123, eta0=0.08383838383838385, l1_ratio=0.44897959183673464, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=16363, n_iter_no_change=6, penalty=l1, tol=0.002454545454545454, validation_fraction=0.573469387755102;, score=0.862 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.0002653061224489796, eta0=0.05404040404040405, l1_ratio=0.01020408163265306, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=9090, n_iter_no_change=1, penalty=None, tol=0.002454545454545454, validation_fraction=0.7040816326530612;, score=0.878 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END alpha=0.0004489795918367347, eta0=0.07020202020202021, l1_ratio=0.4081632653061224, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=18060, n_iter_no_change=10, penalty=l2, tol=0.01, validation_fraction=0.2469387755102041;, score=0.884 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.0004489795918367347, eta0=0.07020202020202021, l1_ratio=0.4081632653061224, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=18060, n_iter_no_change=10, penalty=l2, tol=0.01, validation_fraction=0.2469387755102041;, score=0.903 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.0004489795918367347, eta0=0.07020202020202021, l1_ratio=0.4081632653061224, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=18060, n_iter_no_change=10, penalty=l2, tol=0.01, validation_fraction=0.2469387755102041;, score=0.882 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.0008163265306122449, eta0=0.09242424242424244, l1_ratio=0.13265306122448978, learning_rate=adaptive, loss=huber, max_iter=16606, n_iter_no_change=1, penalty=l2, tol=0.003363636363636363, validation_fraction=0.4755102040816327;, score=-1.779 total time=   0.9s\n",
      "[CV 5/5] END alpha=0.0008163265306122449, eta0=0.09242424242424244, l1_ratio=0.13265306122448978, learning_rate=adaptive, loss=huber, max_iter=16606, n_iter_no_change=1, penalty=l2, tol=0.003363636363636363, validation_fraction=0.4755102040816327;, score=-1.912 total time=   0.9s\n",
      "[CV 4/5] END alpha=0.0004897959183673469, eta0=0.09646464646464648, l1_ratio=0.4081632653061224, learning_rate=optimal, loss=epsilon_insensitive, max_iter=17939, n_iter_no_change=8, penalty=elasticnet, tol=0.00609090909090909, validation_fraction=0.3938775510204082;, score=-5.267 total time=   1.6s\n",
      "[CV 5/5] END alpha=0.0003877551020408163, eta0=0.0803030303030303, l1_ratio=0.0, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=10787, n_iter_no_change=8, penalty=l1, tol=0.006454545454545454, validation_fraction=0.5571428571428572;, score=0.797 total time=   1.0s\n",
      "[CV 2/5] END alpha=0.0005714285714285715, eta0=0.08383838383838385, l1_ratio=0.04081632653061224, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=15757, n_iter_no_change=6, penalty=l1, tol=0.0037272727272727266, validation_fraction=0.42653061224489797;, score=0.886 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.0005714285714285715, eta0=0.08383838383838385, l1_ratio=0.04081632653061224, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=15757, n_iter_no_change=6, penalty=l1, tol=0.0037272727272727266, validation_fraction=0.42653061224489797;, score=0.884 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.0005714285714285715, eta0=0.08383838383838385, l1_ratio=0.04081632653061224, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=15757, n_iter_no_change=6, penalty=l1, tol=0.0037272727272727266, validation_fraction=0.42653061224489797;, score=0.795 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.0005714285714285715, eta0=0.08383838383838385, l1_ratio=0.04081632653061224, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=15757, n_iter_no_change=6, penalty=l1, tol=0.0037272727272727266, validation_fraction=0.42653061224489797;, score=0.776 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.0005306122448979592, eta0=0.07525252525252527, l1_ratio=0.4693877551020408, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=16484, n_iter_no_change=2, penalty=l2, tol=0.009272727272727273, validation_fraction=0.573469387755102;, score=0.878 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.0005306122448979592, eta0=0.07525252525252527, l1_ratio=0.4693877551020408, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=16484, n_iter_no_change=2, penalty=l2, tol=0.009272727272727273, validation_fraction=0.573469387755102;, score=0.903 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.0005306122448979592, eta0=0.07525252525252527, l1_ratio=0.4693877551020408, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=16484, n_iter_no_change=2, penalty=l2, tol=0.009272727272727273, validation_fraction=0.573469387755102;, score=0.926 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.0005306122448979592, eta0=0.07525252525252527, l1_ratio=0.4693877551020408, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=16484, n_iter_no_change=2, penalty=l2, tol=0.009272727272727273, validation_fraction=0.573469387755102;, score=0.894 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.0005306122448979592, eta0=0.07525252525252527, l1_ratio=0.4693877551020408, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=16484, n_iter_no_change=2, penalty=l2, tol=0.009272727272727273, validation_fraction=0.573469387755102;, score=0.885 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.0006938775510204082, eta0=0.062121212121212126, l1_ratio=0.0510204081632653, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=12484, n_iter_no_change=5, penalty=None, tol=0.005818181818181818, validation_fraction=0.1979591836734694;, score=0.866 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.0006938775510204082, eta0=0.062121212121212126, l1_ratio=0.0510204081632653, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=12484, n_iter_no_change=5, penalty=None, tol=0.005818181818181818, validation_fraction=0.1979591836734694;, score=0.888 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.0006938775510204082, eta0=0.062121212121212126, l1_ratio=0.0510204081632653, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=12484, n_iter_no_change=5, penalty=None, tol=0.005818181818181818, validation_fraction=0.1979591836734694;, score=0.908 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.0006938775510204082, eta0=0.062121212121212126, l1_ratio=0.0510204081632653, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=12484, n_iter_no_change=5, penalty=None, tol=0.005818181818181818, validation_fraction=0.1979591836734694;, score=0.881 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.0006938775510204082, eta0=0.062121212121212126, l1_ratio=0.0510204081632653, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=12484, n_iter_no_change=5, penalty=None, tol=0.005818181818181818, validation_fraction=0.1979591836734694;, score=0.826 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.0003469387755102041, eta0=0.0893939393939394, l1_ratio=0.16326530612244897, learning_rate=optimal, loss=huber, max_iter=17939, n_iter_no_change=1, penalty=None, tol=0.004, validation_fraction=0.3938775510204082;, score=-6.607 total time=   1.0s\n",
      "[CV 2/5] END alpha=0.0003469387755102041, eta0=0.0893939393939394, l1_ratio=0.16326530612244897, learning_rate=optimal, loss=huber, max_iter=17939, n_iter_no_change=1, penalty=None, tol=0.004, validation_fraction=0.3938775510204082;, score=-6.806 total time=   0.9s\n",
      "[CV 4/5] END alpha=0.000673469387755102, eta0=0.07121212121212121, l1_ratio=0.2857142857142857, learning_rate=adaptive, loss=huber, max_iter=11393, n_iter_no_change=1, penalty=l1, tol=0.007, validation_fraction=0.1326530612244898;, score=0.506 total time=   1.0s\n",
      "[CV 5/5] END alpha=0.000673469387755102, eta0=0.07121212121212121, l1_ratio=0.2857142857142857, learning_rate=adaptive, loss=huber, max_iter=11393, n_iter_no_change=1, penalty=l1, tol=0.007, validation_fraction=0.1326530612244898;, score=0.545 total time=   1.0s\n",
      "[CV 4/5] END alpha=0.00024489795918367346, eta0=0.09494949494949495, l1_ratio=0.5, learning_rate=constant, loss=huber, max_iter=10787, n_iter_no_change=5, penalty=elasticnet, tol=0.0027272727272727266, validation_fraction=0.8020408163265307;, score=-3.259 total time=   1.0s\n",
      "[CV 5/5] END alpha=0.00024489795918367346, eta0=0.09494949494949495, l1_ratio=0.5, learning_rate=constant, loss=huber, max_iter=10787, n_iter_no_change=5, penalty=elasticnet, tol=0.0027272727272727266, validation_fraction=0.8020408163265307;, score=-3.424 total time=   1.0s\n",
      "[CV 1/5] END alpha=0.0005714285714285715, eta0=0.08282828282828283, l1_ratio=0.39795918367346933, learning_rate=constant, loss=epsilon_insensitive, max_iter=10545, n_iter_no_change=5, penalty=elasticnet, tol=0.008, validation_fraction=0.6877551020408164;, score=-0.104 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END alpha=0.0004489795918367347, eta0=0.07020202020202021, l1_ratio=0.4081632653061224, learning_rate=invscaling, loss=squared_epsilon_insensitive, max_iter=18060, n_iter_no_change=10, penalty=l2, tol=0.01, validation_fraction=0.2469387755102041;, score=0.882 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.0008163265306122449, eta0=0.09242424242424244, l1_ratio=0.13265306122448978, learning_rate=adaptive, loss=huber, max_iter=16606, n_iter_no_change=1, penalty=l2, tol=0.003363636363636363, validation_fraction=0.4755102040816327;, score=-1.655 total time=   0.9s\n",
      "[CV 4/5] END alpha=0.0008163265306122449, eta0=0.09242424242424244, l1_ratio=0.13265306122448978, learning_rate=adaptive, loss=huber, max_iter=16606, n_iter_no_change=1, penalty=l2, tol=0.003363636363636363, validation_fraction=0.4755102040816327;, score=-1.934 total time=   0.9s\n",
      "[CV 3/5] END alpha=0.0004897959183673469, eta0=0.09646464646464648, l1_ratio=0.4081632653061224, learning_rate=optimal, loss=epsilon_insensitive, max_iter=17939, n_iter_no_change=8, penalty=elasticnet, tol=0.00609090909090909, validation_fraction=0.3938775510204082;, score=-4.845 total time=   1.6s\n",
      "[CV 4/5] END alpha=0.0003877551020408163, eta0=0.0803030303030303, l1_ratio=0.0, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=10787, n_iter_no_change=8, penalty=l1, tol=0.006454545454545454, validation_fraction=0.5571428571428572;, score=0.805 total time=   1.0s\n",
      "[CV 5/5] END alpha=0.00028571428571428574, eta0=0.06363636363636364, l1_ratio=0.4183673469387755, learning_rate=adaptive, loss=huber, max_iter=15030, n_iter_no_change=5, penalty=l2, tol=0.0076363636363636364, validation_fraction=0.36122448979591837;, score=-3.779 total time=   0.8s\n",
      "[CV 1/5] END alpha=0.0005714285714285715, eta0=0.08383838383838385, l1_ratio=0.04081632653061224, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=15757, n_iter_no_change=6, penalty=l1, tol=0.0037272727272727266, validation_fraction=0.42653061224489797;, score=0.664 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.0005918367346938776, eta0=0.0691919191919192, l1_ratio=0.0, learning_rate=invscaling, loss=huber, max_iter=10909, n_iter_no_change=6, penalty=l1, tol=0.004, validation_fraction=0.8673469387755103;, score=-8.205 total time=   1.1s\n",
      "[CV 1/5] END alpha=0.00010204081632653062, eta0=0.06515151515151515, l1_ratio=0.08163265306122448, learning_rate=constant, loss=squared_error, max_iter=12969, n_iter_no_change=5, penalty=l2, tol=0.0015454545454545443, validation_fraction=0.2306122448979592;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.000673469387755102, eta0=0.07121212121212121, l1_ratio=0.2857142857142857, learning_rate=adaptive, loss=huber, max_iter=11393, n_iter_no_change=1, penalty=l1, tol=0.007, validation_fraction=0.1326530612244898;, score=0.572 total time=   1.0s\n",
      "[CV 3/5] END alpha=0.000673469387755102, eta0=0.07121212121212121, l1_ratio=0.2857142857142857, learning_rate=adaptive, loss=huber, max_iter=11393, n_iter_no_change=1, penalty=l1, tol=0.007, validation_fraction=0.1326530612244898;, score=0.613 total time=   1.0s\n",
      "[CV 4/5] END alpha=8.163265306122449e-05, eta0=0.09696969696969697, l1_ratio=0.2346938775510204, learning_rate=optimal, loss=squared_error, max_iter=18181, n_iter_no_change=10, penalty=elasticnet, tol=0.006909090909090909, validation_fraction=0.49183673469387756;, score=0.886 total time=   0.0s\n",
      "[CV 5/5] END alpha=8.163265306122449e-05, eta0=0.09696969696969697, l1_ratio=0.2346938775510204, learning_rate=optimal, loss=squared_error, max_iter=18181, n_iter_no_change=10, penalty=elasticnet, tol=0.006909090909090909, validation_fraction=0.49183673469387756;, score=0.831 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.00024489795918367346, eta0=0.09494949494949495, l1_ratio=0.5, learning_rate=constant, loss=huber, max_iter=10787, n_iter_no_change=5, penalty=elasticnet, tol=0.0027272727272727266, validation_fraction=0.8020408163265307;, score=-3.031 total time=   1.0s\n",
      "[CV 3/5] END alpha=0.00024489795918367346, eta0=0.09494949494949495, l1_ratio=0.5, learning_rate=constant, loss=huber, max_iter=10787, n_iter_no_change=5, penalty=elasticnet, tol=0.0027272727272727266, validation_fraction=0.8020408163265307;, score=-2.841 total time=   1.0s\n",
      "[CV 4/5] END alpha=0.0008979591836734694, eta0=0.09595959595959597, l1_ratio=0.02040816326530612, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=12121, n_iter_no_change=10, penalty=None, tol=0.0032727272727272726, validation_fraction=0.9;, score=0.831 total time=   0.7s\n",
      "[CV 5/5] END alpha=0.0008979591836734694, eta0=0.09595959595959597, l1_ratio=0.02040816326530612, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=12121, n_iter_no_change=10, penalty=None, tol=0.0032727272727272726, validation_fraction=0.9;, score=0.817 total time=   0.7s\n",
      "[CV 2/5] END alpha=0.0009387755102040817, eta0=0.05656565656565657, l1_ratio=0.24489795918367346, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=17939, n_iter_no_change=6, penalty=None, tol=0.002, validation_fraction=0.36122448979591837;, score=0.903 total time=   0.2s\n",
      "[CV 3/5] END alpha=0.0009387755102040817, eta0=0.05656565656565657, l1_ratio=0.24489795918367346, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=17939, n_iter_no_change=6, penalty=None, tol=0.002, validation_fraction=0.36122448979591837;, score=0.925 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.000836734693877551, eta0=0.06616161616161617, l1_ratio=0.2040816326530612, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=9575, n_iter_no_change=4, penalty=None, tol=0.005818181818181818, validation_fraction=0.49183673469387756;, score=0.721 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.000836734693877551, eta0=0.06616161616161617, l1_ratio=0.2040816326530612, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=9575, n_iter_no_change=4, penalty=None, tol=0.005818181818181818, validation_fraction=0.49183673469387756;, score=0.903 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.000836734693877551, eta0=0.06616161616161617, l1_ratio=0.2040816326530612, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=9575, n_iter_no_change=4, penalty=None, tol=0.005818181818181818, validation_fraction=0.49183673469387756;, score=0.913 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.000836734693877551, eta0=0.06616161616161617, l1_ratio=0.2040816326530612, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=9575, n_iter_no_change=4, penalty=None, tol=0.005818181818181818, validation_fraction=0.49183673469387756;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.000836734693877551, eta0=0.06616161616161617, l1_ratio=0.2040816326530612, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=9575, n_iter_no_change=4, penalty=None, tol=0.005818181818181818, validation_fraction=0.49183673469387756;, score=0.875 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.0004489795918367347, eta0=0.07575757575757576, l1_ratio=0.4183673469387755, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=10787, n_iter_no_change=2, penalty=l1, tol=0.0022727272727272726, validation_fraction=0.6224489795918368;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.0004489795918367347, eta0=0.07575757575757576, l1_ratio=0.4183673469387755, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=10787, n_iter_no_change=2, penalty=l1, tol=0.0022727272727272726, validation_fraction=0.6224489795918368;, score=0.902 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.0004489795918367347, eta0=0.07575757575757576, l1_ratio=0.4183673469387755, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=10787, n_iter_no_change=2, penalty=l1, tol=0.0022727272727272726, validation_fraction=0.6224489795918368;, score=0.925 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.0005714285714285715, eta0=0.05656565656565657, l1_ratio=0.061224489795918366, learning_rate=optimal, loss=epsilon_insensitive, max_iter=10545, n_iter_no_change=10, penalty=l2, tol=0.007909090909090909, validation_fraction=0.7367346938775511;, score=-5.764 total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDRegressor() RandomCV Best Params : {'validation_fraction': 0.4591836734693878, 'tol': 0.008, 'penalty': 'elasticnet', 'n_iter_no_change': 1, 'max_iter': 14787, 'loss': 'squared_epsilon_insensitive', 'learning_rate': 'adaptive', 'l1_ratio': 0.030612244897959183, 'eta0': 0.09898989898989899, 'alpha': 0.0007755102040816326}\n",
      "SGDRegressor() RandomCV Score: 0.8740977646570636\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Final score is  0.8740829119789157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py:1527: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "5 fits failed out of a total of 500.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py\", line 1561, in fit\n",
      "    return self._fit(\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py\", line 1496, in _fit\n",
      "    self._validate_params()\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_stochastic_gradient.py\", line 150, in _validate_params\n",
      "    raise ValueError(\n",
      "ValueError: alpha must be > 0 since learning_rate is 'optimal'. alpha is used to compute the optimal learning rate.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [ 8.97055915e-01 -1.25308610e+00  8.96922997e-01  8.94555669e-01\n",
      "  8.97004111e-01  8.97532426e-01  8.84319018e-01  8.46198707e-01\n",
      " -7.43275676e+00 -2.35591213e+00  8.56663507e-01 -5.93889847e+00\n",
      " -1.87882817e+00 -4.19520655e+00  8.89526149e-01  8.97912419e-01\n",
      " -7.62500526e+00  8.52389775e-01 -7.26066794e+00  8.78204208e-01\n",
      " -4.49477571e+00  8.93762316e-01 -7.32331498e+00  8.97474959e-01\n",
      "  8.97818842e-01  8.97303166e-01 -3.02884217e+00 -2.21506023e+00\n",
      "  5.63265779e-01  2.82626365e-01  8.81836268e-01  8.42574735e-01\n",
      "  8.94292793e-01  8.92708774e-01 -6.29519303e+00 -4.49059478e+00\n",
      "  8.97218021e-01 -2.11977814e-01 -2.99418148e+00 -8.81912709e-02\n",
      "  8.95584573e-01 -7.37716615e+00  8.79183820e-01  8.96490189e-01\n",
      "  8.97258143e-01  8.27035760e-01 -7.61422148e+00  7.71805422e-01\n",
      " -3.28856193e-01  8.94991127e-01  8.19332218e-01 -8.49775546e-02\n",
      " -7.68807166e+00 -7.66544661e+00 -5.99740869e-02             nan\n",
      "  6.22901521e-01 -7.26814074e-02  8.42097401e-01 -3.42036876e+00\n",
      "  8.95290826e-01  8.43714883e-01  8.95088110e-01 -1.76771714e+00\n",
      " -7.62958355e+00 -5.23947176e+00  8.77772087e-01  8.91283589e-01\n",
      "  7.46876837e-01  8.18704774e-01 -3.44907774e+00  8.01213720e-01\n",
      "  8.97266727e-01  8.73610846e-01 -6.80667004e+00  8.56936134e-01\n",
      " -7.41654557e+00  8.84196204e-01 -5.31259902e+12  5.55429697e-01\n",
      "  8.82218552e-01 -7.00145172e+00 -1.22005493e-01  8.92355955e-01\n",
      " -7.37740498e-02  8.43198166e-01  8.98304741e-01 -3.12906156e+00\n",
      "  8.95719785e-01  8.69099880e-01  8.97285434e-01  8.93882812e-01\n",
      " -3.47420163e+00  8.40353599e-01 -7.78663233e-02  8.97293999e-01\n",
      "  8.53164238e-01  8.97092523e-01 -5.92288286e+00 -3.96519581e+00]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "hyperparameter_tuning(algo=\"SGDRegressor()\",param_grid=random_grid,n_iter=100,cv=5,verbose=3,random_state=42,X_train=X_train.loc[:,list(selected_features)],Y_train=Y_train,X_test=X_test.loc[:,list(selected_features)],Y_test=Y_test,evaluation_metric=\"r2_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "a8c2ebcd-cab7-4c25-9d72-4df71264ce6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "6444b9ae-1d87-4245-a078-43275a3791ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  62 out of  62 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:22] Features: 1/62 -- score: 0.13053016468007567[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  61 out of  61 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:22] Features: 2/62 -- score: 0.21728200829166813[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:22] Features: 3/62 -- score: 0.273145352695731[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  59 out of  59 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:22] Features: 4/62 -- score: 0.31458585776095516[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  58 out of  58 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:22] Features: 5/62 -- score: 0.34893083166468647[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  57 out of  57 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:22] Features: 6/62 -- score: 0.3773518077867486[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  56 out of  56 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:23] Features: 7/62 -- score: 0.4037335718222879[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  55 out of  55 | elapsed:    0.2s finished\n",
      "\n",
      "[2023-02-01 16:22:23] Features: 8/62 -- score: 0.4258362411014994[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  54 out of  54 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:23] Features: 9/62 -- score: 0.44572348792610744[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  53 out of  53 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:23] Features: 10/62 -- score: 0.4623438646040098[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  52 out of  52 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:23] Features: 11/62 -- score: 0.4785434491033649[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  51 out of  51 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:23] Features: 12/62 -- score: 0.49214280515688[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:23] Features: 13/62 -- score: 0.5045173908322456[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  49 out of  49 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:23] Features: 14/62 -- score: 0.5169864925115725[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:24] Features: 15/62 -- score: 0.5280270350992051[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  47 out of  47 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:24] Features: 16/62 -- score: 0.5381281959872894[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  46 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  46 out of  46 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:24] Features: 17/62 -- score: 0.5474868010648716[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:24] Features: 18/62 -- score: 0.5555851893723711[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  44 out of  44 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:24] Features: 19/62 -- score: 0.5628038395822694[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  32 out of  43 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  43 out of  43 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:24] Features: 20/62 -- score: 0.5693115930149818[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 out of  42 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:24] Features: 21/62 -- score: 0.5755512868427699[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  41 out of  41 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:24] Features: 22/62 -- score: 0.5796613657471533[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:24] Features: 23/62 -- score: 0.5836633655312775[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  28 out of  39 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  39 out of  39 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:24] Features: 24/62 -- score: 0.5872811332962572[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  38 out of  38 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:24] Features: 25/62 -- score: 0.5906471593999907[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 out of  37 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  37 out of  37 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:24] Features: 26/62 -- score: 0.5923783404423527[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  36 out of  36 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:25] Features: 27/62 -- score: 0.5935721752286763[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  35 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:25] Features: 28/62 -- score: 0.5940987722524845[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  23 out of  34 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  34 out of  34 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:25] Features: 29/62 -- score: 0.5946046138207652[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  22 out of  33 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  33 out of  33 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:25] Features: 30/62 -- score: 0.5949321737865688[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  32 out of  32 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:25] Features: 31/62 -- score: 0.59523929782896[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  31 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  31 out of  31 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:25] Features: 32/62 -- score: 0.5955129863859767[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:25] Features: 33/62 -- score: 0.5957716632521459[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  29 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  29 out of  29 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:25] Features: 34/62 -- score: 0.5960288161187155[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  28 out of  28 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:25] Features: 35/62 -- score: 0.5962157671975022[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  27 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:25] Features: 36/62 -- score: 0.5963904698901118[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 out of  26 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:25] Features: 37/62 -- score: 0.5965770691857349[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  14 out of  25 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:25] Features: 38/62 -- score: 0.5967539580149612[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:26] Features: 39/62 -- score: 0.5969202166195753[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  23 out of  23 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:26] Features: 40/62 -- score: 0.5970706778307651[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  22 out of  22 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:26] Features: 41/62 -- score: 0.5971925223294505[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  21 out of  21 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  21 out of  21 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:26] Features: 42/62 -- score: 0.5972947439236334[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:26] Features: 43/62 -- score: 0.597391511540954[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  19 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:26] Features: 44/62 -- score: 0.5974816627996484[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  18 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:26] Features: 45/62 -- score: 0.5975577964591694[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  17 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  17 out of  17 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:26] Features: 46/62 -- score: 0.5976173003507169[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  14 out of  16 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  16 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:26] Features: 47/62 -- score: 0.5976680501353447[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  15 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:26] Features: 48/62 -- score: 0.5977124834202929[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  14 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  14 out of  14 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:26] Features: 49/62 -- score: 0.5977553473927397[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of  13 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:26] Features: 50/62 -- score: 0.5977847108941814[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  12 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:26] Features: 51/62 -- score: 0.597805323641892[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  11 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:26] Features: 52/62 -- score: 0.5978194589960939[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "\n",
      "[2023-02-01 16:22:26] Features: 53/62 -- score: 0.5978305577563148[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   9 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "\n",
      "[2023-02-01 16:22:27] Features: 54/62 -- score: 0.5978320036185992[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   8 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.0s finished\n",
      "\n",
      "[2023-02-01 16:22:27] Features: 55/62 -- score: 0.5978321031657119[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "\n",
      "[2023-02-01 16:22:27] Features: 56/62 -- score: 0.5978321031657119[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.0s finished\n",
      "\n",
      "[2023-02-01 16:22:27] Features: 57/62 -- score: 0.5978319911595815[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "\n",
      "[2023-02-01 16:22:27] Features: 58/62 -- score: 0.5978315490988866[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    0.0s finished\n",
      "\n",
      "[2023-02-01 16:22:27] Features: 59/62 -- score: 0.5977921216651986[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features ('MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'BsmtFinSF1', 'TotalBsmtSF', '1stFlrSF', 'GrLivArea', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageYrBlt', 'GarageCars', 'GarageArea', 'OpenPorchSF', 'MoSold', 'MSZoning', 'Street', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'Neighborhood', 'Condition1', 'BldgType', 'HouseStyle', 'RoofStyle', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual', 'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PavedDrive', 'SaleType')\n",
      "Prediction using selected features using ElasticNet() is : 0.6335315363167291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "\n",
      "[2023-02-01 16:22:27] Features: 60/62 -- score: 0.5977439640480293[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "\n",
      "[2023-02-01 16:22:27] Features: 61/62 -- score: 0.5976468198051526[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "\n",
      "[2023-02-01 16:22:27] Features: 62/62 -- score: 0.5975462295546231"
     ]
    }
   ],
   "source": [
    "selected_features= sf_selector(algo=\"ElasticNet()\",forward=True,floating=False,scoring=\"r2\",X_train=X_train,Y_train=Y_train,X_test=X_test,Y_test=Y_test,min_featues=3,cv=5,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "1741f116-ec38-4f1f-b60a-ebbe8a8c4a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'copy_X': ['True', 'False'], 'alpha': [0.0, 0.001002004008016032, 0.002004008016032064, 0.0030060120240480957, 0.004008016032064128, 0.00501002004008016, 0.0060120240480961915, 0.007014028056112224, 0.008016032064128256, 0.009018036072144287, 0.01002004008016032, 0.011022044088176352, 0.012024048096192383, 0.013026052104208416, 0.014028056112224447, 0.01503006012024048, 0.01603206412825651, 0.017034068136272545, 0.018036072144288574, 0.019038076152304607, 0.02004008016032064, 0.02104208416833667, 0.022044088176352703, 0.023046092184368736, 0.024048096192384766, 0.0250501002004008, 0.026052104208416832, 0.027054108216432865, 0.028056112224448895, 0.029058116232464928, 0.03006012024048096, 0.03106212424849699, 0.03206412825651302, 0.033066132264529056, 0.03406813627254509, 0.03507014028056112, 0.03607214428857715, 0.03707414829659318, 0.038076152304609215, 0.03907815631262525, 0.04008016032064128, 0.041082164328657314, 0.04208416833667334, 0.04308617234468937, 0.044088176352705406, 0.04509018036072144, 0.04609218436873747, 0.047094188376753505, 0.04809619238476953, 0.049098196392785565, 0.0501002004008016, 0.05110220440881763, 0.052104208416833664, 0.0531062124248497, 0.05410821643286573, 0.055110220440881756, 0.05611222444889779, 0.05711422845691382, 0.058116232464929855, 0.05911823647294589, 0.06012024048096192, 0.06112224448897795, 0.06212424849699398, 0.06312625250501001, 0.06412825651302605, 0.06513026052104208, 0.06613226452905811, 0.06713426853707415, 0.06813627254509018, 0.06913827655310621, 0.07014028056112225, 0.07114228456913826, 0.0721442885771543, 0.07314629258517033, 0.07414829659318636, 0.0751503006012024, 0.07615230460921843, 0.07715430861723446, 0.0781563126252505, 0.07915831663326653, 0.08016032064128256, 0.0811623246492986, 0.08216432865731463, 0.08316633266533066, 0.08416833667334668, 0.08517034068136271, 0.08617234468937875, 0.08717434869739478, 0.08817635270541081, 0.08917835671342685, 0.09018036072144288, 0.09118236472945891, 0.09218436873747494, 0.09318637274549098, 0.09418837675350701, 0.09519038076152304, 0.09619238476953906, 0.0971943887775551, 0.09819639278557113, 0.09919839679358716, 0.1002004008016032, 0.10120240480961923, 0.10220440881763526, 0.1032064128256513, 0.10420841683366733, 0.10521042084168336, 0.1062124248496994, 0.10721442885771543, 0.10821643286573146, 0.10921843687374748, 0.11022044088176351, 0.11122244488977955, 0.11222444889779558, 0.11322645290581161, 0.11422845691382764, 0.11523046092184368, 0.11623246492985971, 0.11723446893787574, 0.11823647294589178, 0.11923847695390781, 0.12024048096192384, 0.12124248496993988, 0.1222444889779559, 0.12324649298597193, 0.12424849699398796, 0.125250501002004, 0.12625250501002003, 0.12725450901803606, 0.1282565130260521, 0.12925851703406813, 0.13026052104208416, 0.1312625250501002, 0.13226452905811623, 0.13326653306613226, 0.1342685370741483, 0.13527054108216433, 0.13627254509018036, 0.1372745490981964, 0.13827655310621242, 0.13927855711422846, 0.1402805611222445, 0.1412825651302605, 0.14228456913827653, 0.14328657314629256, 0.1442885771543086, 0.14529058116232463, 0.14629258517034066, 0.1472945891783567, 0.14829659318637273, 0.14929859719438876, 0.1503006012024048, 0.15130260521042083, 0.15230460921843686, 0.1533066132264529, 0.15430861723446893, 0.15531062124248496, 0.156312625250501, 0.15731462925851702, 0.15831663326653306, 0.1593186372745491, 0.16032064128256512, 0.16132264529058116, 0.1623246492985972, 0.16332665330661322, 0.16432865731462926, 0.1653306613226453, 0.16633266533066132, 0.16733466933867733, 0.16833667334669336, 0.1693386773547094, 0.17034068136272543, 0.17134268537074146, 0.1723446893787575, 0.17334669338677353, 0.17434869739478956, 0.1753507014028056, 0.17635270541082163, 0.17735470941883766, 0.1783567134268537, 0.17935871743486972, 0.18036072144288576, 0.1813627254509018, 0.18236472945891782, 0.18336673346693386, 0.1843687374749499, 0.18537074148296592, 0.18637274549098196, 0.187374749498998, 0.18837675350701402, 0.18937875751503006, 0.1903807615230461, 0.19138276553106212, 0.19238476953907813, 0.19338677354709416, 0.1943887775551102, 0.19539078156312623, 0.19639278557114226, 0.1973947895791583, 0.19839679358717432, 0.19939879759519036, 0.2004008016032064, 0.20140280561122242, 0.20240480961923846, 0.2034068136272545, 0.20440881763527052, 0.20541082164328656, 0.2064128256513026, 0.20741482965931862, 0.20841683366733466, 0.2094188376753507, 0.21042084168336672, 0.21142284569138275, 0.2124248496993988, 0.21342685370741482, 0.21442885771543085, 0.2154308617234469, 0.21643286573146292, 0.21743486973947895, 0.21843687374749496, 0.219438877755511, 0.22044088176352702, 0.22144288577154306, 0.2224448897795591, 0.22344689378757512, 0.22444889779559116, 0.2254509018036072, 0.22645290581162322, 0.22745490981963926, 0.2284569138276553, 0.22945891783567132, 0.23046092184368736, 0.2314629258517034, 0.23246492985971942, 0.23346693386773545, 0.2344689378757515, 0.23547094188376752, 0.23647294589178355, 0.2374749498997996, 0.23847695390781562, 0.23947895791583165, 0.24048096192384769, 0.24148296593186372, 0.24248496993987975, 0.24348697394789579, 0.2444889779559118, 0.24549098196392782, 0.24649298597194386, 0.2474949899799599, 0.24849699398797592, 0.24949899799599196, 0.250501002004008, 0.251503006012024, 0.25250501002004005, 0.2535070140280561, 0.2545090180360721, 0.25551102204408815, 0.2565130260521042, 0.2575150300601202, 0.25851703406813625, 0.2595190380761523, 0.2605210420841683, 0.26152304609218435, 0.2625250501002004, 0.2635270541082164, 0.26452905811623245, 0.2655310621242485, 0.2665330661322645, 0.26753507014028055, 0.2685370741482966, 0.2695390781563126, 0.27054108216432865, 0.2715430861723447, 0.2725450901803607, 0.27354709418837675, 0.2745490981963928, 0.2755511022044088, 0.27655310621242485, 0.2775551102204409, 0.2785571142284569, 0.27955911823647295, 0.280561122244489, 0.281563126252505, 0.282565130260521, 0.283567134268537, 0.28456913827655306, 0.2855711422845691, 0.2865731462925851, 0.28757515030060116, 0.2885771543086172, 0.2895791583166332, 0.29058116232464926, 0.2915831663326653, 0.2925851703406813, 0.29358717434869736, 0.2945891783567134, 0.2955911823647294, 0.29659318637274545, 0.2975951903807615, 0.2985971943887775, 0.29959919839679355, 0.3006012024048096, 0.3016032064128256, 0.30260521042084165, 0.3036072144288577, 0.3046092184368737, 0.30561122244488975, 0.3066132264529058, 0.3076152304609218, 0.30861723446893785, 0.3096192384769539, 0.3106212424849699, 0.31162324649298595, 0.312625250501002, 0.313627254509018, 0.31462925851703405, 0.3156312625250501, 0.3166332665330661, 0.31763527054108215, 0.3186372745490982, 0.3196392785571142, 0.32064128256513025, 0.3216432865731463, 0.3226452905811623, 0.32364729458917835, 0.3246492985971944, 0.3256513026052104, 0.32665330661322645, 0.3276553106212425, 0.3286573146292585, 0.32965931863727455, 0.3306613226452906, 0.3316633266533066, 0.33266533066132264, 0.3336673346693386, 0.33466933867735466, 0.3356713426853707, 0.3366733466933867, 0.33767535070140275, 0.3386773547094188, 0.3396793587174348, 0.34068136272545085, 0.3416833667334669, 0.3426853707414829, 0.34368737474949895, 0.344689378757515, 0.345691382765531, 0.34669338677354705, 0.3476953907815631, 0.3486973947895791, 0.34969939879759515, 0.3507014028056112, 0.3517034068136272, 0.35270541082164325, 0.3537074148296593, 0.3547094188376753, 0.35571142284569135, 0.3567134268537074, 0.3577154308617234, 0.35871743486973945, 0.3597194388777555, 0.3607214428857715, 0.36172344689378755, 0.3627254509018036, 0.3637274549098196, 0.36472945891783565, 0.3657314629258517, 0.3667334669338677, 0.36773547094188375, 0.3687374749498998, 0.3697394789579158, 0.37074148296593185, 0.3717434869739479, 0.3727454909819639, 0.37374749498997994, 0.374749498997996, 0.375751503006012, 0.37675350701402804, 0.3777555110220441, 0.3787575150300601, 0.37975951903807614, 0.3807615230460922, 0.3817635270541082, 0.38276553106212424, 0.3837675350701403, 0.38476953907815625, 0.3857715430861723, 0.3867735470941883, 0.38777555110220435, 0.3887775551102204, 0.3897795591182364, 0.39078156312625245, 0.3917835671342685, 0.3927855711422845, 0.39378757515030055, 0.3947895791583166, 0.3957915831663326, 0.39679358717434865, 0.3977955911823647, 0.3987975951903807, 0.39979959919839675, 0.4008016032064128, 0.4018036072144288, 0.40280561122244485, 0.4038076152304609, 0.4048096192384769, 0.40581162324649295, 0.406813627254509, 0.407815631262525, 0.40881763527054105, 0.4098196392785571, 0.4108216432865731, 0.41182364729458915, 0.4128256513026052, 0.4138276553106212, 0.41482965931863724, 0.4158316633266533, 0.4168336673346693, 0.41783567134268534, 0.4188376753507014, 0.4198396793587174, 0.42084168336673344, 0.4218436873747495, 0.4228456913827655, 0.42384769539078154, 0.4248496993987976, 0.4258517034068136, 0.42685370741482964, 0.4278557114228457, 0.4288577154308617, 0.42985971943887774, 0.4308617234468938, 0.4318637274549098, 0.43286573146292584, 0.4338677354709419, 0.4348697394789579, 0.43587174348697394, 0.4368737474949899, 0.43787575150300595, 0.438877755511022, 0.439879759519038, 0.44088176352705405, 0.4418837675350701, 0.4428857715430861, 0.44388777555110215, 0.4448897795591182, 0.4458917835671342, 0.44689378757515025, 0.4478957915831663, 0.4488977955911823, 0.44989979959919835, 0.4509018036072144, 0.4519038076152304, 0.45290581162324645, 0.4539078156312625, 0.4549098196392785, 0.45591182364729455, 0.4569138276553106, 0.4579158316633266, 0.45891783567134264, 0.4599198396793587, 0.4609218436873747, 0.46192384769539074, 0.4629258517034068, 0.4639278557114228, 0.46492985971943884, 0.4659318637274549, 0.4669338677354709, 0.46793587174348694, 0.468937875751503, 0.469939879759519, 0.47094188376753504, 0.4719438877755511, 0.4729458917835671, 0.47394789579158314, 0.4749498997995992, 0.4759519038076152, 0.47695390781563124, 0.4779559118236473, 0.4789579158316633, 0.47995991983967934, 0.48096192384769537, 0.4819639278557114, 0.48296593186372744, 0.48396793587174347, 0.4849699398797595, 0.48597194388777554, 0.48697394789579157, 0.48797595190380755, 0.4889779559118236, 0.4899799599198396, 0.49098196392785565, 0.4919839679358717, 0.4929859719438877, 0.49398797595190375, 0.4949899799599198, 0.4959919839679358, 0.49699398797595185, 0.4979959919839679, 0.4989979959919839, 0.5], 'l1_ratio': [0.0, 0.005050505050505051, 0.010101010101010102, 0.015151515151515152, 0.020202020202020204, 0.025252525252525256, 0.030303030303030304, 0.03535353535353536, 0.04040404040404041, 0.045454545454545456, 0.05050505050505051, 0.05555555555555556, 0.06060606060606061, 0.06565656565656566, 0.07070707070707072, 0.07575757575757576, 0.08080808080808081, 0.08585858585858587, 0.09090909090909091, 0.09595959595959597, 0.10101010101010102, 0.10606060606060606, 0.11111111111111112, 0.11616161616161617, 0.12121212121212122, 0.12626262626262627, 0.13131313131313133, 0.13636363636363638, 0.14141414141414144, 0.14646464646464646, 0.15151515151515152, 0.15656565656565657, 0.16161616161616163, 0.16666666666666669, 0.17171717171717174, 0.1767676767676768, 0.18181818181818182, 0.18686868686868688, 0.19191919191919193, 0.196969696969697, 0.20202020202020204, 0.2070707070707071, 0.21212121212121213, 0.21717171717171718, 0.22222222222222224, 0.2272727272727273, 0.23232323232323235, 0.2373737373737374, 0.24242424242424243, 0.2474747474747475, 0.25252525252525254, 0.2575757575757576, 0.26262626262626265, 0.2676767676767677, 0.27272727272727276, 0.2777777777777778, 0.2828282828282829, 0.2878787878787879, 0.29292929292929293, 0.297979797979798, 0.30303030303030304, 0.3080808080808081, 0.31313131313131315, 0.31818181818181823, 0.32323232323232326, 0.3282828282828283, 0.33333333333333337, 0.3383838383838384, 0.3434343434343435, 0.3484848484848485, 0.3535353535353536, 0.3585858585858586, 0.36363636363636365, 0.36868686868686873, 0.37373737373737376, 0.37878787878787884, 0.38383838383838387, 0.3888888888888889, 0.393939393939394, 0.398989898989899, 0.4040404040404041, 0.4090909090909091, 0.4141414141414142, 0.4191919191919192, 0.42424242424242425, 0.42929292929292934, 0.43434343434343436, 0.43939393939393945, 0.4444444444444445, 0.44949494949494956, 0.4545454545454546, 0.4595959595959596, 0.4646464646464647, 0.4696969696969697, 0.4747474747474748, 0.47979797979797983, 0.48484848484848486, 0.48989898989898994, 0.494949494949495, 0.5], 'max_iter': [2000, 2040, 2080, 2120, 2160, 2201, 2241, 2281, 2321, 2361, 2402, 2442, 2482, 2522, 2562, 2603, 2643, 2683, 2723, 2763, 2804, 2844, 2884, 2924, 2964, 3005, 3045, 3085, 3125, 3165, 3206, 3246, 3286, 3326, 3366, 3407, 3447, 3487, 3527, 3567, 3608, 3648, 3688, 3728, 3768, 3809, 3849, 3889, 3929, 3969, 4010, 4050, 4090, 4130, 4170, 4211, 4251, 4291, 4331, 4371, 4412, 4452, 4492, 4532, 4572, 4613, 4653, 4693, 4733, 4773, 4814, 4854, 4894, 4934, 4974, 5015, 5055, 5095, 5135, 5175, 5216, 5256, 5296, 5336, 5376, 5417, 5457, 5497, 5537, 5577, 5618, 5658, 5698, 5738, 5778, 5819, 5859, 5899, 5939, 5979, 6020, 6060, 6100, 6140, 6180, 6221, 6261, 6301, 6341, 6381, 6422, 6462, 6502, 6542, 6582, 6623, 6663, 6703, 6743, 6783, 6824, 6864, 6904, 6944, 6984, 7025, 7065, 7105, 7145, 7185, 7226, 7266, 7306, 7346, 7386, 7427, 7467, 7507, 7547, 7587, 7628, 7668, 7708, 7748, 7788, 7829, 7869, 7909, 7949, 7989, 8030, 8070, 8110, 8150, 8190, 8231, 8271, 8311, 8351, 8391, 8432, 8472, 8512, 8552, 8592, 8633, 8673, 8713, 8753, 8793, 8834, 8874, 8914, 8954, 8994, 9035, 9075, 9115, 9155, 9195, 9236, 9276, 9316, 9356, 9396, 9437, 9477, 9517, 9557, 9597, 9638, 9678, 9718, 9758, 9798, 9839, 9879, 9919, 9959, 10000], 'tol': [0.01, 0.009954773869346734, 0.009909547738693467, 0.0098643216080402, 0.009819095477386935, 0.009773869346733669, 0.009728643216080402, 0.009683417085427136, 0.009638190954773869, 0.009592964824120602, 0.009547738693467337, 0.00950251256281407, 0.009457286432160804, 0.009412060301507538, 0.009366834170854271, 0.009321608040201004, 0.00927638190954774, 0.009231155778894473, 0.009185929648241206, 0.00914070351758794, 0.009095477386934673, 0.009050251256281406, 0.009005025125628141, 0.008959798994974875, 0.008914572864321608, 0.008869346733668342, 0.008824120603015075, 0.008778894472361808, 0.008733668341708543, 0.008688442211055277, 0.00864321608040201, 0.008597989949748744, 0.008552763819095477, 0.00850753768844221, 0.008462311557788945, 0.008417085427135679, 0.008371859296482412, 0.008326633165829146, 0.008281407035175879, 0.008236180904522612, 0.008190954773869347, 0.00814572864321608, 0.008100502512562814, 0.008055276381909547, 0.008010050251256281, 0.007964824120603016, 0.007919597989949748, 0.007874371859296483, 0.007829145728643216, 0.0077839195979899495, 0.007738693467336683, 0.007693467336683416, 0.0076482412060301505, 0.007603015075376885, 0.007557788944723618, 0.0075125628140703515, 0.007467336683417085, 0.007422110552763818, 0.0073768844221105525, 0.007331658291457287, 0.00728643216080402, 0.0072412060301507535, 0.007195979899497487, 0.00715075376884422, 0.0071055276381909544, 0.007060301507537689, 0.007015075376884422, 0.0069698492462311554, 0.006924623115577889, 0.006879396984924622, 0.006834170854271356, 0.006788944723618091, 0.006743718592964824, 0.006698492462311557, 0.006653266331658291, 0.006608040201005024, 0.006562814070351758, 0.006517587939698493, 0.006472361809045226, 0.006427135678391959, 0.006381909547738693, 0.006336683417085426, 0.00629145728643216, 0.006246231155778894, 0.006201005025125628, 0.006155778894472361, 0.006110552763819095, 0.006065326633165829, 0.006020100502512562, 0.005974874371859296, 0.00592964824120603, 0.005884422110552763, 0.005839195979899497, 0.005793969849246231, 0.005748743718592964, 0.005703517587939698, 0.005658291457286432, 0.005613065326633165, 0.005567839195979899, 0.005522613065326632, 0.005477386934673366, 0.0054321608040201, 0.005386934673366833, 0.005341708542713567, 0.005296482412060301, 0.005251256281407034, 0.005206030150753768, 0.005160804020100502, 0.005115577889447235, 0.005070351758793969, 0.005025125628140703, 0.004979899497487436, 0.00493467336683417, 0.004889447236180904, 0.004844221105527637, 0.004798994974874371, 0.004753768844221105, 0.004708542713567838, 0.004663316582914572, 0.004618090452261306, 0.004572864321608039, 0.004527638190954773, 0.004482412060301507, 0.00443718592964824, 0.004391959798994974, 0.004346733668341708, 0.004301507537688441, 0.004256281407035175, 0.004211055276381909, 0.004165829145728642, 0.004120603015075376, 0.00407537688442211, 0.004030150753768843, 0.003984924623115577, 0.003939698492462311, 0.003894472361809044, 0.0038492462311557783, 0.0038040201005025117, 0.003758793969849245, 0.0037135678391959793, 0.0036683417085427127, 0.003623115577889446, 0.0035778894472361803, 0.0035326633165829137, 0.003487437185929647, 0.0034422110552763813, 0.0033969849246231146, 0.003351758793969848, 0.0033065326633165823, 0.0032613065326633156, 0.003216080402010049, 0.0031708542713567833, 0.0031256281407035166, 0.00308040201005025, 0.0030351758793969843, 0.0029899497487437176, 0.002944723618090451, 0.0028994974874371852, 0.0028542713567839186, 0.002809045226130652, 0.0027638190954773854, 0.0027185929648241196, 0.002673366834170853, 0.0026281407035175864, 0.0025829145728643206, 0.002537688442211054, 0.0024924623115577874, 0.0024472361809045216, 0.002402010050251255, 0.0023567839195979884, 0.0023115577889447226, 0.002266331658291456, 0.0022211055276381893, 0.0021758793969849227, 0.002130653266331658, 0.002085427135678391, 0.0020402010050251246, 0.001994974874371858, 0.0019497487437185913, 0.0019045226130653247, 0.0018592964824120598, 0.0018140703517587932, 0.0017688442211055266, 0.00172361809045226, 0.0016783919597989933, 0.0016331658291457267, 0.0015879396984924618, 0.0015427135678391952, 0.0014974874371859286, 0.001452261306532662, 0.0014070351758793953, 0.0013618090452261287, 0.0013165829145728638, 0.0012713567839195972, 0.0012261306532663305, 0.001180904522613064, 0.0011356783919597973, 0.0010904522613065307, 0.001045226130653264, 0.001], 'warm_start': ['True', 'False'], 'selection': ['cyclic', 'random']}\n"
     ]
    }
   ],
   "source": [
    "alpha = [float(x) for x in np.linspace(0, 0.50,500)]\n",
    "positive=['True','False']\n",
    "l1_ratio=[float(x) for x in np.linspace(0, 0.5,100)]\n",
    "max_iter=[int(x) for x in np.linspace(2000, 10000,200)]\n",
    "tol=[float(x) for x in np.linspace(0.01, 0.001,200)]\n",
    "warm_start = ['True','False']\n",
    "selection=['cyclic','random']\n",
    "copy_X=['True','False']\n",
    "\n",
    "random_grid = {'copy_X':copy_X,\n",
    "               'alpha':alpha,\n",
    "               'l1_ratio': l1_ratio,\n",
    "               'max_iter':max_iter,\n",
    "               'tol':tol,\n",
    "                'warm_start':warm_start,\n",
    "                'selection':selection\n",
    "               \n",
    "               \n",
    "                }\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "dbddbfac-127d-4092-b2dd-3909681e6627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "[CV 5/5] END alpha=0.0, eta0=0.0691919191919192, l1_ratio=0.44897959183673464, learning_rate=invscaling, loss=huber, max_iter=12121, n_iter_no_change=10, penalty=elasticnet, tol=0.006454545454545454, validation_fraction=0.5408163265306123;, score=-8.161 total time=   1.3s\n",
      "[CV 3/5] END alpha=0.0009183673469387755, eta0=0.05050505050505051, l1_ratio=0.0510204081632653, learning_rate=adaptive, loss=squared_error, max_iter=13818, n_iter_no_change=10, penalty=l1, tol=0.009727272727272727, validation_fraction=0.573469387755102;, score=0.926 total time=   1.3s\n",
      "[CV 2/5] END alpha=0.0005306122448979592, eta0=0.08383838383838385, l1_ratio=0.0510204081632653, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=15151, n_iter_no_change=1, penalty=l1, tol=0.004818181818181818, validation_fraction=0.6551020408163265;, score=0.854 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.0005306122448979592, eta0=0.08383838383838385, l1_ratio=0.0510204081632653, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=15151, n_iter_no_change=1, penalty=l1, tol=0.004818181818181818, validation_fraction=0.6551020408163265;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.0005306122448979592, eta0=0.08383838383838385, l1_ratio=0.0510204081632653, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=15151, n_iter_no_change=1, penalty=l1, tol=0.004818181818181818, validation_fraction=0.6551020408163265;, score=0.492 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.0005306122448979592, eta0=0.08383838383838385, l1_ratio=0.0510204081632653, learning_rate=constant, loss=squared_epsilon_insensitive, max_iter=15151, n_iter_no_change=1, penalty=l1, tol=0.004818181818181818, validation_fraction=0.6551020408163265;, score=0.756 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.0006530612244897959, eta0=0.06464646464646465, l1_ratio=0.4591836734693877, learning_rate=constant, loss=huber, max_iter=8000, n_iter_no_change=2, penalty=l1, tol=0.005272727272727273, validation_fraction=0.589795918367347;, score=-0.357 total time=   0.7s\n",
      "[CV 2/5] END alpha=0.0006530612244897959, eta0=0.06464646464646465, l1_ratio=0.4591836734693877, learning_rate=constant, loss=huber, max_iter=8000, n_iter_no_change=2, penalty=l1, tol=0.005272727272727273, validation_fraction=0.589795918367347;, score=-0.286 total time=   0.7s\n",
      "[CV 4/5] END alpha=0.0005510204081632653, eta0=0.06767676767676768, l1_ratio=0.11224489795918366, learning_rate=invscaling, loss=huber, max_iter=13818, n_iter_no_change=2, penalty=elasticnet, tol=0.0017272727272727266, validation_fraction=0.7204081632653062;, score=-7.581 total time=   1.4s\n",
      "[CV 5/5] END alpha=0.0005510204081632653, eta0=0.06767676767676768, l1_ratio=0.11224489795918366, learning_rate=invscaling, loss=huber, max_iter=13818, n_iter_no_change=2, penalty=elasticnet, tol=0.0017272727272727266, validation_fraction=0.7204081632653062;, score=-8.482 total time=   1.4s\n",
      "[CV 2/5] END alpha=0.0007551020408163266, eta0=0.09292929292929293, l1_ratio=0.3877551020408163, learning_rate=optimal, loss=epsilon_insensitive, max_iter=18909, n_iter_no_change=6, penalty=l1, tol=0.0032727272727272726, validation_fraction=0.6551020408163265;, score=-3.381 total time=   1.6s\n",
      "[CV 3/5] END alpha=0.0007551020408163266, eta0=0.09292929292929293, l1_ratio=0.3877551020408163, learning_rate=optimal, loss=epsilon_insensitive, max_iter=18909, n_iter_no_change=6, penalty=l1, tol=0.0032727272727272726, validation_fraction=0.6551020408163265;, score=-3.111 total time=   1.6s\n",
      "[CV 5/5] END alpha=0.0004897959183673469, eta0=0.09646464646464648, l1_ratio=0.4081632653061224, learning_rate=optimal, loss=epsilon_insensitive, max_iter=17939, n_iter_no_change=8, penalty=elasticnet, tol=0.00609090909090909, validation_fraction=0.3938775510204082;, score=-5.779 total time=   1.6s\n",
      "[CV 4/5] END alpha=0.00028571428571428574, eta0=0.06363636363636364, l1_ratio=0.4183673469387755, learning_rate=adaptive, loss=huber, max_iter=15030, n_iter_no_change=5, penalty=l2, tol=0.0076363636363636364, validation_fraction=0.36122448979591837;, score=-3.569 total time=   0.9s\n",
      "[CV 3/5] END alpha=0.0005918367346938776, eta0=0.0691919191919192, l1_ratio=0.0, learning_rate=invscaling, loss=huber, max_iter=10909, n_iter_no_change=6, penalty=l1, tol=0.004, validation_fraction=0.8673469387755103;, score=-6.921 total time=   1.1s\n",
      "[CV 4/5] END alpha=0.0005918367346938776, eta0=0.0691919191919192, l1_ratio=0.0, learning_rate=invscaling, loss=huber, max_iter=10909, n_iter_no_change=6, penalty=l1, tol=0.004, validation_fraction=0.8673469387755103;, score=-7.340 total time=   1.1s\n",
      "[CV 3/5] END alpha=0.0005918367346938776, eta0=0.09797979797979799, l1_ratio=0.3571428571428571, learning_rate=constant, loss=epsilon_insensitive, max_iter=16848, n_iter_no_change=2, penalty=elasticnet, tol=0.005, validation_fraction=0.49183673469387756;, score=-0.047 total time=   0.4s\n",
      "[CV 4/5] END alpha=0.0005918367346938776, eta0=0.09797979797979799, l1_ratio=0.3571428571428571, learning_rate=constant, loss=epsilon_insensitive, max_iter=16848, n_iter_no_change=2, penalty=elasticnet, tol=0.005, validation_fraction=0.49183673469387756;, score=-0.246 total time=   0.3s\n",
      "[CV 3/5] END alpha=0.00024489795918367346, eta0=0.07828282828282829, l1_ratio=0.1530612244897959, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=8000, n_iter_no_change=5, penalty=elasticnet, tol=0.001, validation_fraction=0.4591836734693878;, score=-0.020 total time=   0.5s\n",
      "[CV 4/5] END alpha=0.00024489795918367346, eta0=0.07828282828282829, l1_ratio=0.1530612244897959, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=8000, n_iter_no_change=5, penalty=elasticnet, tol=0.001, validation_fraction=0.4591836734693878;, score=-0.162 total time=   0.5s\n",
      "[CV 5/5] END alpha=0.0002653061224489796, eta0=0.05404040404040405, l1_ratio=0.01020408163265306, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=9090, n_iter_no_change=1, penalty=None, tol=0.002454545454545454, validation_fraction=0.7040816326530612;, score=0.885 total time=   0.5s\n",
      "[CV 1/5] END alpha=0.00040816326530612246, eta0=0.05454545454545455, l1_ratio=0.04081632653061224, learning_rate=optimal, loss=squared_error, max_iter=19030, n_iter_no_change=6, penalty=elasticnet, tol=0.001909090909090909, validation_fraction=0.3122448979591837;, score=0.880 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.0007551020408163266, eta0=0.08636363636363636, l1_ratio=0.42857142857142855, learning_rate=optimal, loss=epsilon_insensitive, max_iter=16121, n_iter_no_change=6, penalty=l1, tol=0.004272727272727273, validation_fraction=0.6224489795918368;, score=-3.164 total time=   1.4s\n",
      "[CV 4/5] END alpha=0.0007551020408163266, eta0=0.08636363636363636, l1_ratio=0.42857142857142855, learning_rate=optimal, loss=epsilon_insensitive, max_iter=16121, n_iter_no_change=6, penalty=l1, tol=0.004272727272727273, validation_fraction=0.6224489795918368;, score=-3.534 total time=   1.4s\n",
      "[CV 4/5] END alpha=0.00042857142857142855, eta0=0.08080808080808081, l1_ratio=0.0510204081632653, learning_rate=constant, loss=huber, max_iter=10181, n_iter_no_change=4, penalty=elasticnet, tol=0.006727272727272728, validation_fraction=0.1326530612244898;, score=-4.065 total time=   0.9s\n",
      "[CV 3/5] END alpha=0.0007755102040816326, eta0=0.09898989898989899, l1_ratio=0.030612244897959183, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=14787, n_iter_no_change=1, penalty=elasticnet, tol=0.008, validation_fraction=0.4591836734693878;, score=0.926 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.024048096192384766, copy_X=False, l1_ratio=0.12121212121212122, max_iter=2321, selection=cyclic, tol=0.009683417085427136, warm_start=True;, score=0.860 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.37374749498997994, copy_X=True, l1_ratio=0.08080808080808081, max_iter=8110, selection=cyclic, tol=0.0026281407035175864, warm_start=False;, score=0.674 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.3286573146292585, copy_X=True, l1_ratio=0.27272727272727276, max_iter=8592, selection=random, tol=0.0076482412060301505, warm_start=False;, score=0.768 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.00020408163265306123, eta0=0.06464646464646465, l1_ratio=0.04081632653061224, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=13575, n_iter_no_change=1, penalty=None, tol=0.009272727272727273, validation_fraction=0.2306122448979592;, score=-7622100111711.703 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.00020408163265306123, eta0=0.06464646464646465, l1_ratio=0.04081632653061224, learning_rate=optimal, loss=squared_epsilon_insensitive, max_iter=13575, n_iter_no_change=1, penalty=None, tol=0.009272727272727273, validation_fraction=0.2306122448979592;, score=-6119359874295.474 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.000673469387755102, eta0=0.07121212121212121, l1_ratio=0.2857142857142857, learning_rate=adaptive, loss=huber, max_iter=11393, n_iter_no_change=1, penalty=l1, tol=0.007, validation_fraction=0.1326530612244898;, score=0.541 total time=   1.0s\n",
      "[CV 2/5] END alpha=0.00012244897959183673, eta0=0.06313131313131314, l1_ratio=0.4183673469387755, learning_rate=optimal, loss=huber, max_iter=9696, n_iter_no_change=1, penalty=l2, tol=0.004363636363636363, validation_fraction=0.2306122448979592;, score=-6.995 total time=   0.5s\n",
      "[CV 3/5] END alpha=0.00012244897959183673, eta0=0.06313131313131314, l1_ratio=0.4183673469387755, learning_rate=optimal, loss=huber, max_iter=9696, n_iter_no_change=1, penalty=l2, tol=0.004363636363636363, validation_fraction=0.2306122448979592;, score=-6.525 total time=   0.5s\n",
      "[CV 2/5] END alpha=0.0005306122448979592, eta0=0.07828282828282829, l1_ratio=0.07142857142857142, learning_rate=optimal, loss=squared_error, max_iter=15878, n_iter_no_change=5, penalty=l2, tol=0.002999999999999999, validation_fraction=0.1653061224489796;, score=0.899 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.0005306122448979592, eta0=0.07828282828282829, l1_ratio=0.07142857142857142, learning_rate=optimal, loss=squared_error, max_iter=15878, n_iter_no_change=5, penalty=l2, tol=0.002999999999999999, validation_fraction=0.1653061224489796;, score=0.924 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.0005306122448979592, eta0=0.07828282828282829, l1_ratio=0.07142857142857142, learning_rate=optimal, loss=squared_error, max_iter=15878, n_iter_no_change=5, penalty=l2, tol=0.002999999999999999, validation_fraction=0.1653061224489796;, score=0.891 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.0005306122448979592, eta0=0.07828282828282829, l1_ratio=0.07142857142857142, learning_rate=optimal, loss=squared_error, max_iter=15878, n_iter_no_change=5, penalty=l2, tol=0.002999999999999999, validation_fraction=0.1653061224489796;, score=0.884 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.00024489795918367346, eta0=0.07828282828282829, l1_ratio=0.1530612244897959, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=8000, n_iter_no_change=5, penalty=elasticnet, tol=0.001, validation_fraction=0.4591836734693878;, score=-0.097 total time=   0.5s\n",
      "[CV 2/5] END alpha=0.00024489795918367346, eta0=0.07828282828282829, l1_ratio=0.1530612244897959, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=8000, n_iter_no_change=5, penalty=elasticnet, tol=0.001, validation_fraction=0.4591836734693878;, score=-0.019 total time=   0.5s\n",
      "[CV 3/5] END alpha=0.0002653061224489796, eta0=0.05404040404040405, l1_ratio=0.01020408163265306, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=9090, n_iter_no_change=1, penalty=None, tol=0.002454545454545454, validation_fraction=0.7040816326530612;, score=0.926 total time=   0.5s\n",
      "[CV 4/5] END alpha=0.0002653061224489796, eta0=0.05404040404040405, l1_ratio=0.01020408163265306, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=9090, n_iter_no_change=1, penalty=None, tol=0.002454545454545454, validation_fraction=0.7040816326530612;, score=0.894 total time=   0.4s\n",
      "[CV 2/5] END alpha=0.0008979591836734694, eta0=0.09595959595959597, l1_ratio=0.02040816326530612, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=12121, n_iter_no_change=10, penalty=None, tol=0.0032727272727272726, validation_fraction=0.9;, score=0.849 total time=   0.7s\n",
      "[CV 3/5] END alpha=0.0008979591836734694, eta0=0.09595959595959597, l1_ratio=0.02040816326530612, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=12121, n_iter_no_change=10, penalty=None, tol=0.0032727272727272726, validation_fraction=0.9;, score=0.884 total time=   0.7s\n",
      "[CV 3/5] END alpha=0.0005714285714285715, eta0=0.08282828282828283, l1_ratio=0.39795918367346933, learning_rate=constant, loss=epsilon_insensitive, max_iter=10545, n_iter_no_change=5, penalty=elasticnet, tol=0.008, validation_fraction=0.6877551020408164;, score=-0.015 total time=   0.5s\n",
      "[CV 4/5] END alpha=0.0005714285714285715, eta0=0.08282828282828283, l1_ratio=0.39795918367346933, learning_rate=constant, loss=epsilon_insensitive, max_iter=10545, n_iter_no_change=5, penalty=elasticnet, tol=0.008, validation_fraction=0.6877551020408164;, score=-0.172 total time=   0.5s\n",
      "[CV 5/5] END alpha=0.0005714285714285715, eta0=0.05656565656565657, l1_ratio=0.061224489795918366, learning_rate=optimal, loss=epsilon_insensitive, max_iter=10545, n_iter_no_change=10, penalty=l2, tol=0.007909090909090909, validation_fraction=0.7367346938775511;, score=-6.539 total time=   0.6s\n",
      "[CV 1/5] END alpha=0.00042857142857142855, eta0=0.08080808080808081, l1_ratio=0.0510204081632653, learning_rate=constant, loss=huber, max_iter=10181, n_iter_no_change=4, penalty=elasticnet, tol=0.006727272727272728, validation_fraction=0.1326530612244898;, score=-3.894 total time=   0.9s\n",
      "[CV 5/5] END alpha=0.0007755102040816326, eta0=0.09898989898989899, l1_ratio=0.030612244897959183, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=14787, n_iter_no_change=1, penalty=elasticnet, tol=0.008, validation_fraction=0.4591836734693878;, score=0.886 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.375751503006012, copy_X=True, l1_ratio=0.3484848484848485, max_iter=3005, selection=random, tol=0.004165829145728642, warm_start=False;, score=0.698 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.37374749498997994, copy_X=True, l1_ratio=0.08080808080808081, max_iter=8110, selection=cyclic, tol=0.0026281407035175864, warm_start=False;, score=0.643 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.08016032064128256, copy_X=True, l1_ratio=0.10606060606060606, max_iter=6582, selection=random, tol=0.002673366834170853, warm_start=True;, score=0.827 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.281563126252505, copy_X=False, l1_ratio=0.3535353535353536, max_iter=8190, selection=random, tol=0.0098643216080402, warm_start=True;, score=0.763 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.281563126252505, copy_X=False, l1_ratio=0.3535353535353536, max_iter=8190, selection=random, tol=0.0098643216080402, warm_start=True;, score=0.803 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.4218436873747495, copy_X=False, l1_ratio=0.3282828282828283, max_iter=7507, selection=random, tol=0.005884422110552763, warm_start=False;, score=0.702 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.4218436873747495, copy_X=False, l1_ratio=0.3282828282828283, max_iter=7507, selection=random, tol=0.005884422110552763, warm_start=False;, score=0.705 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.4218436873747495, copy_X=False, l1_ratio=0.3282828282828283, max_iter=7507, selection=random, tol=0.005884422110552763, warm_start=False;, score=0.742 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.4218436873747495, copy_X=False, l1_ratio=0.3282828282828283, max_iter=7507, selection=random, tol=0.005884422110552763, warm_start=False;, score=0.676 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1342685370741483, copy_X=True, l1_ratio=0.32323232323232326, max_iter=5618, selection=cyclic, tol=0.008552763819095477, warm_start=False;, score=0.778 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.08216432865731463, copy_X=False, l1_ratio=0.37878787878787884, max_iter=5135, selection=random, tol=0.008190954773869347, warm_start=True;, score=0.840 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.08216432865731463, copy_X=False, l1_ratio=0.37878787878787884, max_iter=5135, selection=random, tol=0.008190954773869347, warm_start=True;, score=0.855 total time=   0.0s\n",
      "[CV 3/5] END alpha=8.163265306122449e-05, eta0=0.09696969696969697, l1_ratio=0.2346938775510204, learning_rate=optimal, loss=squared_error, max_iter=18181, n_iter_no_change=10, penalty=elasticnet, tol=0.006909090909090909, validation_fraction=0.49183673469387756;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.0007755102040816326, eta0=0.09898989898989899, l1_ratio=0.030612244897959183, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=14787, n_iter_no_change=1, penalty=elasticnet, tol=0.008, validation_fraction=0.4591836734693878;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.0007755102040816326, eta0=0.09898989898989899, l1_ratio=0.030612244897959183, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=14787, n_iter_no_change=1, penalty=elasticnet, tol=0.008, validation_fraction=0.4591836734693878;, score=0.904 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.0007755102040816326, eta0=0.09898989898989899, l1_ratio=0.030612244897959183, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=14787, n_iter_no_change=1, penalty=elasticnet, tol=0.008, validation_fraction=0.4591836734693878;, score=0.927 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.0007755102040816326, eta0=0.09898989898989899, l1_ratio=0.030612244897959183, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=14787, n_iter_no_change=1, penalty=elasticnet, tol=0.008, validation_fraction=0.4591836734693878;, score=0.896 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.0007755102040816326, eta0=0.09898989898989899, l1_ratio=0.030612244897959183, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=14787, n_iter_no_change=1, penalty=elasticnet, tol=0.008, validation_fraction=0.4591836734693878;, score=0.886 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.00024489795918367346, eta0=0.09494949494949495, l1_ratio=0.5, learning_rate=constant, loss=huber, max_iter=10787, n_iter_no_change=5, penalty=elasticnet, tol=0.0027272727272727266, validation_fraction=0.8020408163265307;, score=-3.092 total time=   1.0s\n",
      "[CV 2/5] END alpha=0.00040816326530612246, eta0=0.05454545454545455, l1_ratio=0.04081632653061224, learning_rate=optimal, loss=squared_error, max_iter=19030, n_iter_no_change=6, penalty=elasticnet, tol=0.001909090909090909, validation_fraction=0.3122448979591837;, score=0.897 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.00040816326530612246, eta0=0.05454545454545455, l1_ratio=0.04081632653061224, learning_rate=optimal, loss=squared_error, max_iter=19030, n_iter_no_change=6, penalty=elasticnet, tol=0.001909090909090909, validation_fraction=0.3122448979591837;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.00040816326530612246, eta0=0.05454545454545455, l1_ratio=0.04081632653061224, learning_rate=optimal, loss=squared_error, max_iter=19030, n_iter_no_change=6, penalty=elasticnet, tol=0.001909090909090909, validation_fraction=0.3122448979591837;, score=0.890 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.00040816326530612246, eta0=0.05454545454545455, l1_ratio=0.04081632653061224, learning_rate=optimal, loss=squared_error, max_iter=19030, n_iter_no_change=6, penalty=elasticnet, tol=0.001909090909090909, validation_fraction=0.3122448979591837;, score=0.884 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.0007551020408163266, eta0=0.08636363636363636, l1_ratio=0.42857142857142855, learning_rate=optimal, loss=epsilon_insensitive, max_iter=16121, n_iter_no_change=6, penalty=l1, tol=0.004272727272727273, validation_fraction=0.6224489795918368;, score=-3.405 total time=   1.5s\n",
      "[CV 2/5] END alpha=0.0007551020408163266, eta0=0.08636363636363636, l1_ratio=0.42857142857142855, learning_rate=optimal, loss=epsilon_insensitive, max_iter=16121, n_iter_no_change=6, penalty=l1, tol=0.004272727272727273, validation_fraction=0.6224489795918368;, score=-3.436 total time=   1.5s\n",
      "[CV 2/5] END alpha=0.00042857142857142855, eta0=0.08080808080808081, l1_ratio=0.0510204081632653, learning_rate=constant, loss=huber, max_iter=10181, n_iter_no_change=4, penalty=elasticnet, tol=0.006727272727272728, validation_fraction=0.1326530612244898;, score=-3.882 total time=   0.9s\n",
      "[CV 3/5] END alpha=0.00042857142857142855, eta0=0.08080808080808081, l1_ratio=0.0510204081632653, learning_rate=constant, loss=huber, max_iter=10181, n_iter_no_change=4, penalty=elasticnet, tol=0.006727272727272728, validation_fraction=0.1326530612244898;, score=-3.633 total time=   0.9s\n",
      "[CV 5/5] END alpha=0.375751503006012, copy_X=True, l1_ratio=0.3484848484848485, max_iter=3005, selection=random, tol=0.004165829145728642, warm_start=False;, score=0.690 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.024048096192384766, copy_X=False, l1_ratio=0.12121212121212122, max_iter=2321, selection=cyclic, tol=0.009683417085427136, warm_start=True;, score=0.836 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.08016032064128256, copy_X=True, l1_ratio=0.10606060606060606, max_iter=6582, selection=random, tol=0.002673366834170853, warm_start=True;, score=0.818 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.08016032064128256, copy_X=True, l1_ratio=0.10606060606060606, max_iter=6582, selection=random, tol=0.002673366834170853, warm_start=True;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.281563126252505, copy_X=False, l1_ratio=0.3535353535353536, max_iter=8190, selection=random, tol=0.0098643216080402, warm_start=True;, score=0.737 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.281563126252505, copy_X=False, l1_ratio=0.3535353535353536, max_iter=8190, selection=random, tol=0.0098643216080402, warm_start=True;, score=0.723 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.4478957915831663, copy_X=True, l1_ratio=0.4444444444444445, max_iter=6462, selection=random, tol=0.004120603015075376, warm_start=True;, score=0.724 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.4478957915831663, copy_X=True, l1_ratio=0.4444444444444445, max_iter=6462, selection=random, tol=0.004120603015075376, warm_start=True;, score=0.762 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.4478957915831663, copy_X=True, l1_ratio=0.4444444444444445, max_iter=6462, selection=random, tol=0.004120603015075376, warm_start=True;, score=0.696 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.4478957915831663, copy_X=True, l1_ratio=0.4444444444444445, max_iter=6462, selection=random, tol=0.004120603015075376, warm_start=True;, score=0.688 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1342685370741483, copy_X=True, l1_ratio=0.32323232323232326, max_iter=5618, selection=cyclic, tol=0.008552763819095477, warm_start=False;, score=0.815 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1342685370741483, copy_X=True, l1_ratio=0.32323232323232326, max_iter=5618, selection=cyclic, tol=0.008552763819095477, warm_start=False;, score=0.824 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1342685370741483, copy_X=True, l1_ratio=0.32323232323232326, max_iter=5618, selection=cyclic, tol=0.008552763819095477, warm_start=False;, score=0.864 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1342685370741483, copy_X=True, l1_ratio=0.32323232323232326, max_iter=5618, selection=cyclic, tol=0.008552763819095477, warm_start=False;, score=0.803 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.40581162324649295, copy_X=False, l1_ratio=0.2474747474747475, max_iter=7708, selection=random, tol=0.004030150753768843, warm_start=True;, score=0.660 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.07014028056112225, copy_X=True, l1_ratio=0.43434343434343436, max_iter=8512, selection=random, tol=0.009773869346733669, warm_start=True;, score=0.848 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.07014028056112225, copy_X=True, l1_ratio=0.43434343434343436, max_iter=8512, selection=random, tol=0.009773869346733669, warm_start=True;, score=0.864 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.07014028056112225, copy_X=True, l1_ratio=0.43434343434343436, max_iter=8512, selection=random, tol=0.009773869346733669, warm_start=True;, score=0.901 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.07014028056112225, copy_X=True, l1_ratio=0.43434343434343436, max_iter=8512, selection=random, tol=0.009773869346733669, warm_start=True;, score=0.847 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.0005714285714285715, eta0=0.08282828282828283, l1_ratio=0.39795918367346933, learning_rate=constant, loss=epsilon_insensitive, max_iter=10545, n_iter_no_change=5, penalty=elasticnet, tol=0.008, validation_fraction=0.6877551020408164;, score=-0.019 total time=   0.5s\n",
      "[CV 5/5] END alpha=0.0005714285714285715, eta0=0.08282828282828283, l1_ratio=0.39795918367346933, learning_rate=constant, loss=epsilon_insensitive, max_iter=10545, n_iter_no_change=5, penalty=elasticnet, tol=0.008, validation_fraction=0.6877551020408164;, score=-0.079 total time=   0.5s\n",
      "[CV 1/5] END alpha=0.0009387755102040817, eta0=0.05656565656565657, l1_ratio=0.24489795918367346, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=17939, n_iter_no_change=6, penalty=None, tol=0.002, validation_fraction=0.36122448979591837;, score=0.878 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.0009387755102040817, eta0=0.05656565656565657, l1_ratio=0.24489795918367346, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=17939, n_iter_no_change=6, penalty=None, tol=0.002, validation_fraction=0.36122448979591837;, score=0.893 total time=   0.1s\n",
      "[CV 5/5] END alpha=0.0009387755102040817, eta0=0.05656565656565657, l1_ratio=0.24489795918367346, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=17939, n_iter_no_change=6, penalty=None, tol=0.002, validation_fraction=0.36122448979591837;, score=0.886 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.0004489795918367347, eta0=0.07575757575757576, l1_ratio=0.4183673469387755, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=10787, n_iter_no_change=2, penalty=l1, tol=0.0022727272727272726, validation_fraction=0.6224489795918368;, score=0.893 total time=   0.5s\n",
      "[CV 5/5] END alpha=0.0004489795918367347, eta0=0.07575757575757576, l1_ratio=0.4183673469387755, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=10787, n_iter_no_change=2, penalty=l1, tol=0.0022727272727272726, validation_fraction=0.6224489795918368;, score=0.886 total time=   0.1s\n",
      "[CV 5/5] END alpha=0.00042857142857142855, eta0=0.08080808080808081, l1_ratio=0.0510204081632653, learning_rate=constant, loss=huber, max_iter=10181, n_iter_no_change=4, penalty=elasticnet, tol=0.006727272727272728, validation_fraction=0.1326530612244898;, score=-4.353 total time=   0.9s\n",
      "[CV 4/5] END alpha=0.0007755102040816326, eta0=0.09898989898989899, l1_ratio=0.030612244897959183, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=14787, n_iter_no_change=1, penalty=elasticnet, tol=0.008, validation_fraction=0.4591836734693878;, score=0.894 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.375751503006012, copy_X=True, l1_ratio=0.3484848484848485, max_iter=3005, selection=random, tol=0.004165829145728642, warm_start=False;, score=0.723 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.024048096192384766, copy_X=False, l1_ratio=0.12121212121212122, max_iter=2321, selection=cyclic, tol=0.009683417085427136, warm_start=True;, score=0.880 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.37374749498997994, copy_X=True, l1_ratio=0.08080808080808081, max_iter=8110, selection=cyclic, tol=0.0026281407035175864, warm_start=False;, score=0.671 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.3286573146292585, copy_X=True, l1_ratio=0.27272727272727276, max_iter=8592, selection=random, tol=0.0076482412060301505, warm_start=False;, score=0.726 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.3286573146292585, copy_X=True, l1_ratio=0.27272727272727276, max_iter=8592, selection=random, tol=0.0076482412060301505, warm_start=False;, score=0.729 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.3306613226452906, copy_X=True, l1_ratio=0.07070707070707072, max_iter=9678, selection=random, tol=0.0021758793969849227, warm_start=True;, score=0.659 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.4478957915831663, copy_X=True, l1_ratio=0.4444444444444445, max_iter=6462, selection=random, tol=0.004120603015075376, warm_start=True;, score=0.720 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.2314629258517034, copy_X=True, l1_ratio=0.12121212121212122, max_iter=6422, selection=random, tol=0.0098643216080402, warm_start=False;, score=0.750 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.2314629258517034, copy_X=True, l1_ratio=0.12121212121212122, max_iter=6422, selection=random, tol=0.0098643216080402, warm_start=False;, score=0.790 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.2314629258517034, copy_X=True, l1_ratio=0.12121212121212122, max_iter=6422, selection=random, tol=0.0098643216080402, warm_start=False;, score=0.724 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.2314629258517034, copy_X=True, l1_ratio=0.12121212121212122, max_iter=6422, selection=random, tol=0.0098643216080402, warm_start=False;, score=0.711 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.40581162324649295, copy_X=False, l1_ratio=0.2474747474747475, max_iter=7708, selection=random, tol=0.004030150753768843, warm_start=True;, score=0.690 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.40581162324649295, copy_X=False, l1_ratio=0.2474747474747475, max_iter=7708, selection=random, tol=0.004030150753768843, warm_start=True;, score=0.693 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.40581162324649295, copy_X=False, l1_ratio=0.2474747474747475, max_iter=7708, selection=random, tol=0.004030150753768843, warm_start=True;, score=0.730 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.40581162324649295, copy_X=False, l1_ratio=0.2474747474747475, max_iter=7708, selection=random, tol=0.004030150753768843, warm_start=True;, score=0.664 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.3196392785571142, copy_X=False, l1_ratio=0.2676767676767677, max_iter=7829, selection=cyclic, tol=0.002537688442211054, warm_start=False;, score=0.732 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.3196392785571142, copy_X=False, l1_ratio=0.2676767676767677, max_iter=7829, selection=cyclic, tol=0.002537688442211054, warm_start=False;, score=0.771 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.3196392785571142, copy_X=False, l1_ratio=0.2676767676767677, max_iter=7829, selection=cyclic, tol=0.002537688442211054, warm_start=False;, score=0.705 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.3196392785571142, copy_X=False, l1_ratio=0.2676767676767677, max_iter=7829, selection=cyclic, tol=0.002537688442211054, warm_start=False;, score=0.695 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.4008016032064128, copy_X=True, l1_ratio=0.4040404040404041, max_iter=5939, selection=random, tol=0.0034422110552763813, warm_start=False;, score=0.726 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.4008016032064128, copy_X=True, l1_ratio=0.4040404040404041, max_iter=5939, selection=random, tol=0.0034422110552763813, warm_start=False;, score=0.729 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.4008016032064128, copy_X=True, l1_ratio=0.4040404040404041, max_iter=5939, selection=random, tol=0.0034422110552763813, warm_start=False;, score=0.768 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.4008016032064128, copy_X=True, l1_ratio=0.4040404040404041, max_iter=5939, selection=random, tol=0.0034422110552763813, warm_start=False;, score=0.702 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.27054108216432865, copy_X=True, l1_ratio=0.21717171717171718, max_iter=3326, selection=random, tol=0.0020402010050251246, warm_start=False;, score=0.718 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.27054108216432865, copy_X=True, l1_ratio=0.21717171717171718, max_iter=3326, selection=random, tol=0.0020402010050251246, warm_start=False;, score=0.707 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.4789579158316633, copy_X=True, l1_ratio=0.2575757575757576, max_iter=4291, selection=random, tol=0.002130653266331658, warm_start=False;, score=0.665 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.4789579158316633, copy_X=True, l1_ratio=0.2575757575757576, max_iter=4291, selection=random, tol=0.002130653266331658, warm_start=False;, score=0.668 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.4789579158316633, copy_X=True, l1_ratio=0.2575757575757576, max_iter=4291, selection=random, tol=0.002130653266331658, warm_start=False;, score=0.703 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.4789579158316633, copy_X=True, l1_ratio=0.2575757575757576, max_iter=4291, selection=random, tol=0.002130653266331658, warm_start=False;, score=0.638 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.0002653061224489796, eta0=0.05404040404040405, l1_ratio=0.01020408163265306, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=9090, n_iter_no_change=1, penalty=None, tol=0.002454545454545454, validation_fraction=0.7040816326530612;, score=0.902 total time=   0.5s\n",
      "[CV 5/5] END alpha=0.0007551020408163266, eta0=0.08636363636363636, l1_ratio=0.42857142857142855, learning_rate=optimal, loss=epsilon_insensitive, max_iter=16121, n_iter_no_change=6, penalty=l1, tol=0.004272727272727273, validation_fraction=0.6224489795918368;, score=-3.833 total time=   1.5s\n",
      "[CV 1/5] END alpha=0.0008979591836734694, eta0=0.09595959595959597, l1_ratio=0.02040816326530612, learning_rate=adaptive, loss=epsilon_insensitive, max_iter=12121, n_iter_no_change=10, penalty=None, tol=0.0032727272727272726, validation_fraction=0.9;, score=0.820 total time=   0.8s\n",
      "[CV 3/5] END alpha=0.0005714285714285715, eta0=0.05656565656565657, l1_ratio=0.061224489795918366, learning_rate=optimal, loss=epsilon_insensitive, max_iter=10545, n_iter_no_change=10, penalty=l2, tol=0.007909090909090909, validation_fraction=0.7367346938775511;, score=-5.496 total time=   0.6s\n",
      "[CV 4/5] END alpha=0.0005714285714285715, eta0=0.05656565656565657, l1_ratio=0.061224489795918366, learning_rate=optimal, loss=epsilon_insensitive, max_iter=10545, n_iter_no_change=10, penalty=l2, tol=0.007909090909090909, validation_fraction=0.7367346938775511;, score=-5.925 total time=   0.6s\n",
      "[CV 2/5] END alpha=0.0007755102040816326, eta0=0.09898989898989899, l1_ratio=0.030612244897959183, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=14787, n_iter_no_change=1, penalty=elasticnet, tol=0.008, validation_fraction=0.4591836734693878;, score=0.903 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.375751503006012, copy_X=True, l1_ratio=0.3484848484848485, max_iter=3005, selection=random, tol=0.004165829145728642, warm_start=False;, score=0.726 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.024048096192384766, copy_X=False, l1_ratio=0.12121212121212122, max_iter=2321, selection=cyclic, tol=0.009683417085427136, warm_start=True;, score=0.914 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.37374749498997994, copy_X=True, l1_ratio=0.08080808080808081, max_iter=8110, selection=cyclic, tol=0.0026281407035175864, warm_start=False;, score=0.709 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.37374749498997994, copy_X=True, l1_ratio=0.08080808080808081, max_iter=8110, selection=cyclic, tol=0.0026281407035175864, warm_start=False;, score=0.644 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.3306613226452906, copy_X=True, l1_ratio=0.07070707070707072, max_iter=9678, selection=random, tol=0.0021758793969849227, warm_start=True;, score=0.689 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.3306613226452906, copy_X=True, l1_ratio=0.07070707070707072, max_iter=9678, selection=random, tol=0.0021758793969849227, warm_start=True;, score=0.692 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.49098196392785565, copy_X=True, l1_ratio=0.010101010101010102, max_iter=8351, selection=cyclic, tol=0.005613065326633165, warm_start=True;, score=0.578 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.49098196392785565, copy_X=True, l1_ratio=0.010101010101010102, max_iter=8351, selection=cyclic, tol=0.005613065326633165, warm_start=True;, score=0.584 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1412825651302605, copy_X=False, l1_ratio=0.2878787878787879, max_iter=8673, selection=cyclic, tol=0.0015879396984924618, warm_start=True;, score=0.808 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1412825651302605, copy_X=False, l1_ratio=0.2878787878787879, max_iter=8673, selection=cyclic, tol=0.0015879396984924618, warm_start=True;, score=0.817 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.4849699398797595, copy_X=False, l1_ratio=0.2474747474747475, max_iter=6623, selection=cyclic, tol=0.005115577889447235, warm_start=False;, score=0.698 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.4849699398797595, copy_X=False, l1_ratio=0.2474747474747475, max_iter=6623, selection=cyclic, tol=0.005115577889447235, warm_start=False;, score=0.633 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.4849699398797595, copy_X=False, l1_ratio=0.2474747474747475, max_iter=6623, selection=cyclic, tol=0.005115577889447235, warm_start=False;, score=0.633 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.13527054108216433, copy_X=True, l1_ratio=0.16666666666666669, max_iter=3849, selection=cyclic, tol=0.00864321608040201, warm_start=True;, score=0.801 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.3226452905811623, copy_X=True, l1_ratio=0.10101010101010102, max_iter=8231, selection=random, tol=0.009683417085427136, warm_start=True;, score=0.738 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.3226452905811623, copy_X=True, l1_ratio=0.10101010101010102, max_iter=8231, selection=random, tol=0.009683417085427136, warm_start=True;, score=0.673 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.3226452905811623, copy_X=True, l1_ratio=0.10101010101010102, max_iter=8231, selection=random, tol=0.009683417085427136, warm_start=True;, score=0.668 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1402805611222445, copy_X=True, l1_ratio=0.48484848484848486, max_iter=3728, selection=random, tol=0.009683417085427136, warm_start=False;, score=0.827 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1402805611222445, copy_X=True, l1_ratio=0.48484848484848486, max_iter=3728, selection=random, tol=0.009683417085427136, warm_start=False;, score=0.838 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1402805611222445, copy_X=True, l1_ratio=0.48484848484848486, max_iter=3728, selection=random, tol=0.009683417085427136, warm_start=False;, score=0.877 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1402805611222445, copy_X=True, l1_ratio=0.48484848484848486, max_iter=3728, selection=random, tol=0.009683417085427136, warm_start=False;, score=0.818 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1402805611222445, copy_X=True, l1_ratio=0.48484848484848486, max_iter=3728, selection=random, tol=0.009683417085427136, warm_start=False;, score=0.791 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.06012024048096192, copy_X=True, l1_ratio=0.4646464646464647, max_iter=10000, selection=cyclic, tol=0.0018592964824120598, warm_start=True;, score=0.852 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.06012024048096192, copy_X=True, l1_ratio=0.4646464646464647, max_iter=10000, selection=cyclic, tol=0.0018592964824120598, warm_start=True;, score=0.870 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.06012024048096192, copy_X=True, l1_ratio=0.4646464646464647, max_iter=10000, selection=cyclic, tol=0.0018592964824120598, warm_start=True;, score=0.906 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.06012024048096192, copy_X=True, l1_ratio=0.4646464646464647, max_iter=10000, selection=cyclic, tol=0.0018592964824120598, warm_start=True;, score=0.855 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.06012024048096192, copy_X=True, l1_ratio=0.4646464646464647, max_iter=10000, selection=cyclic, tol=0.0018592964824120598, warm_start=True;, score=0.824 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.27054108216432865, copy_X=True, l1_ratio=0.21717171717171718, max_iter=3326, selection=random, tol=0.0020402010050251246, warm_start=False;, score=0.741 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.27054108216432865, copy_X=True, l1_ratio=0.21717171717171718, max_iter=3326, selection=random, tol=0.0020402010050251246, warm_start=False;, score=0.745 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.27054108216432865, copy_X=True, l1_ratio=0.21717171717171718, max_iter=3326, selection=random, tol=0.0020402010050251246, warm_start=False;, score=0.785 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.18637274549098196, copy_X=False, l1_ratio=0.20202020202020204, max_iter=10000, selection=random, tol=0.00493467336683417, warm_start=True;, score=0.784 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.18637274549098196, copy_X=False, l1_ratio=0.20202020202020204, max_iter=10000, selection=random, tol=0.00493467336683417, warm_start=True;, score=0.825 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.18637274549098196, copy_X=False, l1_ratio=0.20202020202020204, max_iter=10000, selection=random, tol=0.00493467336683417, warm_start=True;, score=0.760 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.08216432865731463, copy_X=False, l1_ratio=0.37878787878787884, max_iter=5135, selection=random, tol=0.008190954773869347, warm_start=True;, score=0.893 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.14629258517034066, copy_X=True, l1_ratio=0.37878787878787884, max_iter=7949, selection=random, tol=0.006110552763819095, warm_start=False;, score=0.803 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.14629258517034066, copy_X=True, l1_ratio=0.37878787878787884, max_iter=7949, selection=random, tol=0.006110552763819095, warm_start=False;, score=0.778 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.3517034068136272, copy_X=True, l1_ratio=0.43434343434343436, max_iter=8110, selection=random, tol=0.003216080402010049, warm_start=False;, score=0.749 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.3517034068136272, copy_X=True, l1_ratio=0.43434343434343436, max_iter=8110, selection=random, tol=0.003216080402010049, warm_start=False;, score=0.753 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.3517034068136272, copy_X=True, l1_ratio=0.43434343434343436, max_iter=8110, selection=random, tol=0.003216080402010049, warm_start=False;, score=0.793 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.3517034068136272, copy_X=True, l1_ratio=0.43434343434343436, max_iter=8110, selection=random, tol=0.003216080402010049, warm_start=False;, score=0.726 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.3517034068136272, copy_X=True, l1_ratio=0.43434343434343436, max_iter=8110, selection=random, tol=0.003216080402010049, warm_start=False;, score=0.714 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.3196392785571142, copy_X=False, l1_ratio=0.2676767676767677, max_iter=7829, selection=cyclic, tol=0.002537688442211054, warm_start=False;, score=0.729 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.18537074148296592, copy_X=False, l1_ratio=0.44949494949494956, max_iter=5939, selection=cyclic, tol=0.005839195979899497, warm_start=False;, score=0.816 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.18537074148296592, copy_X=False, l1_ratio=0.44949494949494956, max_iter=5939, selection=cyclic, tol=0.005839195979899497, warm_start=False;, score=0.856 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.18537074148296592, copy_X=False, l1_ratio=0.44949494949494956, max_iter=5939, selection=cyclic, tol=0.005839195979899497, warm_start=False;, score=0.794 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.18537074148296592, copy_X=False, l1_ratio=0.44949494949494956, max_iter=5939, selection=cyclic, tol=0.005839195979899497, warm_start=False;, score=0.771 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.002004008016032064, copy_X=True, l1_ratio=0.14141414141414144, max_iter=6743, selection=cyclic, tol=0.006562814070351758, warm_start=False;, score=0.878 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.002004008016032064, copy_X=True, l1_ratio=0.14141414141414144, max_iter=6743, selection=cyclic, tol=0.006562814070351758, warm_start=False;, score=0.896 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.002004008016032064, copy_X=True, l1_ratio=0.14141414141414144, max_iter=6743, selection=cyclic, tol=0.006562814070351758, warm_start=False;, score=0.928 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.002004008016032064, copy_X=True, l1_ratio=0.14141414141414144, max_iter=6743, selection=cyclic, tol=0.006562814070351758, warm_start=False;, score=0.891 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.3817635270541082, copy_X=True, l1_ratio=0.48989898989898994, max_iter=2000, selection=cyclic, tol=0.006743718592964824, warm_start=False;, score=0.729 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.3817635270541082, copy_X=True, l1_ratio=0.48989898989898994, max_iter=2000, selection=cyclic, tol=0.006743718592964824, warm_start=False;, score=0.716 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1943887775551102, copy_X=False, l1_ratio=0.08080808080808081, max_iter=6341, selection=cyclic, tol=0.006155778894472361, warm_start=False;, score=0.760 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1943887775551102, copy_X=False, l1_ratio=0.08080808080808081, max_iter=6341, selection=cyclic, tol=0.006155778894472361, warm_start=False;, score=0.765 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1943887775551102, copy_X=False, l1_ratio=0.08080808080808081, max_iter=6341, selection=cyclic, tol=0.006155778894472361, warm_start=False;, score=0.805 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1943887775551102, copy_X=False, l1_ratio=0.08080808080808081, max_iter=6341, selection=cyclic, tol=0.006155778894472361, warm_start=False;, score=0.739 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1943887775551102, copy_X=False, l1_ratio=0.08080808080808081, max_iter=6341, selection=cyclic, tol=0.006155778894472361, warm_start=False;, score=0.725 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.187374749498998, copy_X=True, l1_ratio=0.25252525252525254, max_iter=8231, selection=random, tol=0.005115577889447235, warm_start=False;, score=0.784 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.187374749498998, copy_X=True, l1_ratio=0.25252525252525254, max_iter=8231, selection=random, tol=0.005115577889447235, warm_start=False;, score=0.790 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.187374749498998, copy_X=True, l1_ratio=0.25252525252525254, max_iter=8231, selection=random, tol=0.005115577889447235, warm_start=False;, score=0.831 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.187374749498998, copy_X=True, l1_ratio=0.25252525252525254, max_iter=8231, selection=random, tol=0.005115577889447235, warm_start=False;, score=0.766 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.187374749498998, copy_X=True, l1_ratio=0.25252525252525254, max_iter=8231, selection=random, tol=0.005115577889447235, warm_start=False;, score=0.747 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.25851703406813625, copy_X=False, l1_ratio=0.09090909090909091, max_iter=4854, selection=cyclic, tol=0.009954773869346734, warm_start=False;, score=0.728 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.25851703406813625, copy_X=False, l1_ratio=0.09090909090909091, max_iter=4854, selection=cyclic, tol=0.009954773869346734, warm_start=False;, score=0.732 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.25851703406813625, copy_X=False, l1_ratio=0.09090909090909091, max_iter=4854, selection=cyclic, tol=0.009954773869346734, warm_start=False;, score=0.770 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.25851703406813625, copy_X=False, l1_ratio=0.09090909090909091, max_iter=4854, selection=cyclic, tol=0.009954773869346734, warm_start=False;, score=0.704 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.439879759519038, copy_X=False, l1_ratio=0.196969696969697, max_iter=5457, selection=random, tol=0.006472361809045226, warm_start=True;, score=0.704 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.439879759519038, copy_X=False, l1_ratio=0.196969696969697, max_iter=5457, selection=random, tol=0.006472361809045226, warm_start=True;, score=0.639 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.439879759519038, copy_X=False, l1_ratio=0.196969696969697, max_iter=5457, selection=random, tol=0.006472361809045226, warm_start=True;, score=0.638 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.03907815631262525, copy_X=False, l1_ratio=0.2676767676767677, max_iter=2241, selection=cyclic, tol=0.005025125628140703, warm_start=True;, score=0.855 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.03907815631262525, copy_X=False, l1_ratio=0.2676767676767677, max_iter=2241, selection=cyclic, tol=0.005025125628140703, warm_start=True;, score=0.873 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.03907815631262525, copy_X=False, l1_ratio=0.2676767676767677, max_iter=2241, selection=cyclic, tol=0.005025125628140703, warm_start=True;, score=0.909 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.03907815631262525, copy_X=False, l1_ratio=0.2676767676767677, max_iter=2241, selection=cyclic, tol=0.005025125628140703, warm_start=True;, score=0.859 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.03907815631262525, copy_X=False, l1_ratio=0.2676767676767677, max_iter=2241, selection=cyclic, tol=0.005025125628140703, warm_start=True;, score=0.828 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.29058116232464926, copy_X=False, l1_ratio=0.11616161616161617, max_iter=5537, selection=cyclic, tol=0.003216080402010049, warm_start=True;, score=0.716 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.07014028056112225, copy_X=True, l1_ratio=0.43434343434343436, max_iter=8512, selection=random, tol=0.009773869346733669, warm_start=True;, score=0.817 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.3226452905811623, copy_X=True, l1_ratio=0.10101010101010102, max_iter=8231, selection=random, tol=0.009683417085427136, warm_start=True;, score=0.698 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.3226452905811623, copy_X=True, l1_ratio=0.10101010101010102, max_iter=8231, selection=random, tol=0.009683417085427136, warm_start=True;, score=0.701 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.3837675350701403, copy_X=False, l1_ratio=0.3535353535353536, max_iter=9557, selection=cyclic, tol=0.007738693467336683, warm_start=True;, score=0.763 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.3837675350701403, copy_X=False, l1_ratio=0.3535353535353536, max_iter=9557, selection=cyclic, tol=0.007738693467336683, warm_start=True;, score=0.696 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.3837675350701403, copy_X=False, l1_ratio=0.3535353535353536, max_iter=9557, selection=cyclic, tol=0.007738693467336683, warm_start=True;, score=0.688 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.3597194388777555, copy_X=False, l1_ratio=0.24242424242424243, max_iter=9678, selection=random, tol=0.00950251256281407, warm_start=True;, score=0.708 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.3597194388777555, copy_X=False, l1_ratio=0.24242424242424243, max_iter=9678, selection=random, tol=0.00950251256281407, warm_start=True;, score=0.711 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.3597194388777555, copy_X=False, l1_ratio=0.24242424242424243, max_iter=9678, selection=random, tol=0.00950251256281407, warm_start=True;, score=0.748 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.3597194388777555, copy_X=False, l1_ratio=0.24242424242424243, max_iter=9678, selection=random, tol=0.00950251256281407, warm_start=True;, score=0.682 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.3597194388777555, copy_X=False, l1_ratio=0.24242424242424243, max_iter=9678, selection=random, tol=0.00950251256281407, warm_start=True;, score=0.676 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.3507014028056112, copy_X=True, l1_ratio=0.3080808080808081, max_iter=6502, selection=random, tol=0.003623115577889446, warm_start=False;, score=0.724 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.3507014028056112, copy_X=True, l1_ratio=0.3080808080808081, max_iter=6502, selection=random, tol=0.003623115577889446, warm_start=False;, score=0.727 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.3507014028056112, copy_X=True, l1_ratio=0.3080808080808081, max_iter=6502, selection=random, tol=0.003623115577889446, warm_start=False;, score=0.766 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.3507014028056112, copy_X=True, l1_ratio=0.3080808080808081, max_iter=6502, selection=random, tol=0.003623115577889446, warm_start=False;, score=0.700 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.3507014028056112, copy_X=True, l1_ratio=0.3080808080808081, max_iter=6502, selection=random, tol=0.003623115577889446, warm_start=False;, score=0.691 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.11122244488977955, copy_X=False, l1_ratio=0.3282828282828283, max_iter=9276, selection=cyclic, tol=0.007693467336683416, warm_start=False;, score=0.825 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.11122244488977955, copy_X=False, l1_ratio=0.3282828282828283, max_iter=9276, selection=cyclic, tol=0.007693467336683416, warm_start=False;, score=0.836 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.11122244488977955, copy_X=False, l1_ratio=0.3282828282828283, max_iter=9276, selection=cyclic, tol=0.007693467336683416, warm_start=False;, score=0.876 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.11122244488977955, copy_X=False, l1_ratio=0.3282828282828283, max_iter=9276, selection=cyclic, tol=0.007693467336683416, warm_start=False;, score=0.816 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.11122244488977955, copy_X=False, l1_ratio=0.3282828282828283, max_iter=9276, selection=cyclic, tol=0.007693467336683416, warm_start=False;, score=0.789 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.2915831663326653, copy_X=False, l1_ratio=0.20202020202020204, max_iter=8512, selection=random, tol=0.00814572864321608, warm_start=True;, score=0.729 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.2915831663326653, copy_X=False, l1_ratio=0.20202020202020204, max_iter=8512, selection=random, tol=0.00814572864321608, warm_start=True;, score=0.733 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.2915831663326653, copy_X=False, l1_ratio=0.20202020202020204, max_iter=8512, selection=random, tol=0.00814572864321608, warm_start=True;, score=0.772 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.2915831663326653, copy_X=False, l1_ratio=0.20202020202020204, max_iter=8512, selection=random, tol=0.00814572864321608, warm_start=True;, score=0.706 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.2915831663326653, copy_X=False, l1_ratio=0.20202020202020204, max_iter=8512, selection=random, tol=0.00814572864321608, warm_start=True;, score=0.696 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.18637274549098196, copy_X=False, l1_ratio=0.20202020202020204, max_iter=10000, selection=random, tol=0.00493467336683417, warm_start=True;, score=0.778 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.25851703406813625, copy_X=False, l1_ratio=0.09090909090909091, max_iter=4854, selection=cyclic, tol=0.009954773869346734, warm_start=False;, score=0.695 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.2314629258517034, copy_X=False, l1_ratio=0.33333333333333337, max_iter=2804, selection=random, tol=0.0024472361809045216, warm_start=True;, score=0.775 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.2314629258517034, copy_X=False, l1_ratio=0.33333333333333337, max_iter=2804, selection=random, tol=0.0024472361809045216, warm_start=True;, score=0.781 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.2314629258517034, copy_X=False, l1_ratio=0.33333333333333337, max_iter=2804, selection=random, tol=0.0024472361809045216, warm_start=True;, score=0.821 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.2314629258517034, copy_X=False, l1_ratio=0.33333333333333337, max_iter=2804, selection=random, tol=0.0024472361809045216, warm_start=True;, score=0.756 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.2314629258517034, copy_X=False, l1_ratio=0.33333333333333337, max_iter=2804, selection=random, tol=0.0024472361809045216, warm_start=True;, score=0.739 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.44689378757515025, copy_X=True, l1_ratio=0.48484848484848486, max_iter=3165, selection=random, tol=0.004979899497487436, warm_start=True;, score=0.731 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.44689378757515025, copy_X=True, l1_ratio=0.48484848484848486, max_iter=3165, selection=random, tol=0.004979899497487436, warm_start=True;, score=0.734 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.44689378757515025, copy_X=True, l1_ratio=0.48484848484848486, max_iter=3165, selection=random, tol=0.004979899497487436, warm_start=True;, score=0.773 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.44689378757515025, copy_X=True, l1_ratio=0.48484848484848486, max_iter=3165, selection=random, tol=0.004979899497487436, warm_start=True;, score=0.707 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.44689378757515025, copy_X=True, l1_ratio=0.48484848484848486, max_iter=3165, selection=random, tol=0.004979899497487436, warm_start=True;, score=0.697 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.47995991983967934, copy_X=True, l1_ratio=0.21717171717171718, max_iter=5015, selection=cyclic, tol=0.007557788944723618, warm_start=False;, score=0.656 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.47995991983967934, copy_X=True, l1_ratio=0.21717171717171718, max_iter=5015, selection=cyclic, tol=0.007557788944723618, warm_start=False;, score=0.658 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.47995991983967934, copy_X=True, l1_ratio=0.21717171717171718, max_iter=5015, selection=cyclic, tol=0.007557788944723618, warm_start=False;, score=0.693 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.47995991983967934, copy_X=True, l1_ratio=0.21717171717171718, max_iter=5015, selection=cyclic, tol=0.007557788944723618, warm_start=False;, score=0.628 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.4789579158316633, copy_X=True, l1_ratio=0.2575757575757576, max_iter=4291, selection=random, tol=0.002130653266331658, warm_start=False;, score=0.637 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.18537074148296592, copy_X=False, l1_ratio=0.44949494949494956, max_iter=5939, selection=cyclic, tol=0.005839195979899497, warm_start=False;, score=0.808 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1623246492985972, copy_X=True, l1_ratio=0.12626262626262627, max_iter=5497, selection=cyclic, tol=0.0023115577889447226, warm_start=False;, score=0.829 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1623246492985972, copy_X=True, l1_ratio=0.12626262626262627, max_iter=5497, selection=cyclic, tol=0.0023115577889447226, warm_start=False;, score=0.765 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1623246492985972, copy_X=True, l1_ratio=0.12626262626262627, max_iter=5497, selection=cyclic, tol=0.0023115577889447226, warm_start=False;, score=0.746 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.21042084168336672, copy_X=True, l1_ratio=0.4141414141414142, max_iter=7105, selection=cyclic, tol=0.009231155778894473, warm_start=False;, score=0.794 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.21042084168336672, copy_X=True, l1_ratio=0.4141414141414142, max_iter=7105, selection=cyclic, tol=0.009231155778894473, warm_start=False;, score=0.801 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.21042084168336672, copy_X=True, l1_ratio=0.4141414141414142, max_iter=7105, selection=cyclic, tol=0.009231155778894473, warm_start=False;, score=0.842 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.21042084168336672, copy_X=True, l1_ratio=0.4141414141414142, max_iter=7105, selection=cyclic, tol=0.009231155778894473, warm_start=False;, score=0.778 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.21042084168336672, copy_X=True, l1_ratio=0.4141414141414142, max_iter=7105, selection=cyclic, tol=0.009231155778894473, warm_start=False;, score=0.757 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.13827655310621242, copy_X=True, l1_ratio=0.42424242424242425, max_iter=2844, selection=cyclic, tol=0.00864321608040201, warm_start=True;, score=0.822 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.13827655310621242, copy_X=True, l1_ratio=0.42424242424242425, max_iter=2844, selection=cyclic, tol=0.00864321608040201, warm_start=True;, score=0.833 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.13827655310621242, copy_X=True, l1_ratio=0.42424242424242425, max_iter=2844, selection=cyclic, tol=0.00864321608040201, warm_start=True;, score=0.872 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.13827655310621242, copy_X=True, l1_ratio=0.42424242424242425, max_iter=2844, selection=cyclic, tol=0.00864321608040201, warm_start=True;, score=0.812 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.13827655310621242, copy_X=True, l1_ratio=0.42424242424242425, max_iter=2844, selection=cyclic, tol=0.00864321608040201, warm_start=True;, score=0.786 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.3817635270541082, copy_X=True, l1_ratio=0.48989898989898994, max_iter=2000, selection=cyclic, tol=0.006743718592964824, warm_start=False;, score=0.751 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.3817635270541082, copy_X=True, l1_ratio=0.48989898989898994, max_iter=2000, selection=cyclic, tol=0.006743718592964824, warm_start=False;, score=0.755 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.3817635270541082, copy_X=True, l1_ratio=0.48989898989898994, max_iter=2000, selection=cyclic, tol=0.006743718592964824, warm_start=False;, score=0.795 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.0781563126252505, copy_X=False, l1_ratio=0.25252525252525254, max_iter=5859, selection=cyclic, tol=0.0037135678391959793, warm_start=False;, score=0.849 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.0781563126252505, copy_X=False, l1_ratio=0.25252525252525254, max_iter=5859, selection=cyclic, tol=0.0037135678391959793, warm_start=False;, score=0.887 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.0781563126252505, copy_X=False, l1_ratio=0.25252525252525254, max_iter=5859, selection=cyclic, tol=0.0037135678391959793, warm_start=False;, score=0.830 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.0781563126252505, copy_X=False, l1_ratio=0.25252525252525254, max_iter=5859, selection=cyclic, tol=0.0037135678391959793, warm_start=False;, score=0.802 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.2635270541082164, copy_X=False, l1_ratio=0.27272727272727276, max_iter=5376, selection=cyclic, tol=0.008010050251256281, warm_start=True;, score=0.753 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.2635270541082164, copy_X=False, l1_ratio=0.27272727272727276, max_iter=5376, selection=cyclic, tol=0.008010050251256281, warm_start=True;, score=0.757 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.2635270541082164, copy_X=False, l1_ratio=0.27272727272727276, max_iter=5376, selection=cyclic, tol=0.008010050251256281, warm_start=True;, score=0.797 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.2635270541082164, copy_X=False, l1_ratio=0.27272727272727276, max_iter=5376, selection=cyclic, tol=0.008010050251256281, warm_start=True;, score=0.731 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.2635270541082164, copy_X=False, l1_ratio=0.27272727272727276, max_iter=5376, selection=cyclic, tol=0.008010050251256281, warm_start=True;, score=0.718 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.4849699398797595, copy_X=True, l1_ratio=0.12626262626262627, max_iter=6703, selection=random, tol=0.006879396984924622, warm_start=False;, score=0.634 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.4849699398797595, copy_X=True, l1_ratio=0.12626262626262627, max_iter=6703, selection=random, tol=0.006879396984924622, warm_start=False;, score=0.636 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.4849699398797595, copy_X=True, l1_ratio=0.12626262626262627, max_iter=6703, selection=random, tol=0.006879396984924622, warm_start=False;, score=0.669 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.4849699398797595, copy_X=True, l1_ratio=0.12626262626262627, max_iter=6703, selection=random, tol=0.006879396984924622, warm_start=False;, score=0.605 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.4849699398797595, copy_X=True, l1_ratio=0.12626262626262627, max_iter=6703, selection=random, tol=0.006879396984924622, warm_start=False;, score=0.608 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.439879759519038, copy_X=False, l1_ratio=0.196969696969697, max_iter=5457, selection=random, tol=0.006472361809045226, warm_start=True;, score=0.666 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.439879759519038, copy_X=False, l1_ratio=0.196969696969697, max_iter=5457, selection=random, tol=0.006472361809045226, warm_start=True;, score=0.669 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.374749498997996, copy_X=True, l1_ratio=0.494949494949495, max_iter=3608, selection=random, tol=0.0038040201005025117, warm_start=True;, score=0.754 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.374749498997996, copy_X=True, l1_ratio=0.494949494949495, max_iter=3608, selection=random, tol=0.0038040201005025117, warm_start=True;, score=0.759 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.374749498997996, copy_X=True, l1_ratio=0.494949494949495, max_iter=3608, selection=random, tol=0.0038040201005025117, warm_start=True;, score=0.799 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.374749498997996, copy_X=True, l1_ratio=0.494949494949495, max_iter=3608, selection=random, tol=0.0038040201005025117, warm_start=True;, score=0.733 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.374749498997996, copy_X=True, l1_ratio=0.494949494949495, max_iter=3608, selection=random, tol=0.0038040201005025117, warm_start=True;, score=0.719 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.0811623246492986, copy_X=True, l1_ratio=0.33333333333333337, max_iter=2884, selection=random, tol=0.0032613065326633156, warm_start=True;, score=0.838 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.0811623246492986, copy_X=True, l1_ratio=0.33333333333333337, max_iter=2884, selection=random, tol=0.0032613065326633156, warm_start=True;, score=0.852 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.0811623246492986, copy_X=True, l1_ratio=0.33333333333333337, max_iter=2884, selection=random, tol=0.0032613065326633156, warm_start=True;, score=0.890 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.18637274549098196, copy_X=False, l1_ratio=0.20202020202020204, max_iter=10000, selection=random, tol=0.00493467336683417, warm_start=True;, score=0.742 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.4278557114228457, copy_X=True, l1_ratio=0.11111111111111112, max_iter=5979, selection=random, tol=0.0027638190954773854, warm_start=False;, score=0.653 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.4278557114228457, copy_X=True, l1_ratio=0.11111111111111112, max_iter=5979, selection=random, tol=0.0027638190954773854, warm_start=False;, score=0.656 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.4278557114228457, copy_X=True, l1_ratio=0.11111111111111112, max_iter=5979, selection=random, tol=0.0027638190954773854, warm_start=False;, score=0.690 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.4278557114228457, copy_X=True, l1_ratio=0.11111111111111112, max_iter=5979, selection=random, tol=0.0027638190954773854, warm_start=False;, score=0.626 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.4278557114228457, copy_X=True, l1_ratio=0.11111111111111112, max_iter=5979, selection=random, tol=0.0027638190954773854, warm_start=False;, score=0.627 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.19138276553106212, copy_X=True, l1_ratio=0.2828282828282829, max_iter=3889, selection=cyclic, tol=0.0035778894472361803, warm_start=False;, score=0.786 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.19138276553106212, copy_X=True, l1_ratio=0.2828282828282829, max_iter=3889, selection=cyclic, tol=0.0035778894472361803, warm_start=False;, score=0.792 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.19138276553106212, copy_X=True, l1_ratio=0.2828282828282829, max_iter=3889, selection=cyclic, tol=0.0035778894472361803, warm_start=False;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.19138276553106212, copy_X=True, l1_ratio=0.2828282828282829, max_iter=3889, selection=cyclic, tol=0.0035778894472361803, warm_start=False;, score=0.768 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.19138276553106212, copy_X=True, l1_ratio=0.2828282828282829, max_iter=3889, selection=cyclic, tol=0.0035778894472361803, warm_start=False;, score=0.749 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1623246492985972, copy_X=True, l1_ratio=0.12626262626262627, max_iter=5497, selection=cyclic, tol=0.0023115577889447226, warm_start=False;, score=0.783 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1623246492985972, copy_X=True, l1_ratio=0.12626262626262627, max_iter=5497, selection=cyclic, tol=0.0023115577889447226, warm_start=False;, score=0.789 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.3386773547094188, copy_X=True, l1_ratio=0.3434343434343435, max_iter=3005, selection=random, tol=0.002537688442211054, warm_start=False;, score=0.735 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.3386773547094188, copy_X=True, l1_ratio=0.3434343434343435, max_iter=3005, selection=random, tol=0.002537688442211054, warm_start=False;, score=0.739 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.3386773547094188, copy_X=True, l1_ratio=0.3434343434343435, max_iter=3005, selection=random, tol=0.002537688442211054, warm_start=False;, score=0.778 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.3386773547094188, copy_X=True, l1_ratio=0.3434343434343435, max_iter=3005, selection=random, tol=0.002537688442211054, warm_start=False;, score=0.712 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.3386773547094188, copy_X=True, l1_ratio=0.3434343434343435, max_iter=3005, selection=random, tol=0.002537688442211054, warm_start=False;, score=0.701 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.12925851703406813, copy_X=True, l1_ratio=0.005050505050505051, max_iter=4130, selection=cyclic, tol=0.009366834170854271, warm_start=False;, score=0.791 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.12925851703406813, copy_X=True, l1_ratio=0.005050505050505051, max_iter=4130, selection=cyclic, tol=0.009366834170854271, warm_start=False;, score=0.798 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.12925851703406813, copy_X=True, l1_ratio=0.005050505050505051, max_iter=4130, selection=cyclic, tol=0.009366834170854271, warm_start=False;, score=0.838 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.12925851703406813, copy_X=True, l1_ratio=0.005050505050505051, max_iter=4130, selection=cyclic, tol=0.009366834170854271, warm_start=False;, score=0.774 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.12925851703406813, copy_X=True, l1_ratio=0.005050505050505051, max_iter=4130, selection=cyclic, tol=0.009366834170854271, warm_start=False;, score=0.754 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.2064128256513026, copy_X=False, l1_ratio=0.15151515151515152, max_iter=8391, selection=cyclic, tol=0.006788944723618091, warm_start=True;, score=0.763 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.2064128256513026, copy_X=False, l1_ratio=0.15151515151515152, max_iter=8391, selection=cyclic, tol=0.006788944723618091, warm_start=True;, score=0.767 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.2064128256513026, copy_X=False, l1_ratio=0.15151515151515152, max_iter=8391, selection=cyclic, tol=0.006788944723618091, warm_start=True;, score=0.808 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.2064128256513026, copy_X=False, l1_ratio=0.15151515151515152, max_iter=8391, selection=cyclic, tol=0.006788944723618091, warm_start=True;, score=0.742 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.2064128256513026, copy_X=False, l1_ratio=0.15151515151515152, max_iter=8391, selection=cyclic, tol=0.006788944723618091, warm_start=True;, score=0.727 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.0781563126252505, copy_X=False, l1_ratio=0.25252525252525254, max_iter=5859, selection=cyclic, tol=0.0037135678391959793, warm_start=False;, score=0.835 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.4428857715430861, copy_X=True, l1_ratio=0.04040404040404041, max_iter=9236, selection=cyclic, tol=0.0098643216080402, warm_start=False;, score=0.608 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.4048096192384769, copy_X=False, l1_ratio=0.04040404040404041, max_iter=6703, selection=random, tol=0.003894472361809044, warm_start=True;, score=0.650 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.4048096192384769, copy_X=False, l1_ratio=0.04040404040404041, max_iter=6703, selection=random, tol=0.003894472361809044, warm_start=True;, score=0.652 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.4048096192384769, copy_X=False, l1_ratio=0.04040404040404041, max_iter=6703, selection=random, tol=0.003894472361809044, warm_start=True;, score=0.686 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.4048096192384769, copy_X=False, l1_ratio=0.04040404040404041, max_iter=6703, selection=random, tol=0.003894472361809044, warm_start=True;, score=0.622 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.4048096192384769, copy_X=False, l1_ratio=0.04040404040404041, max_iter=6703, selection=random, tol=0.003894472361809044, warm_start=True;, score=0.623 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.2955911823647294, copy_X=True, l1_ratio=0.12121212121212122, max_iter=7829, selection=cyclic, tol=0.005251256281407034, warm_start=True;, score=0.714 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.2955911823647294, copy_X=True, l1_ratio=0.12121212121212122, max_iter=7829, selection=cyclic, tol=0.005251256281407034, warm_start=True;, score=0.718 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.2955911823647294, copy_X=True, l1_ratio=0.12121212121212122, max_iter=7829, selection=cyclic, tol=0.005251256281407034, warm_start=True;, score=0.756 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.2955911823647294, copy_X=True, l1_ratio=0.12121212121212122, max_iter=7829, selection=cyclic, tol=0.005251256281407034, warm_start=True;, score=0.690 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.2955911823647294, copy_X=True, l1_ratio=0.12121212121212122, max_iter=7829, selection=cyclic, tol=0.005251256281407034, warm_start=True;, score=0.682 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.09519038076152304, copy_X=True, l1_ratio=0.4747474747474748, max_iter=9557, selection=cyclic, tol=0.0098643216080402, warm_start=False;, score=0.841 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.09519038076152304, copy_X=True, l1_ratio=0.4747474747474748, max_iter=9557, selection=cyclic, tol=0.0098643216080402, warm_start=False;, score=0.855 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.991e+11, tolerance: 2.646e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.822e+11, tolerance: 2.616e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END alpha=0.29058116232464926, copy_X=False, l1_ratio=0.11616161616161617, max_iter=5537, selection=cyclic, tol=0.003216080402010049, warm_start=True;, score=0.719 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.29058116232464926, copy_X=False, l1_ratio=0.11616161616161617, max_iter=5537, selection=cyclic, tol=0.003216080402010049, warm_start=True;, score=0.758 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.29058116232464926, copy_X=False, l1_ratio=0.11616161616161617, max_iter=5537, selection=cyclic, tol=0.003216080402010049, warm_start=True;, score=0.691 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.29058116232464926, copy_X=False, l1_ratio=0.11616161616161617, max_iter=5537, selection=cyclic, tol=0.003216080402010049, warm_start=True;, score=0.684 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.002004008016032064, copy_X=True, l1_ratio=0.09595959595959597, max_iter=7909, selection=cyclic, tol=0.004391959798994974, warm_start=True;, score=0.878 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.002004008016032064, copy_X=True, l1_ratio=0.09595959595959597, max_iter=7909, selection=cyclic, tol=0.004391959798994974, warm_start=True;, score=0.896 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.002004008016032064, copy_X=True, l1_ratio=0.09595959595959597, max_iter=7909, selection=cyclic, tol=0.004391959798994974, warm_start=True;, score=0.928 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.35571142284569135, copy_X=False, l1_ratio=0.32323232323232326, max_iter=4452, selection=cyclic, tol=0.0022211055276381893, warm_start=False;, score=0.728 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.35571142284569135, copy_X=False, l1_ratio=0.32323232323232326, max_iter=4452, selection=cyclic, tol=0.0022211055276381893, warm_start=False;, score=0.767 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.35571142284569135, copy_X=False, l1_ratio=0.32323232323232326, max_iter=4452, selection=cyclic, tol=0.0022211055276381893, warm_start=False;, score=0.701 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.35571142284569135, copy_X=False, l1_ratio=0.32323232323232326, max_iter=4452, selection=cyclic, tol=0.0022211055276381893, warm_start=False;, score=0.692 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1222444889779559, copy_X=False, l1_ratio=0.30303030303030304, max_iter=8110, selection=cyclic, tol=0.003623115577889446, warm_start=False;, score=0.818 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1222444889779559, copy_X=False, l1_ratio=0.30303030303030304, max_iter=8110, selection=cyclic, tol=0.003623115577889446, warm_start=False;, score=0.828 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1222444889779559, copy_X=False, l1_ratio=0.30303030303030304, max_iter=8110, selection=cyclic, tol=0.003623115577889446, warm_start=False;, score=0.868 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1222444889779559, copy_X=False, l1_ratio=0.30303030303030304, max_iter=8110, selection=cyclic, tol=0.003623115577889446, warm_start=False;, score=0.807 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1222444889779559, copy_X=False, l1_ratio=0.30303030303030304, max_iter=8110, selection=cyclic, tol=0.003623115577889446, warm_start=False;, score=0.782 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.38276553106212424, copy_X=False, l1_ratio=0.025252525252525256, max_iter=3125, selection=cyclic, tol=0.008371859296482412, warm_start=True;, score=0.657 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.38276553106212424, copy_X=False, l1_ratio=0.025252525252525256, max_iter=3125, selection=cyclic, tol=0.008371859296482412, warm_start=True;, score=0.660 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.38276553106212424, copy_X=False, l1_ratio=0.025252525252525256, max_iter=3125, selection=cyclic, tol=0.008371859296482412, warm_start=True;, score=0.694 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.38276553106212424, copy_X=False, l1_ratio=0.025252525252525256, max_iter=3125, selection=cyclic, tol=0.008371859296482412, warm_start=True;, score=0.629 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.38276553106212424, copy_X=False, l1_ratio=0.025252525252525256, max_iter=3125, selection=cyclic, tol=0.008371859296482412, warm_start=True;, score=0.630 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.4629258517034068, copy_X=False, l1_ratio=0.47979797979797983, max_iter=5899, selection=cyclic, tol=0.004708542713567838, warm_start=False;, score=0.725 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.4629258517034068, copy_X=False, l1_ratio=0.47979797979797983, max_iter=5899, selection=cyclic, tol=0.004708542713567838, warm_start=False;, score=0.728 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.45290581162324645, copy_X=True, l1_ratio=0.42424242424242425, max_iter=7708, selection=random, tol=0.006246231155778894, warm_start=True;, score=0.714 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.45290581162324645, copy_X=True, l1_ratio=0.42424242424242425, max_iter=7708, selection=random, tol=0.006246231155778894, warm_start=True;, score=0.717 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.4929859719438877, copy_X=True, l1_ratio=0.030303030303030304, max_iter=4814, selection=random, tol=0.005206030150753768, warm_start=True;, score=0.644 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.4929859719438877, copy_X=True, l1_ratio=0.030303030303030304, max_iter=4814, selection=random, tol=0.005206030150753768, warm_start=True;, score=0.581 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.439879759519038, copy_X=False, l1_ratio=0.025252525252525256, max_iter=3125, selection=random, tol=0.005567839195979899, warm_start=False;, score=0.631 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.439879759519038, copy_X=False, l1_ratio=0.025252525252525256, max_iter=3125, selection=random, tol=0.005567839195979899, warm_start=False;, score=0.634 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.34368737474949895, copy_X=False, l1_ratio=0.26262626262626265, max_iter=8834, selection=random, tol=0.0023567839195979884, warm_start=True;, score=0.693 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.34368737474949895, copy_X=False, l1_ratio=0.26262626262626265, max_iter=8834, selection=random, tol=0.0023567839195979884, warm_start=True;, score=0.685 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.05110220440881763, copy_X=True, l1_ratio=0.398989898989899, max_iter=2924, selection=cyclic, tol=0.009954773869346734, warm_start=True;, score=0.826 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.13026052104208416, copy_X=True, l1_ratio=0.42424242424242425, max_iter=3567, selection=random, tol=0.008597989949748744, warm_start=True;, score=0.825 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.24849699398797592, copy_X=True, l1_ratio=0.15656565656565657, max_iter=5216, selection=cyclic, tol=0.0012713567839195972, warm_start=True;, score=0.786 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.24849699398797592, copy_X=True, l1_ratio=0.15656565656565657, max_iter=5216, selection=cyclic, tol=0.0012713567839195972, warm_start=True;, score=0.720 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1653306613226453, copy_X=False, l1_ratio=0.393939393939394, max_iter=3728, selection=random, tol=0.0098643216080402, warm_start=True;, score=0.809 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1653306613226453, copy_X=False, l1_ratio=0.393939393939394, max_iter=3728, selection=random, tol=0.0098643216080402, warm_start=True;, score=0.817 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.30260521042084165, copy_X=False, l1_ratio=0.30303030303030304, max_iter=8994, selection=random, tol=0.00864321608040201, warm_start=False;, score=0.746 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.30260521042084165, copy_X=False, l1_ratio=0.30303030303030304, max_iter=8994, selection=random, tol=0.00864321608040201, warm_start=False;, score=0.785 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.27354709418837675, copy_X=False, l1_ratio=0.36363636363636365, max_iter=5778, selection=cyclic, tol=0.0021758793969849227, warm_start=True;, score=0.727 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.09519038076152304, copy_X=True, l1_ratio=0.38383838383838387, max_iter=7708, selection=cyclic, tol=0.003894472361809044, warm_start=True;, score=0.835 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.283567134268537, copy_X=True, l1_ratio=0.31818181818181823, max_iter=8351, selection=random, tol=0.004030150753768843, warm_start=False;, score=0.752 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.47995991983967934, copy_X=True, l1_ratio=0.21717171717171718, max_iter=5015, selection=cyclic, tol=0.007557788944723618, warm_start=False;, score=0.629 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.002004008016032064, copy_X=True, l1_ratio=0.09595959595959597, max_iter=7909, selection=cyclic, tol=0.004391959798994974, warm_start=True;, score=0.891 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.002004008016032064, copy_X=True, l1_ratio=0.09595959595959597, max_iter=7909, selection=cyclic, tol=0.004391959798994974, warm_start=True;, score=0.872 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.3256513026052104, copy_X=True, l1_ratio=0.26262626262626265, max_iter=7507, selection=random, tol=0.008010050251256281, warm_start=True;, score=0.725 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.3256513026052104, copy_X=True, l1_ratio=0.26262626262626265, max_iter=7507, selection=random, tol=0.008010050251256281, warm_start=True;, score=0.729 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.3256513026052104, copy_X=True, l1_ratio=0.26262626262626265, max_iter=7507, selection=random, tol=0.008010050251256281, warm_start=True;, score=0.767 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.3256513026052104, copy_X=True, l1_ratio=0.26262626262626265, max_iter=7507, selection=random, tol=0.008010050251256281, warm_start=True;, score=0.701 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.3256513026052104, copy_X=True, l1_ratio=0.26262626262626265, max_iter=7507, selection=random, tol=0.008010050251256281, warm_start=True;, score=0.692 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.45591182364729455, copy_X=False, l1_ratio=0.15151515151515152, max_iter=7266, selection=cyclic, tol=0.003487437185929647, warm_start=True;, score=0.650 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.45591182364729455, copy_X=False, l1_ratio=0.15151515151515152, max_iter=7266, selection=cyclic, tol=0.003487437185929647, warm_start=True;, score=0.653 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.45591182364729455, copy_X=False, l1_ratio=0.15151515151515152, max_iter=7266, selection=cyclic, tol=0.003487437185929647, warm_start=True;, score=0.687 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.45591182364729455, copy_X=False, l1_ratio=0.15151515151515152, max_iter=7266, selection=cyclic, tol=0.003487437185929647, warm_start=True;, score=0.623 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.45591182364729455, copy_X=False, l1_ratio=0.15151515151515152, max_iter=7266, selection=cyclic, tol=0.003487437185929647, warm_start=True;, score=0.624 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.4428857715430861, copy_X=True, l1_ratio=0.04040404040404041, max_iter=9236, selection=cyclic, tol=0.0098643216080402, warm_start=False;, score=0.633 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.4428857715430861, copy_X=True, l1_ratio=0.04040404040404041, max_iter=9236, selection=cyclic, tol=0.0098643216080402, warm_start=False;, score=0.636 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.4428857715430861, copy_X=True, l1_ratio=0.04040404040404041, max_iter=9236, selection=cyclic, tol=0.0098643216080402, warm_start=False;, score=0.668 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.4428857715430861, copy_X=True, l1_ratio=0.04040404040404041, max_iter=9236, selection=cyclic, tol=0.0098643216080402, warm_start=False;, score=0.605 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.4629258517034068, copy_X=False, l1_ratio=0.47979797979797983, max_iter=5899, selection=cyclic, tol=0.004708542713567838, warm_start=False;, score=0.692 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1472945891783567, copy_X=True, l1_ratio=0.020202020202020204, max_iter=7547, selection=cyclic, tol=0.00493467336683417, warm_start=True;, score=0.781 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.45290581162324645, copy_X=True, l1_ratio=0.42424242424242425, max_iter=7708, selection=random, tol=0.006246231155778894, warm_start=True;, score=0.755 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.45290581162324645, copy_X=True, l1_ratio=0.42424242424242425, max_iter=7708, selection=random, tol=0.006246231155778894, warm_start=True;, score=0.689 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.35871743486973945, copy_X=True, l1_ratio=0.2070707070707071, max_iter=3286, selection=cyclic, tol=0.0028542713567839186, warm_start=False;, score=0.704 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.35871743486973945, copy_X=True, l1_ratio=0.2070707070707071, max_iter=3286, selection=cyclic, tol=0.0028542713567839186, warm_start=False;, score=0.742 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.4929859719438877, copy_X=True, l1_ratio=0.030303030303030304, max_iter=4814, selection=random, tol=0.005206030150753768, warm_start=True;, score=0.587 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.3476953907815631, copy_X=False, l1_ratio=0.297979797979798, max_iter=6984, selection=cyclic, tol=0.009050251256281406, warm_start=False;, score=0.723 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.439879759519038, copy_X=False, l1_ratio=0.025252525252525256, max_iter=3125, selection=random, tol=0.005567839195979899, warm_start=False;, score=0.667 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.439879759519038, copy_X=False, l1_ratio=0.025252525252525256, max_iter=3125, selection=random, tol=0.005567839195979899, warm_start=False;, score=0.603 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.34368737474949895, copy_X=False, l1_ratio=0.26262626262626265, max_iter=8834, selection=random, tol=0.0023567839195979884, warm_start=True;, score=0.721 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.34368737474949895, copy_X=False, l1_ratio=0.26262626262626265, max_iter=8834, selection=random, tol=0.0023567839195979884, warm_start=True;, score=0.760 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.13026052104208416, copy_X=True, l1_ratio=0.42424242424242425, max_iter=3567, selection=random, tol=0.008597989949748744, warm_start=True;, score=0.836 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.13026052104208416, copy_X=True, l1_ratio=0.42424242424242425, max_iter=3567, selection=random, tol=0.008597989949748744, warm_start=True;, score=0.875 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.09619238476953906, copy_X=False, l1_ratio=0.36868686868686873, max_iter=8231, selection=random, tol=0.003758793969849245, warm_start=True;, score=0.847 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.09619238476953906, copy_X=False, l1_ratio=0.36868686868686873, max_iter=8231, selection=random, tol=0.003758793969849245, warm_start=True;, score=0.886 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.27354709418837675, copy_X=False, l1_ratio=0.36363636363636365, max_iter=5778, selection=cyclic, tol=0.0021758793969849227, warm_start=True;, score=0.763 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.27354709418837675, copy_X=False, l1_ratio=0.36363636363636365, max_iter=5778, selection=cyclic, tol=0.0021758793969849227, warm_start=True;, score=0.768 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.09519038076152304, copy_X=True, l1_ratio=0.38383838383838387, max_iter=7708, selection=cyclic, tol=0.003894472361809044, warm_start=True;, score=0.830 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.09519038076152304, copy_X=True, l1_ratio=0.38383838383838387, max_iter=7708, selection=cyclic, tol=0.003894472361809044, warm_start=True;, score=0.801 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.19338677354709416, copy_X=True, l1_ratio=0.18181818181818182, max_iter=9195, selection=cyclic, tol=0.009412060301507538, warm_start=False;, score=0.778 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.19338677354709416, copy_X=True, l1_ratio=0.18181818181818182, max_iter=9195, selection=cyclic, tol=0.009412060301507538, warm_start=False;, score=0.819 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.027054108216432865, copy_X=True, l1_ratio=0.07070707070707072, max_iter=8874, selection=random, tol=0.005613065326633165, warm_start=True;, score=0.832 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.3887775551102204, copy_X=False, l1_ratio=0.16161616161616163, max_iter=6502, selection=cyclic, tol=0.002085427135678391, warm_start=False;, score=0.680 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.33266533066132264, copy_X=True, l1_ratio=0.2373737373737374, max_iter=7708, selection=random, tol=0.006381909547738693, warm_start=True;, score=0.759 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.09519038076152304, copy_X=True, l1_ratio=0.4747474747474748, max_iter=9557, selection=cyclic, tol=0.0098643216080402, warm_start=False;, score=0.893 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.09519038076152304, copy_X=True, l1_ratio=0.4747474747474748, max_iter=9557, selection=cyclic, tol=0.0098643216080402, warm_start=False;, score=0.837 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.09519038076152304, copy_X=True, l1_ratio=0.4747474747474748, max_iter=9557, selection=cyclic, tol=0.0098643216080402, warm_start=False;, score=0.808 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.4629258517034068, copy_X=False, l1_ratio=0.47979797979797983, max_iter=5899, selection=cyclic, tol=0.004708542713567838, warm_start=False;, score=0.767 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.4629258517034068, copy_X=False, l1_ratio=0.47979797979797983, max_iter=5899, selection=cyclic, tol=0.004708542713567838, warm_start=False;, score=0.701 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1472945891783567, copy_X=True, l1_ratio=0.020202020202020204, max_iter=7547, selection=cyclic, tol=0.00493467336683417, warm_start=True;, score=0.787 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1472945891783567, copy_X=True, l1_ratio=0.020202020202020204, max_iter=7547, selection=cyclic, tol=0.00493467336683417, warm_start=True;, score=0.828 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.45290581162324645, copy_X=True, l1_ratio=0.42424242424242425, max_iter=7708, selection=random, tol=0.006246231155778894, warm_start=True;, score=0.682 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.35871743486973945, copy_X=True, l1_ratio=0.2070707070707071, max_iter=3286, selection=cyclic, tol=0.0028542713567839186, warm_start=False;, score=0.701 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.35871743486973945, copy_X=True, l1_ratio=0.2070707070707071, max_iter=3286, selection=cyclic, tol=0.0028542713567839186, warm_start=False;, score=0.676 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.35871743486973945, copy_X=True, l1_ratio=0.2070707070707071, max_iter=3286, selection=cyclic, tol=0.0028542713567839186, warm_start=False;, score=0.670 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.3476953907815631, copy_X=False, l1_ratio=0.297979797979798, max_iter=6984, selection=cyclic, tol=0.009050251256281406, warm_start=False;, score=0.727 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.3476953907815631, copy_X=False, l1_ratio=0.297979797979798, max_iter=6984, selection=cyclic, tol=0.009050251256281406, warm_start=False;, score=0.765 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.439879759519038, copy_X=False, l1_ratio=0.025252525252525256, max_iter=3125, selection=random, tol=0.005567839195979899, warm_start=False;, score=0.606 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.34368737474949895, copy_X=False, l1_ratio=0.26262626262626265, max_iter=8834, selection=random, tol=0.0023567839195979884, warm_start=True;, score=0.718 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.05110220440881763, copy_X=True, l1_ratio=0.398989898989899, max_iter=2924, selection=cyclic, tol=0.009954773869346734, warm_start=True;, score=0.907 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.05110220440881763, copy_X=True, l1_ratio=0.398989898989899, max_iter=2924, selection=cyclic, tol=0.009954773869346734, warm_start=True;, score=0.857 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.24849699398797592, copy_X=True, l1_ratio=0.15656565656565657, max_iter=5216, selection=cyclic, tol=0.0012713567839195972, warm_start=True;, score=0.742 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.24849699398797592, copy_X=True, l1_ratio=0.15656565656565657, max_iter=5216, selection=cyclic, tol=0.0012713567839195972, warm_start=True;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.09619238476953906, copy_X=False, l1_ratio=0.36868686868686873, max_iter=8231, selection=random, tol=0.003758793969849245, warm_start=True;, score=0.828 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.09619238476953906, copy_X=False, l1_ratio=0.36868686868686873, max_iter=8231, selection=random, tol=0.003758793969849245, warm_start=True;, score=0.800 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1653306613226453, copy_X=False, l1_ratio=0.393939393939394, max_iter=3728, selection=random, tol=0.0098643216080402, warm_start=True;, score=0.772 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.30260521042084165, copy_X=False, l1_ratio=0.30303030303030304, max_iter=8994, selection=random, tol=0.00864321608040201, warm_start=False;, score=0.742 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.27354709418837675, copy_X=False, l1_ratio=0.36363636363636365, max_iter=5778, selection=cyclic, tol=0.0021758793969849227, warm_start=True;, score=0.808 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.27354709418837675, copy_X=False, l1_ratio=0.36363636363636365, max_iter=5778, selection=cyclic, tol=0.0021758793969849227, warm_start=True;, score=0.743 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.283567134268537, copy_X=True, l1_ratio=0.31818181818181823, max_iter=8351, selection=random, tol=0.004030150753768843, warm_start=False;, score=0.717 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.19338677354709416, copy_X=True, l1_ratio=0.18181818181818182, max_iter=9195, selection=cyclic, tol=0.009412060301507538, warm_start=False;, score=0.773 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.027054108216432865, copy_X=True, l1_ratio=0.07070707070707072, max_iter=8874, selection=random, tol=0.005613065326633165, warm_start=True;, score=0.911 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.027054108216432865, copy_X=True, l1_ratio=0.07070707070707072, max_iter=8874, selection=random, tol=0.005613065326633165, warm_start=True;, score=0.863 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.33266533066132264, copy_X=True, l1_ratio=0.2373737373737374, max_iter=7708, selection=random, tol=0.006381909547738693, warm_start=True;, score=0.718 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.33266533066132264, copy_X=True, l1_ratio=0.2373737373737374, max_iter=7708, selection=random, tol=0.006381909547738693, warm_start=True;, score=0.721 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.4789579158316633, copy_X=True, l1_ratio=0.25252525252525254, max_iter=9638, selection=cyclic, tol=0.00864321608040201, warm_start=True;, score=0.637 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.4789579158316633, copy_X=True, l1_ratio=0.25252525252525254, max_iter=9638, selection=cyclic, tol=0.00864321608040201, warm_start=True;, score=0.636 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.15230460921843686, copy_X=False, l1_ratio=0.4191919191919192, max_iter=7587, selection=cyclic, tol=0.007015075376884422, warm_start=True;, score=0.826 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.15230460921843686, copy_X=False, l1_ratio=0.4191919191919192, max_iter=7587, selection=cyclic, tol=0.007015075376884422, warm_start=True;, score=0.866 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.15230460921843686, copy_X=False, l1_ratio=0.4191919191919192, max_iter=7587, selection=cyclic, tol=0.007015075376884422, warm_start=True;, score=0.804 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.15230460921843686, copy_X=False, l1_ratio=0.4191919191919192, max_iter=7587, selection=cyclic, tol=0.007015075376884422, warm_start=True;, score=0.780 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.34969939879759515, copy_X=False, l1_ratio=0.05555555555555556, max_iter=8391, selection=cyclic, tol=0.00407537688442211, warm_start=True;, score=0.678 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.34969939879759515, copy_X=False, l1_ratio=0.05555555555555556, max_iter=8391, selection=cyclic, tol=0.00407537688442211, warm_start=True;, score=0.681 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.34969939879759515, copy_X=False, l1_ratio=0.05555555555555556, max_iter=8391, selection=cyclic, tol=0.00407537688442211, warm_start=True;, score=0.649 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.0721442885771543, copy_X=True, l1_ratio=0.4595959595959596, max_iter=3969, selection=random, tol=0.004979899497487436, warm_start=True;, score=0.848 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.0721442885771543, copy_X=True, l1_ratio=0.4595959595959596, max_iter=3969, selection=random, tol=0.004979899497487436, warm_start=True;, score=0.848 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.703e+11, tolerance: 2.575e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.950e+11, tolerance: 2.692e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.939e+11, tolerance: 2.738e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.273e+11, tolerance: 7.733e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.306e+11, tolerance: 7.473e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.138e+11, tolerance: 7.389e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet() RandomCV Best Params : {'warm_start': 'False', 'tol': 0.006562814070351758, 'selection': 'cyclic', 'max_iter': 6743, 'l1_ratio': 0.14141414141414144, 'copy_X': 'True', 'alpha': 0.002004008016032064}\n",
      "ElasticNet() RandomCV Score: 0.8788561761481258\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Final score is  0.8788561761481258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.274e+11, tolerance: 7.604e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.014e+11, tolerance: 7.274e+09 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "hyperparameter_tuning(algo=\"ElasticNet()\",param_grid=random_grid,n_iter=100,cv=5,verbose=3,random_state=42,X_train=X_train.loc[:,list(selected_features)],Y_train=Y_train,X_test=X_test.loc[:,list(selected_features)],Y_test=Y_test,evaluation_metric=\"r2_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "234884e0-9b96-4d91-9dc5-705a6da4977c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "283937bb-dfb8-46d9-8b75-44f034af95bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  62 out of  62 | elapsed:    0.2s finished\n",
      "\n",
      "[2023-02-01 16:22:28] Features: 1/62 -- score: 0.6798454456419083[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  61 out of  61 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:29] Features: 2/62 -- score: 0.7560099049949636[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:29] Features: 3/62 -- score: 0.8182278859860217[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  59 out of  59 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:29] Features: 4/62 -- score: 0.842154301510728[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  58 out of  58 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:29] Features: 5/62 -- score: 0.8581759388486837[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  57 out of  57 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:29] Features: 6/62 -- score: 0.8662320496444046[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  56 out of  56 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:29] Features: 7/62 -- score: 0.8726543168011831[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  55 out of  55 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:29] Features: 8/62 -- score: 0.8767855490918721[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  54 out of  54 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:29] Features: 9/62 -- score: 0.8811787200644247[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  53 out of  53 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:29] Features: 10/62 -- score: 0.8853004895008938[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  52 out of  52 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:30] Features: 11/62 -- score: 0.888625513457532[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  51 out of  51 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:30] Features: 12/62 -- score: 0.89151850345838[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:30] Features: 13/62 -- score: 0.8940634835462289[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  49 out of  49 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:30] Features: 14/62 -- score: 0.895927947681715[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:30] Features: 15/62 -- score: 0.8967125937273938[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  47 out of  47 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:30] Features: 16/62 -- score: 0.8973305877348631[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  46 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  46 out of  46 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:30] Features: 17/62 -- score: 0.8980455925325875[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 out of  45 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:30] Features: 18/62 -- score: 0.8987291816454401[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 out of  44 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  44 out of  44 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:30] Features: 19/62 -- score: 0.8994087144312563[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  32 out of  43 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  43 out of  43 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:31] Features: 20/62 -- score: 0.899899923215392[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 out of  42 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:31] Features: 21/62 -- score: 0.9002079958166943[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  41 out of  41 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:31] Features: 22/62 -- score: 0.9004872951395168[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:31] Features: 23/62 -- score: 0.9007490977881165[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  28 out of  39 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  39 out of  39 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:31] Features: 24/62 -- score: 0.9009899693013441[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  38 out of  38 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:31] Features: 25/62 -- score: 0.9012294030115019[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 out of  37 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  37 out of  37 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:31] Features: 26/62 -- score: 0.9013959205219271[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  36 out of  36 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:31] Features: 27/62 -- score: 0.901701930729159[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  35 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  35 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:32] Features: 28/62 -- score: 0.9017700298818232[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  23 out of  34 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  34 out of  34 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:32] Features: 29/62 -- score: 0.9018142386040167[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  22 out of  33 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  33 out of  33 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:32] Features: 30/62 -- score: 0.9018142386040167[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  21 out of  32 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  32 out of  32 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:32] Features: 31/62 -- score: 0.901776627241126[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  31 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  31 out of  31 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:32] Features: 32/62 -- score: 0.9017316721065047[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    0.2s finished\n",
      "\n",
      "[2023-02-01 16:22:32] Features: 33/62 -- score: 0.9016725974638842[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  29 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  29 out of  29 | elapsed:    0.2s finished\n",
      "\n",
      "[2023-02-01 16:22:32] Features: 34/62 -- score: 0.9015919069098166[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  28 out of  28 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:33] Features: 35/62 -- score: 0.9015098356990927[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  27 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:33] Features: 36/62 -- score: 0.9014024454730027[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 out of  26 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:33] Features: 37/62 -- score: 0.9012810510574715[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  14 out of  25 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:33] Features: 38/62 -- score: 0.9011117995083584[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:33] Features: 39/62 -- score: 0.900899651571688[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  23 out of  23 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:33] Features: 40/62 -- score: 0.9006838713284283[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  22 out of  22 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:33] Features: 41/62 -- score: 0.9004241492608512[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  21 out of  21 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  21 out of  21 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:34] Features: 42/62 -- score: 0.9001582280427721[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:34] Features: 43/62 -- score: 0.8999812443115754[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  19 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:34] Features: 44/62 -- score: 0.8997259040190304[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  18 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:34] Features: 45/62 -- score: 0.8994470429290822[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  17 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  17 out of  17 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:34] Features: 46/62 -- score: 0.8991262427374584[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  14 out of  16 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  16 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:34] Features: 47/62 -- score: 0.8987850127977408[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  15 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:34] Features: 48/62 -- score: 0.89848766420647[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  14 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  14 out of  14 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:34] Features: 49/62 -- score: 0.8981389929214499[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of  13 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:34] Features: 50/62 -- score: 0.897795846294095[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  12 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:35] Features: 51/62 -- score: 0.8974005240219765[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  11 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  11 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:35] Features: 52/62 -- score: 0.8970090792697478[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:35] Features: 53/62 -- score: 0.896543609491218[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   9 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:35] Features: 54/62 -- score: 0.8960061303692409[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   8 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:35] Features: 55/62 -- score: 0.8954196209478591[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   7 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of   7 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:35] Features: 56/62 -- score: 0.8951231496320062[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:35] Features: 57/62 -- score: 0.894701198819136[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "\n",
      "[2023-02-01 16:22:35] Features: 58/62 -- score: 0.894054420311613[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    0.0s finished\n",
      "\n",
      "[2023-02-01 16:22:35] Features: 59/62 -- score: 0.8931465618872231[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:35] Features: 60/62 -- score: 0.8917517796520162[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "\n",
      "[2023-02-01 16:22:35] Features: 61/62 -- score: 0.8902506011986618[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "\n",
      "[2023-02-01 16:22:35] Features: 62/62 -- score: 0.888186562071227"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features ('LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'BsmtFinSF1', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', 'GrLivArea', 'FullBath', 'BedroomAbvGr', 'Fireplaces', 'GarageYrBlt', 'GarageCars', 'LandContour', 'Neighborhood', 'Condition1', 'MasVnrType', 'Foundation', 'BsmtQual', 'BsmtExposure', 'BsmtFinType1', 'HeatingQC', 'KitchenQual', 'Functional', 'GarageType', 'SaleType')\n",
      "Prediction using selected features using Lasso() is : 0.8768979354777238\n"
     ]
    }
   ],
   "source": [
    "selected_features=sf_selector(algo=\"Lasso()\",forward=True,floating=False,scoring=\"r2\",X_train=X_train,Y_train=Y_train,X_test=X_test,Y_test=Y_test,min_featues=3,cv=5,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "19edd94b-281f-441e-849e-dc2b4c0fecf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': [0.0, 0.001002004008016032, 0.002004008016032064, 0.0030060120240480957, 0.004008016032064128, 0.00501002004008016, 0.0060120240480961915, 0.007014028056112224, 0.008016032064128256, 0.009018036072144287, 0.01002004008016032, 0.011022044088176352, 0.012024048096192383, 0.013026052104208416, 0.014028056112224447, 0.01503006012024048, 0.01603206412825651, 0.017034068136272545, 0.018036072144288574, 0.019038076152304607, 0.02004008016032064, 0.02104208416833667, 0.022044088176352703, 0.023046092184368736, 0.024048096192384766, 0.0250501002004008, 0.026052104208416832, 0.027054108216432865, 0.028056112224448895, 0.029058116232464928, 0.03006012024048096, 0.03106212424849699, 0.03206412825651302, 0.033066132264529056, 0.03406813627254509, 0.03507014028056112, 0.03607214428857715, 0.03707414829659318, 0.038076152304609215, 0.03907815631262525, 0.04008016032064128, 0.041082164328657314, 0.04208416833667334, 0.04308617234468937, 0.044088176352705406, 0.04509018036072144, 0.04609218436873747, 0.047094188376753505, 0.04809619238476953, 0.049098196392785565, 0.0501002004008016, 0.05110220440881763, 0.052104208416833664, 0.0531062124248497, 0.05410821643286573, 0.055110220440881756, 0.05611222444889779, 0.05711422845691382, 0.058116232464929855, 0.05911823647294589, 0.06012024048096192, 0.06112224448897795, 0.06212424849699398, 0.06312625250501001, 0.06412825651302605, 0.06513026052104208, 0.06613226452905811, 0.06713426853707415, 0.06813627254509018, 0.06913827655310621, 0.07014028056112225, 0.07114228456913826, 0.0721442885771543, 0.07314629258517033, 0.07414829659318636, 0.0751503006012024, 0.07615230460921843, 0.07715430861723446, 0.0781563126252505, 0.07915831663326653, 0.08016032064128256, 0.0811623246492986, 0.08216432865731463, 0.08316633266533066, 0.08416833667334668, 0.08517034068136271, 0.08617234468937875, 0.08717434869739478, 0.08817635270541081, 0.08917835671342685, 0.09018036072144288, 0.09118236472945891, 0.09218436873747494, 0.09318637274549098, 0.09418837675350701, 0.09519038076152304, 0.09619238476953906, 0.0971943887775551, 0.09819639278557113, 0.09919839679358716, 0.1002004008016032, 0.10120240480961923, 0.10220440881763526, 0.1032064128256513, 0.10420841683366733, 0.10521042084168336, 0.1062124248496994, 0.10721442885771543, 0.10821643286573146, 0.10921843687374748, 0.11022044088176351, 0.11122244488977955, 0.11222444889779558, 0.11322645290581161, 0.11422845691382764, 0.11523046092184368, 0.11623246492985971, 0.11723446893787574, 0.11823647294589178, 0.11923847695390781, 0.12024048096192384, 0.12124248496993988, 0.1222444889779559, 0.12324649298597193, 0.12424849699398796, 0.125250501002004, 0.12625250501002003, 0.12725450901803606, 0.1282565130260521, 0.12925851703406813, 0.13026052104208416, 0.1312625250501002, 0.13226452905811623, 0.13326653306613226, 0.1342685370741483, 0.13527054108216433, 0.13627254509018036, 0.1372745490981964, 0.13827655310621242, 0.13927855711422846, 0.1402805611222445, 0.1412825651302605, 0.14228456913827653, 0.14328657314629256, 0.1442885771543086, 0.14529058116232463, 0.14629258517034066, 0.1472945891783567, 0.14829659318637273, 0.14929859719438876, 0.1503006012024048, 0.15130260521042083, 0.15230460921843686, 0.1533066132264529, 0.15430861723446893, 0.15531062124248496, 0.156312625250501, 0.15731462925851702, 0.15831663326653306, 0.1593186372745491, 0.16032064128256512, 0.16132264529058116, 0.1623246492985972, 0.16332665330661322, 0.16432865731462926, 0.1653306613226453, 0.16633266533066132, 0.16733466933867733, 0.16833667334669336, 0.1693386773547094, 0.17034068136272543, 0.17134268537074146, 0.1723446893787575, 0.17334669338677353, 0.17434869739478956, 0.1753507014028056, 0.17635270541082163, 0.17735470941883766, 0.1783567134268537, 0.17935871743486972, 0.18036072144288576, 0.1813627254509018, 0.18236472945891782, 0.18336673346693386, 0.1843687374749499, 0.18537074148296592, 0.18637274549098196, 0.187374749498998, 0.18837675350701402, 0.18937875751503006, 0.1903807615230461, 0.19138276553106212, 0.19238476953907813, 0.19338677354709416, 0.1943887775551102, 0.19539078156312623, 0.19639278557114226, 0.1973947895791583, 0.19839679358717432, 0.19939879759519036, 0.2004008016032064, 0.20140280561122242, 0.20240480961923846, 0.2034068136272545, 0.20440881763527052, 0.20541082164328656, 0.2064128256513026, 0.20741482965931862, 0.20841683366733466, 0.2094188376753507, 0.21042084168336672, 0.21142284569138275, 0.2124248496993988, 0.21342685370741482, 0.21442885771543085, 0.2154308617234469, 0.21643286573146292, 0.21743486973947895, 0.21843687374749496, 0.219438877755511, 0.22044088176352702, 0.22144288577154306, 0.2224448897795591, 0.22344689378757512, 0.22444889779559116, 0.2254509018036072, 0.22645290581162322, 0.22745490981963926, 0.2284569138276553, 0.22945891783567132, 0.23046092184368736, 0.2314629258517034, 0.23246492985971942, 0.23346693386773545, 0.2344689378757515, 0.23547094188376752, 0.23647294589178355, 0.2374749498997996, 0.23847695390781562, 0.23947895791583165, 0.24048096192384769, 0.24148296593186372, 0.24248496993987975, 0.24348697394789579, 0.2444889779559118, 0.24549098196392782, 0.24649298597194386, 0.2474949899799599, 0.24849699398797592, 0.24949899799599196, 0.250501002004008, 0.251503006012024, 0.25250501002004005, 0.2535070140280561, 0.2545090180360721, 0.25551102204408815, 0.2565130260521042, 0.2575150300601202, 0.25851703406813625, 0.2595190380761523, 0.2605210420841683, 0.26152304609218435, 0.2625250501002004, 0.2635270541082164, 0.26452905811623245, 0.2655310621242485, 0.2665330661322645, 0.26753507014028055, 0.2685370741482966, 0.2695390781563126, 0.27054108216432865, 0.2715430861723447, 0.2725450901803607, 0.27354709418837675, 0.2745490981963928, 0.2755511022044088, 0.27655310621242485, 0.2775551102204409, 0.2785571142284569, 0.27955911823647295, 0.280561122244489, 0.281563126252505, 0.282565130260521, 0.283567134268537, 0.28456913827655306, 0.2855711422845691, 0.2865731462925851, 0.28757515030060116, 0.2885771543086172, 0.2895791583166332, 0.29058116232464926, 0.2915831663326653, 0.2925851703406813, 0.29358717434869736, 0.2945891783567134, 0.2955911823647294, 0.29659318637274545, 0.2975951903807615, 0.2985971943887775, 0.29959919839679355, 0.3006012024048096, 0.3016032064128256, 0.30260521042084165, 0.3036072144288577, 0.3046092184368737, 0.30561122244488975, 0.3066132264529058, 0.3076152304609218, 0.30861723446893785, 0.3096192384769539, 0.3106212424849699, 0.31162324649298595, 0.312625250501002, 0.313627254509018, 0.31462925851703405, 0.3156312625250501, 0.3166332665330661, 0.31763527054108215, 0.3186372745490982, 0.3196392785571142, 0.32064128256513025, 0.3216432865731463, 0.3226452905811623, 0.32364729458917835, 0.3246492985971944, 0.3256513026052104, 0.32665330661322645, 0.3276553106212425, 0.3286573146292585, 0.32965931863727455, 0.3306613226452906, 0.3316633266533066, 0.33266533066132264, 0.3336673346693386, 0.33466933867735466, 0.3356713426853707, 0.3366733466933867, 0.33767535070140275, 0.3386773547094188, 0.3396793587174348, 0.34068136272545085, 0.3416833667334669, 0.3426853707414829, 0.34368737474949895, 0.344689378757515, 0.345691382765531, 0.34669338677354705, 0.3476953907815631, 0.3486973947895791, 0.34969939879759515, 0.3507014028056112, 0.3517034068136272, 0.35270541082164325, 0.3537074148296593, 0.3547094188376753, 0.35571142284569135, 0.3567134268537074, 0.3577154308617234, 0.35871743486973945, 0.3597194388777555, 0.3607214428857715, 0.36172344689378755, 0.3627254509018036, 0.3637274549098196, 0.36472945891783565, 0.3657314629258517, 0.3667334669338677, 0.36773547094188375, 0.3687374749498998, 0.3697394789579158, 0.37074148296593185, 0.3717434869739479, 0.3727454909819639, 0.37374749498997994, 0.374749498997996, 0.375751503006012, 0.37675350701402804, 0.3777555110220441, 0.3787575150300601, 0.37975951903807614, 0.3807615230460922, 0.3817635270541082, 0.38276553106212424, 0.3837675350701403, 0.38476953907815625, 0.3857715430861723, 0.3867735470941883, 0.38777555110220435, 0.3887775551102204, 0.3897795591182364, 0.39078156312625245, 0.3917835671342685, 0.3927855711422845, 0.39378757515030055, 0.3947895791583166, 0.3957915831663326, 0.39679358717434865, 0.3977955911823647, 0.3987975951903807, 0.39979959919839675, 0.4008016032064128, 0.4018036072144288, 0.40280561122244485, 0.4038076152304609, 0.4048096192384769, 0.40581162324649295, 0.406813627254509, 0.407815631262525, 0.40881763527054105, 0.4098196392785571, 0.4108216432865731, 0.41182364729458915, 0.4128256513026052, 0.4138276553106212, 0.41482965931863724, 0.4158316633266533, 0.4168336673346693, 0.41783567134268534, 0.4188376753507014, 0.4198396793587174, 0.42084168336673344, 0.4218436873747495, 0.4228456913827655, 0.42384769539078154, 0.4248496993987976, 0.4258517034068136, 0.42685370741482964, 0.4278557114228457, 0.4288577154308617, 0.42985971943887774, 0.4308617234468938, 0.4318637274549098, 0.43286573146292584, 0.4338677354709419, 0.4348697394789579, 0.43587174348697394, 0.4368737474949899, 0.43787575150300595, 0.438877755511022, 0.439879759519038, 0.44088176352705405, 0.4418837675350701, 0.4428857715430861, 0.44388777555110215, 0.4448897795591182, 0.4458917835671342, 0.44689378757515025, 0.4478957915831663, 0.4488977955911823, 0.44989979959919835, 0.4509018036072144, 0.4519038076152304, 0.45290581162324645, 0.4539078156312625, 0.4549098196392785, 0.45591182364729455, 0.4569138276553106, 0.4579158316633266, 0.45891783567134264, 0.4599198396793587, 0.4609218436873747, 0.46192384769539074, 0.4629258517034068, 0.4639278557114228, 0.46492985971943884, 0.4659318637274549, 0.4669338677354709, 0.46793587174348694, 0.468937875751503, 0.469939879759519, 0.47094188376753504, 0.4719438877755511, 0.4729458917835671, 0.47394789579158314, 0.4749498997995992, 0.4759519038076152, 0.47695390781563124, 0.4779559118236473, 0.4789579158316633, 0.47995991983967934, 0.48096192384769537, 0.4819639278557114, 0.48296593186372744, 0.48396793587174347, 0.4849699398797595, 0.48597194388777554, 0.48697394789579157, 0.48797595190380755, 0.4889779559118236, 0.4899799599198396, 0.49098196392785565, 0.4919839679358717, 0.4929859719438877, 0.49398797595190375, 0.4949899799599198, 0.4959919839679358, 0.49699398797595185, 0.4979959919839679, 0.4989979959919839, 0.5], 'max_iter': [2000, 2016, 2032, 2048, 2064, 2080, 2096, 2112, 2128, 2144, 2160, 2176, 2192, 2208, 2224, 2240, 2256, 2272, 2288, 2304, 2320, 2336, 2352, 2368, 2384, 2400, 2416, 2432, 2448, 2464, 2480, 2496, 2513, 2529, 2545, 2561, 2577, 2593, 2609, 2625, 2641, 2657, 2673, 2689, 2705, 2721, 2737, 2753, 2769, 2785, 2801, 2817, 2833, 2849, 2865, 2881, 2897, 2913, 2929, 2945, 2961, 2977, 2993, 3010, 3026, 3042, 3058, 3074, 3090, 3106, 3122, 3138, 3154, 3170, 3186, 3202, 3218, 3234, 3250, 3266, 3282, 3298, 3314, 3330, 3346, 3362, 3378, 3394, 3410, 3426, 3442, 3458, 3474, 3490, 3507, 3523, 3539, 3555, 3571, 3587, 3603, 3619, 3635, 3651, 3667, 3683, 3699, 3715, 3731, 3747, 3763, 3779, 3795, 3811, 3827, 3843, 3859, 3875, 3891, 3907, 3923, 3939, 3955, 3971, 3987, 4004, 4020, 4036, 4052, 4068, 4084, 4100, 4116, 4132, 4148, 4164, 4180, 4196, 4212, 4228, 4244, 4260, 4276, 4292, 4308, 4324, 4340, 4356, 4372, 4388, 4404, 4420, 4436, 4452, 4468, 4484, 4501, 4517, 4533, 4549, 4565, 4581, 4597, 4613, 4629, 4645, 4661, 4677, 4693, 4709, 4725, 4741, 4757, 4773, 4789, 4805, 4821, 4837, 4853, 4869, 4885, 4901, 4917, 4933, 4949, 4965, 4981, 4997, 5014, 5030, 5046, 5062, 5078, 5094, 5110, 5126, 5142, 5158, 5174, 5190, 5206, 5222, 5238, 5254, 5270, 5286, 5302, 5318, 5334, 5350, 5366, 5382, 5398, 5414, 5430, 5446, 5462, 5478, 5494, 5511, 5527, 5543, 5559, 5575, 5591, 5607, 5623, 5639, 5655, 5671, 5687, 5703, 5719, 5735, 5751, 5767, 5783, 5799, 5815, 5831, 5847, 5863, 5879, 5895, 5911, 5927, 5943, 5959, 5975, 5991, 6008, 6024, 6040, 6056, 6072, 6088, 6104, 6120, 6136, 6152, 6168, 6184, 6200, 6216, 6232, 6248, 6264, 6280, 6296, 6312, 6328, 6344, 6360, 6376, 6392, 6408, 6424, 6440, 6456, 6472, 6488, 6505, 6521, 6537, 6553, 6569, 6585, 6601, 6617, 6633, 6649, 6665, 6681, 6697, 6713, 6729, 6745, 6761, 6777, 6793, 6809, 6825, 6841, 6857, 6873, 6889, 6905, 6921, 6937, 6953, 6969, 6985, 7002, 7018, 7034, 7050, 7066, 7082, 7098, 7114, 7130, 7146, 7162, 7178, 7194, 7210, 7226, 7242, 7258, 7274, 7290, 7306, 7322, 7338, 7354, 7370, 7386, 7402, 7418, 7434, 7450, 7466, 7482, 7498, 7515, 7531, 7547, 7563, 7579, 7595, 7611, 7627, 7643, 7659, 7675, 7691, 7707, 7723, 7739, 7755, 7771, 7787, 7803, 7819, 7835, 7851, 7867, 7883, 7899, 7915, 7931, 7947, 7963, 7979, 7995, 8012, 8028, 8044, 8060, 8076, 8092, 8108, 8124, 8140, 8156, 8172, 8188, 8204, 8220, 8236, 8252, 8268, 8284, 8300, 8316, 8332, 8348, 8364, 8380, 8396, 8412, 8428, 8444, 8460, 8476, 8492, 8509, 8525, 8541, 8557, 8573, 8589, 8605, 8621, 8637, 8653, 8669, 8685, 8701, 8717, 8733, 8749, 8765, 8781, 8797, 8813, 8829, 8845, 8861, 8877, 8893, 8909, 8925, 8941, 8957, 8973, 8989, 9006, 9022, 9038, 9054, 9070, 9086, 9102, 9118, 9134, 9150, 9166, 9182, 9198, 9214, 9230, 9246, 9262, 9278, 9294, 9310, 9326, 9342, 9358, 9374, 9390, 9406, 9422, 9438, 9454, 9470, 9486, 9503, 9519, 9535, 9551, 9567, 9583, 9599, 9615, 9631, 9647, 9663, 9679, 9695, 9711, 9727, 9743, 9759, 9775, 9791, 9807, 9823, 9839, 9855, 9871, 9887, 9903, 9919, 9935, 9951, 9967, 9983, 10000], 'tol': [0.01, 0.00996989966555184, 0.009939799331103678, 0.009909698996655518, 0.009879598662207358, 0.009849498327759198, 0.009819397993311036, 0.009789297658862876, 0.009759197324414716, 0.009729096989966556, 0.009698996655518394, 0.009668896321070234, 0.009638795986622074, 0.009608695652173913, 0.009578595317725752, 0.009548494983277592, 0.009518394648829432, 0.00948829431438127, 0.00945819397993311, 0.00942809364548495, 0.009397993311036789, 0.009367892976588629, 0.009337792642140469, 0.009307692307692308, 0.009277591973244147, 0.009247491638795987, 0.009217391304347827, 0.009187290969899665, 0.009157190635451505, 0.009127090301003345, 0.009096989966555185, 0.009066889632107023, 0.009036789297658863, 0.009006688963210703, 0.008976588628762543, 0.00894648829431438, 0.00891638795986622, 0.00888628762541806, 0.008856187290969899, 0.008826086956521739, 0.008795986622073579, 0.008765886287625419, 0.008735785953177257, 0.008705685618729097, 0.008675585284280937, 0.008645484949832777, 0.008615384615384615, 0.008585284280936455, 0.008555183946488295, 0.008525083612040133, 0.008494983277591973, 0.008464882943143813, 0.008434782608695653, 0.008404682274247491, 0.008374581939799331, 0.008344481605351171, 0.008314381270903011, 0.00828428093645485, 0.00825418060200669, 0.008224080267558529, 0.008193979933110367, 0.008163879598662207, 0.008133779264214047, 0.008103678929765885, 0.008073578595317725, 0.008043478260869565, 0.008013377926421405, 0.007983277591973245, 0.007953177257525083, 0.007923076923076923, 0.007892976588628763, 0.007862876254180601, 0.007832775919732441, 0.007802675585284281, 0.00777257525083612, 0.0077424749163879595, 0.0077123745819397994, 0.007682274247491639, 0.007652173913043478, 0.0076220735785953175, 0.0075919732441471575, 0.0075618729096989966, 0.007531772575250836, 0.007501672240802676, 0.0074715719063545155, 0.007441471571906355, 0.007411371237458194, 0.007381270903010034, 0.007351170568561873, 0.007321070234113712, 0.007290969899665552, 0.007260869565217392, 0.007230769230769231, 0.00720066889632107, 0.00717056856187291, 0.00714046822742475, 0.007110367892976589, 0.007080267558528428, 0.007050167224080268, 0.007020066889632107, 0.006989966555183946, 0.006959866220735786, 0.006929765886287626, 0.006899665551839465, 0.006869565217391304, 0.006839464882943144, 0.006809364548494983, 0.006779264214046822, 0.006749163879598662, 0.006719063545150502, 0.006688963210702341, 0.00665886287625418, 0.00662876254180602, 0.00659866220735786, 0.006568561872909699, 0.006538461538461538, 0.006508361204013378, 0.006478260869565217, 0.006448160535117056, 0.006418060200668896, 0.006387959866220736, 0.006357859531772575, 0.006327759197324414, 0.006297658862876254, 0.006267558528428093, 0.006237458193979932, 0.006207357859531772, 0.006177257525083612, 0.006147157190635451, 0.00611705685618729, 0.00608695652173913, 0.006056856187290969, 0.006026755852842809, 0.005996655518394648, 0.005966555183946488, 0.0059364548494983274, 0.005906354515050167, 0.0058762541806020065, 0.0058461538461538455, 0.0058160535117056855, 0.0057859531772575246, 0.0057558528428093645, 0.005725752508361204, 0.0056956521739130435, 0.005665551839464883, 0.0056354515050167225, 0.005605351170568562, 0.005575250836120401, 0.005545150501672241, 0.00551505016722408, 0.00548494983277592, 0.005454849498327759, 0.005424749163879599, 0.005394648829431438, 0.005364548494983278, 0.005334448160535117, 0.005304347826086956, 0.005274247491638796, 0.005244147157190635, 0.005214046822742475, 0.005183946488294314, 0.005153846153846154, 0.005123745819397993, 0.005093645484949833, 0.005063545150501672, 0.005033444816053511, 0.005003344481605351, 0.00497324414715719, 0.00494314381270903, 0.004913043478260869, 0.004882943143812709, 0.004852842809364548, 0.004822742474916388, 0.004792642140468227, 0.004762541806020066, 0.004732441471571906, 0.004702341137123745, 0.004672240802675585, 0.004642140468227424, 0.004612040133779264, 0.004581939799331103, 0.004551839464882943, 0.004521739130434782, 0.004491638795986621, 0.004461538461538461, 0.0044314381270903, 0.00440133779264214, 0.004371237458193979, 0.004341137123745819, 0.004311036789297658, 0.004280936454849498, 0.004250836120401337, 0.004220735785953177, 0.004190635451505016, 0.0041605351170568555, 0.004130434782608695, 0.0041003344481605345, 0.004070234113712374, 0.0040401337792642135, 0.0040100334448160534, 0.0039799331103678925, 0.0039498327759197325, 0.0039197324414715715, 0.0038896321070234106, 0.0038595317725752505, 0.0038294314381270896, 0.0037993311036789296, 0.0037692307692307686, 0.0037391304347826086, 0.0037090301003344477, 0.0036789297658862876, 0.0036488294314381267, 0.0036187290969899658, 0.0035886287625418057, 0.0035585284280936448, 0.0035284280936454847, 0.003498327759197324, 0.0034682274247491637, 0.003438127090301003, 0.0034080267558528428, 0.003377926421404682, 0.003347826086956521, 0.003317725752508361, 0.0032876254180602, 0.00325752508361204, 0.003227424749163879, 0.003197324414715719, 0.003167224080267558, 0.003137123745819398, 0.003107023411371237, 0.003076923076923076, 0.003046822742474916, 0.003016722408026755, 0.002986622073578595, 0.002956521739130434, 0.002926421404682274, 0.002896321070234113, 0.002866220735785953, 0.002836120401337792, 0.002806020066889631, 0.002775919732441471, 0.0027458193979933102, 0.00271571906354515, 0.0026856187290969892, 0.002655518394648829, 0.0026254180602006683, 0.002595317725752508, 0.0025652173913043473, 0.0025351170568561864, 0.0025050167224080263, 0.0024749163879598654, 0.0024448160535117053, 0.0024147157190635444, 0.0023846153846153843, 0.0023545150501672234, 0.0023244147157190633, 0.0022943143812709024, 0.0022642140468227415, 0.0022341137123745814, 0.0022040133779264205, 0.0021739130434782605, 0.0021438127090301004, 0.0021137123745819386, 0.0020836120401337786, 0.0020535117056856185, 0.0020234113712374584, 0.0019933110367892967, 0.0019632107023411366, 0.0019331103678929765, 0.0019030100334448147, 0.0018729096989966547, 0.0018428093645484946, 0.0018127090301003346, 0.0017826086956521728, 0.0017525083612040127, 0.0017224080267558527, 0.0016923076923076909, 0.0016622073578595308, 0.0016321070234113708, 0.0016020066889632107, 0.001571906354515049, 0.0015418060200668889, 0.0015117056856187288, 0.0014816053511705687, 0.001451505016722407, 0.001421404682274247, 0.0013913043478260868, 0.001361204013377925, 0.001331103678929765, 0.001301003344481605, 0.0012709030100334449, 0.001240802675585283, 0.001210702341137123, 0.001180602006688963, 0.0011505016722408012, 0.0011204013377926411, 0.001090301003344481, 0.001060200668896321, 0.0010301003344481592, 0.001], 'positive': ['True', 'False'], 'copy_X': ['True', 'False'], 'warm_start': ['True', 'False'], 'selection': ['cyclic', 'random']}\n"
     ]
    }
   ],
   "source": [
    "max_iter=[int(x) for x in np.linspace(2000, 10000,500)]\n",
    "tol=[float(x) for x in np.linspace(0.01, 0.001,300)]\n",
    "warm_start = ['True','False']\n",
    "selection=['cyclic','random']\n",
    "alpha = [float(x) for x in np.linspace(0,0.50,500)]\n",
    "# positive=['True','False']\n",
    "copy_X=['True','False']\n",
    "random_grid = {\n",
    "               'alpha':alpha,\n",
    "              \n",
    "               'max_iter':max_iter,\n",
    "               'tol':tol,\n",
    "                'positive':positive,\n",
    "                'copy_X':copy_X,\n",
    "                'warm_start':warm_start,\n",
    "                'selection':selection\n",
    "               \n",
    "               \n",
    "                }\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "c5e98480-6e98-49d1-af3b-d9fa6e194cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "[CV 2/5] END alpha=0.0005714285714285715, eta0=0.05656565656565657, l1_ratio=0.061224489795918366, learning_rate=optimal, loss=epsilon_insensitive, max_iter=10545, n_iter_no_change=10, penalty=l2, tol=0.007909090909090909, validation_fraction=0.7367346938775511;, score=-5.891 total time=   0.6s\n",
      "[CV 1/5] END alpha=0.0007755102040816326, eta0=0.09898989898989899, l1_ratio=0.030612244897959183, learning_rate=adaptive, loss=squared_epsilon_insensitive, max_iter=14787, n_iter_no_change=1, penalty=elasticnet, tol=0.008, validation_fraction=0.4591836734693878;, score=0.877 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.375751503006012, copy_X=True, l1_ratio=0.3484848484848485, max_iter=3005, selection=random, tol=0.004165829145728642, warm_start=False;, score=0.765 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.024048096192384766, copy_X=False, l1_ratio=0.12121212121212122, max_iter=2321, selection=cyclic, tol=0.009683417085427136, warm_start=True;, score=0.867 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.08016032064128256, copy_X=True, l1_ratio=0.10606060606060606, max_iter=6582, selection=random, tol=0.002673366834170853, warm_start=True;, score=0.839 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.08016032064128256, copy_X=True, l1_ratio=0.10606060606060606, max_iter=6582, selection=random, tol=0.002673366834170853, warm_start=True;, score=0.878 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.3286573146292585, copy_X=True, l1_ratio=0.27272727272727276, max_iter=8592, selection=random, tol=0.0076482412060301505, warm_start=False;, score=0.693 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.281563126252505, copy_X=False, l1_ratio=0.3535353535353536, max_iter=8190, selection=random, tol=0.0098643216080402, warm_start=True;, score=0.758 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.4218436873747495, copy_X=False, l1_ratio=0.3282828282828283, max_iter=7507, selection=random, tol=0.005884422110552763, warm_start=False;, score=0.671 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.49098196392785565, copy_X=True, l1_ratio=0.010101010101010102, max_iter=8351, selection=cyclic, tol=0.005613065326633165, warm_start=True;, score=0.607 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.49098196392785565, copy_X=True, l1_ratio=0.010101010101010102, max_iter=8351, selection=cyclic, tol=0.005613065326633165, warm_start=True;, score=0.609 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.49098196392785565, copy_X=True, l1_ratio=0.010101010101010102, max_iter=8351, selection=cyclic, tol=0.005613065326633165, warm_start=True;, score=0.640 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.08216432865731463, copy_X=False, l1_ratio=0.37878787878787884, max_iter=5135, selection=random, tol=0.008190954773869347, warm_start=True;, score=0.836 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.08216432865731463, copy_X=False, l1_ratio=0.37878787878787884, max_iter=5135, selection=random, tol=0.008190954773869347, warm_start=True;, score=0.807 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.4849699398797595, copy_X=False, l1_ratio=0.2474747474747475, max_iter=6623, selection=cyclic, tol=0.005115577889447235, warm_start=False;, score=0.661 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.4849699398797595, copy_X=False, l1_ratio=0.2474747474747475, max_iter=6623, selection=cyclic, tol=0.005115577889447235, warm_start=False;, score=0.663 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.4338677354709419, copy_X=False, l1_ratio=0.398989898989899, max_iter=2321, selection=random, tol=0.0013618090452261287, warm_start=True;, score=0.714 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.4338677354709419, copy_X=False, l1_ratio=0.398989898989899, max_iter=2321, selection=random, tol=0.0013618090452261287, warm_start=True;, score=0.717 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.4338677354709419, copy_X=False, l1_ratio=0.398989898989899, max_iter=2321, selection=random, tol=0.0013618090452261287, warm_start=True;, score=0.755 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.4338677354709419, copy_X=False, l1_ratio=0.398989898989899, max_iter=2321, selection=random, tol=0.0013618090452261287, warm_start=True;, score=0.689 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.4338677354709419, copy_X=False, l1_ratio=0.398989898989899, max_iter=2321, selection=random, tol=0.0013618090452261287, warm_start=True;, score=0.682 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.14629258517034066, copy_X=True, l1_ratio=0.37878787878787884, max_iter=7949, selection=random, tol=0.006110552763819095, warm_start=False;, score=0.815 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.14629258517034066, copy_X=True, l1_ratio=0.37878787878787884, max_iter=7949, selection=random, tol=0.006110552763819095, warm_start=False;, score=0.824 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.14629258517034066, copy_X=True, l1_ratio=0.37878787878787884, max_iter=7949, selection=random, tol=0.006110552763819095, warm_start=False;, score=0.864 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.002004008016032064, copy_X=True, l1_ratio=0.14141414141414144, max_iter=6743, selection=cyclic, tol=0.006562814070351758, warm_start=False;, score=0.872 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.03006012024048096, copy_X=False, l1_ratio=0.494949494949495, max_iter=2040, selection=random, tol=0.005296482412060301, warm_start=False;, score=0.864 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.03006012024048096, copy_X=False, l1_ratio=0.494949494949495, max_iter=2040, selection=random, tol=0.005296482412060301, warm_start=False;, score=0.885 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.03006012024048096, copy_X=False, l1_ratio=0.494949494949495, max_iter=2040, selection=random, tol=0.005296482412060301, warm_start=False;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.03006012024048096, copy_X=False, l1_ratio=0.494949494949495, max_iter=2040, selection=random, tol=0.005296482412060301, warm_start=False;, score=0.875 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.03006012024048096, copy_X=False, l1_ratio=0.494949494949495, max_iter=2040, selection=random, tol=0.005296482412060301, warm_start=False;, score=0.844 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.43587174348697394, copy_X=True, l1_ratio=0.0, max_iter=6904, selection=random, tol=0.0010904522613065307, warm_start=False;, score=0.628 total time=   0.2s\n",
      "[CV 2/5] END alpha=0.43587174348697394, copy_X=True, l1_ratio=0.0, max_iter=6904, selection=random, tol=0.0010904522613065307, warm_start=False;, score=0.631 total time=   0.2s\n",
      "[CV 3/5] END alpha=0.34969939879759515, copy_X=False, l1_ratio=0.05555555555555556, max_iter=8391, selection=cyclic, tol=0.00407537688442211, warm_start=True;, score=0.716 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.34969939879759515, copy_X=False, l1_ratio=0.05555555555555556, max_iter=8391, selection=cyclic, tol=0.00407537688442211, warm_start=True;, score=0.651 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.0721442885771543, copy_X=True, l1_ratio=0.4595959595959596, max_iter=3969, selection=random, tol=0.004979899497487436, warm_start=True;, score=0.864 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.0721442885771543, copy_X=True, l1_ratio=0.4595959595959596, max_iter=3969, selection=random, tol=0.004979899497487436, warm_start=True;, score=0.901 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.002004008016032064, copy_X=True, l1_ratio=0.14141414141414144, max_iter=6743, selection=cyclic, tol=0.006562814070351758, warm_start=False;, score=0.878 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.3286573146292585, copy_X=True, max_iter=6312, positive=True, selection=random, tol=0.006779264214046822, warm_start=True;, score=0.918 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.17635270541082163, copy_X=False, max_iter=2897, positive=True, selection=cyclic, tol=0.0013913043478260868, warm_start=True;, score=0.905 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.17334669338677353, copy_X=True, max_iter=7130, positive=True, selection=cyclic, tol=0.0058461538461538455, warm_start=True;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.17334669338677353, copy_X=True, max_iter=7130, positive=True, selection=cyclic, tol=0.0058461538461538455, warm_start=True;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1783567134268537, copy_X=False, max_iter=8605, positive=True, selection=cyclic, tol=0.006779264214046822, warm_start=True;, score=0.881 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.0811623246492986, copy_X=True, l1_ratio=0.33333333333333337, max_iter=2884, selection=random, tol=0.0032613065326633156, warm_start=True;, score=0.834 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.0811623246492986, copy_X=True, l1_ratio=0.33333333333333337, max_iter=2884, selection=random, tol=0.0032613065326633156, warm_start=True;, score=0.805 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.12424849699398796, copy_X=True, l1_ratio=0.3282828282828283, max_iter=3567, selection=random, tol=0.0014974874371859286, warm_start=False;, score=0.819 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.12424849699398796, copy_X=True, l1_ratio=0.3282828282828283, max_iter=3567, selection=random, tol=0.0014974874371859286, warm_start=False;, score=0.830 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.12424849699398796, copy_X=True, l1_ratio=0.3282828282828283, max_iter=3567, selection=random, tol=0.0014974874371859286, warm_start=False;, score=0.869 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.12424849699398796, copy_X=True, l1_ratio=0.3282828282828283, max_iter=3567, selection=random, tol=0.0014974874371859286, warm_start=False;, score=0.808 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.12424849699398796, copy_X=True, l1_ratio=0.3282828282828283, max_iter=3567, selection=random, tol=0.0014974874371859286, warm_start=False;, score=0.783 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.35571142284569135, copy_X=False, l1_ratio=0.32323232323232326, max_iter=4452, selection=cyclic, tol=0.0022211055276381893, warm_start=False;, score=0.725 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1472945891783567, copy_X=True, l1_ratio=0.020202020202020204, max_iter=7547, selection=cyclic, tol=0.00493467336683417, warm_start=True;, score=0.763 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1472945891783567, copy_X=True, l1_ratio=0.020202020202020204, max_iter=7547, selection=cyclic, tol=0.00493467336683417, warm_start=True;, score=0.745 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.4929859719438877, copy_X=True, l1_ratio=0.030303030303030304, max_iter=4814, selection=random, tol=0.005206030150753768, warm_start=True;, score=0.610 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.4929859719438877, copy_X=True, l1_ratio=0.030303030303030304, max_iter=4814, selection=random, tol=0.005206030150753768, warm_start=True;, score=0.613 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.3476953907815631, copy_X=False, l1_ratio=0.297979797979798, max_iter=6984, selection=cyclic, tol=0.009050251256281406, warm_start=False;, score=0.699 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.3476953907815631, copy_X=False, l1_ratio=0.297979797979798, max_iter=6984, selection=cyclic, tol=0.009050251256281406, warm_start=False;, score=0.690 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.05110220440881763, copy_X=True, l1_ratio=0.398989898989899, max_iter=2924, selection=cyclic, tol=0.009954773869346734, warm_start=True;, score=0.853 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.05110220440881763, copy_X=True, l1_ratio=0.398989898989899, max_iter=2924, selection=cyclic, tol=0.009954773869346734, warm_start=True;, score=0.871 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.13026052104208416, copy_X=True, l1_ratio=0.42424242424242425, max_iter=3567, selection=random, tol=0.008597989949748744, warm_start=True;, score=0.815 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.13026052104208416, copy_X=True, l1_ratio=0.42424242424242425, max_iter=3567, selection=random, tol=0.008597989949748744, warm_start=True;, score=0.789 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.24849699398797592, copy_X=True, l1_ratio=0.15656565656565657, max_iter=5216, selection=cyclic, tol=0.0012713567839195972, warm_start=True;, score=0.708 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.09619238476953906, copy_X=False, l1_ratio=0.36868686868686873, max_iter=8231, selection=random, tol=0.003758793969849245, warm_start=True;, score=0.834 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1653306613226453, copy_X=False, l1_ratio=0.393939393939394, max_iter=3728, selection=random, tol=0.0098643216080402, warm_start=True;, score=0.858 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1653306613226453, copy_X=False, l1_ratio=0.393939393939394, max_iter=3728, selection=random, tol=0.0098643216080402, warm_start=True;, score=0.795 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.30260521042084165, copy_X=False, l1_ratio=0.30303030303030304, max_iter=8994, selection=random, tol=0.00864321608040201, warm_start=False;, score=0.719 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.30260521042084165, copy_X=False, l1_ratio=0.30303030303030304, max_iter=8994, selection=random, tol=0.00864321608040201, warm_start=False;, score=0.707 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.09519038076152304, copy_X=True, l1_ratio=0.38383838383838387, max_iter=7708, selection=cyclic, tol=0.003894472361809044, warm_start=True;, score=0.849 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.09519038076152304, copy_X=True, l1_ratio=0.38383838383838387, max_iter=7708, selection=cyclic, tol=0.003894472361809044, warm_start=True;, score=0.887 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.283567134268537, copy_X=True, l1_ratio=0.31818181818181823, max_iter=8351, selection=random, tol=0.004030150753768843, warm_start=False;, score=0.796 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.283567134268537, copy_X=True, l1_ratio=0.31818181818181823, max_iter=8351, selection=random, tol=0.004030150753768843, warm_start=False;, score=0.730 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.027054108216432865, copy_X=True, l1_ratio=0.07070707070707072, max_iter=8874, selection=random, tol=0.005613065326633165, warm_start=True;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.027054108216432865, copy_X=True, l1_ratio=0.07070707070707072, max_iter=8874, selection=random, tol=0.005613065326633165, warm_start=True;, score=0.876 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.3887775551102204, copy_X=False, l1_ratio=0.16161616161616163, max_iter=6502, selection=cyclic, tol=0.002085427135678391, warm_start=False;, score=0.653 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.3887775551102204, copy_X=False, l1_ratio=0.16161616161616163, max_iter=6502, selection=cyclic, tol=0.002085427135678391, warm_start=False;, score=0.651 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.33266533066132264, copy_X=True, l1_ratio=0.2373737373737374, max_iter=7708, selection=random, tol=0.006381909547738693, warm_start=True;, score=0.685 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.4789579158316633, copy_X=True, l1_ratio=0.25252525252525254, max_iter=9638, selection=cyclic, tol=0.00864321608040201, warm_start=True;, score=0.664 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.49699398797595185, copy_X=True, l1_ratio=0.0, max_iter=8030, selection=random, tol=0.00308040201005025, warm_start=False;, score=0.636 total time=   0.4s\n",
      "[CV 4/5] END alpha=0.49699398797595185, copy_X=True, l1_ratio=0.0, max_iter=8030, selection=random, tol=0.00308040201005025, warm_start=False;, score=0.573 total time=   0.3s\n",
      "[CV 1/5] END alpha=0.4158316633266533, copy_X=True, max_iter=4709, positive=True, selection=random, tol=0.007321070234113712, warm_start=True;, score=0.881 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.4158316633266533, copy_X=True, max_iter=4709, positive=True, selection=random, tol=0.007321070234113712, warm_start=True;, score=0.892 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.17334669338677353, copy_X=True, max_iter=7130, positive=True, selection=cyclic, tol=0.0058461538461538455, warm_start=True;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.17334669338677353, copy_X=True, max_iter=7130, positive=True, selection=cyclic, tol=0.0058461538461538455, warm_start=True;, score=0.918 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.27955911823647295, copy_X=True, max_iter=4613, positive=True, selection=cyclic, tol=0.007321070234113712, warm_start=True;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.27955911823647295, copy_X=True, max_iter=4613, positive=True, selection=cyclic, tol=0.007321070234113712, warm_start=True;, score=0.918 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1783567134268537, copy_X=False, max_iter=8605, positive=True, selection=cyclic, tol=0.006779264214046822, warm_start=True;, score=0.883 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.3286573146292585, copy_X=True, l1_ratio=0.27272727272727276, max_iter=8592, selection=random, tol=0.0076482412060301505, warm_start=False;, score=0.702 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.3306613226452906, copy_X=True, l1_ratio=0.07070707070707072, max_iter=9678, selection=random, tol=0.0021758793969849227, warm_start=True;, score=0.729 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.3306613226452906, copy_X=True, l1_ratio=0.07070707070707072, max_iter=9678, selection=random, tol=0.0021758793969849227, warm_start=True;, score=0.663 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1412825651302605, copy_X=False, l1_ratio=0.2878787878787879, max_iter=8673, selection=cyclic, tol=0.0015879396984924618, warm_start=True;, score=0.857 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1412825651302605, copy_X=False, l1_ratio=0.2878787878787879, max_iter=8673, selection=cyclic, tol=0.0015879396984924618, warm_start=True;, score=0.795 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1412825651302605, copy_X=False, l1_ratio=0.2878787878787879, max_iter=8673, selection=cyclic, tol=0.0015879396984924618, warm_start=True;, score=0.772 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.2314629258517034, copy_X=True, l1_ratio=0.12121212121212122, max_iter=6422, selection=random, tol=0.0098643216080402, warm_start=False;, score=0.746 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.13527054108216433, copy_X=True, l1_ratio=0.16666666666666669, max_iter=3849, selection=cyclic, tol=0.00864321608040201, warm_start=True;, score=0.809 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.13527054108216433, copy_X=True, l1_ratio=0.16666666666666669, max_iter=3849, selection=cyclic, tol=0.00864321608040201, warm_start=True;, score=0.849 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.13527054108216433, copy_X=True, l1_ratio=0.16666666666666669, max_iter=3849, selection=cyclic, tol=0.00864321608040201, warm_start=True;, score=0.786 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.13527054108216433, copy_X=True, l1_ratio=0.16666666666666669, max_iter=3849, selection=cyclic, tol=0.00864321608040201, warm_start=True;, score=0.764 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.4008016032064128, copy_X=True, l1_ratio=0.4040404040404041, max_iter=5939, selection=random, tol=0.0034422110552763813, warm_start=False;, score=0.693 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.4659318637274549, copy_X=True, l1_ratio=0.30303030303030304, max_iter=3648, selection=random, tol=0.008371859296482412, warm_start=True;, score=0.680 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.4659318637274549, copy_X=True, l1_ratio=0.30303030303030304, max_iter=3648, selection=random, tol=0.008371859296482412, warm_start=True;, score=0.683 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.4659318637274549, copy_X=True, l1_ratio=0.30303030303030304, max_iter=3648, selection=random, tol=0.008371859296482412, warm_start=True;, score=0.719 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.4659318637274549, copy_X=True, l1_ratio=0.30303030303030304, max_iter=3648, selection=random, tol=0.008371859296482412, warm_start=True;, score=0.654 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.4659318637274549, copy_X=True, l1_ratio=0.30303030303030304, max_iter=3648, selection=random, tol=0.008371859296482412, warm_start=True;, score=0.651 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.3837675350701403, copy_X=False, l1_ratio=0.3535353535353536, max_iter=9557, selection=cyclic, tol=0.007738693467336683, warm_start=True;, score=0.721 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.3837675350701403, copy_X=False, l1_ratio=0.3535353535353536, max_iter=9557, selection=cyclic, tol=0.007738693467336683, warm_start=True;, score=0.724 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.43587174348697394, copy_X=True, l1_ratio=0.0, max_iter=6904, selection=random, tol=0.0010904522613065307, warm_start=False;, score=0.663 total time=   0.2s\n",
      "[CV 4/5] END alpha=0.43587174348697394, copy_X=True, l1_ratio=0.0, max_iter=6904, selection=random, tol=0.0010904522613065307, warm_start=False;, score=0.600 total time=   0.2s\n",
      "[CV 5/5] END alpha=0.43587174348697394, copy_X=True, l1_ratio=0.0, max_iter=6904, selection=random, tol=0.0010904522613065307, warm_start=False;, score=0.603 total time=   0.2s\n",
      "[CV 1/5] END alpha=0.3607214428857715, copy_X=True, l1_ratio=0.14141414141414144, max_iter=4452, selection=cyclic, tol=0.003623115577889446, warm_start=False;, score=0.688 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.3607214428857715, copy_X=True, l1_ratio=0.14141414141414144, max_iter=4452, selection=cyclic, tol=0.003623115577889446, warm_start=False;, score=0.691 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.3607214428857715, copy_X=True, l1_ratio=0.14141414141414144, max_iter=4452, selection=cyclic, tol=0.003623115577889446, warm_start=False;, score=0.728 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.3607214428857715, copy_X=True, l1_ratio=0.14141414141414144, max_iter=4452, selection=cyclic, tol=0.003623115577889446, warm_start=False;, score=0.662 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.3607214428857715, copy_X=True, l1_ratio=0.14141414141414144, max_iter=4452, selection=cyclic, tol=0.003623115577889446, warm_start=False;, score=0.658 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.002004008016032064, copy_X=True, l1_ratio=0.14141414141414144, max_iter=6743, selection=cyclic, tol=0.006562814070351758, warm_start=False;, score=0.928 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.3286573146292585, copy_X=True, max_iter=6312, positive=True, selection=random, tol=0.006779264214046822, warm_start=True;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.17635270541082163, copy_X=False, max_iter=2897, positive=True, selection=cyclic, tol=0.0013913043478260868, warm_start=True;, score=0.881 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.27955911823647295, copy_X=True, max_iter=5302, positive=True, selection=cyclic, tol=0.0017224080267558527, warm_start=True;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.27955911823647295, copy_X=True, max_iter=5302, positive=True, selection=cyclic, tol=0.0017224080267558527, warm_start=True;, score=0.905 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.27054108216432865, copy_X=True, max_iter=2400, positive=True, selection=random, tol=0.003107023411371237, warm_start=True;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.27054108216432865, copy_X=True, max_iter=2400, positive=True, selection=random, tol=0.003107023411371237, warm_start=True;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.27054108216432865, copy_X=True, max_iter=2400, positive=True, selection=random, tol=0.003107023411371237, warm_start=True;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.27054108216432865, copy_X=True, max_iter=2400, positive=True, selection=random, tol=0.003107023411371237, warm_start=True;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.001002004008016032, copy_X=True, max_iter=8300, positive=False, selection=cyclic, tol=0.004461538461538461, warm_start=False;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.001002004008016032, copy_X=True, max_iter=8300, positive=False, selection=cyclic, tol=0.004461538461538461, warm_start=False;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.001002004008016032, copy_X=True, max_iter=8300, positive=False, selection=cyclic, tol=0.004461538461538461, warm_start=False;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.001002004008016032, copy_X=True, max_iter=8300, positive=False, selection=cyclic, tol=0.004461538461538461, warm_start=False;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.044088176352705406, copy_X=True, max_iter=7370, positive=False, selection=random, tol=0.0015418060200668889, warm_start=True;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.2004008016032064, copy_X=True, max_iter=4693, positive=False, selection=cyclic, tol=0.007923076923076923, warm_start=True;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.2004008016032064, copy_X=True, max_iter=4693, positive=False, selection=cyclic, tol=0.007923076923076923, warm_start=True;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.2004008016032064, copy_X=True, max_iter=4693, positive=False, selection=cyclic, tol=0.007923076923076923, warm_start=True;, score=0.918 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.283567134268537, copy_X=True, l1_ratio=0.31818181818181823, max_iter=8351, selection=random, tol=0.004030150753768843, warm_start=False;, score=0.756 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.19338677354709416, copy_X=True, l1_ratio=0.18181818181818182, max_iter=9195, selection=cyclic, tol=0.009412060301507538, warm_start=False;, score=0.753 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.19338677354709416, copy_X=True, l1_ratio=0.18181818181818182, max_iter=9195, selection=cyclic, tol=0.009412060301507538, warm_start=False;, score=0.737 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.3887775551102204, copy_X=False, l1_ratio=0.16161616161616163, max_iter=6502, selection=cyclic, tol=0.002085427135678391, warm_start=False;, score=0.683 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.3887775551102204, copy_X=False, l1_ratio=0.16161616161616163, max_iter=6502, selection=cyclic, tol=0.002085427135678391, warm_start=False;, score=0.719 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.4789579158316633, copy_X=True, l1_ratio=0.25252525252525254, max_iter=9638, selection=cyclic, tol=0.00864321608040201, warm_start=True;, score=0.667 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.4789579158316633, copy_X=True, l1_ratio=0.25252525252525254, max_iter=9638, selection=cyclic, tol=0.00864321608040201, warm_start=True;, score=0.702 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.49699398797595185, copy_X=True, l1_ratio=0.0, max_iter=8030, selection=random, tol=0.00308040201005025, warm_start=False;, score=0.580 total time=   0.3s\n",
      "[CV 1/5] END alpha=0.15230460921843686, copy_X=False, l1_ratio=0.4191919191919192, max_iter=7587, selection=cyclic, tol=0.007015075376884422, warm_start=True;, score=0.816 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.002004008016032064, copy_X=True, l1_ratio=0.14141414141414144, max_iter=6743, selection=cyclic, tol=0.006562814070351758, warm_start=False;, score=0.891 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.3286573146292585, copy_X=True, max_iter=6312, positive=True, selection=random, tol=0.006779264214046822, warm_start=True;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.4158316633266533, copy_X=True, max_iter=4709, positive=True, selection=random, tol=0.007321070234113712, warm_start=True;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.17635270541082163, copy_X=False, max_iter=2897, positive=True, selection=cyclic, tol=0.0013913043478260868, warm_start=True;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.17635270541082163, copy_X=False, max_iter=2897, positive=True, selection=cyclic, tol=0.0013913043478260868, warm_start=True;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.27955911823647295, copy_X=True, max_iter=5302, positive=True, selection=cyclic, tol=0.0017224080267558527, warm_start=True;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.27955911823647295, copy_X=True, max_iter=4613, positive=True, selection=cyclic, tol=0.007321070234113712, warm_start=True;, score=0.881 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1783567134268537, copy_X=False, max_iter=8605, positive=True, selection=cyclic, tol=0.006779264214046822, warm_start=True;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1783567134268537, copy_X=False, max_iter=8605, positive=True, selection=cyclic, tol=0.006779264214046822, warm_start=True;, score=0.892 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.25551102204408815, copy_X=False, max_iter=4725, positive=True, selection=cyclic, tol=0.005575250836120401, warm_start=False;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.25551102204408815, copy_X=False, max_iter=4725, positive=True, selection=cyclic, tol=0.005575250836120401, warm_start=False;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.3727454909819639, copy_X=True, max_iter=7771, positive=True, selection=random, tol=0.005214046822742475, warm_start=False;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.3727454909819639, copy_X=True, max_iter=7771, positive=True, selection=random, tol=0.005214046822742475, warm_start=False;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.3977955911823647, copy_X=True, max_iter=6521, positive=True, selection=random, tol=0.009066889632107023, warm_start=False;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.3977955911823647, copy_X=True, max_iter=6521, positive=True, selection=random, tol=0.009066889632107023, warm_start=False;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.3977955911823647, copy_X=True, max_iter=6521, positive=True, selection=random, tol=0.009066889632107023, warm_start=False;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.37975951903807614, copy_X=False, max_iter=9935, positive=False, selection=cyclic, tol=0.004882943143812709, warm_start=False;, score=0.881 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.19939879759519036, copy_X=False, max_iter=6985, positive=True, selection=cyclic, tol=0.0057859531772575246, warm_start=False;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.19939879759519036, copy_X=False, max_iter=6985, positive=True, selection=cyclic, tol=0.0057859531772575246, warm_start=False;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.19939879759519036, copy_X=False, max_iter=6985, positive=True, selection=cyclic, tol=0.0057859531772575246, warm_start=False;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.19939879759519036, copy_X=False, max_iter=6985, positive=True, selection=cyclic, tol=0.0057859531772575246, warm_start=False;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.19939879759519036, copy_X=False, max_iter=6985, positive=True, selection=cyclic, tol=0.0057859531772575246, warm_start=False;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.044088176352705406, copy_X=True, max_iter=6857, positive=True, selection=random, tol=0.005725752508361204, warm_start=False;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.044088176352705406, copy_X=True, max_iter=6857, positive=True, selection=random, tol=0.005725752508361204, warm_start=False;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.044088176352705406, copy_X=True, max_iter=6857, positive=True, selection=random, tol=0.005725752508361204, warm_start=False;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1623246492985972, copy_X=True, max_iter=4340, positive=False, selection=cyclic, tol=0.008856187290969899, warm_start=False;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1623246492985972, copy_X=True, max_iter=4340, positive=False, selection=cyclic, tol=0.008856187290969899, warm_start=False;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.21142284569138275, copy_X=False, max_iter=7771, positive=True, selection=cyclic, tol=0.009096989966555185, warm_start=False;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.21142284569138275, copy_X=False, max_iter=7771, positive=True, selection=cyclic, tol=0.009096989966555185, warm_start=False;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.21142284569138275, copy_X=False, max_iter=7771, positive=True, selection=cyclic, tol=0.009096989966555185, warm_start=False;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.21142284569138275, copy_X=False, max_iter=7771, positive=True, selection=cyclic, tol=0.009096989966555185, warm_start=False;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.21142284569138275, copy_X=False, max_iter=7771, positive=True, selection=cyclic, tol=0.009096989966555185, warm_start=False;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.3577154308617234, copy_X=True, max_iter=7290, positive=True, selection=cyclic, tol=0.0044314381270903, warm_start=True;, score=0.881 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.17434869739478956, copy_X=False, max_iter=6665, positive=True, selection=cyclic, tol=0.00777257525083612, warm_start=True;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.17434869739478956, copy_X=False, max_iter=6665, positive=True, selection=cyclic, tol=0.00777257525083612, warm_start=True;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.17434869739478956, copy_X=False, max_iter=6665, positive=True, selection=cyclic, tol=0.00777257525083612, warm_start=True;, score=0.883 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.33266533066132264, copy_X=True, l1_ratio=0.2373737373737374, max_iter=7708, selection=random, tol=0.006381909547738693, warm_start=True;, score=0.693 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.49699398797595185, copy_X=True, l1_ratio=0.0, max_iter=8030, selection=random, tol=0.00308040201005025, warm_start=False;, score=0.602 total time=   0.4s\n",
      "[CV 2/5] END alpha=0.49699398797595185, copy_X=True, l1_ratio=0.0, max_iter=8030, selection=random, tol=0.00308040201005025, warm_start=False;, score=0.605 total time=   0.3s\n",
      "[CV 5/5] END alpha=0.002004008016032064, copy_X=True, l1_ratio=0.14141414141414144, max_iter=6743, selection=cyclic, tol=0.006562814070351758, warm_start=False;, score=0.872 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.3286573146292585, copy_X=True, max_iter=6312, positive=True, selection=random, tol=0.006779264214046822, warm_start=True;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.4158316633266533, copy_X=True, max_iter=4709, positive=True, selection=random, tol=0.007321070234113712, warm_start=True;, score=0.883 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.27955911823647295, copy_X=True, max_iter=5302, positive=True, selection=cyclic, tol=0.0017224080267558527, warm_start=True;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.27955911823647295, copy_X=True, max_iter=5302, positive=True, selection=cyclic, tol=0.0017224080267558527, warm_start=True;, score=0.892 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.18036072144288576, copy_X=False, max_iter=9246, positive=True, selection=random, tol=0.005996655518394648, warm_start=False;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.18036072144288576, copy_X=False, max_iter=9246, positive=True, selection=random, tol=0.005996655518394648, warm_start=False;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.18036072144288576, copy_X=False, max_iter=9246, positive=True, selection=random, tol=0.005996655518394648, warm_start=False;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.18036072144288576, copy_X=False, max_iter=9246, positive=True, selection=random, tol=0.005996655518394648, warm_start=False;, score=0.892 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1002004008016032, copy_X=False, max_iter=9246, positive=True, selection=random, tol=0.002836120401337792, warm_start=True;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1002004008016032, copy_X=False, max_iter=9246, positive=True, selection=random, tol=0.002836120401337792, warm_start=True;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.3977955911823647, copy_X=True, max_iter=6521, positive=True, selection=random, tol=0.009066889632107023, warm_start=False;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.3977955911823647, copy_X=True, max_iter=6521, positive=True, selection=random, tol=0.009066889632107023, warm_start=False;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.3286573146292585, copy_X=True, max_iter=5446, positive=True, selection=cyclic, tol=0.00440133779264214, warm_start=True;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.3286573146292585, copy_X=True, max_iter=5446, positive=True, selection=cyclic, tol=0.00440133779264214, warm_start=True;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.3286573146292585, copy_X=True, max_iter=5446, positive=True, selection=cyclic, tol=0.00440133779264214, warm_start=True;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.21042084168336672, copy_X=True, max_iter=5863, positive=True, selection=random, tol=0.006508361204013378, warm_start=True;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.21042084168336672, copy_X=True, max_iter=5863, positive=True, selection=random, tol=0.006508361204013378, warm_start=True;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.21042084168336672, copy_X=True, max_iter=5863, positive=True, selection=random, tol=0.006508361204013378, warm_start=True;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.21042084168336672, copy_X=True, max_iter=5863, positive=True, selection=random, tol=0.006508361204013378, warm_start=True;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.21042084168336672, copy_X=True, max_iter=5863, positive=True, selection=random, tol=0.006508361204013378, warm_start=True;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.4168336673346693, copy_X=False, max_iter=2961, positive=False, selection=cyclic, tol=0.008585284280936455, warm_start=True;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.4168336673346693, copy_X=False, max_iter=2961, positive=False, selection=cyclic, tol=0.008585284280936455, warm_start=True;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.4168336673346693, copy_X=False, max_iter=2961, positive=False, selection=cyclic, tol=0.008585284280936455, warm_start=True;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.4168336673346693, copy_X=False, max_iter=2961, positive=False, selection=cyclic, tol=0.008585284280936455, warm_start=True;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.4168336673346693, copy_X=False, max_iter=2961, positive=False, selection=cyclic, tol=0.008585284280936455, warm_start=True;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1623246492985972, copy_X=True, max_iter=4340, positive=False, selection=cyclic, tol=0.008856187290969899, warm_start=False;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1623246492985972, copy_X=True, max_iter=4340, positive=False, selection=cyclic, tol=0.008856187290969899, warm_start=False;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1623246492985972, copy_X=True, max_iter=4340, positive=False, selection=cyclic, tol=0.008856187290969899, warm_start=False;, score=0.918 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.023046092184368736, copy_X=False, max_iter=5815, positive=False, selection=cyclic, tol=0.0075919732441471575, warm_start=False;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.023046092184368736, copy_X=False, max_iter=5815, positive=False, selection=cyclic, tol=0.0075919732441471575, warm_start=False;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.023046092184368736, copy_X=False, max_iter=5815, positive=False, selection=cyclic, tol=0.0075919732441471575, warm_start=False;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.023046092184368736, copy_X=False, max_iter=5815, positive=False, selection=cyclic, tol=0.0075919732441471575, warm_start=False;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.11322645290581161, copy_X=True, max_iter=6136, positive=False, selection=cyclic, tol=0.0037993311036789296, warm_start=False;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.11322645290581161, copy_X=True, max_iter=6136, positive=False, selection=cyclic, tol=0.0037993311036789296, warm_start=False;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.11322645290581161, copy_X=True, max_iter=6136, positive=False, selection=cyclic, tol=0.0037993311036789296, warm_start=False;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.11322645290581161, copy_X=True, max_iter=6136, positive=False, selection=cyclic, tol=0.0037993311036789296, warm_start=False;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.11322645290581161, copy_X=True, max_iter=6136, positive=False, selection=cyclic, tol=0.0037993311036789296, warm_start=False;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.028056112224448895, copy_X=False, max_iter=3154, positive=False, selection=cyclic, tol=0.0016923076923076909, warm_start=False;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.028056112224448895, copy_X=False, max_iter=3154, positive=False, selection=cyclic, tol=0.0016923076923076909, warm_start=False;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.028056112224448895, copy_X=False, max_iter=3154, positive=False, selection=cyclic, tol=0.0016923076923076909, warm_start=False;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.028056112224448895, copy_X=False, max_iter=3154, positive=False, selection=cyclic, tol=0.0016923076923076909, warm_start=False;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.0721442885771543, copy_X=True, l1_ratio=0.4595959595959596, max_iter=3969, selection=random, tol=0.004979899497487436, warm_start=True;, score=0.818 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.002004008016032064, copy_X=True, l1_ratio=0.14141414141414144, max_iter=6743, selection=cyclic, tol=0.006562814070351758, warm_start=False;, score=0.896 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.3286573146292585, copy_X=True, max_iter=6312, positive=True, selection=random, tol=0.006779264214046822, warm_start=True;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.4158316633266533, copy_X=True, max_iter=4709, positive=True, selection=random, tol=0.007321070234113712, warm_start=True;, score=0.918 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.17635270541082163, copy_X=False, max_iter=2897, positive=True, selection=cyclic, tol=0.0013913043478260868, warm_start=True;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.17334669338677353, copy_X=True, max_iter=7130, positive=True, selection=cyclic, tol=0.0058461538461538455, warm_start=True;, score=0.881 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.27955911823647295, copy_X=True, max_iter=4613, positive=True, selection=cyclic, tol=0.007321070234113712, warm_start=True;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.27955911823647295, copy_X=True, max_iter=4613, positive=True, selection=cyclic, tol=0.007321070234113712, warm_start=True;, score=0.883 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1032064128256513, copy_X=False, max_iter=9118, positive=False, selection=cyclic, tol=0.0038294314381270896, warm_start=True;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1032064128256513, copy_X=False, max_iter=9118, positive=False, selection=cyclic, tol=0.0038294314381270896, warm_start=True;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1032064128256513, copy_X=False, max_iter=9118, positive=False, selection=cyclic, tol=0.0038294314381270896, warm_start=True;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1032064128256513, copy_X=False, max_iter=9118, positive=False, selection=cyclic, tol=0.0038294314381270896, warm_start=True;, score=0.883 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.03607214428857715, copy_X=False, max_iter=7402, positive=True, selection=random, tol=0.004762541806020066, warm_start=False;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1002004008016032, copy_X=False, max_iter=9246, positive=True, selection=random, tol=0.002836120401337792, warm_start=True;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1002004008016032, copy_X=False, max_iter=9246, positive=True, selection=random, tol=0.002836120401337792, warm_start=True;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1002004008016032, copy_X=False, max_iter=9246, positive=True, selection=random, tol=0.002836120401337792, warm_start=True;, score=0.918 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.041082164328657314, copy_X=True, max_iter=6344, positive=False, selection=random, tol=0.007351170568561873, warm_start=True;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.041082164328657314, copy_X=True, max_iter=6344, positive=False, selection=random, tol=0.007351170568561873, warm_start=True;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.041082164328657314, copy_X=True, max_iter=6344, positive=False, selection=random, tol=0.007351170568561873, warm_start=True;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.041082164328657314, copy_X=True, max_iter=6344, positive=False, selection=random, tol=0.007351170568561873, warm_start=True;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.044088176352705406, copy_X=True, max_iter=7370, positive=False, selection=random, tol=0.0015418060200668889, warm_start=True;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.044088176352705406, copy_X=True, max_iter=7370, positive=False, selection=random, tol=0.0015418060200668889, warm_start=True;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.044088176352705406, copy_X=True, max_iter=7370, positive=False, selection=random, tol=0.0015418060200668889, warm_start=True;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.044088176352705406, copy_X=True, max_iter=7370, positive=False, selection=random, tol=0.0015418060200668889, warm_start=True;, score=0.892 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.08316633266533066, copy_X=True, max_iter=4020, positive=True, selection=cyclic, tol=0.001301003344481605, warm_start=True;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.08316633266533066, copy_X=True, max_iter=4020, positive=True, selection=cyclic, tol=0.001301003344481605, warm_start=True;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.08316633266533066, copy_X=True, max_iter=4020, positive=True, selection=cyclic, tol=0.001301003344481605, warm_start=True;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.19238476953907813, copy_X=True, max_iter=9358, positive=True, selection=cyclic, tol=0.009729096989966556, warm_start=True;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.19238476953907813, copy_X=True, max_iter=9358, positive=True, selection=cyclic, tol=0.009729096989966556, warm_start=True;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.19238476953907813, copy_X=True, max_iter=9358, positive=True, selection=cyclic, tol=0.009729096989966556, warm_start=True;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.19238476953907813, copy_X=True, max_iter=9358, positive=True, selection=cyclic, tol=0.009729096989966556, warm_start=True;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.19238476953907813, copy_X=True, max_iter=9358, positive=True, selection=cyclic, tol=0.009729096989966556, warm_start=True;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.32665330661322645, copy_X=True, max_iter=3987, positive=True, selection=cyclic, tol=0.003498327759197324, warm_start=False;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.32665330661322645, copy_X=True, max_iter=3987, positive=True, selection=cyclic, tol=0.003498327759197324, warm_start=False;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.32665330661322645, copy_X=True, max_iter=3987, positive=True, selection=cyclic, tol=0.003498327759197324, warm_start=False;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.32665330661322645, copy_X=True, max_iter=3987, positive=True, selection=cyclic, tol=0.003498327759197324, warm_start=False;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.32665330661322645, copy_X=True, max_iter=3987, positive=True, selection=cyclic, tol=0.003498327759197324, warm_start=False;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.29058116232464926, copy_X=False, max_iter=7515, positive=False, selection=random, tol=0.002806020066889631, warm_start=False;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.29058116232464926, copy_X=False, max_iter=7515, positive=False, selection=random, tol=0.002806020066889631, warm_start=False;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.29058116232464926, copy_X=False, max_iter=7515, positive=False, selection=random, tol=0.002806020066889631, warm_start=False;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.29058116232464926, copy_X=False, max_iter=7515, positive=False, selection=random, tol=0.002806020066889631, warm_start=False;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.29058116232464926, copy_X=False, max_iter=7515, positive=False, selection=random, tol=0.002806020066889631, warm_start=False;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.4569138276553106, copy_X=False, max_iter=9807, positive=True, selection=cyclic, tol=0.008525083612040133, warm_start=False;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.4569138276553106, copy_X=False, max_iter=9807, positive=True, selection=cyclic, tol=0.008525083612040133, warm_start=False;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.4569138276553106, copy_X=False, max_iter=9807, positive=True, selection=cyclic, tol=0.008525083612040133, warm_start=False;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.4569138276553106, copy_X=False, max_iter=9807, positive=True, selection=cyclic, tol=0.008525083612040133, warm_start=False;, score=0.892 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1032064128256513, copy_X=False, max_iter=9118, positive=False, selection=cyclic, tol=0.0038294314381270896, warm_start=True;, score=0.881 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.18036072144288576, copy_X=False, max_iter=9246, positive=True, selection=random, tol=0.005996655518394648, warm_start=False;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.25551102204408815, copy_X=False, max_iter=4725, positive=True, selection=cyclic, tol=0.005575250836120401, warm_start=False;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.25551102204408815, copy_X=False, max_iter=4725, positive=True, selection=cyclic, tol=0.005575250836120401, warm_start=False;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.25551102204408815, copy_X=False, max_iter=4725, positive=True, selection=cyclic, tol=0.005575250836120401, warm_start=False;, score=0.918 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.03607214428857715, copy_X=False, max_iter=7402, positive=True, selection=random, tol=0.004762541806020066, warm_start=False;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.03607214428857715, copy_X=False, max_iter=7402, positive=True, selection=random, tol=0.004762541806020066, warm_start=False;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.03607214428857715, copy_X=False, max_iter=7402, positive=True, selection=random, tol=0.004762541806020066, warm_start=False;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.03607214428857715, copy_X=False, max_iter=7402, positive=True, selection=random, tol=0.004762541806020066, warm_start=False;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.001002004008016032, copy_X=True, max_iter=8300, positive=False, selection=cyclic, tol=0.004461538461538461, warm_start=False;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.3256513026052104, copy_X=True, max_iter=8220, positive=True, selection=random, tol=0.0026856187290969892, warm_start=False;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.3256513026052104, copy_X=True, max_iter=8220, positive=True, selection=random, tol=0.0026856187290969892, warm_start=False;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.3256513026052104, copy_X=True, max_iter=8220, positive=True, selection=random, tol=0.0026856187290969892, warm_start=False;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.3256513026052104, copy_X=True, max_iter=8220, positive=True, selection=random, tol=0.0026856187290969892, warm_start=False;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.3256513026052104, copy_X=True, max_iter=8220, positive=True, selection=random, tol=0.0026856187290969892, warm_start=False;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.3286573146292585, copy_X=True, max_iter=5446, positive=True, selection=cyclic, tol=0.00440133779264214, warm_start=True;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.3286573146292585, copy_X=True, max_iter=5446, positive=True, selection=cyclic, tol=0.00440133779264214, warm_start=True;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.24949899799599196, copy_X=False, max_iter=4132, positive=False, selection=random, tol=0.001331103678929765, warm_start=False;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.24949899799599196, copy_X=False, max_iter=4132, positive=False, selection=random, tol=0.001331103678929765, warm_start=False;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.24949899799599196, copy_X=False, max_iter=4132, positive=False, selection=random, tol=0.001331103678929765, warm_start=False;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.08316633266533066, copy_X=False, max_iter=2176, positive=True, selection=random, tol=0.0022040133779264205, warm_start=False;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.08316633266533066, copy_X=False, max_iter=2176, positive=True, selection=random, tol=0.0022040133779264205, warm_start=False;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.08316633266533066, copy_X=False, max_iter=2176, positive=True, selection=random, tol=0.0022040133779264205, warm_start=False;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.08316633266533066, copy_X=False, max_iter=2176, positive=True, selection=random, tol=0.0022040133779264205, warm_start=False;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.08316633266533066, copy_X=False, max_iter=2176, positive=True, selection=random, tol=0.0022040133779264205, warm_start=False;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.3226452905811623, copy_X=False, max_iter=4757, positive=False, selection=random, tol=0.004250836120401337, warm_start=True;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.3226452905811623, copy_X=False, max_iter=4757, positive=False, selection=random, tol=0.004250836120401337, warm_start=True;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.3226452905811623, copy_X=False, max_iter=4757, positive=False, selection=random, tol=0.004250836120401337, warm_start=True;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.3226452905811623, copy_X=False, max_iter=4757, positive=False, selection=random, tol=0.004250836120401337, warm_start=True;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.3226452905811623, copy_X=False, max_iter=4757, positive=False, selection=random, tol=0.004250836120401337, warm_start=True;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.30561122244488975, copy_X=True, max_iter=4629, positive=False, selection=random, tol=0.007892976588628763, warm_start=True;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.30561122244488975, copy_X=True, max_iter=4629, positive=False, selection=random, tol=0.007892976588628763, warm_start=True;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.30561122244488975, copy_X=True, max_iter=4629, positive=False, selection=random, tol=0.007892976588628763, warm_start=True;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.30561122244488975, copy_X=True, max_iter=4629, positive=False, selection=random, tol=0.007892976588628763, warm_start=True;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.30561122244488975, copy_X=True, max_iter=4629, positive=False, selection=random, tol=0.007892976588628763, warm_start=True;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.11623246492985971, copy_X=True, max_iter=8637, positive=True, selection=random, tol=0.0059364548494983274, warm_start=True;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.11623246492985971, copy_X=True, max_iter=8637, positive=True, selection=random, tol=0.0059364548494983274, warm_start=True;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.11623246492985971, copy_X=True, max_iter=8637, positive=True, selection=random, tol=0.0059364548494983274, warm_start=True;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.11623246492985971, copy_X=True, max_iter=8637, positive=True, selection=random, tol=0.0059364548494983274, warm_start=True;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.11623246492985971, copy_X=True, max_iter=8637, positive=True, selection=random, tol=0.0059364548494983274, warm_start=True;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.023046092184368736, copy_X=False, max_iter=5815, positive=False, selection=cyclic, tol=0.0075919732441471575, warm_start=False;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.03507014028056112, copy_X=False, max_iter=8621, positive=True, selection=cyclic, tol=0.005605351170568562, warm_start=False;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.03507014028056112, copy_X=False, max_iter=8621, positive=True, selection=cyclic, tol=0.005605351170568562, warm_start=False;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.03507014028056112, copy_X=False, max_iter=8621, positive=True, selection=cyclic, tol=0.005605351170568562, warm_start=False;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.03507014028056112, copy_X=False, max_iter=8621, positive=True, selection=cyclic, tol=0.005605351170568562, warm_start=False;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.3727454909819639, copy_X=True, max_iter=4020, positive=True, selection=cyclic, tol=0.006327759197324414, warm_start=False;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1783567134268537, copy_X=False, max_iter=8605, positive=True, selection=cyclic, tol=0.006779264214046822, warm_start=True;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.3727454909819639, copy_X=True, max_iter=7771, positive=True, selection=random, tol=0.005214046822742475, warm_start=False;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.3727454909819639, copy_X=True, max_iter=7771, positive=True, selection=random, tol=0.005214046822742475, warm_start=False;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.3727454909819639, copy_X=True, max_iter=7771, positive=True, selection=random, tol=0.005214046822742475, warm_start=False;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.27054108216432865, copy_X=True, max_iter=2400, positive=True, selection=random, tol=0.003107023411371237, warm_start=True;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.37975951903807614, copy_X=False, max_iter=9935, positive=False, selection=cyclic, tol=0.004882943143812709, warm_start=False;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.37975951903807614, copy_X=False, max_iter=9935, positive=False, selection=cyclic, tol=0.004882943143812709, warm_start=False;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.37975951903807614, copy_X=False, max_iter=9935, positive=False, selection=cyclic, tol=0.004882943143812709, warm_start=False;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.37975951903807614, copy_X=False, max_iter=9935, positive=False, selection=cyclic, tol=0.004882943143812709, warm_start=False;, score=0.883 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.044088176352705406, copy_X=True, max_iter=6857, positive=True, selection=random, tol=0.005725752508361204, warm_start=False;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.044088176352705406, copy_X=True, max_iter=6857, positive=True, selection=random, tol=0.005725752508361204, warm_start=False;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.012024048096192383, copy_X=False, max_iter=4324, positive=False, selection=cyclic, tol=0.004521739130434782, warm_start=True;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.012024048096192383, copy_X=False, max_iter=4324, positive=False, selection=cyclic, tol=0.004521739130434782, warm_start=True;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.012024048096192383, copy_X=False, max_iter=4324, positive=False, selection=cyclic, tol=0.004521739130434782, warm_start=True;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.012024048096192383, copy_X=False, max_iter=4324, positive=False, selection=cyclic, tol=0.004521739130434782, warm_start=True;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.012024048096192383, copy_X=False, max_iter=4324, positive=False, selection=cyclic, tol=0.004521739130434782, warm_start=True;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.041082164328657314, copy_X=True, max_iter=6344, positive=False, selection=random, tol=0.007351170568561873, warm_start=True;, score=0.881 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.0250501002004008, copy_X=True, max_iter=9583, positive=False, selection=cyclic, tol=0.00942809364548495, warm_start=True;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1653306613226453, copy_X=True, max_iter=8124, positive=True, selection=random, tol=0.007501672240802676, warm_start=False;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1653306613226453, copy_X=True, max_iter=8124, positive=True, selection=random, tol=0.007501672240802676, warm_start=False;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1653306613226453, copy_X=True, max_iter=8124, positive=True, selection=random, tol=0.007501672240802676, warm_start=False;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1653306613226453, copy_X=True, max_iter=8124, positive=True, selection=random, tol=0.007501672240802676, warm_start=False;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1653306613226453, copy_X=True, max_iter=8124, positive=True, selection=random, tol=0.007501672240802676, warm_start=False;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.08316633266533066, copy_X=True, max_iter=4020, positive=True, selection=cyclic, tol=0.001301003344481605, warm_start=True;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.08316633266533066, copy_X=True, max_iter=4020, positive=True, selection=cyclic, tol=0.001301003344481605, warm_start=True;, score=0.905 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.19639278557114226, copy_X=False, max_iter=7547, positive=False, selection=cyclic, tol=0.003347826086956521, warm_start=False;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.06112224448897795, copy_X=False, max_iter=2641, positive=False, selection=cyclic, tol=0.004250836120401337, warm_start=True;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.06112224448897795, copy_X=False, max_iter=2641, positive=False, selection=cyclic, tol=0.004250836120401337, warm_start=True;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.06112224448897795, copy_X=False, max_iter=2641, positive=False, selection=cyclic, tol=0.004250836120401337, warm_start=True;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.06112224448897795, copy_X=False, max_iter=2641, positive=False, selection=cyclic, tol=0.004250836120401337, warm_start=True;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.06112224448897795, copy_X=False, max_iter=2641, positive=False, selection=cyclic, tol=0.004250836120401337, warm_start=True;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.3106212424849699, copy_X=True, max_iter=5975, positive=True, selection=cyclic, tol=0.0056354515050167225, warm_start=True;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.3106212424849699, copy_X=True, max_iter=5975, positive=True, selection=cyclic, tol=0.0056354515050167225, warm_start=True;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.3106212424849699, copy_X=True, max_iter=5975, positive=True, selection=cyclic, tol=0.0056354515050167225, warm_start=True;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.3106212424849699, copy_X=True, max_iter=5975, positive=True, selection=cyclic, tol=0.0056354515050167225, warm_start=True;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.3106212424849699, copy_X=True, max_iter=5975, positive=True, selection=cyclic, tol=0.0056354515050167225, warm_start=True;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.4639278557114228, copy_X=True, max_iter=3667, positive=False, selection=random, tol=0.007682274247491639, warm_start=False;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.4639278557114228, copy_X=True, max_iter=3667, positive=False, selection=random, tol=0.007682274247491639, warm_start=False;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.4639278557114228, copy_X=True, max_iter=3667, positive=False, selection=random, tol=0.007682274247491639, warm_start=False;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.4639278557114228, copy_X=True, max_iter=3667, positive=False, selection=random, tol=0.007682274247491639, warm_start=False;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.4639278557114228, copy_X=True, max_iter=3667, positive=False, selection=random, tol=0.007682274247491639, warm_start=False;, score=0.883 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.07114228456913826, copy_X=True, max_iter=2496, positive=False, selection=random, tol=0.007020066889632107, warm_start=True;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.07114228456913826, copy_X=True, max_iter=2496, positive=False, selection=random, tol=0.007020066889632107, warm_start=True;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.07114228456913826, copy_X=True, max_iter=2496, positive=False, selection=random, tol=0.007020066889632107, warm_start=True;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.07114228456913826, copy_X=True, max_iter=2496, positive=False, selection=random, tol=0.007020066889632107, warm_start=True;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.15531062124248496, copy_X=True, max_iter=5959, positive=True, selection=random, tol=0.009548494983277592, warm_start=False;, score=0.881 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.2004008016032064, copy_X=True, max_iter=4693, positive=False, selection=cyclic, tol=0.007923076923076923, warm_start=True;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.2004008016032064, copy_X=True, max_iter=4693, positive=False, selection=cyclic, tol=0.007923076923076923, warm_start=True;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.24949899799599196, copy_X=False, max_iter=4132, positive=False, selection=random, tol=0.001331103678929765, warm_start=False;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.24949899799599196, copy_X=False, max_iter=4132, positive=False, selection=random, tol=0.001331103678929765, warm_start=False;, score=0.905 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.3577154308617234, copy_X=True, max_iter=7290, positive=True, selection=cyclic, tol=0.0044314381270903, warm_start=True;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.3577154308617234, copy_X=True, max_iter=7290, positive=True, selection=cyclic, tol=0.0044314381270903, warm_start=True;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.3577154308617234, copy_X=True, max_iter=7290, positive=True, selection=cyclic, tol=0.0044314381270903, warm_start=True;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.3577154308617234, copy_X=True, max_iter=7290, positive=True, selection=cyclic, tol=0.0044314381270903, warm_start=True;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.0250501002004008, copy_X=True, max_iter=9583, positive=False, selection=cyclic, tol=0.00942809364548495, warm_start=True;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.0250501002004008, copy_X=True, max_iter=9583, positive=False, selection=cyclic, tol=0.00942809364548495, warm_start=True;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.0250501002004008, copy_X=True, max_iter=9583, positive=False, selection=cyclic, tol=0.00942809364548495, warm_start=True;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.0250501002004008, copy_X=True, max_iter=9583, positive=False, selection=cyclic, tol=0.00942809364548495, warm_start=True;, score=0.892 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.4318637274549098, copy_X=True, max_iter=7306, positive=False, selection=random, tol=0.005394648829431438, warm_start=False;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.4318637274549098, copy_X=True, max_iter=7306, positive=False, selection=random, tol=0.005394648829431438, warm_start=False;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.3276553106212425, copy_X=False, max_iter=9406, positive=False, selection=random, tol=0.006357859531772575, warm_start=False;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.3276553106212425, copy_X=False, max_iter=9406, positive=False, selection=random, tol=0.006357859531772575, warm_start=False;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.3276553106212425, copy_X=False, max_iter=9406, positive=False, selection=random, tol=0.006357859531772575, warm_start=False;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.3276553106212425, copy_X=False, max_iter=9406, positive=False, selection=random, tol=0.006357859531772575, warm_start=False;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.3276553106212425, copy_X=False, max_iter=9406, positive=False, selection=random, tol=0.006357859531772575, warm_start=False;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.21843687374749496, copy_X=True, max_iter=8332, positive=False, selection=random, tol=0.0037692307692307686, warm_start=True;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.21843687374749496, copy_X=True, max_iter=8332, positive=False, selection=random, tol=0.0037692307692307686, warm_start=True;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.21843687374749496, copy_X=True, max_iter=8332, positive=False, selection=random, tol=0.0037692307692307686, warm_start=True;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.21843687374749496, copy_X=True, max_iter=8332, positive=False, selection=random, tol=0.0037692307692307686, warm_start=True;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.21843687374749496, copy_X=True, max_iter=8332, positive=False, selection=random, tol=0.0037692307692307686, warm_start=True;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.19639278557114226, copy_X=False, max_iter=7547, positive=False, selection=cyclic, tol=0.003347826086956521, warm_start=False;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.19639278557114226, copy_X=False, max_iter=7547, positive=False, selection=cyclic, tol=0.003347826086956521, warm_start=False;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.19639278557114226, copy_X=False, max_iter=7547, positive=False, selection=cyclic, tol=0.003347826086956521, warm_start=False;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.19639278557114226, copy_X=False, max_iter=7547, positive=False, selection=cyclic, tol=0.003347826086956521, warm_start=False;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.15831663326653306, copy_X=True, max_iter=7819, positive=True, selection=random, tol=0.0011204013377926411, warm_start=False;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.12625250501002003, copy_X=True, max_iter=3026, positive=True, selection=random, tol=0.00440133779264214, warm_start=False;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.12625250501002003, copy_X=True, max_iter=3026, positive=True, selection=random, tol=0.00440133779264214, warm_start=False;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.12625250501002003, copy_X=True, max_iter=3026, positive=True, selection=random, tol=0.00440133779264214, warm_start=False;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.12625250501002003, copy_X=True, max_iter=3026, positive=True, selection=random, tol=0.00440133779264214, warm_start=False;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.12625250501002003, copy_X=True, max_iter=3026, positive=True, selection=random, tol=0.00440133779264214, warm_start=False;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.3507014028056112, copy_X=False, max_iter=5591, positive=False, selection=random, tol=0.0011204013377926411, warm_start=True;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.3507014028056112, copy_X=False, max_iter=5591, positive=False, selection=random, tol=0.0011204013377926411, warm_start=True;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.3507014028056112, copy_X=False, max_iter=5591, positive=False, selection=random, tol=0.0011204013377926411, warm_start=True;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.3507014028056112, copy_X=False, max_iter=5591, positive=False, selection=random, tol=0.0011204013377926411, warm_start=True;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.3507014028056112, copy_X=False, max_iter=5591, positive=False, selection=random, tol=0.0011204013377926411, warm_start=True;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.03707414829659318, copy_X=True, max_iter=6553, positive=True, selection=random, tol=0.0056354515050167225, warm_start=False;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.03707414829659318, copy_X=True, max_iter=6553, positive=True, selection=random, tol=0.0056354515050167225, warm_start=False;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.03707414829659318, copy_X=True, max_iter=6553, positive=True, selection=random, tol=0.0056354515050167225, warm_start=False;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.03707414829659318, copy_X=True, max_iter=6553, positive=True, selection=random, tol=0.0056354515050167225, warm_start=False;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.03707414829659318, copy_X=True, max_iter=6553, positive=True, selection=random, tol=0.0056354515050167225, warm_start=False;, score=0.883 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.25250501002004005, copy_X=True, max_iter=5094, positive=False, selection=cyclic, tol=0.0019331103678929765, warm_start=True;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.2955911823647294, copy_X=False, max_iter=6104, positive=False, selection=cyclic, tol=0.0023545150501672234, warm_start=True;, score=0.881 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.4138276553106212, copy_X=True, max_iter=5206, positive=False, selection=cyclic, tol=0.006869565217391304, warm_start=False;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.4138276553106212, copy_X=True, max_iter=5206, positive=False, selection=cyclic, tol=0.006869565217391304, warm_start=False;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.4138276553106212, copy_X=True, max_iter=5206, positive=False, selection=cyclic, tol=0.006869565217391304, warm_start=False;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.4138276553106212, copy_X=True, max_iter=5206, positive=False, selection=cyclic, tol=0.006869565217391304, warm_start=False;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.4138276553106212, copy_X=True, max_iter=5206, positive=False, selection=cyclic, tol=0.006869565217391304, warm_start=False;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.32965931863727455, copy_X=False, max_iter=5158, positive=False, selection=random, tol=0.006478260869565217, warm_start=False;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.32965931863727455, copy_X=False, max_iter=5158, positive=False, selection=random, tol=0.006478260869565217, warm_start=False;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.32965931863727455, copy_X=False, max_iter=5158, positive=False, selection=random, tol=0.006478260869565217, warm_start=False;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.32965931863727455, copy_X=False, max_iter=5158, positive=False, selection=random, tol=0.006478260869565217, warm_start=False;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.32965931863727455, copy_X=False, max_iter=5158, positive=False, selection=random, tol=0.006478260869565217, warm_start=False;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.4318637274549098, copy_X=True, max_iter=7306, positive=False, selection=random, tol=0.005394648829431438, warm_start=False;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.4318637274549098, copy_X=True, max_iter=7306, positive=False, selection=random, tol=0.005394648829431438, warm_start=False;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.4318637274549098, copy_X=True, max_iter=7306, positive=False, selection=random, tol=0.005394648829431438, warm_start=False;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.4929859719438877, copy_X=True, max_iter=7915, positive=True, selection=random, tol=0.005665551839464883, warm_start=False;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.4929859719438877, copy_X=True, max_iter=7915, positive=True, selection=random, tol=0.005665551839464883, warm_start=False;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1753507014028056, copy_X=True, max_iter=5174, positive=False, selection=random, tol=0.007050167224080268, warm_start=False;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1753507014028056, copy_X=True, max_iter=5174, positive=False, selection=random, tol=0.007050167224080268, warm_start=False;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1753507014028056, copy_X=True, max_iter=5174, positive=False, selection=random, tol=0.007050167224080268, warm_start=False;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1753507014028056, copy_X=True, max_iter=5174, positive=False, selection=random, tol=0.007050167224080268, warm_start=False;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1753507014028056, copy_X=True, max_iter=5174, positive=False, selection=random, tol=0.007050167224080268, warm_start=False;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.406813627254509, copy_X=False, max_iter=5511, positive=True, selection=cyclic, tol=0.00714046822742475, warm_start=True;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.406813627254509, copy_X=False, max_iter=5511, positive=True, selection=cyclic, tol=0.00714046822742475, warm_start=True;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.406813627254509, copy_X=False, max_iter=5511, positive=True, selection=cyclic, tol=0.00714046822742475, warm_start=True;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.406813627254509, copy_X=False, max_iter=5511, positive=True, selection=cyclic, tol=0.00714046822742475, warm_start=True;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.406813627254509, copy_X=False, max_iter=5511, positive=True, selection=cyclic, tol=0.00714046822742475, warm_start=True;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.15831663326653306, copy_X=True, max_iter=7819, positive=True, selection=random, tol=0.0011204013377926411, warm_start=False;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.15831663326653306, copy_X=True, max_iter=7819, positive=True, selection=random, tol=0.0011204013377926411, warm_start=False;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.15831663326653306, copy_X=True, max_iter=7819, positive=True, selection=random, tol=0.0011204013377926411, warm_start=False;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.15831663326653306, copy_X=True, max_iter=7819, positive=True, selection=random, tol=0.0011204013377926411, warm_start=False;, score=0.892 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.25250501002004005, copy_X=True, max_iter=5094, positive=False, selection=cyclic, tol=0.0019331103678929765, warm_start=True;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.25250501002004005, copy_X=True, max_iter=5094, positive=False, selection=cyclic, tol=0.0019331103678929765, warm_start=True;, score=0.905 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.2955911823647294, copy_X=False, max_iter=6104, positive=False, selection=cyclic, tol=0.0023545150501672234, warm_start=True;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.2955911823647294, copy_X=False, max_iter=6104, positive=False, selection=cyclic, tol=0.0023545150501672234, warm_start=True;, score=0.883 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.027054108216432865, copy_X=False, max_iter=9727, positive=True, selection=random, tol=0.00325752508361204, warm_start=True;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.027054108216432865, copy_X=False, max_iter=9727, positive=True, selection=random, tol=0.00325752508361204, warm_start=True;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.35571142284569135, copy_X=False, max_iter=3843, positive=False, selection=cyclic, tol=0.007682274247491639, warm_start=False;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.35571142284569135, copy_X=False, max_iter=3843, positive=False, selection=cyclic, tol=0.007682274247491639, warm_start=False;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.35571142284569135, copy_X=False, max_iter=7482, positive=True, selection=random, tol=0.006719063545150502, warm_start=True;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.35571142284569135, copy_X=False, max_iter=7482, positive=True, selection=random, tol=0.006719063545150502, warm_start=True;, score=0.905 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.37074148296593185, copy_X=True, max_iter=4965, positive=False, selection=cyclic, tol=0.005183946488294314, warm_start=True;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.37074148296593185, copy_X=True, max_iter=4965, positive=False, selection=cyclic, tol=0.005183946488294314, warm_start=True;, score=0.883 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.4098196392785571, copy_X=False, max_iter=7194, positive=True, selection=random, tol=0.00888628762541806, warm_start=True;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.4098196392785571, copy_X=False, max_iter=7194, positive=True, selection=random, tol=0.00888628762541806, warm_start=True;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.13226452905811623, copy_X=False, max_iter=2128, positive=True, selection=cyclic, tol=0.008013377926421405, warm_start=True;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.13226452905811623, copy_X=False, max_iter=2128, positive=True, selection=cyclic, tol=0.008013377926421405, warm_start=True;, score=0.905 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.27054108216432865, copy_X=True, max_iter=7803, positive=False, selection=random, tol=0.005424749163879599, warm_start=False;, score=0.892 total time=   0.0s\n",
      "Lasso() RandomCV Best Params : {'warm_start': 'False', 'tol': 0.005394648829431438, 'selection': 'random', 'positive': 'False', 'max_iter': 7306, 'copy_X': 'True', 'alpha': 0.4318637274549098}\n",
      "Lasso() RandomCV Score: 0.863699700265015\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Final score is  0.8636966761305713\n"
     ]
    }
   ],
   "source": [
    "hyperparameter_tuning(algo=\"Lasso()\",param_grid=random_grid,n_iter=100,cv=5,verbose=3,random_state=42,X_train=X_train.loc[:,list(selected_features)],Y_train=Y_train,X_test=X_test.loc[:,list(selected_features)],Y_test=Y_test,evaluation_metric=\"r2_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "d2478cae-cfb2-4097-89e0-cdb761482721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "1f8d1eaa-1a6f-419a-b24e-38517cea15f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  62 out of  62 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:36] Features: 1/62 -- score: 0.6776702727966265[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  61 out of  61 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:36] Features: 2/62 -- score: 0.7548308929184657[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:36] Features: 3/62 -- score: 0.817083647269284[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  59 out of  59 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:36] Features: 4/62 -- score: 0.8413284453405584[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  58 out of  58 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:37] Features: 5/62 -- score: 0.8573931678309201[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  57 out of  57 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:37] Features: 6/62 -- score: 0.8656202037913531[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  56 out of  56 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:37] Features: 7/62 -- score: 0.8718858435134651[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  55 out of  55 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:37] Features: 8/62 -- score: 0.8761724700574041[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  54 out of  54 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:37] Features: 9/62 -- score: 0.8807198954471278[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  53 out of  53 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:37] Features: 10/62 -- score: 0.8847959701636043[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  52 out of  52 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:37] Features: 11/62 -- score: 0.8879827000146634[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  51 out of  51 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:37] Features: 12/62 -- score: 0.8908880210243403[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:38] Features: 13/62 -- score: 0.8934583366963089[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  38 out of  49 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  49 out of  49 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:38] Features: 14/62 -- score: 0.8945797133390793[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:38] Features: 15/62 -- score: 0.8953546424418601[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  47 out of  47 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:38] Features: 16/62 -- score: 0.8960577832414641[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  46 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  46 out of  46 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:38] Features: 17/62 -- score: 0.8967017658131221[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:38] Features: 18/62 -- score: 0.8972696084721674[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 out of  44 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  44 out of  44 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:38] Features: 19/62 -- score: 0.8979667173046473[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  43 out of  43 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:38] Features: 20/62 -- score: 0.898420011851025[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 out of  42 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:38] Features: 21/62 -- score: 0.898769265694144[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  41 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  41 out of  41 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:39] Features: 22/62 -- score: 0.8990784543682[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:39] Features: 23/62 -- score: 0.8993869226305076[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  28 out of  39 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  39 out of  39 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:39] Features: 24/62 -- score: 0.8997040596441179[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  38 out of  38 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:39] Features: 25/62 -- score: 0.8998217914758527[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 out of  37 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  37 out of  37 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:39] Features: 26/62 -- score: 0.8999527167779829[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  36 out of  36 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:39] Features: 27/62 -- score: 0.9000583566918114[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  35 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:39] Features: 28/62 -- score: 0.9001179934458655[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  23 out of  34 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  34 out of  34 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:39] Features: 29/62 -- score: 0.9001605932751927[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  22 out of  33 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  33 out of  33 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:39] Features: 30/62 -- score: 0.9002100633013214[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  21 out of  32 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  32 out of  32 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:40] Features: 31/62 -- score: 0.900235483410361[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  31 out of  31 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:40] Features: 32/62 -- score: 0.900235483410361[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:40] Features: 33/62 -- score: 0.9002193912662314[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  29 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  29 out of  29 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:40] Features: 34/62 -- score: 0.9001935978851501[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  28 out of  28 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:40] Features: 35/62 -- score: 0.9001481558732699[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  27 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:40] Features: 36/62 -- score: 0.9000941043677322[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 out of  26 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:40] Features: 37/62 -- score: 0.9000346330160485[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  14 out of  25 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:40] Features: 38/62 -- score: 0.8999011839897207[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:40] Features: 39/62 -- score: 0.8997481481013139[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  23 out of  23 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:40] Features: 40/62 -- score: 0.8995894319969541[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  22 out of  22 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:40] Features: 41/62 -- score: 0.8994175451579652[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  21 out of  21 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  21 out of  21 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:40] Features: 42/62 -- score: 0.8992029849189038[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:41] Features: 43/62 -- score: 0.8990442241986913[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  19 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:41] Features: 44/62 -- score: 0.8988846854502792[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  18 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:41] Features: 45/62 -- score: 0.898670707026621[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  17 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  17 out of  17 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:41] Features: 46/62 -- score: 0.8984536281335563[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  14 out of  16 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  16 out of  16 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:41] Features: 47/62 -- score: 0.8982202516983382[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  15 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:41] Features: 48/62 -- score: 0.8979376784543099[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  14 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  14 out of  14 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:41] Features: 49/62 -- score: 0.897622979941483[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of  13 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  13 out of  13 | elapsed:    0.1s finished\n",
      "\n",
      "[2023-02-01 16:22:41] Features: 50/62 -- score: 0.8974605421018188[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  12 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    0.0s finished\n",
      "\n",
      "[2023-02-01 16:22:41] Features: 51/62 -- score: 0.8971513806869584[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  11 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  11 | elapsed:    0.0s finished\n",
      "\n",
      "[2023-02-01 16:22:41] Features: 52/62 -- score: 0.896806331988428[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "\n",
      "[2023-02-01 16:22:41] Features: 53/62 -- score: 0.8965826503914387[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:    0.0s finished\n",
      "\n",
      "[2023-02-01 16:22:41] Features: 54/62 -- score: 0.8962688181053929[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   8 | elapsed:    0.0s remaining:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features ('LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'BsmtFinSF1', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', 'GrLivArea', 'FullBath', 'BedroomAbvGr', 'Fireplaces', 'GarageYrBlt', 'GarageCars', 'Street', 'LandContour', 'Neighborhood', 'Condition1', 'MasVnrType', 'Foundation', 'BsmtQual', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'HeatingQC', 'KitchenQual', 'Functional', 'GarageType', 'SaleType')\n",
      "Prediction using selected features using Ridge() is : 0.875279031226215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.0s finished\n",
      "\n",
      "[2023-02-01 16:22:41] Features: 55/62 -- score: 0.8958429392986638[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of   7 | elapsed:    0.0s finished\n",
      "\n",
      "[2023-02-01 16:22:41] Features: 56/62 -- score: 0.8953674495181028[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.0s finished\n",
      "\n",
      "[2023-02-01 16:22:41] Features: 57/62 -- score: 0.8949155408692624[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.0s finished\n",
      "\n",
      "[2023-02-01 16:22:41] Features: 58/62 -- score: 0.8944356475362005[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    0.0s finished\n",
      "\n",
      "[2023-02-01 16:22:41] Features: 59/62 -- score: 0.8938610043927[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "\n",
      "[2023-02-01 16:22:41] Features: 60/62 -- score: 0.8928658991054348[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "\n",
      "[2023-02-01 16:22:41] Features: 61/62 -- score: 0.8919140790850223[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "\n",
      "[2023-02-01 16:22:41] Features: 62/62 -- score: 0.8904638225301522"
     ]
    }
   ],
   "source": [
    "selected_features=sf_selector(algo=\"Ridge()\",forward=True,floating=False,scoring=\"r2\",X_train=X_train,Y_train=Y_train,X_test=X_test,Y_test=Y_test,min_featues=3,cv=5,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "7c5ae5a0-a815-4a03-b86f-03a0943557e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': [0.1, 0.10100250626566416, 0.10200501253132832, 0.10300751879699249, 0.10401002506265665, 0.10501253132832081, 0.10601503759398496, 0.10701754385964912, 0.1080200501253133, 0.10902255639097745, 0.11002506265664161, 0.11102756892230577, 0.11203007518796992, 0.1130325814536341, 0.11403508771929825, 0.11503759398496241, 0.11604010025062657, 0.11704260651629073, 0.1180451127819549, 0.11904761904761905, 0.12005012531328321, 0.12105263157894737, 0.12205513784461153, 0.1230576441102757, 0.12406015037593986, 0.12506265664160401, 0.12606516290726819, 0.12706766917293233, 0.1280701754385965, 0.12907268170426067, 0.13007518796992482, 0.131077694235589, 0.13208020050125313, 0.1330827067669173, 0.13408521303258147, 0.13508771929824562, 0.1360902255639098, 0.13709273182957393, 0.1380952380952381, 0.13909774436090228, 0.14010025062656642, 0.1411027568922306, 0.14210526315789473, 0.1431077694235589, 0.14411027568922308, 0.14511278195488722, 0.1461152882205514, 0.14711779448621554, 0.1481203007518797, 0.14912280701754388, 0.15012531328320802, 0.1511278195488722, 0.15213032581453634, 0.1531328320802005, 0.15413533834586468, 0.15513784461152882, 0.156140350877193, 0.15714285714285714, 0.1581453634085213, 0.15914786967418548, 0.16015037593984963, 0.1611528822055138, 0.16215538847117794, 0.1631578947368421, 0.16416040100250628, 0.16516290726817043, 0.16616541353383457, 0.16716791979949874, 0.16817042606516291, 0.16917293233082709, 0.17017543859649123, 0.17117794486215537, 0.17218045112781954, 0.17318295739348372, 0.1741854636591479, 0.17518796992481203, 0.17619047619047618, 0.17719298245614035, 0.17819548872180452, 0.1791979949874687, 0.18020050125313283, 0.18120300751879698, 0.18220551378446115, 0.18320802005012532, 0.1842105263157895, 0.18521303258145363, 0.18621553884711778, 0.18721804511278195, 0.18822055137844612, 0.1892230576441103, 0.19022556390977444, 0.19122807017543858, 0.19223057644110275, 0.19323308270676692, 0.1942355889724311, 0.19523809523809524, 0.1962406015037594, 0.19724310776942355, 0.19824561403508772, 0.1992481203007519, 0.20025062656641604, 0.2012531328320802, 0.20225563909774436, 0.20325814536340853, 0.2042606516290727, 0.20526315789473684, 0.206265664160401, 0.20726817042606516, 0.20827067669172933, 0.2092731829573935, 0.21027568922305764, 0.21127819548872181, 0.21228070175438596, 0.21328320802005013, 0.2142857142857143, 0.21528822055137845, 0.21629072681704262, 0.21729323308270676, 0.21829573934837093, 0.2192982456140351, 0.22030075187969925, 0.22130325814536342, 0.22230576441102756, 0.22330827067669173, 0.2243107769423559, 0.22531328320802005, 0.22631578947368422, 0.22731829573934836, 0.22832080200501254, 0.2293233082706767, 0.23032581453634085, 0.23132832080200502, 0.23233082706766917, 0.23333333333333334, 0.2343358395989975, 0.23533834586466165, 0.23634085213032582, 0.23734335839598997, 0.23834586466165414, 0.2393483709273183, 0.24035087719298245, 0.24135338345864663, 0.24235588972431077, 0.24335839598997494, 0.2443609022556391, 0.24536340852130326, 0.24636591478696743, 0.24736842105263157, 0.24837092731829574, 0.2493734335839599, 0.25037593984962403, 0.25137844611528826, 0.2523809523809524, 0.25338345864661654, 0.2543859649122807, 0.25538847117794483, 0.25639097744360906, 0.2573934837092732, 0.25839598997493735, 0.2593984962406015, 0.26040100250626563, 0.26140350877192986, 0.262406015037594, 0.26340852130325815, 0.2644110275689223, 0.26541353383458643, 0.26641604010025066, 0.2674185463659148, 0.26842105263157895, 0.2694235588972431, 0.27042606516290724, 0.27142857142857146, 0.2724310776942356, 0.27343358395989975, 0.2744360902255639, 0.27543859649122804, 0.27644110275689227, 0.2774436090225564, 0.27844611528822055, 0.2794486215538847, 0.28045112781954884, 0.28145363408521307, 0.2824561403508772, 0.28345864661654135, 0.2844611528822055, 0.28546365914786964, 0.28646616541353387, 0.287468671679198, 0.28847117794486216, 0.2894736842105263, 0.29047619047619044, 0.29147869674185467, 0.2924812030075188, 0.29348370927318296, 0.29448621553884713, 0.29548872180451125, 0.29649122807017547, 0.2974937343358396, 0.29849624060150376, 0.29949874686716793, 0.30050125313283205, 0.3015037593984963, 0.3025062656641604, 0.30350877192982456, 0.30451127819548873, 0.30551378446115285, 0.3065162907268171, 0.3075187969924812, 0.30852130325814536, 0.30952380952380953, 0.31052631578947365, 0.3115288220551379, 0.312531328320802, 0.31353383458646616, 0.31453634085213034, 0.31553884711779445, 0.3165413533834587, 0.3175438596491228, 0.31854636591478697, 0.31954887218045114, 0.32055137844611525, 0.3215538847117795, 0.3225563909774436, 0.32355889724310777, 0.32456140350877194, 0.32556390977443606, 0.3265664160401003, 0.3275689223057644, 0.32857142857142857, 0.32957393483709274, 0.33057644110275686, 0.3315789473684211, 0.3325814536340852, 0.33358395989974937, 0.33458646616541354, 0.33558897243107766, 0.3365914786967419, 0.337593984962406, 0.3385964912280702, 0.33959899749373434, 0.34060150375939846, 0.3416040100250627, 0.3426065162907268, 0.343609022556391, 0.34461152882205515, 0.34561403508771926, 0.3466165413533835, 0.3476190476190476, 0.3486215538847118, 0.34962406015037595, 0.35062656641604006, 0.3516290726817043, 0.3526315789473684, 0.35363408521303263, 0.35463659147869675, 0.35563909774436087, 0.3566416040100251, 0.3576441102756892, 0.35864661654135344, 0.35964912280701755, 0.36065162907268167, 0.3616541353383459, 0.36265664160401, 0.36365914786967424, 0.36466165413533835, 0.36566416040100247, 0.3666666666666667, 0.3676691729323308, 0.36867167919799504, 0.36967418546365916, 0.37067669172932327, 0.3716791979949875, 0.3726817042606516, 0.37368421052631584, 0.37468671679197996, 0.3756892230576441, 0.3766917293233083, 0.3776942355889724, 0.37869674185463664, 0.37969924812030076, 0.3807017543859649, 0.3817042606516291, 0.3827067669172932, 0.38370927318295744, 0.38471177944862156, 0.3857142857142857, 0.3867167919799499, 0.387719298245614, 0.38872180451127825, 0.38972431077694236, 0.3907268170426065, 0.3917293233082707, 0.3927318295739348, 0.39373433583959905, 0.39473684210526316, 0.3957393483709273, 0.3967418546365915, 0.3977443609022556, 0.39874686716791985, 0.39974937343358397, 0.4007518796992481, 0.4017543859649123, 0.4027568922305764, 0.40375939849624065, 0.40476190476190477, 0.4057644110275689, 0.4067669172932331, 0.4077694235588972, 0.40877192982456145, 0.40977443609022557, 0.4107769423558897, 0.4117794486215539, 0.412781954887218, 0.41378446115288225, 0.41478696741854637, 0.4157894736842105, 0.4167919799498747, 0.41779448621553883, 0.41879699248120306, 0.4197994987468672, 0.4208020050125313, 0.4218045112781955, 0.42280701754385963, 0.42380952380952386, 0.424812030075188, 0.4258145363408521, 0.4268170426065163, 0.42781954887218043, 0.42882205513784466, 0.4298245614035088, 0.4308270676691729, 0.4318295739348371, 0.43283208020050123, 0.43383458646616546, 0.4348370927318296, 0.4358395989974937, 0.4368421052631579, 0.43784461152882204, 0.43884711779448626, 0.4398496240601504, 0.4408521303258145, 0.4418546365914787, 0.44285714285714284, 0.44385964912280707, 0.4448621553884712, 0.4458646616541353, 0.4468671679197995, 0.44786967418546364, 0.44887218045112787, 0.449874686716792, 0.4508771929824561, 0.4518796992481203, 0.45288220551378444, 0.45388471177944867, 0.4548872180451128, 0.4558897243107769, 0.4568922305764411, 0.45789473684210524, 0.45889724310776947, 0.4598997493734336, 0.4609022556390977, 0.46190476190476193, 0.46290726817042605, 0.46390977443609027, 0.4649122807017544, 0.4659147869674185, 0.46691729323308273, 0.46791979949874685, 0.4689223057644111, 0.4699248120300752, 0.4709273182957393, 0.47192982456140353, 0.47293233082706765, 0.4739348370927319, 0.474937343358396, 0.4759398496240601, 0.47694235588972433, 0.47794486215538845, 0.4789473684210527, 0.4799498746867168, 0.4809523809523809, 0.48195488721804514, 0.48295739348370925, 0.4839598997493735, 0.4849624060150376, 0.4859649122807017, 0.48696741854636594, 0.48796992481203005, 0.4889724310776943, 0.4899749373433584, 0.4909774436090225, 0.49197994987468674, 0.49298245614035086, 0.4939849624060151, 0.4949874686716792, 0.4959899749373433, 0.49699248120300754, 0.49799498746867166, 0.4989974937343359, 0.5], 'max_iter': [2000, 2040, 2080, 2120, 2160, 2201, 2241, 2281, 2321, 2361, 2402, 2442, 2482, 2522, 2562, 2603, 2643, 2683, 2723, 2763, 2804, 2844, 2884, 2924, 2964, 3005, 3045, 3085, 3125, 3165, 3206, 3246, 3286, 3326, 3366, 3407, 3447, 3487, 3527, 3567, 3608, 3648, 3688, 3728, 3768, 3809, 3849, 3889, 3929, 3969, 4010, 4050, 4090, 4130, 4170, 4211, 4251, 4291, 4331, 4371, 4412, 4452, 4492, 4532, 4572, 4613, 4653, 4693, 4733, 4773, 4814, 4854, 4894, 4934, 4974, 5015, 5055, 5095, 5135, 5175, 5216, 5256, 5296, 5336, 5376, 5417, 5457, 5497, 5537, 5577, 5618, 5658, 5698, 5738, 5778, 5819, 5859, 5899, 5939, 5979, 6020, 6060, 6100, 6140, 6180, 6221, 6261, 6301, 6341, 6381, 6422, 6462, 6502, 6542, 6582, 6623, 6663, 6703, 6743, 6783, 6824, 6864, 6904, 6944, 6984, 7025, 7065, 7105, 7145, 7185, 7226, 7266, 7306, 7346, 7386, 7427, 7467, 7507, 7547, 7587, 7628, 7668, 7708, 7748, 7788, 7829, 7869, 7909, 7949, 7989, 8030, 8070, 8110, 8150, 8190, 8231, 8271, 8311, 8351, 8391, 8432, 8472, 8512, 8552, 8592, 8633, 8673, 8713, 8753, 8793, 8834, 8874, 8914, 8954, 8994, 9035, 9075, 9115, 9155, 9195, 9236, 9276, 9316, 9356, 9396, 9437, 9477, 9517, 9557, 9597, 9638, 9678, 9718, 9758, 9798, 9839, 9879, 9919, 9959, 10000], 'tol': [0.01, 0.009954773869346734, 0.009909547738693467, 0.0098643216080402, 0.009819095477386935, 0.009773869346733669, 0.009728643216080402, 0.009683417085427136, 0.009638190954773869, 0.009592964824120602, 0.009547738693467337, 0.00950251256281407, 0.009457286432160804, 0.009412060301507538, 0.009366834170854271, 0.009321608040201004, 0.00927638190954774, 0.009231155778894473, 0.009185929648241206, 0.00914070351758794, 0.009095477386934673, 0.009050251256281406, 0.009005025125628141, 0.008959798994974875, 0.008914572864321608, 0.008869346733668342, 0.008824120603015075, 0.008778894472361808, 0.008733668341708543, 0.008688442211055277, 0.00864321608040201, 0.008597989949748744, 0.008552763819095477, 0.00850753768844221, 0.008462311557788945, 0.008417085427135679, 0.008371859296482412, 0.008326633165829146, 0.008281407035175879, 0.008236180904522612, 0.008190954773869347, 0.00814572864321608, 0.008100502512562814, 0.008055276381909547, 0.008010050251256281, 0.007964824120603016, 0.007919597989949748, 0.007874371859296483, 0.007829145728643216, 0.0077839195979899495, 0.007738693467336683, 0.007693467336683416, 0.0076482412060301505, 0.007603015075376885, 0.007557788944723618, 0.0075125628140703515, 0.007467336683417085, 0.007422110552763818, 0.0073768844221105525, 0.007331658291457287, 0.00728643216080402, 0.0072412060301507535, 0.007195979899497487, 0.00715075376884422, 0.0071055276381909544, 0.007060301507537689, 0.007015075376884422, 0.0069698492462311554, 0.006924623115577889, 0.006879396984924622, 0.006834170854271356, 0.006788944723618091, 0.006743718592964824, 0.006698492462311557, 0.006653266331658291, 0.006608040201005024, 0.006562814070351758, 0.006517587939698493, 0.006472361809045226, 0.006427135678391959, 0.006381909547738693, 0.006336683417085426, 0.00629145728643216, 0.006246231155778894, 0.006201005025125628, 0.006155778894472361, 0.006110552763819095, 0.006065326633165829, 0.006020100502512562, 0.005974874371859296, 0.00592964824120603, 0.005884422110552763, 0.005839195979899497, 0.005793969849246231, 0.005748743718592964, 0.005703517587939698, 0.005658291457286432, 0.005613065326633165, 0.005567839195979899, 0.005522613065326632, 0.005477386934673366, 0.0054321608040201, 0.005386934673366833, 0.005341708542713567, 0.005296482412060301, 0.005251256281407034, 0.005206030150753768, 0.005160804020100502, 0.005115577889447235, 0.005070351758793969, 0.005025125628140703, 0.004979899497487436, 0.00493467336683417, 0.004889447236180904, 0.004844221105527637, 0.004798994974874371, 0.004753768844221105, 0.004708542713567838, 0.004663316582914572, 0.004618090452261306, 0.004572864321608039, 0.004527638190954773, 0.004482412060301507, 0.00443718592964824, 0.004391959798994974, 0.004346733668341708, 0.004301507537688441, 0.004256281407035175, 0.004211055276381909, 0.004165829145728642, 0.004120603015075376, 0.00407537688442211, 0.004030150753768843, 0.003984924623115577, 0.003939698492462311, 0.003894472361809044, 0.0038492462311557783, 0.0038040201005025117, 0.003758793969849245, 0.0037135678391959793, 0.0036683417085427127, 0.003623115577889446, 0.0035778894472361803, 0.0035326633165829137, 0.003487437185929647, 0.0034422110552763813, 0.0033969849246231146, 0.003351758793969848, 0.0033065326633165823, 0.0032613065326633156, 0.003216080402010049, 0.0031708542713567833, 0.0031256281407035166, 0.00308040201005025, 0.0030351758793969843, 0.0029899497487437176, 0.002944723618090451, 0.0028994974874371852, 0.0028542713567839186, 0.002809045226130652, 0.0027638190954773854, 0.0027185929648241196, 0.002673366834170853, 0.0026281407035175864, 0.0025829145728643206, 0.002537688442211054, 0.0024924623115577874, 0.0024472361809045216, 0.002402010050251255, 0.0023567839195979884, 0.0023115577889447226, 0.002266331658291456, 0.0022211055276381893, 0.0021758793969849227, 0.002130653266331658, 0.002085427135678391, 0.0020402010050251246, 0.001994974874371858, 0.0019497487437185913, 0.0019045226130653247, 0.0018592964824120598, 0.0018140703517587932, 0.0017688442211055266, 0.00172361809045226, 0.0016783919597989933, 0.0016331658291457267, 0.0015879396984924618, 0.0015427135678391952, 0.0014974874371859286, 0.001452261306532662, 0.0014070351758793953, 0.0013618090452261287, 0.0013165829145728638, 0.0012713567839195972, 0.0012261306532663305, 0.001180904522613064, 0.0011356783919597973, 0.0010904522613065307, 0.001045226130653264, 0.001], 'positive': ['False'], 'copy_X': ['True', 'False'], 'solver': ['auto']}\n"
     ]
    }
   ],
   "source": [
    "max_iter=[int(x) for x in np.linspace(2000, 10000,200)]\n",
    "tol=[float(x) for x in np.linspace(0.01, 0.001,200)]\n",
    "alpha = [float(x) for x in np.linspace(0.1,0.50,400)]\n",
    "positive=['False']\n",
    "copy_X=['True','False']\n",
    "solver=[\"auto\"]\n",
    "\n",
    "random_grid = {\n",
    "               'alpha':alpha,\n",
    "              \n",
    "               'max_iter':max_iter,\n",
    "               'tol':tol,\n",
    "                'positive':positive,\n",
    "                'copy_X':copy_X,\n",
    "                'solver':solver\n",
    "               \n",
    "               \n",
    "                }\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "7b92d976-12ff-4b24-9760-431fddc9405a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "[CV 5/5] END alpha=0.028056112224448895, copy_X=False, max_iter=3154, positive=False, selection=cyclic, tol=0.0016923076923076909, warm_start=False;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.17434869739478956, copy_X=False, max_iter=6665, positive=True, selection=cyclic, tol=0.00777257525083612, warm_start=True;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.17434869739478956, copy_X=False, max_iter=6665, positive=True, selection=cyclic, tol=0.00777257525083612, warm_start=True;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.12124248496993988, copy_X=True, max_iter=4468, positive=True, selection=random, tol=0.0026254180602006683, warm_start=False;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.12124248496993988, copy_X=True, max_iter=4468, positive=True, selection=random, tol=0.0026254180602006683, warm_start=False;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.12124248496993988, copy_X=True, max_iter=4468, positive=True, selection=random, tol=0.0026254180602006683, warm_start=False;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.3306613226452906, copy_X=False, max_iter=6953, positive=False, selection=random, tol=0.003076923076923076, warm_start=False;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.3306613226452906, copy_X=False, max_iter=6953, positive=False, selection=random, tol=0.003076923076923076, warm_start=False;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.3306613226452906, copy_X=False, max_iter=6953, positive=False, selection=random, tol=0.003076923076923076, warm_start=False;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.3306613226452906, copy_X=False, max_iter=6953, positive=False, selection=random, tol=0.003076923076923076, warm_start=False;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.3306613226452906, copy_X=False, max_iter=6953, positive=False, selection=random, tol=0.003076923076923076, warm_start=False;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.05611222444889779, copy_X=True, max_iter=2593, positive=True, selection=random, tol=0.007531772575250836, warm_start=True;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.05611222444889779, copy_X=True, max_iter=2593, positive=True, selection=random, tol=0.007531772575250836, warm_start=True;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.05611222444889779, copy_X=True, max_iter=2593, positive=True, selection=random, tol=0.007531772575250836, warm_start=True;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.05611222444889779, copy_X=True, max_iter=2593, positive=True, selection=random, tol=0.007531772575250836, warm_start=True;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.05611222444889779, copy_X=True, max_iter=2593, positive=True, selection=random, tol=0.007531772575250836, warm_start=True;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.4929859719438877, copy_X=True, max_iter=7915, positive=True, selection=random, tol=0.005665551839464883, warm_start=False;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.4929859719438877, copy_X=True, max_iter=7915, positive=True, selection=random, tol=0.005665551839464883, warm_start=False;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.4929859719438877, copy_X=True, max_iter=7915, positive=True, selection=random, tol=0.005665551839464883, warm_start=False;, score=0.918 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.07615230460921843, copy_X=True, max_iter=8525, positive=False, selection=cyclic, tol=0.00551505016722408, warm_start=False;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.49398797595190375, copy_X=False, max_iter=8717, positive=False, selection=random, tol=0.008976588628762543, warm_start=True;, score=0.881 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.49398797595190375, copy_X=False, max_iter=8717, positive=False, selection=random, tol=0.008976588628762543, warm_start=True;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.49398797595190375, copy_X=False, max_iter=8717, positive=False, selection=random, tol=0.008976588628762543, warm_start=True;, score=0.883 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.2955911823647294, copy_X=False, max_iter=6104, positive=False, selection=cyclic, tol=0.0023545150501672234, warm_start=True;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.2955911823647294, copy_X=False, max_iter=6104, positive=False, selection=cyclic, tol=0.0023545150501672234, warm_start=True;, score=0.918 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.13326653306613226, copy_X=True, max_iter=8621, positive=False, selection=cyclic, tol=0.007351170568561873, warm_start=True;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.027054108216432865, copy_X=False, max_iter=9727, positive=True, selection=random, tol=0.00325752508361204, warm_start=True;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.35571142284569135, copy_X=False, max_iter=3843, positive=False, selection=cyclic, tol=0.007682274247491639, warm_start=False;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.35571142284569135, copy_X=False, max_iter=3843, positive=False, selection=cyclic, tol=0.007682274247491639, warm_start=False;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.0250501002004008, copy_X=True, max_iter=5142, positive=False, selection=random, tol=0.007260869565217392, warm_start=True;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.0250501002004008, copy_X=True, max_iter=5142, positive=False, selection=random, tol=0.007260869565217392, warm_start=True;, score=0.883 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.35571142284569135, copy_X=False, max_iter=7482, positive=True, selection=random, tol=0.006719063545150502, warm_start=True;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.37074148296593185, copy_X=True, max_iter=4965, positive=False, selection=cyclic, tol=0.005183946488294314, warm_start=True;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.4098196392785571, copy_X=False, max_iter=7194, positive=True, selection=random, tol=0.00888628762541806, warm_start=True;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.4098196392785571, copy_X=False, max_iter=7194, positive=True, selection=random, tol=0.00888628762541806, warm_start=True;, score=0.918 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.13226452905811623, copy_X=False, max_iter=2128, positive=True, selection=cyclic, tol=0.008013377926421405, warm_start=True;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.13226452905811623, copy_X=False, max_iter=2128, positive=True, selection=cyclic, tol=0.008013377926421405, warm_start=True;, score=0.892 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.22044088176352702, copy_X=False, max_iter=4404, positive=False, selection=cyclic, tol=0.006779264214046822, warm_start=False;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.22044088176352702, copy_X=False, max_iter=4404, positive=False, selection=cyclic, tol=0.006779264214046822, warm_start=False;, score=0.918 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.17034068136272543, copy_X=False, max_iter=5895, positive=True, selection=cyclic, tol=0.008073578595317725, warm_start=True;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.11322645290581161, copy_X=False, max_iter=5879, positive=True, selection=cyclic, tol=0.006418060200668896, warm_start=False;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.29659318637274545, copy_X=False, max_iter=8877, positive=False, selection=cyclic, tol=0.0058461538461538455, warm_start=True;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.29659318637274545, copy_X=False, max_iter=8877, positive=False, selection=cyclic, tol=0.0058461538461538455, warm_start=True;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.16332665330661322, copy_X=True, max_iter=8140, positive=False, selection=random, tol=0.00996989966555184, warm_start=False;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.16332665330661322, copy_X=True, max_iter=8140, positive=False, selection=random, tol=0.00996989966555184, warm_start=False;, score=0.883 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.4318637274549098, copy_X=True, max_iter=7306, positive=False, selection=random, tol=0.005394648829431438, warm_start=False;, score=0.883 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.3727454909819639, copy_X=True, max_iter=4020, positive=True, selection=cyclic, tol=0.006327759197324414, warm_start=False;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.3727454909819639, copy_X=True, max_iter=4020, positive=True, selection=cyclic, tol=0.006327759197324414, warm_start=False;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.3727454909819639, copy_X=True, max_iter=4020, positive=True, selection=cyclic, tol=0.006327759197324414, warm_start=False;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.3727454909819639, copy_X=True, max_iter=4020, positive=True, selection=cyclic, tol=0.006327759197324414, warm_start=False;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.08316633266533066, copy_X=False, max_iter=3458, positive=True, selection=random, tol=0.008314381270903011, warm_start=False;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.08316633266533066, copy_X=False, max_iter=3458, positive=True, selection=random, tol=0.008314381270903011, warm_start=False;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.08316633266533066, copy_X=False, max_iter=3458, positive=True, selection=random, tol=0.008314381270903011, warm_start=False;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.08316633266533066, copy_X=False, max_iter=3458, positive=True, selection=random, tol=0.008314381270903011, warm_start=False;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.08316633266533066, copy_X=False, max_iter=3458, positive=True, selection=random, tol=0.008314381270903011, warm_start=False;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.12124248496993988, copy_X=True, max_iter=4468, positive=True, selection=random, tol=0.0026254180602006683, warm_start=False;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.12124248496993988, copy_X=True, max_iter=4468, positive=True, selection=random, tol=0.0026254180602006683, warm_start=False;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.07615230460921843, copy_X=True, max_iter=8525, positive=False, selection=cyclic, tol=0.00551505016722408, warm_start=False;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.07615230460921843, copy_X=True, max_iter=8525, positive=False, selection=cyclic, tol=0.00551505016722408, warm_start=False;, score=0.892 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.49398797595190375, copy_X=False, max_iter=8717, positive=False, selection=random, tol=0.008976588628762543, warm_start=True;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.49398797595190375, copy_X=False, max_iter=8717, positive=False, selection=random, tol=0.008976588628762543, warm_start=True;, score=0.918 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.25250501002004005, copy_X=True, max_iter=5094, positive=False, selection=cyclic, tol=0.0019331103678929765, warm_start=True;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.25250501002004005, copy_X=True, max_iter=5094, positive=False, selection=cyclic, tol=0.0019331103678929765, warm_start=True;, score=0.892 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.13326653306613226, copy_X=True, max_iter=8621, positive=False, selection=cyclic, tol=0.007351170568561873, warm_start=True;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.13326653306613226, copy_X=True, max_iter=8621, positive=False, selection=cyclic, tol=0.007351170568561873, warm_start=True;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.48797595190380755, copy_X=True, max_iter=5206, positive=False, selection=random, tol=0.0011204013377926411, warm_start=False;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.35571142284569135, copy_X=False, max_iter=3843, positive=False, selection=cyclic, tol=0.007682274247491639, warm_start=False;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.0250501002004008, copy_X=True, max_iter=5142, positive=False, selection=random, tol=0.007260869565217392, warm_start=True;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.0250501002004008, copy_X=True, max_iter=5142, positive=False, selection=random, tol=0.007260869565217392, warm_start=True;, score=0.918 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.37074148296593185, copy_X=True, max_iter=4965, positive=False, selection=cyclic, tol=0.005183946488294314, warm_start=True;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.37074148296593185, copy_X=True, max_iter=4965, positive=False, selection=cyclic, tol=0.005183946488294314, warm_start=True;, score=0.918 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.48597194388777554, copy_X=True, max_iter=9326, positive=True, selection=cyclic, tol=0.00325752508361204, warm_start=True;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.48597194388777554, copy_X=True, max_iter=9326, positive=True, selection=cyclic, tol=0.00325752508361204, warm_start=True;, score=0.905 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.18937875751503006, copy_X=False, max_iter=3955, positive=False, selection=random, tol=0.009247491638795987, warm_start=True;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.18937875751503006, copy_X=False, max_iter=3955, positive=False, selection=random, tol=0.009247491638795987, warm_start=True;, score=0.883 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.27054108216432865, copy_X=True, max_iter=7803, positive=False, selection=random, tol=0.005424749163879599, warm_start=False;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.27054108216432865, copy_X=True, max_iter=7803, positive=False, selection=random, tol=0.005424749163879599, warm_start=False;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.22044088176352702, copy_X=False, max_iter=4404, positive=False, selection=cyclic, tol=0.006779264214046822, warm_start=False;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.22044088176352702, copy_X=False, max_iter=4404, positive=False, selection=cyclic, tol=0.006779264214046822, warm_start=False;, score=0.883 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.11322645290581161, copy_X=False, max_iter=5879, positive=True, selection=cyclic, tol=0.006418060200668896, warm_start=False;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.11322645290581161, copy_X=False, max_iter=5879, positive=True, selection=cyclic, tol=0.006418060200668896, warm_start=False;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.29659318637274545, copy_X=False, max_iter=8877, positive=False, selection=cyclic, tol=0.0058461538461538455, warm_start=True;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.29659318637274545, copy_X=False, max_iter=8877, positive=False, selection=cyclic, tol=0.0058461538461538455, warm_start=True;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.4318637274549098, copy_X=True, max_iter=7306, positive=False, selection=random, tol=0.005394648829431438, warm_start=False;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.4949874686716792, copy_X=False, max_iter=5859, positive=False, solver=auto, tol=0.008281407035175879;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.3907268170426065, copy_X=True, max_iter=2120, positive=False, solver=auto, tol=0.009819095477386935;, score=0.919 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.3015037593984963, copy_X=True, max_iter=4894, positive=False, solver=auto, tol=0.006472361809045226;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.3015037593984963, copy_X=True, max_iter=4894, positive=False, solver=auto, tol=0.006472361809045226;, score=0.891 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.4358395989974937, copy_X=False, max_iter=5698, positive=False, solver=auto, tol=0.0024472361809045216;, score=0.879 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.36365914786967424, copy_X=False, max_iter=2321, positive=False, solver=auto, tol=0.0014974874371859286;, score=0.878 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.26641604010025066, copy_X=True, max_iter=9035, positive=False, solver=auto, tol=0.005839195979899497;, score=0.879 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.12706766917293233, copy_X=False, max_iter=8914, positive=False, solver=auto, tol=0.005974874371859296;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.4659147869674185, copy_X=True, max_iter=4130, positive=False, solver=auto, tol=0.004979899497487436;, score=0.905 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.4569138276553106, copy_X=False, max_iter=9807, positive=True, selection=cyclic, tol=0.008525083612040133, warm_start=False;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.03507014028056112, copy_X=False, max_iter=8621, positive=True, selection=cyclic, tol=0.005605351170568562, warm_start=False;, score=0.881 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.08016032064128256, copy_X=False, max_iter=9006, positive=True, selection=random, tol=0.005183946488294314, warm_start=True;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.08016032064128256, copy_X=False, max_iter=9006, positive=True, selection=random, tol=0.005183946488294314, warm_start=True;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.08016032064128256, copy_X=False, max_iter=9006, positive=True, selection=random, tol=0.005183946488294314, warm_start=True;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.08016032064128256, copy_X=False, max_iter=9006, positive=True, selection=random, tol=0.005183946488294314, warm_start=True;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.08016032064128256, copy_X=False, max_iter=9006, positive=True, selection=random, tol=0.005183946488294314, warm_start=True;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.4428857715430861, copy_X=False, max_iter=3539, positive=False, selection=cyclic, tol=0.00717056856187291, warm_start=True;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.4428857715430861, copy_X=False, max_iter=3539, positive=False, selection=cyclic, tol=0.00717056856187291, warm_start=True;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.4428857715430861, copy_X=False, max_iter=3539, positive=False, selection=cyclic, tol=0.00717056856187291, warm_start=True;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.4428857715430861, copy_X=False, max_iter=3539, positive=False, selection=cyclic, tol=0.00717056856187291, warm_start=True;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.4428857715430861, copy_X=False, max_iter=3539, positive=False, selection=cyclic, tol=0.00717056856187291, warm_start=True;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.48597194388777554, copy_X=False, max_iter=3571, positive=True, selection=cyclic, tol=0.009759197324414716, warm_start=False;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.48597194388777554, copy_X=False, max_iter=3571, positive=True, selection=cyclic, tol=0.009759197324414716, warm_start=False;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.48597194388777554, copy_X=False, max_iter=3571, positive=True, selection=cyclic, tol=0.009759197324414716, warm_start=False;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.48597194388777554, copy_X=False, max_iter=3571, positive=True, selection=cyclic, tol=0.009759197324414716, warm_start=False;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.48597194388777554, copy_X=False, max_iter=3571, positive=True, selection=cyclic, tol=0.009759197324414716, warm_start=False;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.07114228456913826, copy_X=True, max_iter=2496, positive=False, selection=random, tol=0.007020066889632107, warm_start=True;, score=0.881 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.13326653306613226, copy_X=True, max_iter=8621, positive=False, selection=cyclic, tol=0.007351170568561873, warm_start=True;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.13326653306613226, copy_X=True, max_iter=8621, positive=False, selection=cyclic, tol=0.007351170568561873, warm_start=True;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.48797595190380755, copy_X=True, max_iter=5206, positive=False, selection=random, tol=0.0011204013377926411, warm_start=False;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.48797595190380755, copy_X=True, max_iter=5206, positive=False, selection=random, tol=0.0011204013377926411, warm_start=False;, score=0.892 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.009018036072144287, copy_X=False, max_iter=8124, positive=True, selection=cyclic, tol=0.0019632107023411366, warm_start=False;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.009018036072144287, copy_X=False, max_iter=8124, positive=True, selection=cyclic, tol=0.0019632107023411366, warm_start=False;, score=0.905 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.3787575150300601, copy_X=True, max_iter=5382, positive=True, selection=cyclic, tol=0.004612040133779264, warm_start=False;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.3787575150300601, copy_X=True, max_iter=5382, positive=True, selection=cyclic, tol=0.004612040133779264, warm_start=False;, score=0.905 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.18937875751503006, copy_X=False, max_iter=3955, positive=False, selection=random, tol=0.009247491638795987, warm_start=True;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.18937875751503006, copy_X=False, max_iter=3955, positive=False, selection=random, tol=0.009247491638795987, warm_start=True;, score=0.918 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.20741482965931862, copy_X=True, max_iter=7691, positive=False, selection=random, tol=0.01, warm_start=True;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.22044088176352702, copy_X=False, max_iter=4404, positive=False, selection=cyclic, tol=0.006779264214046822, warm_start=False;, score=0.881 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.30260521042084165, copy_X=True, max_iter=4452, positive=True, selection=cyclic, tol=0.002836120401337792, warm_start=False;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.30260521042084165, copy_X=True, max_iter=4452, positive=True, selection=cyclic, tol=0.002836120401337792, warm_start=False;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.4108216432865731, copy_X=False, max_iter=8348, positive=True, selection=random, tol=0.009849498327759198, warm_start=True;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.4108216432865731, copy_X=False, max_iter=8348, positive=True, selection=random, tol=0.009849498327759198, warm_start=True;, score=0.892 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.4318637274549098, copy_X=True, max_iter=7306, positive=False, selection=random, tol=0.005394648829431438, warm_start=False;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.4949874686716792, copy_X=False, max_iter=5859, positive=False, solver=auto, tol=0.008281407035175879;, score=0.893 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.3907268170426065, copy_X=True, max_iter=2120, positive=False, solver=auto, tol=0.009819095477386935;, score=0.893 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.3015037593984963, copy_X=True, max_iter=4894, positive=False, solver=auto, tol=0.006472361809045226;, score=0.879 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.3917293233082707, copy_X=False, max_iter=3567, positive=False, solver=auto, tol=0.007738693467336683;, score=0.878 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.36365914786967424, copy_X=False, max_iter=2321, positive=False, solver=auto, tol=0.0014974874371859286;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.36365914786967424, copy_X=False, max_iter=2321, positive=False, solver=auto, tol=0.0014974874371859286;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.2824561403508772, copy_X=True, max_iter=7226, positive=False, solver=auto, tol=0.0015879396984924618;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.2824561403508772, copy_X=True, max_iter=7226, positive=False, solver=auto, tol=0.0015879396984924618;, score=0.880 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.42882205513784466, copy_X=False, max_iter=6381, positive=False, solver=auto, tol=0.005567839195979899;, score=0.878 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.42882205513784466, copy_X=False, max_iter=6381, positive=False, solver=auto, tol=0.005567839195979899;, score=0.905 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.36566416040100247, copy_X=False, max_iter=3929, positive=False, solver=auto, tol=0.006065326633165829;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.36566416040100247, copy_X=False, max_iter=3929, positive=False, solver=auto, tol=0.006065326633165829;, score=0.919 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.15531062124248496, copy_X=True, max_iter=5959, positive=True, selection=random, tol=0.009548494983277592, warm_start=False;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.15531062124248496, copy_X=True, max_iter=5959, positive=True, selection=random, tol=0.009548494983277592, warm_start=False;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.15531062124248496, copy_X=True, max_iter=5959, positive=True, selection=random, tol=0.009548494983277592, warm_start=False;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.15531062124248496, copy_X=True, max_iter=5959, positive=True, selection=random, tol=0.009548494983277592, warm_start=False;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.19138276553106212, copy_X=False, max_iter=2721, positive=True, selection=random, tol=0.00996989966555184, warm_start=False;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.19138276553106212, copy_X=False, max_iter=2721, positive=True, selection=random, tol=0.00996989966555184, warm_start=False;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.19138276553106212, copy_X=False, max_iter=2721, positive=True, selection=random, tol=0.00996989966555184, warm_start=False;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.19138276553106212, copy_X=False, max_iter=2721, positive=True, selection=random, tol=0.00996989966555184, warm_start=False;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.19138276553106212, copy_X=False, max_iter=2721, positive=True, selection=random, tol=0.00996989966555184, warm_start=False;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.07615230460921843, copy_X=True, max_iter=8525, positive=False, selection=cyclic, tol=0.00551505016722408, warm_start=False;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.07615230460921843, copy_X=True, max_iter=8525, positive=False, selection=cyclic, tol=0.00551505016722408, warm_start=False;, score=0.905 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.48797595190380755, copy_X=True, max_iter=5206, positive=False, selection=random, tol=0.0011204013377926411, warm_start=False;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.48797595190380755, copy_X=True, max_iter=5206, positive=False, selection=random, tol=0.0011204013377926411, warm_start=False;, score=0.905 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.009018036072144287, copy_X=False, max_iter=8124, positive=True, selection=cyclic, tol=0.0019632107023411366, warm_start=False;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.0250501002004008, copy_X=True, max_iter=5142, positive=False, selection=random, tol=0.007260869565217392, warm_start=True;, score=0.881 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.3787575150300601, copy_X=True, max_iter=5382, positive=True, selection=cyclic, tol=0.004612040133779264, warm_start=False;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.3787575150300601, copy_X=True, max_iter=5382, positive=True, selection=cyclic, tol=0.004612040133779264, warm_start=False;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.48597194388777554, copy_X=True, max_iter=9326, positive=True, selection=cyclic, tol=0.00325752508361204, warm_start=True;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.18937875751503006, copy_X=False, max_iter=3955, positive=False, selection=random, tol=0.009247491638795987, warm_start=True;, score=0.881 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.20741482965931862, copy_X=True, max_iter=7691, positive=False, selection=random, tol=0.01, warm_start=True;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.20741482965931862, copy_X=True, max_iter=7691, positive=False, selection=random, tol=0.01, warm_start=True;, score=0.905 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.11322645290581161, copy_X=False, max_iter=5879, positive=True, selection=cyclic, tol=0.006418060200668896, warm_start=False;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.11322645290581161, copy_X=False, max_iter=5879, positive=True, selection=cyclic, tol=0.006418060200668896, warm_start=False;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.4108216432865731, copy_X=False, max_iter=8348, positive=True, selection=random, tol=0.009849498327759198, warm_start=True;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.4108216432865731, copy_X=False, max_iter=8348, positive=True, selection=random, tol=0.009849498327759198, warm_start=True;, score=0.905 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.4318637274549098, copy_X=True, max_iter=7306, positive=False, selection=random, tol=0.005394648829431438, warm_start=False;, score=0.905 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.4949874686716792, copy_X=False, max_iter=5859, positive=False, solver=auto, tol=0.008281407035175879;, score=0.879 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.3907268170426065, copy_X=True, max_iter=2120, positive=False, solver=auto, tol=0.009819095477386935;, score=0.879 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.3917293233082707, copy_X=False, max_iter=3567, positive=False, solver=auto, tol=0.007738693467336683;, score=0.893 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.3917293233082707, copy_X=False, max_iter=3567, positive=False, solver=auto, tol=0.007738693467336683;, score=0.879 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.36365914786967424, copy_X=False, max_iter=2321, positive=False, solver=auto, tol=0.0014974874371859286;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.36365914786967424, copy_X=False, max_iter=2321, positive=False, solver=auto, tol=0.0014974874371859286;, score=0.879 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.4348370927318296, copy_X=True, max_iter=5175, positive=False, solver=auto, tol=0.00864321608040201;, score=0.878 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.4348370927318296, copy_X=True, max_iter=5175, positive=False, solver=auto, tol=0.00864321608040201;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.4348370927318296, copy_X=True, max_iter=5175, positive=False, solver=auto, tol=0.00864321608040201;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.4348370927318296, copy_X=True, max_iter=5175, positive=False, solver=auto, tol=0.00864321608040201;, score=0.893 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.4959899749373433, copy_X=True, max_iter=8512, positive=False, solver=auto, tol=0.006246231155778894;, score=0.893 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.4959899749373433, copy_X=True, max_iter=8512, positive=False, solver=auto, tol=0.006246231155778894;, score=0.879 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.22030075187969925, copy_X=True, max_iter=7708, positive=False, solver=auto, tol=0.004618090452261306;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.22030075187969925, copy_X=True, max_iter=7708, positive=False, solver=auto, tol=0.004618090452261306;, score=0.905 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.3315789473684211, copy_X=False, max_iter=6824, positive=False, solver=auto, tol=0.005160804020100502;, score=0.891 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.3315789473684211, copy_X=False, max_iter=6824, positive=False, solver=auto, tol=0.005160804020100502;, score=0.879 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.156140350877193, copy_X=False, max_iter=2241, positive=False, solver=auto, tol=0.0021758793969849227;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.156140350877193, copy_X=False, max_iter=2241, positive=False, solver=auto, tol=0.0021758793969849227;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.156140350877193, copy_X=False, max_iter=2241, positive=False, solver=auto, tol=0.0021758793969849227;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.156140350877193, copy_X=False, max_iter=2241, positive=False, solver=auto, tol=0.0021758793969849227;, score=0.891 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.156140350877193, copy_X=False, max_iter=2241, positive=False, solver=auto, tol=0.0021758793969849227;, score=0.880 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.17518796992481203, copy_X=True, max_iter=5979, positive=False, solver=auto, tol=0.006517587939698493;, score=0.879 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.5, copy_X=True, max_iter=6703, positive=False, solver=auto, tol=0.00493467336683417;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.027054108216432865, copy_X=False, max_iter=9727, positive=True, selection=random, tol=0.00325752508361204, warm_start=True;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.027054108216432865, copy_X=False, max_iter=9727, positive=True, selection=random, tol=0.00325752508361204, warm_start=True;, score=0.883 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.009018036072144287, copy_X=False, max_iter=8124, positive=True, selection=cyclic, tol=0.0019632107023411366, warm_start=False;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.009018036072144287, copy_X=False, max_iter=8124, positive=True, selection=cyclic, tol=0.0019632107023411366, warm_start=False;, score=0.892 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.35571142284569135, copy_X=False, max_iter=7482, positive=True, selection=random, tol=0.006719063545150502, warm_start=True;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.35571142284569135, copy_X=False, max_iter=7482, positive=True, selection=random, tol=0.006719063545150502, warm_start=True;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.3787575150300601, copy_X=True, max_iter=5382, positive=True, selection=cyclic, tol=0.004612040133779264, warm_start=False;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.4098196392785571, copy_X=False, max_iter=7194, positive=True, selection=random, tol=0.00888628762541806, warm_start=True;, score=0.881 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.48597194388777554, copy_X=True, max_iter=9326, positive=True, selection=cyclic, tol=0.00325752508361204, warm_start=True;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.48597194388777554, copy_X=True, max_iter=9326, positive=True, selection=cyclic, tol=0.00325752508361204, warm_start=True;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.13226452905811623, copy_X=False, max_iter=2128, positive=True, selection=cyclic, tol=0.008013377926421405, warm_start=True;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.27054108216432865, copy_X=True, max_iter=7803, positive=False, selection=random, tol=0.005424749163879599, warm_start=False;, score=0.881 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.20741482965931862, copy_X=True, max_iter=7691, positive=False, selection=random, tol=0.01, warm_start=True;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.20741482965931862, copy_X=True, max_iter=7691, positive=False, selection=random, tol=0.01, warm_start=True;, score=0.892 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.17034068136272543, copy_X=False, max_iter=5895, positive=True, selection=cyclic, tol=0.008073578595317725, warm_start=True;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.17034068136272543, copy_X=False, max_iter=5895, positive=True, selection=cyclic, tol=0.008073578595317725, warm_start=True;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.30260521042084165, copy_X=True, max_iter=4452, positive=True, selection=cyclic, tol=0.002836120401337792, warm_start=False;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.29659318637274545, copy_X=False, max_iter=8877, positive=False, selection=cyclic, tol=0.0058461538461538455, warm_start=True;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.16332665330661322, copy_X=True, max_iter=8140, positive=False, selection=random, tol=0.00996989966555184, warm_start=False;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.16332665330661322, copy_X=True, max_iter=8140, positive=False, selection=random, tol=0.00996989966555184, warm_start=False;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.4318637274549098, copy_X=True, max_iter=7306, positive=False, selection=random, tol=0.005394648829431438, warm_start=False;, score=0.892 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.4949874686716792, copy_X=False, max_iter=5859, positive=False, solver=auto, tol=0.008281407035175879;, score=0.919 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.3015037593984963, copy_X=True, max_iter=4894, positive=False, solver=auto, tol=0.006472361809045226;, score=0.879 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.4358395989974937, copy_X=False, max_iter=5698, positive=False, solver=auto, tol=0.0024472361809045216;, score=0.878 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.4358395989974937, copy_X=False, max_iter=5698, positive=False, solver=auto, tol=0.0024472361809045216;, score=0.905 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.12706766917293233, copy_X=False, max_iter=8914, positive=False, solver=auto, tol=0.005974874371859296;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.12706766917293233, copy_X=False, max_iter=8914, positive=False, solver=auto, tol=0.005974874371859296;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.12706766917293233, copy_X=False, max_iter=8914, positive=False, solver=auto, tol=0.005974874371859296;, score=0.891 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.12706766917293233, copy_X=False, max_iter=8914, positive=False, solver=auto, tol=0.005974874371859296;, score=0.880 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.39974937343358397, copy_X=False, max_iter=6301, positive=False, solver=auto, tol=0.008733668341708543;, score=0.878 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.39974937343358397, copy_X=False, max_iter=6301, positive=False, solver=auto, tol=0.008733668341708543;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.39974937343358397, copy_X=False, max_iter=6301, positive=False, solver=auto, tol=0.008733668341708543;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.39974937343358397, copy_X=False, max_iter=6301, positive=False, solver=auto, tol=0.008733668341708543;, score=0.893 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.23132832080200502, copy_X=False, max_iter=3366, positive=False, solver=auto, tol=0.007738693467336683;, score=0.880 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.3666666666666667, copy_X=True, max_iter=6180, positive=False, solver=auto, tol=0.006155778894472361;, score=0.878 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.3666666666666667, copy_X=True, max_iter=6180, positive=False, solver=auto, tol=0.006155778894472361;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.3666666666666667, copy_X=True, max_iter=6180, positive=False, solver=auto, tol=0.006155778894472361;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.3666666666666667, copy_X=True, max_iter=6180, positive=False, solver=auto, tol=0.006155778894472361;, score=0.891 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.3666666666666667, copy_X=True, max_iter=6180, positive=False, solver=auto, tol=0.006155778894472361;, score=0.879 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.19223057644110275, copy_X=False, max_iter=2964, positive=False, solver=auto, tol=0.0076482412060301505;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.19223057644110275, copy_X=False, max_iter=2964, positive=False, solver=auto, tol=0.0076482412060301505;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.10100250626566416, copy_X=True, max_iter=6663, positive=False, solver=auto, tol=0.0029899497487437176;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.10100250626566416, copy_X=True, max_iter=6663, positive=False, solver=auto, tol=0.0029899497487437176;, score=0.891 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.10100250626566416, copy_X=True, max_iter=6663, positive=False, solver=auto, tol=0.0029899497487437176;, score=0.880 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.29949874686716793, copy_X=False, max_iter=2884, positive=False, solver=auto, tol=0.008371859296482412;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.29949874686716793, copy_X=False, max_iter=2884, positive=False, solver=auto, tol=0.008371859296482412;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.29949874686716793, copy_X=False, max_iter=2884, positive=False, solver=auto, tol=0.008371859296482412;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.29949874686716793, copy_X=False, max_iter=2884, positive=False, solver=auto, tol=0.008371859296482412;, score=0.891 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.29949874686716793, copy_X=False, max_iter=2884, positive=False, solver=auto, tol=0.008371859296482412;, score=0.879 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.27054108216432865, copy_X=True, max_iter=7803, positive=False, selection=random, tol=0.005424749163879599, warm_start=False;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.17034068136272543, copy_X=False, max_iter=5895, positive=True, selection=cyclic, tol=0.008073578595317725, warm_start=True;, score=0.881 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.17034068136272543, copy_X=False, max_iter=5895, positive=True, selection=cyclic, tol=0.008073578595317725, warm_start=True;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.30260521042084165, copy_X=True, max_iter=4452, positive=True, selection=cyclic, tol=0.002836120401337792, warm_start=False;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.30260521042084165, copy_X=True, max_iter=4452, positive=True, selection=cyclic, tol=0.002836120401337792, warm_start=False;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.4108216432865731, copy_X=False, max_iter=8348, positive=True, selection=random, tol=0.009849498327759198, warm_start=True;, score=0.883 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.16332665330661322, copy_X=True, max_iter=8140, positive=False, selection=random, tol=0.00996989966555184, warm_start=False;, score=0.881 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.3907268170426065, copy_X=True, max_iter=2120, positive=False, solver=auto, tol=0.009819095477386935;, score=0.878 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.3015037593984963, copy_X=True, max_iter=4894, positive=False, solver=auto, tol=0.006472361809045226;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.4358395989974937, copy_X=False, max_iter=5698, positive=False, solver=auto, tol=0.0024472361809045216;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.4358395989974937, copy_X=False, max_iter=5698, positive=False, solver=auto, tol=0.0024472361809045216;, score=0.891 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.26641604010025066, copy_X=True, max_iter=9035, positive=False, solver=auto, tol=0.005839195979899497;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.26641604010025066, copy_X=True, max_iter=9035, positive=False, solver=auto, tol=0.005839195979899497;, score=0.891 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.4348370927318296, copy_X=True, max_iter=5175, positive=False, solver=auto, tol=0.00864321608040201;, score=0.879 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.2824561403508772, copy_X=True, max_iter=7226, positive=False, solver=auto, tol=0.0015879396984924618;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.2824561403508772, copy_X=True, max_iter=7226, positive=False, solver=auto, tol=0.0015879396984924618;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.2824561403508772, copy_X=True, max_iter=7226, positive=False, solver=auto, tol=0.0015879396984924618;, score=0.918 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.39974937343358397, copy_X=False, max_iter=6301, positive=False, solver=auto, tol=0.008733668341708543;, score=0.879 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.4959899749373433, copy_X=True, max_iter=8512, positive=False, solver=auto, tol=0.006246231155778894;, score=0.878 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.4959899749373433, copy_X=True, max_iter=8512, positive=False, solver=auto, tol=0.006246231155778894;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.4959899749373433, copy_X=True, max_iter=8512, positive=False, solver=auto, tol=0.006246231155778894;, score=0.919 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.19223057644110275, copy_X=False, max_iter=2964, positive=False, solver=auto, tol=0.0076482412060301505;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.19223057644110275, copy_X=False, max_iter=2964, positive=False, solver=auto, tol=0.0076482412060301505;, score=0.891 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.19223057644110275, copy_X=False, max_iter=2964, positive=False, solver=auto, tol=0.0076482412060301505;, score=0.880 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.16215538847117794, copy_X=True, max_iter=6301, positive=False, solver=auto, tol=0.005251256281407034;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.16215538847117794, copy_X=True, max_iter=6301, positive=False, solver=auto, tol=0.005251256281407034;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.16215538847117794, copy_X=True, max_iter=6301, positive=False, solver=auto, tol=0.005251256281407034;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.16215538847117794, copy_X=True, max_iter=6301, positive=False, solver=auto, tol=0.005251256281407034;, score=0.891 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.16215538847117794, copy_X=True, max_iter=6301, positive=False, solver=auto, tol=0.005251256281407034;, score=0.880 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.11503759398496241, copy_X=False, max_iter=6542, positive=False, solver=auto, tol=0.0031256281407035166;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.11503759398496241, copy_X=False, max_iter=6542, positive=False, solver=auto, tol=0.0031256281407035166;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.11503759398496241, copy_X=False, max_iter=6542, positive=False, solver=auto, tol=0.0031256281407035166;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.11503759398496241, copy_X=False, max_iter=6542, positive=False, solver=auto, tol=0.0031256281407035166;, score=0.891 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.11503759398496241, copy_X=False, max_iter=6542, positive=False, solver=auto, tol=0.0031256281407035166;, score=0.880 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.4959899749373433, copy_X=False, max_iter=2402, positive=False, solver=auto, tol=0.007331658291457287;, score=0.878 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.4959899749373433, copy_X=False, max_iter=2402, positive=False, solver=auto, tol=0.007331658291457287;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.4959899749373433, copy_X=False, max_iter=2402, positive=False, solver=auto, tol=0.007331658291457287;, score=0.919 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.45889724310776947, copy_X=False, max_iter=5256, positive=False, solver=auto, tol=0.00850753768844221;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.45889724310776947, copy_X=False, max_iter=5256, positive=False, solver=auto, tol=0.00850753768844221;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.45889724310776947, copy_X=False, max_iter=5256, positive=False, solver=auto, tol=0.00850753768844221;, score=0.893 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.45889724310776947, copy_X=False, max_iter=5256, positive=False, solver=auto, tol=0.00850753768844221;, score=0.879 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.26541353383458643, copy_X=True, max_iter=9557, positive=False, solver=auto, tol=0.00443718592964824;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.26541353383458643, copy_X=True, max_iter=9557, positive=False, solver=auto, tol=0.00443718592964824;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.26541353383458643, copy_X=True, max_iter=9557, positive=False, solver=auto, tol=0.00443718592964824;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.26541353383458643, copy_X=True, max_iter=9557, positive=False, solver=auto, tol=0.00443718592964824;, score=0.891 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.26541353383458643, copy_X=True, max_iter=9557, positive=False, solver=auto, tol=0.00443718592964824;, score=0.879 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.36867167919799504, copy_X=False, max_iter=5698, positive=False, solver=auto, tol=0.0029899497487437176;, score=0.878 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.36867167919799504, copy_X=False, max_iter=5698, positive=False, solver=auto, tol=0.0029899497487437176;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.36867167919799504, copy_X=False, max_iter=5698, positive=False, solver=auto, tol=0.0029899497487437176;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.36867167919799504, copy_X=False, max_iter=5698, positive=False, solver=auto, tol=0.0029899497487437176;, score=0.891 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.36867167919799504, copy_X=False, max_iter=5698, positive=False, solver=auto, tol=0.0029899497487437176;, score=0.879 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.4949874686716792, copy_X=False, max_iter=5859, positive=False, solver=auto, tol=0.008281407035175879;, score=0.878 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.3907268170426065, copy_X=True, max_iter=2120, positive=False, solver=auto, tol=0.009819095477386935;, score=0.905 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.3917293233082707, copy_X=False, max_iter=3567, positive=False, solver=auto, tol=0.007738693467336683;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.3917293233082707, copy_X=False, max_iter=3567, positive=False, solver=auto, tol=0.007738693467336683;, score=0.919 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.26641604010025066, copy_X=True, max_iter=9035, positive=False, solver=auto, tol=0.005839195979899497;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.26641604010025066, copy_X=True, max_iter=9035, positive=False, solver=auto, tol=0.005839195979899497;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.42882205513784466, copy_X=False, max_iter=6381, positive=False, solver=auto, tol=0.005567839195979899;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.42882205513784466, copy_X=False, max_iter=6381, positive=False, solver=auto, tol=0.005567839195979899;, score=0.891 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.42882205513784466, copy_X=False, max_iter=6381, positive=False, solver=auto, tol=0.005567839195979899;, score=0.879 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.4659147869674185, copy_X=True, max_iter=4130, positive=False, solver=auto, tol=0.004979899497487436;, score=0.878 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.23132832080200502, copy_X=False, max_iter=3366, positive=False, solver=auto, tol=0.007738693467336683;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.23132832080200502, copy_X=False, max_iter=3366, positive=False, solver=auto, tol=0.007738693467336683;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.23132832080200502, copy_X=False, max_iter=3366, positive=False, solver=auto, tol=0.007738693467336683;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.23132832080200502, copy_X=False, max_iter=3366, positive=False, solver=auto, tol=0.007738693467336683;, score=0.891 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1411027568922306, copy_X=False, max_iter=6944, positive=False, solver=auto, tol=0.0023567839195979884;, score=0.880 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.2142857142857143, copy_X=False, max_iter=6060, positive=False, solver=auto, tol=0.0031708542713567833;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.2142857142857143, copy_X=False, max_iter=6060, positive=False, solver=auto, tol=0.0031708542713567833;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.2142857142857143, copy_X=False, max_iter=6060, positive=False, solver=auto, tol=0.0031708542713567833;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.2142857142857143, copy_X=False, max_iter=6060, positive=False, solver=auto, tol=0.0031708542713567833;, score=0.891 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.2142857142857143, copy_X=False, max_iter=6060, positive=False, solver=auto, tol=0.0031708542713567833;, score=0.880 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.10100250626566416, copy_X=True, max_iter=6663, positive=False, solver=auto, tol=0.0029899497487437176;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.10100250626566416, copy_X=True, max_iter=6663, positive=False, solver=auto, tol=0.0029899497487437176;, score=0.905 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.4799498746867168, copy_X=True, max_iter=7909, positive=False, solver=auto, tol=0.0025829145728643206;, score=0.879 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.22130325814536342, copy_X=True, max_iter=5175, positive=False, solver=auto, tol=0.0019045226130653247;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.22130325814536342, copy_X=True, max_iter=5175, positive=False, solver=auto, tol=0.0019045226130653247;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.22130325814536342, copy_X=True, max_iter=5175, positive=False, solver=auto, tol=0.0019045226130653247;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.22130325814536342, copy_X=True, max_iter=5175, positive=False, solver=auto, tol=0.0019045226130653247;, score=0.891 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.22130325814536342, copy_X=True, max_iter=5175, positive=False, solver=auto, tol=0.0019045226130653247;, score=0.880 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.5, copy_X=True, max_iter=6703, positive=False, solver=auto, tol=0.00493467336683417;, score=0.878 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.5, copy_X=True, max_iter=6703, positive=False, solver=auto, tol=0.00493467336683417;, score=0.905 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.33458646616541354, copy_X=True, max_iter=4291, positive=False, solver=auto, tol=0.0023115577889447226;, score=0.879 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.4448621553884712, copy_X=False, max_iter=6422, positive=False, solver=auto, tol=0.009728643216080402;, score=0.878 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.4448621553884712, copy_X=False, max_iter=6422, positive=False, solver=auto, tol=0.009728643216080402;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.4448621553884712, copy_X=False, max_iter=6422, positive=False, solver=auto, tol=0.009728643216080402;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.4448621553884712, copy_X=False, max_iter=6422, positive=False, solver=auto, tol=0.009728643216080402;, score=0.893 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.4448621553884712, copy_X=False, max_iter=6422, positive=False, solver=auto, tol=0.009728643216080402;, score=0.879 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.45889724310776947, copy_X=True, max_iter=2080, positive=False, solver=auto, tol=0.005522613065326632;, score=0.878 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.45889724310776947, copy_X=True, max_iter=2080, positive=False, solver=auto, tol=0.005522613065326632;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.45889724310776947, copy_X=True, max_iter=2080, positive=False, solver=auto, tol=0.005522613065326632;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.45889724310776947, copy_X=True, max_iter=2080, positive=False, solver=auto, tol=0.005522613065326632;, score=0.891 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.45889724310776947, copy_X=True, max_iter=2080, positive=False, solver=auto, tol=0.005522613065326632;, score=0.879 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.44786967418546364, copy_X=False, max_iter=5778, positive=False, solver=auto, tol=0.009321608040201004;, score=0.878 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.44786967418546364, copy_X=False, max_iter=5778, positive=False, solver=auto, tol=0.009321608040201004;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.44786967418546364, copy_X=False, max_iter=5778, positive=False, solver=auto, tol=0.009321608040201004;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.44786967418546364, copy_X=False, max_iter=5778, positive=False, solver=auto, tol=0.009321608040201004;, score=0.893 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.44786967418546364, copy_X=False, max_iter=5778, positive=False, solver=auto, tol=0.009321608040201004;, score=0.879 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.14210526315789473, copy_X=True, max_iter=7065, positive=False, solver=auto, tol=0.0028994974874371852;, score=0.880 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.29949874686716793, copy_X=True, max_iter=4733, positive=False, solver=auto, tol=0.006336683417085426;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.29949874686716793, copy_X=True, max_iter=4733, positive=False, solver=auto, tol=0.006336683417085426;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.29949874686716793, copy_X=True, max_iter=4733, positive=False, solver=auto, tol=0.006336683417085426;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.29949874686716793, copy_X=True, max_iter=4733, positive=False, solver=auto, tol=0.006336683417085426;, score=0.891 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.29949874686716793, copy_X=True, max_iter=4733, positive=False, solver=auto, tol=0.006336683417085426;, score=0.879 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.4659147869674185, copy_X=True, max_iter=4130, positive=False, solver=auto, tol=0.004979899497487436;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.4659147869674185, copy_X=True, max_iter=4130, positive=False, solver=auto, tol=0.004979899497487436;, score=0.891 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.4659147869674185, copy_X=True, max_iter=4130, positive=False, solver=auto, tol=0.004979899497487436;, score=0.879 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.22030075187969925, copy_X=True, max_iter=7708, positive=False, solver=auto, tol=0.004618090452261306;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.22030075187969925, copy_X=True, max_iter=7708, positive=False, solver=auto, tol=0.004618090452261306;, score=0.891 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.22030075187969925, copy_X=True, max_iter=7708, positive=False, solver=auto, tol=0.004618090452261306;, score=0.880 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.36566416040100247, copy_X=False, max_iter=3929, positive=False, solver=auto, tol=0.006065326633165829;, score=0.878 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.2744360902255639, copy_X=True, max_iter=8673, positive=False, solver=auto, tol=0.0024472361809045216;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.2744360902255639, copy_X=True, max_iter=8673, positive=False, solver=auto, tol=0.0024472361809045216;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.2744360902255639, copy_X=True, max_iter=8673, positive=False, solver=auto, tol=0.0024472361809045216;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.2744360902255639, copy_X=True, max_iter=8673, positive=False, solver=auto, tol=0.0024472361809045216;, score=0.891 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.2744360902255639, copy_X=True, max_iter=8673, positive=False, solver=auto, tol=0.0024472361809045216;, score=0.879 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.3315789473684211, copy_X=False, max_iter=6824, positive=False, solver=auto, tol=0.005160804020100502;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.3315789473684211, copy_X=False, max_iter=6824, positive=False, solver=auto, tol=0.005160804020100502;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.3315789473684211, copy_X=False, max_iter=6824, positive=False, solver=auto, tol=0.005160804020100502;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.4959899749373433, copy_X=False, max_iter=2402, positive=False, solver=auto, tol=0.007331658291457287;, score=0.893 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.4959899749373433, copy_X=False, max_iter=2402, positive=False, solver=auto, tol=0.007331658291457287;, score=0.879 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.22230576441102756, copy_X=True, max_iter=6944, positive=False, solver=auto, tol=0.00850753768844221;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.22230576441102756, copy_X=True, max_iter=6944, positive=False, solver=auto, tol=0.00850753768844221;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.22230576441102756, copy_X=True, max_iter=6944, positive=False, solver=auto, tol=0.00850753768844221;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.22230576441102756, copy_X=True, max_iter=6944, positive=False, solver=auto, tol=0.00850753768844221;, score=0.891 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.22230576441102756, copy_X=True, max_iter=6944, positive=False, solver=auto, tol=0.00850753768844221;, score=0.880 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.17017543859649123, copy_X=False, max_iter=6944, positive=False, solver=auto, tol=0.001452261306532662;, score=0.879 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.4759398496240601, copy_X=True, max_iter=3648, positive=False, solver=auto, tol=0.006788944723618091;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.4759398496240601, copy_X=True, max_iter=3648, positive=False, solver=auto, tol=0.006788944723618091;, score=0.893 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.4759398496240601, copy_X=True, max_iter=3648, positive=False, solver=auto, tol=0.006788944723618091;, score=0.879 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.43383458646616546, copy_X=True, max_iter=7346, positive=False, solver=auto, tol=0.0024924623115577874;, score=0.878 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.43383458646616546, copy_X=True, max_iter=7346, positive=False, solver=auto, tol=0.0024924623115577874;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.43383458646616546, copy_X=True, max_iter=7346, positive=False, solver=auto, tol=0.0024924623115577874;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.43383458646616546, copy_X=True, max_iter=7346, positive=False, solver=auto, tol=0.0024924623115577874;, score=0.891 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.43383458646616546, copy_X=True, max_iter=7346, positive=False, solver=auto, tol=0.0024924623115577874;, score=0.879 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.25839598997493735, copy_X=True, max_iter=3728, positive=False, solver=auto, tol=0.008326633165829146;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.25839598997493735, copy_X=True, max_iter=3728, positive=False, solver=auto, tol=0.008326633165829146;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.25839598997493735, copy_X=True, max_iter=3728, positive=False, solver=auto, tol=0.008326633165829146;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.25839598997493735, copy_X=True, max_iter=3728, positive=False, solver=auto, tol=0.008326633165829146;, score=0.891 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.25839598997493735, copy_X=True, max_iter=3728, positive=False, solver=auto, tol=0.008326633165829146;, score=0.879 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.35062656641604006, copy_X=False, max_iter=4572, positive=False, solver=auto, tol=0.004346733668341708;, score=0.878 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.35062656641604006, copy_X=False, max_iter=4572, positive=False, solver=auto, tol=0.004346733668341708;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.35062656641604006, copy_X=False, max_iter=4572, positive=False, solver=auto, tol=0.004346733668341708;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.29147869674185467, copy_X=False, max_iter=7226, positive=False, solver=auto, tol=0.007693467336683416;, score=0.891 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.29147869674185467, copy_X=False, max_iter=7226, positive=False, solver=auto, tol=0.007693467336683416;, score=0.879 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.3526315789473684, copy_X=True, max_iter=8793, positive=False, solver=auto, tol=0.006381909547738693;, score=0.878 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.3526315789473684, copy_X=True, max_iter=8793, positive=False, solver=auto, tol=0.006381909547738693;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.3526315789473684, copy_X=True, max_iter=8793, positive=False, solver=auto, tol=0.006381909547738693;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.3526315789473684, copy_X=True, max_iter=8793, positive=False, solver=auto, tol=0.006381909547738693;, score=0.891 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.3526315789473684, copy_X=True, max_iter=8793, positive=False, solver=auto, tol=0.006381909547738693;, score=0.879 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.3526315789473684, copy_X=True, max_iter=2562, positive=False, solver=auto, tol=0.006608040201005024;, score=0.878 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.3526315789473684, copy_X=True, max_iter=2562, positive=False, solver=auto, tol=0.006608040201005024;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.3526315789473684, copy_X=True, max_iter=2562, positive=False, solver=auto, tol=0.006608040201005024;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.3526315789473684, copy_X=True, max_iter=2562, positive=False, solver=auto, tol=0.006608040201005024;, score=0.891 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.3526315789473684, copy_X=True, max_iter=2562, positive=False, solver=auto, tol=0.006608040201005024;, score=0.879 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.14210526315789473, copy_X=True, max_iter=7065, positive=False, solver=auto, tol=0.0028994974874371852;, score=0.879 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.36566416040100247, copy_X=False, max_iter=3929, positive=False, solver=auto, tol=0.006065326633165829;, score=0.891 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.36566416040100247, copy_X=False, max_iter=3929, positive=False, solver=auto, tol=0.006065326633165829;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.17518796992481203, copy_X=True, max_iter=5979, positive=False, solver=auto, tol=0.006517587939698493;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.17518796992481203, copy_X=True, max_iter=5979, positive=False, solver=auto, tol=0.006517587939698493;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.17518796992481203, copy_X=True, max_iter=5979, positive=False, solver=auto, tol=0.006517587939698493;, score=0.891 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.17518796992481203, copy_X=True, max_iter=5979, positive=False, solver=auto, tol=0.006517587939698493;, score=0.880 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1411027568922306, copy_X=False, max_iter=6944, positive=False, solver=auto, tol=0.0023567839195979884;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1411027568922306, copy_X=False, max_iter=6944, positive=False, solver=auto, tol=0.0023567839195979884;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1411027568922306, copy_X=False, max_iter=6944, positive=False, solver=auto, tol=0.0023567839195979884;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1411027568922306, copy_X=False, max_iter=6944, positive=False, solver=auto, tol=0.0023567839195979884;, score=0.891 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.17017543859649123, copy_X=False, max_iter=6944, positive=False, solver=auto, tol=0.001452261306532662;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.17017543859649123, copy_X=False, max_iter=6944, positive=False, solver=auto, tol=0.001452261306532662;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.17017543859649123, copy_X=False, max_iter=6944, positive=False, solver=auto, tol=0.001452261306532662;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.17017543859649123, copy_X=False, max_iter=6944, positive=False, solver=auto, tol=0.001452261306532662;, score=0.880 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.4799498746867168, copy_X=True, max_iter=7909, positive=False, solver=auto, tol=0.0025829145728643206;, score=0.878 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.4799498746867168, copy_X=True, max_iter=7909, positive=False, solver=auto, tol=0.0025829145728643206;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.4799498746867168, copy_X=True, max_iter=7909, positive=False, solver=auto, tol=0.0025829145728643206;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.4799498746867168, copy_X=True, max_iter=7909, positive=False, solver=auto, tol=0.0025829145728643206;, score=0.891 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.35062656641604006, copy_X=False, max_iter=4572, positive=False, solver=auto, tol=0.004346733668341708;, score=0.891 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.35062656641604006, copy_X=False, max_iter=4572, positive=False, solver=auto, tol=0.004346733668341708;, score=0.879 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.31052631578947365, copy_X=False, max_iter=6381, positive=False, solver=auto, tol=0.006834170854271356;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.31052631578947365, copy_X=False, max_iter=6381, positive=False, solver=auto, tol=0.006834170854271356;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.31052631578947365, copy_X=False, max_iter=6381, positive=False, solver=auto, tol=0.006834170854271356;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.31052631578947365, copy_X=False, max_iter=6381, positive=False, solver=auto, tol=0.006834170854271356;, score=0.891 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.31052631578947365, copy_X=False, max_iter=6381, positive=False, solver=auto, tol=0.006834170854271356;, score=0.879 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.16416040100250628, copy_X=True, max_iter=7507, positive=False, solver=auto, tol=0.0018140703517587932;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.16416040100250628, copy_X=True, max_iter=7507, positive=False, solver=auto, tol=0.0018140703517587932;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.16416040100250628, copy_X=True, max_iter=7507, positive=False, solver=auto, tol=0.0018140703517587932;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.16416040100250628, copy_X=True, max_iter=7507, positive=False, solver=auto, tol=0.0018140703517587932;, score=0.891 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.16416040100250628, copy_X=True, max_iter=7507, positive=False, solver=auto, tol=0.0018140703517587932;, score=0.880 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.33458646616541354, copy_X=True, max_iter=4291, positive=False, solver=auto, tol=0.0023115577889447226;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.33458646616541354, copy_X=True, max_iter=4291, positive=False, solver=auto, tol=0.0023115577889447226;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.33458646616541354, copy_X=True, max_iter=4291, positive=False, solver=auto, tol=0.0023115577889447226;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.33458646616541354, copy_X=True, max_iter=4291, positive=False, solver=auto, tol=0.0023115577889447226;, score=0.891 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.31052631578947365, copy_X=False, max_iter=3045, positive=False, solver=auto, tol=0.0025829145728643206;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.31052631578947365, copy_X=False, max_iter=3045, positive=False, solver=auto, tol=0.0025829145728643206;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.31052631578947365, copy_X=False, max_iter=3045, positive=False, solver=auto, tol=0.0025829145728643206;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.31052631578947365, copy_X=False, max_iter=3045, positive=False, solver=auto, tol=0.0025829145728643206;, score=0.891 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.31052631578947365, copy_X=False, max_iter=3045, positive=False, solver=auto, tol=0.0025829145728643206;, score=0.879 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.3325814536340852, copy_X=False, max_iter=2562, positive=False, solver=auto, tol=0.006336683417085426;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.3325814536340852, copy_X=False, max_iter=2562, positive=False, solver=auto, tol=0.006336683417085426;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.3325814536340852, copy_X=False, max_iter=2562, positive=False, solver=auto, tol=0.006336683417085426;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.3325814536340852, copy_X=False, max_iter=2562, positive=False, solver=auto, tol=0.006336683417085426;, score=0.891 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.3325814536340852, copy_X=False, max_iter=2562, positive=False, solver=auto, tol=0.006336683417085426;, score=0.879 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.34461152882205515, copy_X=True, max_iter=2562, positive=False, solver=auto, tol=0.005522613065326632;, score=0.878 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.34461152882205515, copy_X=True, max_iter=2562, positive=False, solver=auto, tol=0.005522613065326632;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.34461152882205515, copy_X=True, max_iter=2562, positive=False, solver=auto, tol=0.005522613065326632;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.34461152882205515, copy_X=True, max_iter=2562, positive=False, solver=auto, tol=0.005522613065326632;, score=0.891 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.34461152882205515, copy_X=True, max_iter=2562, positive=False, solver=auto, tol=0.005522613065326632;, score=0.879 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.45789473684210524, copy_X=True, max_iter=2683, positive=False, solver=auto, tol=0.003351758793969848;, score=0.878 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.26040100250626563, copy_X=True, max_iter=9919, positive=False, solver=auto, tol=0.009095477386934673;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.26040100250626563, copy_X=True, max_iter=9919, positive=False, solver=auto, tol=0.009095477386934673;, score=0.891 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.5, copy_X=True, max_iter=6703, positive=False, solver=auto, tol=0.00493467336683417;, score=0.891 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.5, copy_X=True, max_iter=6703, positive=False, solver=auto, tol=0.00493467336683417;, score=0.879 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.21629072681704262, copy_X=True, max_iter=7145, positive=False, solver=auto, tol=0.007829145728643216;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.21629072681704262, copy_X=True, max_iter=7145, positive=False, solver=auto, tol=0.007829145728643216;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.21629072681704262, copy_X=True, max_iter=7145, positive=False, solver=auto, tol=0.007829145728643216;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.21629072681704262, copy_X=True, max_iter=7145, positive=False, solver=auto, tol=0.007829145728643216;, score=0.891 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.21629072681704262, copy_X=True, max_iter=7145, positive=False, solver=auto, tol=0.007829145728643216;, score=0.880 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.412781954887218, copy_X=False, max_iter=5979, positive=False, solver=auto, tol=0.005658291457286432;, score=0.878 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.412781954887218, copy_X=False, max_iter=5979, positive=False, solver=auto, tol=0.005658291457286432;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.412781954887218, copy_X=False, max_iter=5979, positive=False, solver=auto, tol=0.005658291457286432;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.412781954887218, copy_X=False, max_iter=5979, positive=False, solver=auto, tol=0.005658291457286432;, score=0.891 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.412781954887218, copy_X=False, max_iter=5979, positive=False, solver=auto, tol=0.005658291457286432;, score=0.879 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.49699248120300754, copy_X=False, max_iter=4170, positive=False, solver=auto, tol=0.009185929648241206;, score=0.878 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.49699248120300754, copy_X=False, max_iter=4170, positive=False, solver=auto, tol=0.009185929648241206;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.49699248120300754, copy_X=False, max_iter=4170, positive=False, solver=auto, tol=0.009185929648241206;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.49699248120300754, copy_X=False, max_iter=4170, positive=False, solver=auto, tol=0.009185929648241206;, score=0.893 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.49699248120300754, copy_X=False, max_iter=4170, positive=False, solver=auto, tol=0.009185929648241206;, score=0.879 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.13007518796992482, copy_X=True, max_iter=7668, positive=False, solver=auto, tol=0.0014974874371859286;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.13007518796992482, copy_X=True, max_iter=7668, positive=False, solver=auto, tol=0.0014974874371859286;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.13007518796992482, copy_X=True, max_iter=7668, positive=False, solver=auto, tol=0.0014974874371859286;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.13007518796992482, copy_X=True, max_iter=7668, positive=False, solver=auto, tol=0.0014974874371859286;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.13007518796992482, copy_X=True, max_iter=7668, positive=False, solver=auto, tol=0.0014974874371859286;, score=0.880 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.4218045112781955, copy_X=True, max_iter=4814, positive=False, solver=auto, tol=0.009909547738693467;, score=0.878 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.45789473684210524, copy_X=True, max_iter=2683, positive=False, solver=auto, tol=0.003351758793969848;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.45789473684210524, copy_X=True, max_iter=2683, positive=False, solver=auto, tol=0.003351758793969848;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.45789473684210524, copy_X=True, max_iter=2683, positive=False, solver=auto, tol=0.003351758793969848;, score=0.891 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.45789473684210524, copy_X=True, max_iter=2683, positive=False, solver=auto, tol=0.003351758793969848;, score=0.879 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.24235588972431077, copy_X=True, max_iter=8472, positive=False, solver=auto, tol=0.0024924623115577874;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.24235588972431077, copy_X=True, max_iter=8472, positive=False, solver=auto, tol=0.0024924623115577874;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.24235588972431077, copy_X=True, max_iter=8472, positive=False, solver=auto, tol=0.0024924623115577874;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.24235588972431077, copy_X=True, max_iter=8472, positive=False, solver=auto, tol=0.0024924623115577874;, score=0.891 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.24235588972431077, copy_X=True, max_iter=8472, positive=False, solver=auto, tol=0.0024924623115577874;, score=0.879 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.29147869674185467, copy_X=False, max_iter=9798, positive=False, solver=auto, tol=0.005160804020100502;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.29147869674185467, copy_X=False, max_iter=9798, positive=False, solver=auto, tol=0.005160804020100502;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.29147869674185467, copy_X=False, max_iter=9798, positive=False, solver=auto, tol=0.005160804020100502;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.29147869674185467, copy_X=False, max_iter=9798, positive=False, solver=auto, tol=0.005160804020100502;, score=0.891 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.29147869674185467, copy_X=False, max_iter=9798, positive=False, solver=auto, tol=0.005160804020100502;, score=0.879 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.36065162907268167, copy_X=True, max_iter=8753, positive=False, solver=auto, tol=0.003939698492462311;, score=0.878 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.36065162907268167, copy_X=True, max_iter=8753, positive=False, solver=auto, tol=0.003939698492462311;, score=0.905 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.26040100250626563, copy_X=True, max_iter=9919, positive=False, solver=auto, tol=0.009095477386934673;, score=0.879 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.3726817042606516, copy_X=True, max_iter=5015, positive=False, solver=auto, tol=0.004979899497487436;, score=0.878 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.26842105263157895, copy_X=True, max_iter=10000, positive=False, solver=auto, tol=0.007557788944723618;, score=0.879 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1791979949874687, copy_X=False, max_iter=9597, positive=False, solver=auto, tol=0.0015879396984924618;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1230576441102757, copy_X=True, max_iter=8190, positive=False, solver=auto, tol=0.004211055276381909;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1230576441102757, copy_X=True, max_iter=8190, positive=False, solver=auto, tol=0.004211055276381909;, score=0.918 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.4368421052631579, copy_X=False, max_iter=5859, positive=False, solver=auto, tol=0.008236180904522612;, score=0.879 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.387719298245614, copy_X=False, max_iter=7427, positive=False, solver=auto, tol=0.006608040201005024;, score=0.878 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.27644110275689227, copy_X=True, max_iter=4251, positive=False, solver=auto, tol=0.0072412060301507535;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.27644110275689227, copy_X=True, max_iter=4251, positive=False, solver=auto, tol=0.0072412060301507535;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.35864661654135344, copy_X=False, max_iter=3487, positive=False, solver=auto, tol=0.009412060301507538;, score=0.893 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.35864661654135344, copy_X=False, max_iter=3487, positive=False, solver=auto, tol=0.009412060301507538;, score=0.879 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.10300751879699249, copy_X=True, max_iter=8391, positive=False, solver=auto, tol=0.008371859296482412;, score=0.879 total time=   0.0s\n",
      "Ridge() RandomCV Best Params : {'tol': 0.001180904522613064, 'solver': 'auto', 'positive': 'False', 'max_iter': 7989, 'copy_X': 'True', 'alpha': 0.1330827067669173}\n",
      "Ridge() RandomCV Score: 0.8632007478818366\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END alpha=0.17117794486215537, copy_X=False, max_iter=6623, positive=False, solver=auto, tol=0.007015075376884422;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.17117794486215537, copy_X=False, max_iter=6623, positive=False, solver=auto, tol=0.007015075376884422;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.17117794486215537, copy_X=False, max_iter=6623, positive=False, solver=auto, tol=0.007015075376884422;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.17117794486215537, copy_X=False, max_iter=6623, positive=False, solver=auto, tol=0.007015075376884422;, score=0.891 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.17117794486215537, copy_X=False, max_iter=6623, positive=False, solver=auto, tol=0.007015075376884422;, score=0.880 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.23333333333333334, copy_X=True, max_iter=2482, positive=False, solver=auto, tol=0.00592964824120603;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.23333333333333334, copy_X=True, max_iter=2482, positive=False, solver=auto, tol=0.00592964824120603;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.23333333333333334, copy_X=True, max_iter=2482, positive=False, solver=auto, tol=0.00592964824120603;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.23333333333333334, copy_X=True, max_iter=2482, positive=False, solver=auto, tol=0.00592964824120603;, score=0.891 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.23333333333333334, copy_X=True, max_iter=2482, positive=False, solver=auto, tol=0.00592964824120603;, score=0.880 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.17619047619047618, copy_X=True, max_iter=8753, positive=False, solver=auto, tol=0.0014070351758793953;, score=0.880 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.17619047619047618, copy_X=True, max_iter=8753, positive=False, solver=auto, tol=0.0014070351758793953;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.17619047619047618, copy_X=True, max_iter=8753, positive=False, solver=auto, tol=0.0014070351758793953;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.17619047619047618, copy_X=True, max_iter=8753, positive=False, solver=auto, tol=0.0014070351758793953;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.17619047619047618, copy_X=True, max_iter=8753, positive=False, solver=auto, tol=0.0014070351758793953;, score=0.880 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.45889724310776947, copy_X=False, max_iter=5256, positive=False, solver=auto, tol=0.00850753768844221;, score=0.878 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.37869674185463664, copy_X=True, max_iter=9396, positive=False, solver=auto, tol=0.0038492462311557783;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.37869674185463664, copy_X=True, max_iter=9396, positive=False, solver=auto, tol=0.0038492462311557783;, score=0.891 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.37869674185463664, copy_X=True, max_iter=9396, positive=False, solver=auto, tol=0.0038492462311557783;, score=0.879 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.23634085213032582, copy_X=False, max_iter=9839, positive=False, solver=auto, tol=0.009366834170854271;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.23634085213032582, copy_X=False, max_iter=9839, positive=False, solver=auto, tol=0.009366834170854271;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.23634085213032582, copy_X=False, max_iter=9839, positive=False, solver=auto, tol=0.009366834170854271;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.23634085213032582, copy_X=False, max_iter=9839, positive=False, solver=auto, tol=0.009366834170854271;, score=0.891 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.23634085213032582, copy_X=False, max_iter=9839, positive=False, solver=auto, tol=0.009366834170854271;, score=0.880 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.3927318295739348, copy_X=False, max_iter=5618, positive=False, solver=auto, tol=0.004165829145728642;, score=0.878 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.3927318295739348, copy_X=False, max_iter=5618, positive=False, solver=auto, tol=0.004165829145728642;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.3927318295739348, copy_X=False, max_iter=5618, positive=False, solver=auto, tol=0.004165829145728642;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.3927318295739348, copy_X=False, max_iter=5618, positive=False, solver=auto, tol=0.004165829145728642;, score=0.891 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.3927318295739348, copy_X=False, max_iter=5618, positive=False, solver=auto, tol=0.004165829145728642;, score=0.879 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.29147869674185467, copy_X=False, max_iter=7226, positive=False, solver=auto, tol=0.007693467336683416;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.29147869674185467, copy_X=False, max_iter=7226, positive=False, solver=auto, tol=0.007693467336683416;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.29147869674185467, copy_X=False, max_iter=7226, positive=False, solver=auto, tol=0.007693467336683416;, score=0.919 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1330827067669173, copy_X=True, max_iter=7989, positive=False, solver=auto, tol=0.001180904522613064;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1330827067669173, copy_X=True, max_iter=7989, positive=False, solver=auto, tol=0.001180904522613064;, score=0.918 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.26842105263157895, copy_X=True, max_iter=10000, positive=False, solver=auto, tol=0.007557788944723618;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.26842105263157895, copy_X=True, max_iter=10000, positive=False, solver=auto, tol=0.007557788944723618;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.2644110275689223, copy_X=False, max_iter=7467, positive=False, solver=auto, tol=0.006517587939698493;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.2644110275689223, copy_X=False, max_iter=7467, positive=False, solver=auto, tol=0.006517587939698493;, score=0.891 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1511278195488722, copy_X=False, max_iter=9075, positive=False, solver=auto, tol=0.005522613065326632;, score=0.880 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.23634085213032582, copy_X=False, max_iter=7226, positive=False, solver=auto, tol=0.005613065326633165;, score=0.879 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.47794486215538845, copy_X=True, max_iter=3206, positive=False, solver=auto, tol=0.009231155778894473;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.47794486215538845, copy_X=True, max_iter=3206, positive=False, solver=auto, tol=0.009231155778894473;, score=0.893 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.35864661654135344, copy_X=False, max_iter=3487, positive=False, solver=auto, tol=0.009412060301507538;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.35864661654135344, copy_X=False, max_iter=3487, positive=False, solver=auto, tol=0.009412060301507538;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.3776942355889724, copy_X=True, max_iter=8391, positive=False, solver=auto, tol=0.004346733668341708;, score=0.891 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.3776942355889724, copy_X=True, max_iter=8391, positive=False, solver=auto, tol=0.004346733668341708;, score=0.879 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.14411027568922308, copy_X=False, max_iter=6944, positive=False, solver=auto, tol=0.005386934673366833;, score=0.891 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.14411027568922308, copy_X=False, max_iter=6944, positive=False, solver=auto, tol=0.005386934673366833;, score=0.880 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.3385964912280702, copy_X=True, max_iter=9356, positive=False, solver=auto, tol=0.007693467336683416;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.3385964912280702, copy_X=True, max_iter=9356, positive=False, solver=auto, tol=0.007693467336683416;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.3426065162907268, copy_X=False, max_iter=9155, positive=False, solver=auto, tol=0.004527638190954773;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.3426065162907268, copy_X=False, max_iter=9155, positive=False, solver=auto, tol=0.004527638190954773;, score=0.891 total time=   0.0s\n",
      "Final score is  0.8632007478818366\n",
      "[CV 2/5] END alpha=0.1791979949874687, copy_X=False, max_iter=9597, positive=False, solver=auto, tol=0.0015879396984924618;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1791979949874687, copy_X=False, max_iter=9597, positive=False, solver=auto, tol=0.0015879396984924618;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1230576441102757, copy_X=True, max_iter=8190, positive=False, solver=auto, tol=0.004211055276381909;, score=0.891 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1230576441102757, copy_X=True, max_iter=8190, positive=False, solver=auto, tol=0.004211055276381909;, score=0.880 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.23634085213032582, copy_X=False, max_iter=7226, positive=False, solver=auto, tol=0.005613065326633165;, score=0.891 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.23634085213032582, copy_X=False, max_iter=7226, positive=False, solver=auto, tol=0.005613065326633165;, score=0.880 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.387719298245614, copy_X=False, max_iter=7427, positive=False, solver=auto, tol=0.006608040201005024;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.387719298245614, copy_X=False, max_iter=7427, positive=False, solver=auto, tol=0.006608040201005024;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.27644110275689227, copy_X=True, max_iter=4251, positive=False, solver=auto, tol=0.0072412060301507535;, score=0.891 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.27644110275689227, copy_X=True, max_iter=4251, positive=False, solver=auto, tol=0.0072412060301507535;, score=0.879 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.37969924812030076, copy_X=True, max_iter=5055, positive=False, solver=auto, tol=0.008417085427135679;, score=0.878 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.37969924812030076, copy_X=True, max_iter=5055, positive=False, solver=auto, tol=0.008417085427135679;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.10300751879699249, copy_X=True, max_iter=8391, positive=False, solver=auto, tol=0.008371859296482412;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.10300751879699249, copy_X=True, max_iter=8391, positive=False, solver=auto, tol=0.008371859296482412;, score=0.891 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.4408521303258145, copy_X=False, max_iter=6261, positive=False, solver=auto, tol=0.004165829145728642;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.4408521303258145, copy_X=False, max_iter=6261, positive=False, solver=auto, tol=0.004165829145728642;, score=0.891 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.3385964912280702, copy_X=True, max_iter=9356, positive=False, solver=auto, tol=0.007693467336683416;, score=0.879 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.20726817042606516, copy_X=True, max_iter=7065, positive=False, solver=auto, tol=0.001994974874371858;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.32556390977443606, copy_X=False, max_iter=3768, positive=False, solver=auto, tol=0.0028994974874371852;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.32556390977443606, copy_X=False, max_iter=3768, positive=False, solver=auto, tol=0.0028994974874371852;, score=0.919 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.10300751879699249, copy_X=True, max_iter=8391, positive=False, solver=auto, tol=0.008371859296482412;, score=0.905 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.4408521303258145, copy_X=False, max_iter=6261, positive=False, solver=auto, tol=0.004165829145728642;, score=0.878 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.4408521303258145, copy_X=False, max_iter=6261, positive=False, solver=auto, tol=0.004165829145728642;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.3385964912280702, copy_X=True, max_iter=9356, positive=False, solver=auto, tol=0.007693467336683416;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.3385964912280702, copy_X=True, max_iter=9356, positive=False, solver=auto, tol=0.007693467336683416;, score=0.893 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.3426065162907268, copy_X=False, max_iter=9155, positive=False, solver=auto, tol=0.004527638190954773;, score=0.879 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.32556390977443606, copy_X=False, max_iter=3768, positive=False, solver=auto, tol=0.0028994974874371852;, score=0.879 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1330827067669173, copy_X=True, max_iter=7989, positive=False, solver=auto, tol=0.001180904522613064;, score=0.880 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.14210526315789473, copy_X=True, max_iter=7065, positive=False, solver=auto, tol=0.0028994974874371852;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.14210526315789473, copy_X=True, max_iter=7065, positive=False, solver=auto, tol=0.0028994974874371852;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.14210526315789473, copy_X=True, max_iter=7065, positive=False, solver=auto, tol=0.0028994974874371852;, score=0.891 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.26040100250626563, copy_X=True, max_iter=9919, positive=False, solver=auto, tol=0.009095477386934673;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.26040100250626563, copy_X=True, max_iter=9919, positive=False, solver=auto, tol=0.009095477386934673;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.26842105263157895, copy_X=True, max_iter=10000, positive=False, solver=auto, tol=0.007557788944723618;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.26842105263157895, copy_X=True, max_iter=10000, positive=False, solver=auto, tol=0.007557788944723618;, score=0.891 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.2644110275689223, copy_X=False, max_iter=7467, positive=False, solver=auto, tol=0.006517587939698493;, score=0.879 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1230576441102757, copy_X=True, max_iter=8190, positive=False, solver=auto, tol=0.004211055276381909;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.23634085213032582, copy_X=False, max_iter=7226, positive=False, solver=auto, tol=0.005613065326633165;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.23634085213032582, copy_X=False, max_iter=7226, positive=False, solver=auto, tol=0.005613065326633165;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.387719298245614, copy_X=False, max_iter=7427, positive=False, solver=auto, tol=0.006608040201005024;, score=0.891 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.387719298245614, copy_X=False, max_iter=7427, positive=False, solver=auto, tol=0.006608040201005024;, score=0.879 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.3385964912280702, copy_X=False, max_iter=2522, positive=False, solver=auto, tol=0.008688442211055277;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.3385964912280702, copy_X=False, max_iter=2522, positive=False, solver=auto, tol=0.008688442211055277;, score=0.893 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.3776942355889724, copy_X=True, max_iter=8391, positive=False, solver=auto, tol=0.004346733668341708;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.3776942355889724, copy_X=True, max_iter=8391, positive=False, solver=auto, tol=0.004346733668341708;, score=0.919 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.4408521303258145, copy_X=False, max_iter=6261, positive=False, solver=auto, tol=0.004165829145728642;, score=0.879 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.19122807017543858, copy_X=True, max_iter=2241, positive=False, solver=auto, tol=0.0023567839195979884;, score=0.879 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.20726817042606516, copy_X=True, max_iter=7065, positive=False, solver=auto, tol=0.001994974874371858;, score=0.891 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.20726817042606516, copy_X=True, max_iter=7065, positive=False, solver=auto, tol=0.001994974874371858;, score=0.880 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1330827067669173, copy_X=True, max_iter=7989, positive=False, solver=auto, tol=0.001180904522613064;, score=0.918 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1330827067669173, copy_X=True, max_iter=7989, positive=False, solver=auto, tol=0.001180904522613064;, score=0.881 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.2393483709273183, copy_X=False, max_iter=6824, positive=False, solver=auto, tol=0.004527638190954773;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.2393483709273183, copy_X=False, max_iter=6824, positive=False, solver=auto, tol=0.004527638190954773;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.2393483709273183, copy_X=False, max_iter=6824, positive=False, solver=auto, tol=0.004527638190954773;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.2393483709273183, copy_X=False, max_iter=6824, positive=False, solver=auto, tol=0.004527638190954773;, score=0.891 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.2393483709273183, copy_X=False, max_iter=6824, positive=False, solver=auto, tol=0.004527638190954773;, score=0.880 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1180451127819549, copy_X=True, max_iter=7145, positive=False, solver=auto, tol=0.005974874371859296;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1180451127819549, copy_X=True, max_iter=7145, positive=False, solver=auto, tol=0.005974874371859296;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1180451127819549, copy_X=True, max_iter=7145, positive=False, solver=auto, tol=0.005974874371859296;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1180451127819549, copy_X=True, max_iter=7145, positive=False, solver=auto, tol=0.005974874371859296;, score=0.891 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1180451127819549, copy_X=True, max_iter=7145, positive=False, solver=auto, tol=0.005974874371859296;, score=0.880 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.36065162907268167, copy_X=True, max_iter=8753, positive=False, solver=auto, tol=0.003939698492462311;, score=0.879 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1330827067669173, copy_X=True, max_iter=7989, positive=False, solver=auto, tol=0.001180904522613064;, score=0.880 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.3726817042606516, copy_X=True, max_iter=5015, positive=False, solver=auto, tol=0.004979899497487436;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.3726817042606516, copy_X=True, max_iter=5015, positive=False, solver=auto, tol=0.004979899497487436;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1791979949874687, copy_X=False, max_iter=9597, positive=False, solver=auto, tol=0.0015879396984924618;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1791979949874687, copy_X=False, max_iter=9597, positive=False, solver=auto, tol=0.0015879396984924618;, score=0.880 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1511278195488722, copy_X=False, max_iter=9075, positive=False, solver=auto, tol=0.005522613065326632;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1511278195488722, copy_X=False, max_iter=9075, positive=False, solver=auto, tol=0.005522613065326632;, score=0.905 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.4368421052631579, copy_X=False, max_iter=5859, positive=False, solver=auto, tol=0.008236180904522612;, score=0.878 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.4368421052631579, copy_X=False, max_iter=5859, positive=False, solver=auto, tol=0.008236180904522612;, score=0.905 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.47794486215538845, copy_X=True, max_iter=3206, positive=False, solver=auto, tol=0.009231155778894473;, score=0.879 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.27644110275689227, copy_X=True, max_iter=4251, positive=False, solver=auto, tol=0.0072412060301507535;, score=0.879 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.3385964912280702, copy_X=False, max_iter=2522, positive=False, solver=auto, tol=0.008688442211055277;, score=0.879 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.35864661654135344, copy_X=False, max_iter=3487, positive=False, solver=auto, tol=0.009412060301507538;, score=0.878 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.37969924812030076, copy_X=True, max_iter=5055, positive=False, solver=auto, tol=0.008417085427135679;, score=0.879 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.3776942355889724, copy_X=True, max_iter=8391, positive=False, solver=auto, tol=0.004346733668341708;, score=0.878 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.14411027568922308, copy_X=False, max_iter=6944, positive=False, solver=auto, tol=0.005386934673366833;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.14411027568922308, copy_X=False, max_iter=6944, positive=False, solver=auto, tol=0.005386934673366833;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.19122807017543858, copy_X=True, max_iter=2241, positive=False, solver=auto, tol=0.0023567839195979884;, score=0.891 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.19122807017543858, copy_X=True, max_iter=2241, positive=False, solver=auto, tol=0.0023567839195979884;, score=0.880 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.3426065162907268, copy_X=False, max_iter=9155, positive=False, solver=auto, tol=0.004527638190954773;, score=0.878 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.3426065162907268, copy_X=False, max_iter=9155, positive=False, solver=auto, tol=0.004527638190954773;, score=0.905 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1330827067669173, copy_X=True, max_iter=7989, positive=False, solver=auto, tol=0.001180904522613064;, score=0.905 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1330827067669173, copy_X=True, max_iter=7989, positive=False, solver=auto, tol=0.001180904522613064;, score=0.892 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.4759398496240601, copy_X=True, max_iter=3648, positive=False, solver=auto, tol=0.006788944723618091;, score=0.878 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.4759398496240601, copy_X=True, max_iter=3648, positive=False, solver=auto, tol=0.006788944723618091;, score=0.905 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.4218045112781955, copy_X=True, max_iter=4814, positive=False, solver=auto, tol=0.009909547738693467;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.4218045112781955, copy_X=True, max_iter=4814, positive=False, solver=auto, tol=0.009909547738693467;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.4218045112781955, copy_X=True, max_iter=4814, positive=False, solver=auto, tol=0.009909547738693467;, score=0.893 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.4218045112781955, copy_X=True, max_iter=4814, positive=False, solver=auto, tol=0.009909547738693467;, score=0.879 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.1330827067669173, copy_X=True, max_iter=6623, positive=False, solver=auto, tol=0.007919597989949748;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.1330827067669173, copy_X=True, max_iter=6623, positive=False, solver=auto, tol=0.007919597989949748;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1330827067669173, copy_X=True, max_iter=6623, positive=False, solver=auto, tol=0.007919597989949748;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1330827067669173, copy_X=True, max_iter=6623, positive=False, solver=auto, tol=0.007919597989949748;, score=0.891 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1330827067669173, copy_X=True, max_iter=6623, positive=False, solver=auto, tol=0.007919597989949748;, score=0.880 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.4468671679197995, copy_X=False, max_iter=8512, positive=False, solver=auto, tol=0.006924623115577889;, score=0.878 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.4468671679197995, copy_X=False, max_iter=8512, positive=False, solver=auto, tol=0.006924623115577889;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.4468671679197995, copy_X=False, max_iter=8512, positive=False, solver=auto, tol=0.006924623115577889;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.4468671679197995, copy_X=False, max_iter=8512, positive=False, solver=auto, tol=0.006924623115577889;, score=0.893 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.4468671679197995, copy_X=False, max_iter=8512, positive=False, solver=auto, tol=0.006924623115577889;, score=0.879 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.37869674185463664, copy_X=True, max_iter=9396, positive=False, solver=auto, tol=0.0038492462311557783;, score=0.878 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.37869674185463664, copy_X=True, max_iter=9396, positive=False, solver=auto, tol=0.0038492462311557783;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.36065162907268167, copy_X=True, max_iter=8753, positive=False, solver=auto, tol=0.003939698492462311;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.36065162907268167, copy_X=True, max_iter=8753, positive=False, solver=auto, tol=0.003939698492462311;, score=0.891 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1330827067669173, copy_X=True, max_iter=7989, positive=False, solver=auto, tol=0.001180904522613064;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.1330827067669173, copy_X=True, max_iter=7989, positive=False, solver=auto, tol=0.001180904522613064;, score=0.881 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.3726817042606516, copy_X=True, max_iter=5015, positive=False, solver=auto, tol=0.004979899497487436;, score=0.891 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.3726817042606516, copy_X=True, max_iter=5015, positive=False, solver=auto, tol=0.004979899497487436;, score=0.879 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.2644110275689223, copy_X=False, max_iter=7467, positive=False, solver=auto, tol=0.006517587939698493;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.2644110275689223, copy_X=False, max_iter=7467, positive=False, solver=auto, tol=0.006517587939698493;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.1511278195488722, copy_X=False, max_iter=9075, positive=False, solver=auto, tol=0.005522613065326632;, score=0.918 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.1511278195488722, copy_X=False, max_iter=9075, positive=False, solver=auto, tol=0.005522613065326632;, score=0.891 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.4368421052631579, copy_X=False, max_iter=5859, positive=False, solver=auto, tol=0.008236180904522612;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.4368421052631579, copy_X=False, max_iter=5859, positive=False, solver=auto, tol=0.008236180904522612;, score=0.893 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.47794486215538845, copy_X=True, max_iter=3206, positive=False, solver=auto, tol=0.009231155778894473;, score=0.878 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.47794486215538845, copy_X=True, max_iter=3206, positive=False, solver=auto, tol=0.009231155778894473;, score=0.905 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.3385964912280702, copy_X=False, max_iter=2522, positive=False, solver=auto, tol=0.008688442211055277;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.3385964912280702, copy_X=False, max_iter=2522, positive=False, solver=auto, tol=0.008688442211055277;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.37969924812030076, copy_X=True, max_iter=5055, positive=False, solver=auto, tol=0.008417085427135679;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.37969924812030076, copy_X=True, max_iter=5055, positive=False, solver=auto, tol=0.008417085427135679;, score=0.893 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.10300751879699249, copy_X=True, max_iter=8391, positive=False, solver=auto, tol=0.008371859296482412;, score=0.880 total time=   0.0s\n",
      "[CV 1/5] END alpha=0.14411027568922308, copy_X=False, max_iter=6944, positive=False, solver=auto, tol=0.005386934673366833;, score=0.879 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.19122807017543858, copy_X=True, max_iter=2241, positive=False, solver=auto, tol=0.0023567839195979884;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.19122807017543858, copy_X=True, max_iter=2241, positive=False, solver=auto, tol=0.0023567839195979884;, score=0.918 total time=   0.0s\n",
      "[CV 2/5] END alpha=0.20726817042606516, copy_X=True, max_iter=7065, positive=False, solver=auto, tol=0.001994974874371858;, score=0.905 total time=   0.0s\n",
      "[CV 3/5] END alpha=0.20726817042606516, copy_X=True, max_iter=7065, positive=False, solver=auto, tol=0.001994974874371858;, score=0.919 total time=   0.0s\n",
      "[CV 4/5] END alpha=0.32556390977443606, copy_X=False, max_iter=3768, positive=False, solver=auto, tol=0.0028994974874371852;, score=0.891 total time=   0.0s\n",
      "[CV 5/5] END alpha=0.32556390977443606, copy_X=False, max_iter=3768, positive=False, solver=auto, tol=0.0028994974874371852;, score=0.879 total time=   0.0s\n"
     ]
    }
   ],
   "source": [
    "hyperparameter_tuning(algo=\"Ridge()\",param_grid=random_grid,n_iter=100,cv=5,verbose=3,random_state=42,X_train=X_train.loc[:,list(selected_features)],Y_train=Y_train,X_test=X_test.loc[:,list(selected_features)],Y_test=Y_test,evaluation_metric=\"r2_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "a37365bb-2e51-428f-a0dd-cc6e72fadb7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LinearRegression()': 0.8636738877114871,\n",
       " 'RandomForestRegressor()': 0.9027404283164311,\n",
       " 'SVR()': -1.724446512385569e-05,\n",
       " 'KNeighborsRegressor()': 0.8713196886668324,\n",
       " 'DecisionTreeRegressor()': 0.7306322588578171,\n",
       " 'SGDRegressor()': 0.8740829119789157,\n",
       " 'ElasticNet()': 0.8788561761481258,\n",
       " 'Lasso()': 0.8636966761305713,\n",
       " 'Ridge()': 0.8632007478818366}"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies_with_hyperparameter_tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6a44fa-79cb-49bb-aa0f-4a097d4b5158",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies_with_sfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0f0078-9d52-4994-a2b0-eef749913dc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24068f6-e1d0-49ef-aaf1-e886ac0d057b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621044df-b36a-4de7-8b8e-38c1028592da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac35c62-d351-4b21-88d9-fed42181cc0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2daf76b1-69b2-4031-aa2d-53187f9aba41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a298c96e-2379-4619-bf55-b645cf974ff6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ed88d4-b936-4898-afcf-ee6658514ba1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca7d6e8-b10c-406e-912b-646af074543c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "4b4922a9-cfe9-434a-92bb-4124854a98d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "e4e20558-17b5-49db-a12a-4523458f2624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['sqrt', 'log2'], 'max_depth': [10, 120, 230, 340, 450, 560, 670, 780, 890, 1000], 'min_samples_split': [2, 3, 4, 5, 10, 14], 'min_samples_leaf': [1, 2, 4, 6, 8], 'criterion': ['squared_error', 'absolute_error', 'friedman_mse', 'poisson']}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "681322cd-1ddc-43ff-b400-6fb7e3d1d161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "RandomForestRegressor() RandomCV Best Params : {'n_estimators': 200, 'min_samples_split': 14, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 890, 'criterion': 'friedman_mse'}\n",
      "RandomForestRegressor() RandomCV Score: 0.8154736655041288\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Final score is  0.8201522653525275\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter_tuning(algo=\"RandomForestRegressor()\",param_grid=random_grid,n_iter=10,cv=5,verbose=3,random_state=42,X_train=X_train,Y_train=Y_train,X_test=X_test,Y_test=Y_test,evaluation_metric=\"r2_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "98c058e1-c70b-4ed4-a115-75fb89d19041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "23ba846f-adbc-4f0c-83e5-adb53edcc0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernel': ['linear', 'poly', 'sigmoid', 'poly'], 'degree': [1, 3, 5, 7, 9, 11, 13, 15, 17, 20], 'max_iter': [100], 'tol': [0.01], 'gamma': ['scale', 'auto']}\n"
     ]
    }
   ],
   "source": [
    "# kernel = [\"linear\", \"poly\", \"sigmoid\",\"poly\"]\n",
    "# degree = [int(x) for x in np.linspace(start = 1, stop = 20, num = 10)]\n",
    "# gamma= [\"scale\", \"auto\"]\n",
    "\n",
    "# tol=[1e-2]\n",
    "# max_iter=[100]\n",
    "\n",
    "\n",
    "# random_grid = {'kernel': kernel,\n",
    "#                'degree':degree,\n",
    "#                'max_iter':max_iter,\n",
    "#                'tol':tol,\n",
    "#                'gamma':gamma\n",
    "               \n",
    "               \n",
    "#                }\n",
    "# print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99f2387a-c7b7-4cc0-a6ba-373a48f4b23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter_tuning(algo=\"SVR()\",param_grid=random_grid,n_iter=10,cv=5,verbose=0,random_state=42,X_train=X_train,Y_train=Y_train,X_test=X_test,Y_test=Y_test,evaluation_metric=\"r2_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "54ce9b9e-23a7-4be8-857d-86f034efa2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 KNN Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "4aa457e1-0391-4560-90ea-dca061d05c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'weights': ['uniform', 'distance'], 'n_neighbors': [5, 12, 19, 26, 33, 40, 47, 54, 61, 68, 75, 82, 89, 96, 103, 110, 117, 124, 131, 138, 145, 152, 159, 166, 173, 181, 188, 195, 202, 209, 216, 223, 230, 237, 244, 251, 258, 265, 272, 279, 286, 293, 300, 307, 314, 321, 328, 335, 342, 350], 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], 'leaf_size': [5, 6, 8, 10, 11, 13, 15, 16, 18, 20], 'p': [1, 2]}\n"
     ]
    }
   ],
   "source": [
    "# weights=[\"uniform\", \"distance\"]\n",
    "# n_neighbors = [int(x) for x in np.linspace(start = 5, stop = 350, num = 50)]\n",
    "# algorithm= [\"auto\", \"ball_tree\",\"kd_tree\",\"brute\"]\n",
    "# leaf_size=[int(x) for x in np.linspace(start = 5, stop = 20, num = 10)]\n",
    "# p = [1,2]\n",
    "\n",
    "\n",
    "# random_grid = {'weights': weights,\n",
    "#                'n_neighbors': n_neighbors,\n",
    "#                'algorithm': algorithm,\n",
    "#                'leaf_size':leaf_size,\n",
    "#                'p':p\n",
    "#                }\n",
    "# print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b88b6711-3867-4aff-92ec-ce861183e3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter_tuning(algo=\"KNeighborsRegressor()\",param_grid=random_grid,n_iter=10,cv=5,verbose=2,random_state=42,X_train=X_train,Y_train=Y_train,X_test=X_test,Y_test=Y_test,evaluation_metric=\"r2_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36af1563-e691-49d1-9f98-cccc6ddba236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=KNeighborsRegressor()\n",
    "# knn_random_cv=RandomizedSearchCV(estimator=model,param_distributions=random_grid,n_iter=100,cv=5,verbose=1,random_state=100,n_jobs=-1)\n",
    "# knn_random_cv.fit(X_train,Y_train)\n",
    "# best_params_=knn_random_cv.best_params_\n",
    "# print(\"RandomCV Best Params :\",best_params_)\n",
    "# best_random_grid=knn_random_cv.best_estimator_\n",
    "# y_pred4=best_random_grid.predict(X_test)\n",
    "# score_4=r2_score(Y_test,y_pred4)\n",
    "# print(\"RandomCV Score: \",score_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "723f749c-ae27-4753-8a7d-a63a9d0fb3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid4=defaultdict(list)\n",
    "# for val in best_params_:\n",
    "#     param_grid4[val].append(best_params_[val])\n",
    "# print(param_grid4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed56a0b4-ea4b-4a71-a57f-8706465ab897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=KNeighborsRegressor()\n",
    "# grid_search=GridSearchCV(estimator=model,param_grid=param_grid4,cv=5,n_jobs=-1,verbose=3)\n",
    "# grid_search.fit(X_train,Y_train)\n",
    "# print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca600f00-e26a-4ac7-afa5-792a45ac3f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_grid2=grid_search.best_estimator_\n",
    "# final=best_grid2.predict(X_test)\n",
    "# score_final4=r2_score(Y_test,final)\n",
    "# print(score_final4)\n",
    "# accuracies[\"KNeighborsRegressor\"]=score_final4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a8fea44b-4eeb-4bc3-989d-2c2f6826d88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5 DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1e5d7bf-71e3-4a7c-bce8-e8c924f7a515",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m max_features \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msqrt\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog2\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Maximum number of levels in tree\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m max_depth \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mint\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m1000\u001b[39m,\u001b[38;5;241m100\u001b[39m)]\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Minimum number of samples required to split a node\u001b[39;00m\n\u001b[1;32m      7\u001b[0m min_samples_split \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m14\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# splitter=[\"best\", \"random\"]\n",
    "# # Number of features to consider at every split\n",
    "# max_features = ['sqrt','log2']\n",
    "# # Maximum number of levels in tree\n",
    "# max_depth = [int(x) for x in np.linspace(10, 1000,100)]\n",
    "# # Minimum number of samples required to split a node\n",
    "# min_samples_split = [2,3,4, 5, 10,14]\n",
    "# # Minimum number of samples required at each leaf node\n",
    "# min_samples_leaf = [1,2, 4,6,8]\n",
    "# # Create the random grid\n",
    "# random_grid = {'splitter':splitter,\n",
    "#                'ccp_alpha':[1,0],\n",
    "#                'max_features': max_features,\n",
    "#                'max_depth': max_depth,\n",
    "#                'min_samples_split': min_samples_split,\n",
    "#                'min_samples_leaf': min_samples_leaf,\n",
    "#               'criterion':['squared_error','absolute_error','friedman_mse','poisson']}\n",
    "# print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8eab1272-c8ff-4111-b5a4-16e9edb41fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter_tuning(algo=\"DecisionTreeRegressor()\",param_grid=random_grid,n_iter=10,cv=5,verbose=2,random_state=42,X_train=X_train,Y_train=Y_train,X_test=X_test,Y_test=Y_test,evaluation_metric=\"r2_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "4152fecd-e5cb-44b1-8cef-76544e83c7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dt=DecisionTreeRegressor()\n",
    "# dt_random_cv=RandomizedSearchCV(estimator=dt,param_distributions=random_grid,n_iter=100,cv=5,verbose=0,random_state=100,n_jobs=-1)\n",
    "# dt_random_cv.fit(X_train,Y_train)\n",
    "\n",
    "# best_params_=dt_random_cv.best_params_\n",
    "# print(\"RandomCV Best Params :\",best_params_)\n",
    "# best_random_grid=dt_random_cv.best_estimator_\n",
    "# y_pred5=best_random_grid.predict(X_test)\n",
    "# score_5=r2_score(Y_test,y_pred5)\n",
    "# print(\"RandomCV Score: \",score_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "d3ef23e3-a882-486b-9ce6-626a6695c674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid5=defaultdict(list)\n",
    "# for val in best_params_:\n",
    "#     param_grid5[val].append(best_params_[val])\n",
    "# print(param_grid5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "8f5b1961-7341-4f46-a938-778d752a10db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=DecisionTreeRegressor()\n",
    "# grid_search=GridSearchCV(estimator=model,param_grid=param_grid5,cv=5,n_jobs=-1,verbose=3)\n",
    "# grid_search.fit(X_train,Y_train)\n",
    "# print(grid_search.best_estimator_)\n",
    "# best_grid2=grid_search.best_estimator_\n",
    "# final5=best_grid2.predict(X_test)\n",
    "# score_final5=r2_score(Y_test,final5)\n",
    "# print(score_final5)\n",
    "# accuracies[\"DecisionTreeRegressor\"]=score_final5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "9786a182-4bd1-47c6-b3a3-39abe0b6f7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 6 SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb3b9860-4ce6-4527-b5b8-3012f8e51e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = ['squared_error','huber','epsilon_insensitive','squared_epsilon_insensitive']\n",
    "# penalty=['l2','l1','elasticnet','None']\n",
    "# alpha = [float(x) for x in np.linspace(0, 0.001,50)]\n",
    "# l1_ratio=[float(x) for x in np.linspace(0, 0.5,50)]\n",
    "# max_iter=[int(x) for x in np.linspace(8000, 20000,100)]\n",
    "# tol=[float(x) for x in np.linspace(0.01, 0.001,100)]\n",
    "# learning_rate=['constant','optimal','invscaling','adaptive']\n",
    "# eta0=[float(x) for x in np.linspace(0.1, 0.05,100)]\n",
    "# early_stopping = ['True','False']\n",
    "# validation_fraction=[float(x) for x in np.linspace(0.1, 0.9,50)]\n",
    "# n_iter_no_change = [1,2, 4,6,8,5,10]\n",
    "# average=['bool','int']\n",
    "# random_grid = {\n",
    "#                'loss': loss,\n",
    "#                'penalty': penalty,\n",
    "#                'alpha': alpha,\n",
    "#                'l1_ratio': l1_ratio,\n",
    "#               'max_iter':max_iter,\n",
    "#                'tol':tol,\n",
    "#                 'learning_rate':learning_rate,\n",
    "#                 'eta0':eta0,\n",
    "               \n",
    "#                 'validation_fraction':validation_fraction,\n",
    "#                 'n_iter_no_change':n_iter_no_change\n",
    "#                 }\n",
    "# print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e64b77a0-63ee-4ac6-86f1-4a8b4203b97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter_tuning(algo=\"SGDRegressor()\",param_grid=random_grid,n_iter=10,cv=5,verbose=2,random_state=42,X_train=X_train,Y_train=Y_train,X_test=X_test,Y_test=Y_test,evaluation_metric=\"r2_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "37e2e660-67b1-442d-a83b-aefd51711b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sgd=SGDRegressor()\n",
    "# sgd_random_cv=RandomizedSearchCV(estimator=sgd,param_distributions=random_grid,n_iter=100,cv=5,verbose=0,random_state=100,n_jobs=-1)\n",
    "# sgd_random_cv.fit(X_train,Y_train)\n",
    "\n",
    "# best_params_=sgd_random_cv.best_params_\n",
    "# print(\"RandomCV Best Params :\",best_params_)\n",
    "# best_random_grid=sgd_random_cv.best_estimator_\n",
    "# y_pred6=best_random_grid.predict(X_test)\n",
    "# score_6=r2_score(Y_test,y_pred6)\n",
    "# print(\"RandomCV Score: \",score_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "6cf817db-1727-479e-ba86-5de2b6ffeca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid6=defaultdict(list)\n",
    "# for val in best_params_:\n",
    "#     param_grid6[val].append(best_params_[val])\n",
    "# print(param_grid6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "6a24ac32-6482-4ca4-9d32-63087706a0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=SGDRegressor()\n",
    "# grid_search=GridSearchCV(estimator=model,param_grid=param_grid6,cv=5,n_jobs=-1,verbose=3)\n",
    "# grid_search.fit(X_train,Y_train)\n",
    "# print(grid_search.best_estimator_)\n",
    "# best_grid2=grid_search.best_estimator_\n",
    "# final6=best_grid2.predict(X_test)\n",
    "# score_final6=r2_score(Y_test,final6)\n",
    "# print(score_final6)\n",
    "# accuracies[\"SGDRegressor\"]=score_final6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "2141aa06-dd6d-4ac4-9719-08bdaa5468ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7 ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "32abb30c-1645-4fe7-9eb9-d0d4acc83f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha = [float(x) for x in np.linspace(0, 0.50,500)]\n",
    "# positive=['True','False']\n",
    "# l1_ratio=[float(x) for x in np.linspace(0, 0.5,100)]\n",
    "# max_iter=[int(x) for x in np.linspace(2000, 10000,200)]\n",
    "# tol=[float(x) for x in np.linspace(0.01, 0.001,200)]\n",
    "# warm_start = ['True','False']\n",
    "# selection=['cyclic','random']\n",
    "# copy_X=['True','False']\n",
    "\n",
    "# random_grid = {'copy_X':copy_X,\n",
    "#                'alpha':alpha,\n",
    "#                'l1_ratio': l1_ratio,\n",
    "#                'max_iter':max_iter,\n",
    "#                'tol':tol,\n",
    "#                 'warm_start':warm_start,\n",
    "#                 'selection':selection\n",
    "               \n",
    "               \n",
    "#                 }\n",
    "# print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "95622f55-f4ca-4104-9feb-585f93bbbbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter_tuning(algo=\"ElasticNet()\",param_grid=random_grid,n_iter=10,cv=5,verbose=2,random_state=42,X_train=X_train,Y_train=Y_train,X_test=X_test,Y_test=Y_test,evaluation_metric=\"r2_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "0d745e93-d4ff-4131-96e4-86f431c9b58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# en=ElasticNet()\n",
    "# en_random_cv=RandomizedSearchCV(estimator=en,param_distributions=random_grid,n_iter=100,cv=5,verbose=0,random_state=100,n_jobs=-1)\n",
    "# en_random_cv.fit(X_train,Y_train)\n",
    "\n",
    "# best_params_=en_random_cv.best_params_\n",
    "# print(\"RandomCV Best Params :\",best_params_)\n",
    "# best_random_grid=en_random_cv.best_estimator_\n",
    "# y_pred7=best_random_grid.predict(X_test)\n",
    "# score_7=r2_score(Y_test,y_pred7)\n",
    "# print(\"RandomCV Score: \",score_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "9edc15ed-8b5a-4dac-9ebb-41e2d31bfb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid7=defaultdict(list)\n",
    "# for val in best_params_:\n",
    "#     param_grid7[val].append(best_params_[val])\n",
    "# print(param_grid7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "f4c9b668-460a-42db-9ade-3fb9b0cd949e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=ElasticNet()\n",
    "# grid_search=GridSearchCV(estimator=model,param_grid=param_grid7,cv=5,n_jobs=-1,verbose=3)\n",
    "# grid_search.fit(X_train,Y_train)\n",
    "# print(grid_search.best_estimator_)\n",
    "# best_grid2=grid_search.best_estimator_\n",
    "# final7=best_grid2.predict(X_test)\n",
    "# score_final7=r2_score(Y_test,final7)\n",
    "# print(score_final7)\n",
    "# accuracies[\"ElasticNet\"]=score_final7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "002e93f2-e515-4e66-91de-4340e3539ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8 Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "31f642c6-7d05-4099-a0ab-f90ea6957573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha = [float(x) for x in np.linspace(0, 0.50,500)]\n",
    "# positive=['True','False']\n",
    "# l1_ratio=[float(x) for x in np.linspace(0, 0.5,100)]\n",
    "# max_iter=[int(x) for x in np.linspace(2000, 10000,200)]\n",
    "# tol=[float(x) for x in np.linspace(0.01, 0.001,200)]\n",
    "# warm_start = ['True','False']\n",
    "# selection=['cyclic','random']\n",
    "# copy_X=['True','False']\n",
    "\n",
    "# random_grid = {'copy_X':copy_X,\n",
    "#                'alpha':alpha,\n",
    "#                'l1_ratio': l1_ratio,\n",
    "#                'max_iter':max_iter,\n",
    "#                'tol':tol,\n",
    "#                 'warm_start':warm_start,\n",
    "#                 'selection':selection\n",
    "               \n",
    "               \n",
    "#                 }\n",
    "# print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1790528e-99ec-46a5-97d3-4c4697ec1c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_iter=[int(x) for x in np.linspace(2000, 10000,500)]\n",
    "# tol=[float(x) for x in np.linspace(0.01, 0.001,300)]\n",
    "# warm_start = ['True','False']\n",
    "# selection=['cyclic','random']\n",
    "# alpha = [float(x) for x in np.linspace(0,0.50,500)]\n",
    "# # positive=['True','False']\n",
    "# copy_X=['True','False']\n",
    "# random_grid = {\n",
    "#                'alpha':alpha,\n",
    "              \n",
    "#                'max_iter':max_iter,\n",
    "#                'tol':tol,\n",
    "#                 'positive':positive,\n",
    "#                 'copy_X':copy_X,\n",
    "#                 'warm_start':warm_start,\n",
    "#                 'selection':selection\n",
    "               \n",
    "               \n",
    "#                 }\n",
    "# print(random_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "65634dbf-9acf-4e93-87bb-dc6a115ddf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter_tuning(algo=\"Lasso()\",param_grid=random_grid,n_iter=10,cv=5,verbose=2,random_state=42,X_train=X_train,Y_train=Y_train,X_test=X_test,Y_test=Y_test,evaluation_metric=\"r2_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "39d3cc51-896a-40f7-b054-4aa7292beda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lasso=Lasso()\n",
    "# lasso_random_cv=RandomizedSearchCV(estimator=lasso,param_distributions=random_grid,n_iter=100,cv=5,verbose=0,random_state=100,n_jobs=-1)\n",
    "# lasso_random_cv.fit(X_train,Y_train)\n",
    "\n",
    "# best_params_=lasso_random_cv.best_params_\n",
    "# print(\"RandomCV Best Params :\",best_params_)\n",
    "# best_random_grid=lasso_random_cv.best_estimator_\n",
    "# y_pred8=best_random_grid.predict(X_test)\n",
    "# score_8=r2_score(Y_test,y_pred8)\n",
    "# print(\"RandomCV Score: \",score_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "969a2eba-a27a-439f-91bd-6c515f294e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid8=defaultdict(list)\n",
    "# for val in best_params_:\n",
    "#     param_grid8[val].append(best_params_[val])\n",
    "# print(param_grid8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "287bd780-0547-4030-9542-6838397890e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "9d9c4a31-bf56-4ef1-9507-404c74187183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=Lasso()\n",
    "# grid_search=GridSearchCV(estimator=model,param_grid=param_grid8,cv=5,n_jobs=-1,verbose=3)\n",
    "# grid_search.fit(X_train,Y_train)\n",
    "# print(grid_search.best_estimator_)\n",
    "# best_grid2=grid_search.best_estimator_\n",
    "# final8=best_grid2.predict(X_test)\n",
    "# score_final8=r2_score(Y_test,final8)\n",
    "# print(score_final8)\n",
    "# accuracies[\"Lasso\"]=score_final8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "e03ddb79-98f3-44be-ab10-779acdec79ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9 Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d8ba451f-ca1f-448e-bde5-fd475a803231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_iter=[int(x) for x in np.linspace(2000, 10000,200)]\n",
    "# tol=[float(x) for x in np.linspace(0.01, 0.001,200)]\n",
    "# alpha = [float(x) for x in np.linspace(0.1,0.50,400)]\n",
    "# positive=['False']\n",
    "# copy_X=['True','False']\n",
    "# solver=[\"auto\"]\n",
    "\n",
    "# random_grid = {\n",
    "#                'alpha':alpha,\n",
    "              \n",
    "#                'max_iter':max_iter,\n",
    "#                'tol':tol,\n",
    "#                 'positive':positive,\n",
    "#                 'copy_X':copy_X,\n",
    "#                 'solver':solver\n",
    "               \n",
    "               \n",
    "#                 }\n",
    "# print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dcff6032-101e-4f88-b4f3-f34464b8b5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter_tuning(algo=\"Ridge()\",param_grid=random_grid,n_iter=10,cv=5,verbose=2,random_state=42,X_train=X_train,Y_train=Y_train,X_test=X_test,Y_test=Y_test,evaluation_metric=\"r2_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "48b2927c-6780-461a-865a-0dada3e32d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ridge=Ridge()\n",
    "# ridge_random_cv=RandomizedSearchCV(estimator=ridge,param_distributions=random_grid,n_iter=100,cv=5,verbose=0,random_state=100,n_jobs=-1)\n",
    "# ridge_random_cv.fit(X_train,Y_train)\n",
    "\n",
    "# best_params_=ridge_random_cv.best_params_\n",
    "# print(\"RandomCV Best Params :\",best_params_)\n",
    "# best_random_grid=ridge_random_cv.best_estimator_\n",
    "# y_pred9=best_random_grid.predict(X_test)\n",
    "# score_9=r2_score(Y_test,y_pred9)\n",
    "# print(\"RandomCV Score: \",score_9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "c2875580-d424-4c36-8504-41e1ac645c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid9=defaultdict(list)\n",
    "# for val in best_params_:\n",
    "#     param_grid9[val].append(best_params_[val])\n",
    "# print(param_grid9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "48325357-fd66-4ee0-944c-b6295647c4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=Ridge()\n",
    "# grid_search=GridSearchCV(estimator=model,param_grid=param_grid9,cv=5,n_jobs=-1,verbose=3)\n",
    "# grid_search.fit(X_train,Y_train)\n",
    "# print(grid_search.best_estimator_)\n",
    "# best_grid2=grid_search.best_estimator_\n",
    "# final9=best_grid2.predict(X_test)\n",
    "# score_final9=r2_score(Y_test,final9)\n",
    "# print(score_final9)\n",
    "# accuracies[\"Ridge\"]=score_final9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49692bca-f241-40d9-9de6-b6ee7638227a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0714a8-194b-4b89-8bff-44e8c06d935f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5573bcb8-4b0f-4724-a68b-125e5601fb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# sfs1 = SFS(RandomForestRegressor(), \n",
    "#                k_features=(3,len(X_train.columns)), \n",
    "#                forward=True, \n",
    "#                floating=False, \n",
    "#                verbose=1,\n",
    "#                scoring='r2',\n",
    "#                cv=5,\n",
    "#                n_jobs=-1)\n",
    "# sfs1=sfs1.fit(X_train, Y_train)\n",
    "# print(\"sfs1 max score features are :\",sfs1.k_feature_names_)\n",
    "# print(\"sfs1 max score is :\",sfs1.k_score_)\n",
    "# print()\n",
    "# model_=RandomForestRegressor()\n",
    "# model_.fit(X_train.loc[:,list(sfs1.k_feature_names_)],Y_train)\n",
    "# score=model_.score(X_test.loc[:,list(sfs1.k_feature_names_)],Y_test)\n",
    "# print(\"Prediction using selected features is :\",score)\n",
    "# accuracies[\"RandomForestRegressor\"]=score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c50c4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sfs1 = SFS(SVR(), \n",
    "#            k_features=(3,len(X_train.columns)), \n",
    "#            forward=True, \n",
    "#            floating=False, \n",
    "#            verbose=1,\n",
    "#            scoring='r2',\n",
    "#            cv=5,\n",
    "#            n_jobs=-1)\n",
    "# sfs1=sfs1.fit(X_train, Y_train)\n",
    "# print(\"sfs1 max score features are :\",sfs1.k_feature_names_)\n",
    "# print(\"sfs1 max score is :\",sfs1.k_score_)\n",
    "# print()\n",
    "# model_=SVR()\n",
    "# model_.fit(X_train.loc[:,list(sfs1.k_feature_names_)],Y_train)\n",
    "# score=model_.score(X_test.loc[:,list(sfs1.k_feature_names_)],Y_test)\n",
    "# print(\"Prediction using selected features is :\",score)\n",
    "# accuracies[\"SVR\"]=score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8980a5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sfs1 = SFS(KNeighborsRegressor(), \n",
    "#            k_features=(3,len(X_train.columns)), \n",
    "#            forward=True, \n",
    "#            floating=False, \n",
    "#            verbose=1,\n",
    "#            scoring='r2',\n",
    "#            cv=5,\n",
    "#            n_jobs=-1)\n",
    "# sfs1=sfs1.fit(X_train, Y_train)\n",
    "# print(\"sfs1 max score features are :\",sfs1.k_feature_names_)\n",
    "# print(\"sfs1 max score is :\",sfs1.k_score_)\n",
    "# print()\n",
    "# model_=KNeighborsRegressor()\n",
    "# model_.fit(X_train.loc[:,list(sfs1.k_feature_names_)],Y_train)\n",
    "# score=model_.score(X_test.loc[:,list(sfs1.k_feature_names_)],Y_test)\n",
    "# print(\"Prediction using selected features is :\",score)\n",
    "# accuracies[\"KNeighborsRegressor\"]=score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d210de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sfs1 = SFS(DecisionTreeRegressor(), \n",
    "#                k_features=(3,len(X_train.columns)), \n",
    "#                forward=True, \n",
    "#                floating=False, \n",
    "#                verbose=1,\n",
    "#                scoring='r2',\n",
    "#                cv=5,\n",
    "#                n_jobs=-1)\n",
    "# sfs1=sfs1.fit(X_train, Y_train)\n",
    "# print(\"sfs1 max score features are :\",sfs1.k_feature_names_)\n",
    "# print(\"sfs1 max score is :\",sfs1.k_score_)\n",
    "# print()\n",
    "# model_=DecisionTreeRegressor()\n",
    "# model_.fit(X_train.loc[:,list(sfs1.k_feature_names_)],Y_train)\n",
    "# score=model_.score(X_test.loc[:,list(sfs1.k_feature_names_)],Y_test)\n",
    "# print(\"Prediction using selected features is :\",score)\n",
    "# accuracies[\"DecisionTreeRegressor\"]=score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7552b8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sfs1 = SFS(SGDRegressor(), \n",
    "#                k_features=(3,len(X_train.columns)), \n",
    "#                forward=True, \n",
    "#                floating=False, \n",
    "#                verbose=1,\n",
    "#                scoring='r2',\n",
    "#                cv=5,\n",
    "#                n_jobs=-1)\n",
    "# sfs1=sfs1.fit(X_train, Y_train)\n",
    "# print(\"sfs1 max score features are :\",sfs1.k_feature_names_)\n",
    "# print(\"sfs1 max score is :\",sfs1.k_score_)\n",
    "# print()\n",
    "# model_=SGDRegressor()\n",
    "# model_.fit(X_train.loc[:,list(sfs1.k_feature_names_)],Y_train)\n",
    "# score=model_.score(X_test.loc[:,list(sfs1.k_feature_names_)],Y_test)\n",
    "# print(\"Prediction using selected features is :\",score)\n",
    "# accuracies[\"SGDRegressor\"]=score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "e6060cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sfs1 = SFS(ElasticNet(), \n",
    "#                k_features=(3,len(X_train.columns)), \n",
    "#                forward=True, \n",
    "#                floating=False, \n",
    "#                verbose=1,\n",
    "#                scoring='r2',\n",
    "#                cv=5,\n",
    "#                n_jobs=-1)\n",
    "# sfs1=sfs1.fit(X_train, Y_train)\n",
    "# print(\"sfs1 max score features are :\",sfs1.k_feature_names_)\n",
    "# print(\"sfs1 max score is :\",sfs1.k_score_)\n",
    "# print()\n",
    "# model_=ElasticNet()\n",
    "# model_.fit(X_train.loc[:,list(sfs1.k_feature_names_)],Y_train)\n",
    "# score=model_.score(X_test.loc[:,list(sfs1.k_feature_names_)],Y_test)\n",
    "# print(\"Prediction using selected features is :\",score)\n",
    "# accuracies[\"ElasticNet\"]=score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "9caeb8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sfs1 = SFS(Lasso(), \n",
    "#                k_features=(3,len(X_train.columns)), \n",
    "#                forward=True, \n",
    "#                floating=False, \n",
    "#                verbose=1,\n",
    "#                scoring='r2',\n",
    "#                cv=5,\n",
    "#                n_jobs=-1)\n",
    "# sfs1=sfs1.fit(X_train, Y_train)\n",
    "# print(\"sfs1 max score features are :\",sfs1.k_feature_names_)\n",
    "# print(\"sfs1 max score is :\",sfs1.k_score_)\n",
    "# print()\n",
    "# model_=Lasso()\n",
    "# model_.fit(X_train.loc[:,list(sfs1.k_feature_names_)],Y_train)\n",
    "# score=model_.score(X_test.loc[:,list(sfs1.k_feature_names_)],Y_test)\n",
    "# print(\"Prediction using selected features is :\",score)\n",
    "# accuracies[\"Lasso\"]=score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f002ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sfs1 = SFS(Ridge(), \n",
    "#                k_features=(3,len(X_train.columns)), \n",
    "#                forward=True, \n",
    "#                floating=False, \n",
    "#                verbose=1,\n",
    "#                scoring='r2',\n",
    "#                cv=5,\n",
    "#                n_jobs=-1)\n",
    "# sfs1=sfs1.fit(X_train, Y_train)\n",
    "# print(\"sfs1 max score features are :\",sfs1.k_feature_names_)\n",
    "# print(\"sfs1 max score is :\",sfs1.k_score_)\n",
    "# print()\n",
    "# model_=Ridge()\n",
    "# model_.fit(X_train.loc[:,list(sfs1.k_feature_names_)],Y_train)\n",
    "# score=model_.score(X_test.loc[:,list(sfs1.k_feature_names_)],Y_test)\n",
    "# print(\"Prediction using selected features is :\",score)\n",
    "# accuracies[\"Ridge\"]=score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b21196c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a64d9c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2d9060-53c4-4991-b3e7-b3342b622c6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bdcef6-1147-4b56-b7c0-f56fc4ec2a44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9466320b-145c-4a8a-a347-690994f7e1d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7da7d8-3924-4710-b506-aaf35ac6f7c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
