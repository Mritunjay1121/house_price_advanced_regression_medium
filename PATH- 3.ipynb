{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "addeba46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression,ElasticNet,Lasso,Ridge\n",
    "from sklearn.linear_model import SGDRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "298c7238",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.read_csv(\"house_price_train.csv\")\n",
    "df_train.drop(\"Id\",axis=1,inplace=True) ## redundant\n",
    "output_col=df_train['SalePrice']\n",
    "df_train=df_train.drop('SalePrice',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a57d23f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>...</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>13175</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9042</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GdPrv</td>\n",
       "      <td>Shed</td>\n",
       "      <td>2500</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0             60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1             20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2             60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3             70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4             60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "...          ...      ...          ...      ...    ...   ...      ...   \n",
       "1455          60       RL         62.0     7917   Pave   NaN      Reg   \n",
       "1456          20       RL         85.0    13175   Pave   NaN      Reg   \n",
       "1457          70       RL         66.0     9042   Pave   NaN      Reg   \n",
       "1458          20       RL         68.0     9717   Pave   NaN      Reg   \n",
       "1459          20       RL         75.0     9937   Pave   NaN      Reg   \n",
       "\n",
       "     LandContour Utilities LotConfig  ... ScreenPorch PoolArea PoolQC  Fence  \\\n",
       "0            Lvl    AllPub    Inside  ...           0        0    NaN    NaN   \n",
       "1            Lvl    AllPub       FR2  ...           0        0    NaN    NaN   \n",
       "2            Lvl    AllPub    Inside  ...           0        0    NaN    NaN   \n",
       "3            Lvl    AllPub    Corner  ...           0        0    NaN    NaN   \n",
       "4            Lvl    AllPub       FR2  ...           0        0    NaN    NaN   \n",
       "...          ...       ...       ...  ...         ...      ...    ...    ...   \n",
       "1455         Lvl    AllPub    Inside  ...           0        0    NaN    NaN   \n",
       "1456         Lvl    AllPub    Inside  ...           0        0    NaN  MnPrv   \n",
       "1457         Lvl    AllPub    Inside  ...           0        0    NaN  GdPrv   \n",
       "1458         Lvl    AllPub    Inside  ...           0        0    NaN    NaN   \n",
       "1459         Lvl    AllPub    Inside  ...           0        0    NaN    NaN   \n",
       "\n",
       "     MiscFeature MiscVal  MoSold  YrSold  SaleType  SaleCondition  \n",
       "0            NaN       0       2    2008        WD         Normal  \n",
       "1            NaN       0       5    2007        WD         Normal  \n",
       "2            NaN       0       9    2008        WD         Normal  \n",
       "3            NaN       0       2    2006        WD        Abnorml  \n",
       "4            NaN       0      12    2008        WD         Normal  \n",
       "...          ...     ...     ...     ...       ...            ...  \n",
       "1455         NaN       0       8    2007        WD         Normal  \n",
       "1456         NaN       0       2    2010        WD         Normal  \n",
       "1457        Shed    2500       5    2010        WD         Normal  \n",
       "1458         NaN       0       4    2010        WD         Normal  \n",
       "1459         NaN       0       6    2008        WD         Normal  \n",
       "\n",
       "[1460 rows x 79 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c0c131a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSSubClass         int64\n",
       "MSZoning          object\n",
       "LotFrontage      float64\n",
       "LotArea            int64\n",
       "Street            object\n",
       "                  ...   \n",
       "MiscVal            int64\n",
       "MoSold             int64\n",
       "YrSold             int64\n",
       "SaleType          object\n",
       "SaleCondition     object\n",
       "Length: 79, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e55e99",
   "metadata": {},
   "source": [
    "## PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6012cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.columns[df_train.isnull().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb6ea24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.heatmap(df_train.isnull(),yticklabels=False,cbar=False,cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c14be27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(30,30))\n",
    "# sns.heatmap(pd.concat([df_train,output_col],axis=1).loc[:,list(pd.concat([df_train,output_col],axis=1).select_dtypes(include= np.number).columns)].corr(method='spearman'),annot=True,cmap=\"RdYlGn\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e88102fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(nrows = 12, ncols = 3)    # axes is 2d array (3x3)\n",
    "# axes = axes.flatten()         # Convert axes to 1d array of length 9\n",
    "# fig.set_size_inches(30,30)\n",
    "# cols=list(df_train.select_dtypes(include= np.number).columns)\n",
    "# for ax, col in zip(axes, cols):\n",
    "#     print()\n",
    "#     sns.boxplot(df_train[col], ax = ax)\n",
    "#     ax.set_title(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3639e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(nrows = 12, ncols = 3)    # axes is 2d array (3x3)\n",
    "# axes = axes.flatten()         # Convert axes to 1d array of length 9\n",
    "# fig.set_size_inches(30,30)\n",
    "# cols=list(df_train.select_dtypes(include= np.number).columns)\n",
    "# for ax, col in zip(axes, cols):\n",
    "#     print()\n",
    "#     sns.distplot(df_train[col], ax = ax)\n",
    "#     ax.set_title(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc93ea2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def column_with_most_reduntant_null_values(threshold,df_train:pd.DataFrame):\n",
    "    null_cols=[]\n",
    "    for col in df_train.columns:\n",
    "        if df_train[col].isnull().sum()>=(threshold*len(df_train)):\n",
    "            null_cols.append(col)\n",
    "    df_train.drop(null_cols,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f067d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_with_most_reduntant_null_values(threshold=0.5,df_train=df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44f576a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>...</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>35</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>13175</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9042</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2500</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass MSZoning  LotFrontage  LotArea Street LotShape LandContour  \\\n",
       "0             60       RL         65.0     8450   Pave      Reg         Lvl   \n",
       "1             20       RL         80.0     9600   Pave      Reg         Lvl   \n",
       "2             60       RL         68.0    11250   Pave      IR1         Lvl   \n",
       "3             70       RL         60.0     9550   Pave      IR1         Lvl   \n",
       "4             60       RL         84.0    14260   Pave      IR1         Lvl   \n",
       "...          ...      ...          ...      ...    ...      ...         ...   \n",
       "1455          60       RL         62.0     7917   Pave      Reg         Lvl   \n",
       "1456          20       RL         85.0    13175   Pave      Reg         Lvl   \n",
       "1457          70       RL         66.0     9042   Pave      Reg         Lvl   \n",
       "1458          20       RL         68.0     9717   Pave      Reg         Lvl   \n",
       "1459          20       RL         75.0     9937   Pave      Reg         Lvl   \n",
       "\n",
       "     Utilities LotConfig LandSlope  ... OpenPorchSF EnclosedPorch 3SsnPorch  \\\n",
       "0       AllPub    Inside       Gtl  ...          61             0         0   \n",
       "1       AllPub       FR2       Gtl  ...           0             0         0   \n",
       "2       AllPub    Inside       Gtl  ...          42             0         0   \n",
       "3       AllPub    Corner       Gtl  ...          35           272         0   \n",
       "4       AllPub       FR2       Gtl  ...          84             0         0   \n",
       "...        ...       ...       ...  ...         ...           ...       ...   \n",
       "1455    AllPub    Inside       Gtl  ...          40             0         0   \n",
       "1456    AllPub    Inside       Gtl  ...           0             0         0   \n",
       "1457    AllPub    Inside       Gtl  ...          60             0         0   \n",
       "1458    AllPub    Inside       Gtl  ...           0           112         0   \n",
       "1459    AllPub    Inside       Gtl  ...          68             0         0   \n",
       "\n",
       "     ScreenPorch PoolArea  MiscVal  MoSold  YrSold  SaleType SaleCondition  \n",
       "0              0        0        0       2    2008        WD        Normal  \n",
       "1              0        0        0       5    2007        WD        Normal  \n",
       "2              0        0        0       9    2008        WD        Normal  \n",
       "3              0        0        0       2    2006        WD       Abnorml  \n",
       "4              0        0        0      12    2008        WD        Normal  \n",
       "...          ...      ...      ...     ...     ...       ...           ...  \n",
       "1455           0        0        0       8    2007        WD        Normal  \n",
       "1456           0        0        0       2    2010        WD        Normal  \n",
       "1457           0        0     2500       5    2010        WD        Normal  \n",
       "1458           0        0        0       4    2010        WD        Normal  \n",
       "1459           0        0        0       6    2008        WD        Normal  \n",
       "\n",
       "[1460 rows x 75 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "260544ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_cols=list(df_train.select_dtypes(include= np.number).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ace0da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols=list(df_train.select_dtypes(exclude= np.number).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a41f6482",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_correlated=dict()\n",
    "for col1 in continuous_cols:\n",
    "    for col2 in continuous_cols:\n",
    "        if col1!=col2 and abs(df_train[col1].corr(df_train[col2],method='spearman'))>=0.80:\n",
    "            if (col1 not in most_correlated) and (col2 not in most_correlated):\n",
    "                most_correlated[col1]=col2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9147486",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop(columns=list(most_correlated),axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b4fd101",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_null_values(for_numerical_cols:str,for_categorical_cols:str,df_train):\n",
    "    for cols in df_train.columns:\n",
    "        if df_train[cols].dtype==\"int64\" or df_train[cols].dtype==\"float64\":\n",
    "            if for_numerical_cols==\"median\":\n",
    "                median_=df_train[cols].median()\n",
    "                df_train[cols].fillna(median_,inplace=True)\n",
    "        elif df_train[cols].dtype==\"object\":\n",
    "            if for_categorical_cols==\"most_frequent\":\n",
    "                d=list(df_train[cols].value_counts().index) # most frequent\n",
    "                df_train[cols].fillna(d[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8529bb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_null_values(for_numerical_cols=\"median\",for_categorical_cols=\"most_frequent\",df_train=df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13f5495b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_train.columns:\n",
    "    if df_train[col].isnull().sum()>(0):\n",
    "\n",
    "        print(col,df[col].isnull().sum(),df_train[col].dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fcb707f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_cols=list(df_train.select_dtypes(include= np.number).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5db0ff8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols=list(df_train.select_dtypes(exclude= np.number).columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490ee470-1a92-424a-bad2-d93f045e0a02",
   "metadata": {},
   "source": [
    "Deleting Outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3f112f-9625-467b-8691-cbdbc3cbc316",
   "metadata": {},
   "source": [
    "Here we are deleting outliers using Inter Quartile Range Strategy. Since for a column ouliers are in a specifc row and for different columns the oulier contained rows are different and if we delete those specific row then that row in output label should also be deleted thats why we are first adding label into our features after that we will separate the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "36641c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.concat([output_col,df_train],axis=1) # since rows will be deleted here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9e4e54d1-110a-4480-a358-574ff85f3de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -55.0 , 145.0 ]\n",
      "[ 30.0 , 110.0 ]\n",
      "[ 2440.0 , 16936.0 ]\n",
      "[ 2.0 , 10.0 ]\n",
      "[ 3.5 , 7.5 ]\n",
      "[ 1909.0 , 2061.0 ]\n",
      "[ -255.75 , 426.25 ]\n",
      "[ -1060.5 , 1767.5 ]\n",
      "[ 0.0 , 0.0 ]\n",
      "[ -579.875 , 1725.125 ]\n",
      "[ 199.0 , 2037.0 ]\n",
      "[ -1092.375 , 1820.625 ]\n",
      "[ 0.0 , 0.0 ]\n",
      "[ -1.5 , 2.5 ]\n",
      "[ 0.0 , 0.0 ]\n",
      "[ -0.5 , 3.5 ]\n",
      "[ -1.5 , 2.5 ]\n",
      "[ 0.5 , 4.5 ]\n",
      "[ 1.0 , 1.0 ]\n",
      "[ 2.0 , 10.0 ]\n",
      "[ -1.5 , 2.5 ]\n",
      "[ 1903.0 , 2063.0 ]\n",
      "[ -19.0 , 933.0 ]\n",
      "[ -239.625 , 399.375 ]\n",
      "[ -97.5 , 162.5 ]\n",
      "[ 0.0 , 0.0 ]\n",
      "[ 0.0 , 0.0 ]\n",
      "[ 0.0 , 0.0 ]\n",
      "[ 0.0 , 0.0 ]\n",
      "[ 0.0 , 0.0 ]\n",
      "[ 0.5 , 12.5 ]\n",
      "[ 2004.0 , 2012.0 ]\n"
     ]
    }
   ],
   "source": [
    "# Outlier delete\n",
    "\n",
    "for col in continuous_cols:\n",
    "    q1=df_train[col].quantile(0.25)\n",
    "    q3=df_train[col].quantile(0.75)\n",
    "    iqr=q3-q1\n",
    "    l=q1-1.5*iqr\n",
    "    h=q3+1.5*iqr\n",
    "    print(\"[\",l,\",\",h,\"]\")\n",
    "    df_train = df_train[(df_train[col] <= h)] \n",
    "    df_train = df_train[(df_train[col] >=l)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f27e13f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output_col=df_train['SalePrice']\n",
    "df_train.drop(\"SalePrice\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d210b4a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>...</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>10084</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>70.0</td>\n",
       "      <td>11200</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>63.0</td>\n",
       "      <td>8500</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1448</th>\n",
       "      <td>50</td>\n",
       "      <td>RL</td>\n",
       "      <td>70.0</td>\n",
       "      <td>11767</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>78.0</td>\n",
       "      <td>9262</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2009</td>\n",
       "      <td>New</td>\n",
       "      <td>Partial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>20</td>\n",
       "      <td>FV</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7500</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>576 rows × 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass MSZoning  LotFrontage  LotArea Street LotShape LandContour  \\\n",
       "0             60       RL         65.0     8450   Pave      Reg         Lvl   \n",
       "2             60       RL         68.0    11250   Pave      IR1         Lvl   \n",
       "4             60       RL         84.0    14260   Pave      IR1         Lvl   \n",
       "6             20       RL         75.0    10084   Pave      Reg         Lvl   \n",
       "10            20       RL         70.0    11200   Pave      Reg         Lvl   \n",
       "...          ...      ...          ...      ...    ...      ...         ...   \n",
       "1444          20       RL         63.0     8500   Pave      Reg         Lvl   \n",
       "1448          50       RL         70.0    11767   Pave      Reg         Lvl   \n",
       "1451          20       RL         78.0     9262   Pave      Reg         Lvl   \n",
       "1454          20       FV         62.0     7500   Pave      Reg         Lvl   \n",
       "1455          60       RL         62.0     7917   Pave      Reg         Lvl   \n",
       "\n",
       "     Utilities LotConfig LandSlope  ... OpenPorchSF EnclosedPorch 3SsnPorch  \\\n",
       "0       AllPub    Inside       Gtl  ...          61             0         0   \n",
       "2       AllPub    Inside       Gtl  ...          42             0         0   \n",
       "4       AllPub       FR2       Gtl  ...          84             0         0   \n",
       "6       AllPub    Inside       Gtl  ...          57             0         0   \n",
       "10      AllPub    Inside       Gtl  ...           0             0         0   \n",
       "...        ...       ...       ...  ...         ...           ...       ...   \n",
       "1444    AllPub       FR2       Gtl  ...          60             0         0   \n",
       "1448    AllPub    Inside       Gtl  ...          24             0         0   \n",
       "1451    AllPub    Inside       Gtl  ...          36             0         0   \n",
       "1454    AllPub    Inside       Gtl  ...         113             0         0   \n",
       "1455    AllPub    Inside       Gtl  ...          40             0         0   \n",
       "\n",
       "     ScreenPorch PoolArea  MiscVal  MoSold  YrSold SaleType SaleCondition  \n",
       "0              0        0        0       2    2008       WD        Normal  \n",
       "2              0        0        0       9    2008       WD        Normal  \n",
       "4              0        0        0      12    2008       WD        Normal  \n",
       "6              0        0        0       8    2007       WD        Normal  \n",
       "10             0        0        0       2    2008       WD        Normal  \n",
       "...          ...      ...      ...     ...     ...      ...           ...  \n",
       "1444           0        0        0      11    2007       WD        Normal  \n",
       "1448           0        0        0       5    2007       WD        Normal  \n",
       "1451           0        0        0       5    2009      New       Partial  \n",
       "1454           0        0        0      10    2009       WD        Normal  \n",
       "1455           0        0        0       8    2007       WD        Normal  \n",
       "\n",
       "[576 rows x 71 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30980e0-62ca-4aa2-95c8-14c550eb7188",
   "metadata": {},
   "source": [
    "Here we are encoding our categorical columns using 'one_hot_encoding' as a strategy. We will be experimenting other strategies later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b315dce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def encoding_categorical_cols(df_train:pd.DataFrame,categorical_columns:list,strategy:str):\n",
    "    df_categorical=pd.DataFrame(df_train.loc[:,categorical_columns])\n",
    "    if strategy==\"labelencoder\":\n",
    "        for col in list(df_categorical.columns):\n",
    "            cat=[]\n",
    "            d={}\n",
    "\n",
    "            cat.append([df_categorical[col].value_counts().index,len(df_categorical[col].value_counts().index)])\n",
    "\n",
    "            for j in range(int(cat[0][1])):\n",
    "                d[str(cat[0][0][j])]=j\n",
    "            df_categorical[col]=df_categorical[col].map(d)\n",
    "        df_train.drop(categorical_columns,axis=1,inplace=True)\n",
    "        \n",
    "        df_train=pd.concat([df_train,df_categorical],axis=1)\n",
    "        \n",
    "    if strategy==\"onehotencoder\":\n",
    "        one_hot_encoded=pd.get_dummies(df_categorical)\n",
    "        # print(one_hot_encoded)\n",
    "        df_train.drop(categorical_columns,axis=1,inplace=True)\n",
    "        df_train=pd.concat([df_train,one_hot_encoded],axis=1)\n",
    "    return df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0e862a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=encoding_categorical_cols(df_train=df_train,categorical_columns=categorical_cols,strategy=\"onehotencoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "adc20103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>...</th>\n",
       "      <th>SaleType_ConLw</th>\n",
       "      <th>SaleType_New</th>\n",
       "      <th>SaleType_Oth</th>\n",
       "      <th>SaleType_WD</th>\n",
       "      <th>SaleCondition_Abnorml</th>\n",
       "      <th>SaleCondition_AdjLand</th>\n",
       "      <th>SaleCondition_Alloca</th>\n",
       "      <th>SaleCondition_Family</th>\n",
       "      <th>SaleCondition_Normal</th>\n",
       "      <th>SaleCondition_Partial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>196.0</td>\n",
       "      <td>706</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2002</td>\n",
       "      <td>162.0</td>\n",
       "      <td>486</td>\n",
       "      <td>0</td>\n",
       "      <td>434</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>350.0</td>\n",
       "      <td>655</td>\n",
       "      <td>0</td>\n",
       "      <td>490</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20</td>\n",
       "      <td>75.0</td>\n",
       "      <td>10084</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2005</td>\n",
       "      <td>186.0</td>\n",
       "      <td>1369</td>\n",
       "      <td>0</td>\n",
       "      <td>317</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20</td>\n",
       "      <td>70.0</td>\n",
       "      <td>11200</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>906</td>\n",
       "      <td>0</td>\n",
       "      <td>134</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444</th>\n",
       "      <td>20</td>\n",
       "      <td>63.0</td>\n",
       "      <td>8500</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2004</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1422</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1448</th>\n",
       "      <td>50</td>\n",
       "      <td>70.0</td>\n",
       "      <td>11767</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>560</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451</th>\n",
       "      <td>20</td>\n",
       "      <td>78.0</td>\n",
       "      <td>9262</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2009</td>\n",
       "      <td>194.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1573</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>20</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7500</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>410</td>\n",
       "      <td>0</td>\n",
       "      <td>811</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>60</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>953</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>576 rows × 217 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  \\\n",
       "0             60         65.0     8450            7            5   \n",
       "2             60         68.0    11250            7            5   \n",
       "4             60         84.0    14260            8            5   \n",
       "6             20         75.0    10084            8            5   \n",
       "10            20         70.0    11200            5            5   \n",
       "...          ...          ...      ...          ...          ...   \n",
       "1444          20         63.0     8500            7            5   \n",
       "1448          50         70.0    11767            4            7   \n",
       "1451          20         78.0     9262            8            5   \n",
       "1454          20         62.0     7500            7            5   \n",
       "1455          60         62.0     7917            6            5   \n",
       "\n",
       "      YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  BsmtUnfSF  ...  \\\n",
       "0             2003       196.0         706           0        150  ...   \n",
       "2             2002       162.0         486           0        434  ...   \n",
       "4             2000       350.0         655           0        490  ...   \n",
       "6             2005       186.0        1369           0        317  ...   \n",
       "10            1965         0.0         906           0        134  ...   \n",
       "...            ...         ...         ...         ...        ...  ...   \n",
       "1444          2004       106.0           0           0       1422  ...   \n",
       "1448          2000         0.0           0           0        560  ...   \n",
       "1451          2009       194.0           0           0       1573  ...   \n",
       "1454          2005         0.0         410           0        811  ...   \n",
       "1455          2000         0.0           0           0        953  ...   \n",
       "\n",
       "      SaleType_ConLw  SaleType_New  SaleType_Oth  SaleType_WD  \\\n",
       "0                  0             0             0            1   \n",
       "2                  0             0             0            1   \n",
       "4                  0             0             0            1   \n",
       "6                  0             0             0            1   \n",
       "10                 0             0             0            1   \n",
       "...              ...           ...           ...          ...   \n",
       "1444               0             0             0            1   \n",
       "1448               0             0             0            1   \n",
       "1451               0             1             0            0   \n",
       "1454               0             0             0            1   \n",
       "1455               0             0             0            1   \n",
       "\n",
       "      SaleCondition_Abnorml  SaleCondition_AdjLand  SaleCondition_Alloca  \\\n",
       "0                         0                      0                     0   \n",
       "2                         0                      0                     0   \n",
       "4                         0                      0                     0   \n",
       "6                         0                      0                     0   \n",
       "10                        0                      0                     0   \n",
       "...                     ...                    ...                   ...   \n",
       "1444                      0                      0                     0   \n",
       "1448                      0                      0                     0   \n",
       "1451                      0                      0                     0   \n",
       "1454                      0                      0                     0   \n",
       "1455                      0                      0                     0   \n",
       "\n",
       "      SaleCondition_Family  SaleCondition_Normal  SaleCondition_Partial  \n",
       "0                        0                     1                      0  \n",
       "2                        0                     1                      0  \n",
       "4                        0                     1                      0  \n",
       "6                        0                     1                      0  \n",
       "10                       0                     1                      0  \n",
       "...                    ...                   ...                    ...  \n",
       "1444                     0                     1                      0  \n",
       "1448                     0                     1                      0  \n",
       "1451                     0                     0                      1  \n",
       "1454                     0                     1                      0  \n",
       "1455                     0                     1                      0  \n",
       "\n",
       "[576 rows x 217 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f1709177",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_train.columns:\n",
    "    if df_train[col].isnull().sum()>0:\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1767ae8f-7210-4fd2-a815-ee593924ee40",
   "metadata": {},
   "source": [
    "Now we will be scaling our columns using Min Max Scaler which will make our value in the range 0 to 1.Scaling is done due to following resons :\n",
    "1. To make the gradient descent converge fast so to reduce the error as much as possible\n",
    "2. To make all features on a specific scale.\n",
    "\n",
    "We do scaling mainly for the distance based algorithms such as KNN,K-Means , SVM and so on. Since it helps them to reduce the error using radient very quickly. But for tree based algorithms we didnt need sacling since their accuracy is based on the split so even though the values are scaled the splitting won't be affected.And since we are using both types of algorithms we will us\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "152a28be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>...</th>\n",
       "      <th>SaleType_ConLw</th>\n",
       "      <th>SaleType_New</th>\n",
       "      <th>SaleType_Oth</th>\n",
       "      <th>SaleType_WD</th>\n",
       "      <th>SaleCondition_Abnorml</th>\n",
       "      <th>SaleCondition_AdjLand</th>\n",
       "      <th>SaleCondition_Alloca</th>\n",
       "      <th>SaleCondition_Family</th>\n",
       "      <th>SaleCondition_Normal</th>\n",
       "      <th>SaleCondition_Partial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.400706</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.463357</td>\n",
       "      <td>0.436072</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.087771</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4750</td>\n",
       "      <td>0.602391</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.382979</td>\n",
       "      <td>0.300185</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.253950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6750</td>\n",
       "      <td>0.819203</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.827423</td>\n",
       "      <td>0.404571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.286717</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.518404</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.439716</td>\n",
       "      <td>0.845584</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.185489</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.598790</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.559605</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.078408</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4125</td>\n",
       "      <td>0.404307</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.250591</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.832066</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1448</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.639631</td>\n",
       "      <td>0.250</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.327677</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.459195</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.458629</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.920421</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.332277</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.253243</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.474547</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.362314</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.557636</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>576 rows × 217 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass  LotFrontage   LotArea  OverallQual  OverallCond  \\\n",
       "0            0.4       0.4375  0.400706        0.625     0.333333   \n",
       "2            0.4       0.4750  0.602391        0.625     0.333333   \n",
       "4            0.4       0.6750  0.819203        0.750     0.333333   \n",
       "6            0.0       0.5625  0.518404        0.750     0.333333   \n",
       "10           0.0       0.5000  0.598790        0.375     0.333333   \n",
       "...          ...          ...       ...          ...          ...   \n",
       "1444         0.0       0.4125  0.404307        0.625     0.333333   \n",
       "1448         0.3       0.5000  0.639631        0.250     1.000000   \n",
       "1451         0.0       0.6000  0.459195        0.750     0.333333   \n",
       "1454         0.0       0.4000  0.332277        0.625     0.333333   \n",
       "1455         0.4       0.4000  0.362314        0.500     0.333333   \n",
       "\n",
       "      YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  BsmtUnfSF  ...  \\\n",
       "0         0.883333    0.463357    0.436072         0.0   0.087771  ...   \n",
       "2         0.866667    0.382979    0.300185         0.0   0.253950  ...   \n",
       "4         0.833333    0.827423    0.404571         0.0   0.286717  ...   \n",
       "6         0.916667    0.439716    0.845584         0.0   0.185489  ...   \n",
       "10        0.250000    0.000000    0.559605         0.0   0.078408  ...   \n",
       "...            ...         ...         ...         ...        ...  ...   \n",
       "1444      0.900000    0.250591    0.000000         0.0   0.832066  ...   \n",
       "1448      0.833333    0.000000    0.000000         0.0   0.327677  ...   \n",
       "1451      0.983333    0.458629    0.000000         0.0   0.920421  ...   \n",
       "1454      0.916667    0.000000    0.253243         0.0   0.474547  ...   \n",
       "1455      0.833333    0.000000    0.000000         0.0   0.557636  ...   \n",
       "\n",
       "      SaleType_ConLw  SaleType_New  SaleType_Oth  SaleType_WD  \\\n",
       "0                0.0           0.0           0.0          1.0   \n",
       "2                0.0           0.0           0.0          1.0   \n",
       "4                0.0           0.0           0.0          1.0   \n",
       "6                0.0           0.0           0.0          1.0   \n",
       "10               0.0           0.0           0.0          1.0   \n",
       "...              ...           ...           ...          ...   \n",
       "1444             0.0           0.0           0.0          1.0   \n",
       "1448             0.0           0.0           0.0          1.0   \n",
       "1451             0.0           1.0           0.0          0.0   \n",
       "1454             0.0           0.0           0.0          1.0   \n",
       "1455             0.0           0.0           0.0          1.0   \n",
       "\n",
       "      SaleCondition_Abnorml  SaleCondition_AdjLand  SaleCondition_Alloca  \\\n",
       "0                       0.0                    0.0                   0.0   \n",
       "2                       0.0                    0.0                   0.0   \n",
       "4                       0.0                    0.0                   0.0   \n",
       "6                       0.0                    0.0                   0.0   \n",
       "10                      0.0                    0.0                   0.0   \n",
       "...                     ...                    ...                   ...   \n",
       "1444                    0.0                    0.0                   0.0   \n",
       "1448                    0.0                    0.0                   0.0   \n",
       "1451                    0.0                    0.0                   0.0   \n",
       "1454                    0.0                    0.0                   0.0   \n",
       "1455                    0.0                    0.0                   0.0   \n",
       "\n",
       "      SaleCondition_Family  SaleCondition_Normal  SaleCondition_Partial  \n",
       "0                      0.0                   1.0                    0.0  \n",
       "2                      0.0                   1.0                    0.0  \n",
       "4                      0.0                   1.0                    0.0  \n",
       "6                      0.0                   1.0                    0.0  \n",
       "10                     0.0                   1.0                    0.0  \n",
       "...                    ...                   ...                    ...  \n",
       "1444                   0.0                   1.0                    0.0  \n",
       "1448                   0.0                   1.0                    0.0  \n",
       "1451                   0.0                   0.0                    1.0  \n",
       "1454                   0.0                   1.0                    0.0  \n",
       "1455                   0.0                   1.0                    0.0  \n",
       "\n",
       "[576 rows x 217 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler=MinMaxScaler()\n",
    "df_train=pd.DataFrame(scaler.fit_transform(df_train),index=df_train.index, columns=df_train.columns)\n",
    "df_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2b0069d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11426f5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "589aafd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df_train\n",
    "Y=output_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "03f5b5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_accuracies={}\n",
    "highest_accuracies={}\n",
    "algorithms_tested=[\"LinearRegression()\",\"RandomForestRegressor()\",\"SVR()\",\"KNeighborsRegressor()\",\"SGDRegressor()\",\"DecisionTreeRegressor()\",\"ElasticNet()\",\"Lasso()\",\"Ridge()\"]\n",
    "for al in algorithms_tested:\n",
    "    avg_accuracies[al]=0\n",
    "    highest_accuracies[al]=float('-inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9fe025b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def algo_testing(algo:str,test_size:float,X,Y,evaluation_metric:str,random_state,shuffle):\n",
    "    model=eval(algo)\n",
    "    evaluation_metric=eval(evaluation_metric)\n",
    "    X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=random_state,shuffle=shuffle)\n",
    "   \n",
    "    model.fit(X_train,Y_train)\n",
    "    predicted=model.predict(X_test)\n",
    "    \n",
    "    r2=evaluation_metric(Y_test, predicted)\n",
    "    print(f\"Testing r2_score of {model} is \",r2)\n",
    "    print(f\"Training r2_score of {model} is \", model.score(X_train,Y_train))\n",
    "    if highest_accuracies[algo]<r2:\n",
    "        \n",
    "        highest_accuracies[algo]=r2\n",
    "    avg_accuracies[algo]+=r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "49a7f5e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of LinearRegression() is  -4.989267423077935e+18\n",
      "Training r2_score of LinearRegression() is  0.9634176282092857\n",
      "Testing r2_score of LinearRegression() is  -7.914833594608799e+20\n",
      "Training r2_score of LinearRegression() is  0.9588237493465864\n",
      "Testing r2_score of LinearRegression() is  -3.5884785466180087e+21\n",
      "Training r2_score of LinearRegression() is  0.9572176127283847\n",
      "Testing r2_score of LinearRegression() is  -9.00905499480437e+19\n",
      "Training r2_score of LinearRegression() is  0.9616302776565767\n",
      "Testing r2_score of LinearRegression() is  -1.6241119812823958e+19\n",
      "Training r2_score of LinearRegression() is  0.9627825315654909\n",
      "Testing r2_score of LinearRegression() is  -1.3864468983129076e+19\n",
      "Training r2_score of LinearRegression() is  0.9638323338759022\n",
      "Testing r2_score of LinearRegression() is  -2.609394476302644e+17\n",
      "Training r2_score of LinearRegression() is  0.9605065404547755\n",
      "Testing r2_score of LinearRegression() is  -3.554585790993539e+20\n",
      "Training r2_score of LinearRegression() is  0.9660486656813626\n",
      "Testing r2_score of LinearRegression() is  -3.491846330350387e+19\n",
      "Training r2_score of LinearRegression() is  0.9672942264836792\n",
      "Testing r2_score of LinearRegression() is  -1.7303600599883663e+19\n",
      "Training r2_score of LinearRegression() is  0.9590046707526495\n",
      "Testing r2_score of LinearRegression() is  -7.276261687268029e+20\n",
      "Training r2_score of LinearRegression() is  0.9695564403310284\n",
      "Testing r2_score of LinearRegression() is  -3.9180939727066686e+21\n",
      "Training r2_score of LinearRegression() is  0.9576072491545828\n",
      "Testing r2_score of LinearRegression() is  -6.397648750123489e+17\n",
      "Training r2_score of LinearRegression() is  0.9656644369597837\n",
      "Testing r2_score of LinearRegression() is  -1.2220556117223703e+20\n",
      "Training r2_score of LinearRegression() is  0.9653400591794641\n",
      "Testing r2_score of LinearRegression() is  -2.1470695203404444e+16\n",
      "Training r2_score of LinearRegression() is  0.9630048010668856\n",
      "Testing r2_score of LinearRegression() is  -3.602193916054148e+21\n",
      "Training r2_score of LinearRegression() is  0.9624036211272612\n",
      "Testing r2_score of LinearRegression() is  -8.037375607857701e+18\n",
      "Training r2_score of LinearRegression() is  0.9632716336651329\n",
      "Testing r2_score of LinearRegression() is  -1.7766517884267598e+19\n",
      "Training r2_score of LinearRegression() is  0.9658525268046496\n",
      "Testing r2_score of LinearRegression() is  -8.746006870333167e+20\n",
      "Training r2_score of LinearRegression() is  0.9635636216936062\n",
      "Testing r2_score of LinearRegression() is  -1.3161303410867776e+17\n",
      "Training r2_score of LinearRegression() is  0.9636659251925322\n",
      "Testing r2_score of LinearRegression() is  -1.5709144437188188e+21\n",
      "Training r2_score of LinearRegression() is  0.9658570333361559\n",
      "Testing r2_score of LinearRegression() is  -2.3523799688624464e+21\n",
      "Training r2_score of LinearRegression() is  0.9622620134196255\n",
      "Testing r2_score of LinearRegression() is  -3.806787390664725e+21\n",
      "Training r2_score of LinearRegression() is  0.9617512395702665\n",
      "Testing r2_score of LinearRegression() is  -3.134384125385057e+21\n",
      "Training r2_score of LinearRegression() is  0.9621810019879342\n",
      "Testing r2_score of LinearRegression() is  -6.659188723895746e+20\n",
      "Training r2_score of LinearRegression() is  0.9598231086694764\n",
      "Testing r2_score of LinearRegression() is  -6.301690689171913e+19\n",
      "Training r2_score of LinearRegression() is  0.9589661354210883\n",
      "Testing r2_score of LinearRegression() is  -2.723551944239532e+18\n",
      "Training r2_score of LinearRegression() is  0.9638810286144576\n",
      "Testing r2_score of LinearRegression() is  -8.683497559253985e+19\n",
      "Training r2_score of LinearRegression() is  0.9615207903006194\n",
      "Testing r2_score of LinearRegression() is  -1.7178189026519366e+17\n",
      "Training r2_score of LinearRegression() is  0.9639474883229303\n",
      "Testing r2_score of LinearRegression() is  -1.0465494647806997e+20\n",
      "Training r2_score of LinearRegression() is  0.9596059149491085\n",
      "Testing r2_score of LinearRegression() is  -4.8332062472430215e+19\n",
      "Training r2_score of LinearRegression() is  0.9627337744116349\n",
      "Testing r2_score of LinearRegression() is  -1.505924225249159e+22\n",
      "Training r2_score of LinearRegression() is  0.960955603830227\n",
      "Testing r2_score of LinearRegression() is  -2.671102534650619e+21\n",
      "Training r2_score of LinearRegression() is  0.963820832387182\n",
      "Testing r2_score of LinearRegression() is  -7.723755414637901e+20\n",
      "Training r2_score of LinearRegression() is  0.9578991097482185\n",
      "Testing r2_score of LinearRegression() is  -2.9021937008457926e+17\n",
      "Training r2_score of LinearRegression() is  0.9629070158052039\n",
      "Testing r2_score of LinearRegression() is  -1.981777147243499e+20\n",
      "Training r2_score of LinearRegression() is  0.962364834576984\n",
      "Testing r2_score of LinearRegression() is  -2.1868536257971542e+20\n",
      "Training r2_score of LinearRegression() is  0.9551717566323897\n",
      "Testing r2_score of LinearRegression() is  -9.817656167598914e+18\n",
      "Training r2_score of LinearRegression() is  0.9643578587157411\n",
      "Testing r2_score of LinearRegression() is  -3.514422742539108e+20\n",
      "Training r2_score of LinearRegression() is  0.9597038009952147\n",
      "Testing r2_score of LinearRegression() is  -1.9660496561811569e+18\n",
      "Training r2_score of LinearRegression() is  0.9609145500779709\n",
      "Testing r2_score of LinearRegression() is  -2.615547335350183e+19\n",
      "Training r2_score of LinearRegression() is  0.9605711069090185\n",
      "Testing r2_score of LinearRegression() is  -3.288018521820372e+20\n",
      "Training r2_score of LinearRegression() is  0.9638639135928682\n",
      "Testing r2_score of LinearRegression() is  -1.1577048709601488e+20\n",
      "Training r2_score of LinearRegression() is  0.9668732814212793\n",
      "Testing r2_score of LinearRegression() is  -3.483333113546638e+20\n",
      "Training r2_score of LinearRegression() is  0.9670448873904889\n",
      "Testing r2_score of LinearRegression() is  -1.5950112055113882e+20\n",
      "Training r2_score of LinearRegression() is  0.9589842705173355\n",
      "Testing r2_score of LinearRegression() is  -2.761625310664705e+19\n",
      "Training r2_score of LinearRegression() is  0.9624454246746615\n",
      "Testing r2_score of LinearRegression() is  -1.949842078217962e+21\n",
      "Training r2_score of LinearRegression() is  0.9638503789809898\n",
      "Testing r2_score of LinearRegression() is  -7.159926616120582e+19\n",
      "Training r2_score of LinearRegression() is  0.9614576844253313\n",
      "Testing r2_score of LinearRegression() is  -3.5780503640874634e+20\n",
      "Training r2_score of LinearRegression() is  0.9567328921828606\n",
      "Testing r2_score of LinearRegression() is  -1.7597894113348278e+21\n",
      "Training r2_score of LinearRegression() is  0.9656342890044632\n"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    algo_testing(algo=\"LinearRegression()\",test_size=0.2,X=X,Y=Y,evaluation_metric=\"r2_score\",random_state=None,shuffle=True)\n",
    "avg_accuracies[\"LinearRegression()\"]/=50\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dcfd7698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of RandomForestRegressor() is  0.8621047937140652\n",
      "Training r2_score of RandomForestRegressor() is  0.9832777875775764\n",
      "Testing r2_score of RandomForestRegressor() is  0.7546481022947797\n",
      "Training r2_score of RandomForestRegressor() is  0.9815929089591211\n",
      "Testing r2_score of RandomForestRegressor() is  0.8775623266169511\n",
      "Training r2_score of RandomForestRegressor() is  0.9807355531345958\n",
      "Testing r2_score of RandomForestRegressor() is  0.9057096766923298\n",
      "Training r2_score of RandomForestRegressor() is  0.9800679008630854\n",
      "Testing r2_score of RandomForestRegressor() is  0.8896119385699892\n",
      "Training r2_score of RandomForestRegressor() is  0.9806587647687046\n",
      "Testing r2_score of RandomForestRegressor() is  0.87702349637391\n",
      "Training r2_score of RandomForestRegressor() is  0.9802518252980459\n",
      "Testing r2_score of RandomForestRegressor() is  0.875068763658562\n",
      "Training r2_score of RandomForestRegressor() is  0.9814790297234179\n",
      "Testing r2_score of RandomForestRegressor() is  0.8318431955858424\n",
      "Training r2_score of RandomForestRegressor() is  0.9812989961274269\n",
      "Testing r2_score of RandomForestRegressor() is  0.7962878073964674\n",
      "Training r2_score of RandomForestRegressor() is  0.9847550649186053\n",
      "Testing r2_score of RandomForestRegressor() is  0.8634014003090144\n",
      "Training r2_score of RandomForestRegressor() is  0.9816593592794943\n",
      "Testing r2_score of RandomForestRegressor() is  0.8807771967151604\n",
      "Training r2_score of RandomForestRegressor() is  0.9811240852976715\n",
      "Testing r2_score of RandomForestRegressor() is  0.8899228485028665\n",
      "Training r2_score of RandomForestRegressor() is  0.9801338587949675\n",
      "Testing r2_score of RandomForestRegressor() is  0.8342925177027435\n",
      "Training r2_score of RandomForestRegressor() is  0.9831883663047434\n",
      "Testing r2_score of RandomForestRegressor() is  0.9054203657260016\n",
      "Training r2_score of RandomForestRegressor() is  0.9813568016910451\n",
      "Testing r2_score of RandomForestRegressor() is  0.8646004548528977\n",
      "Training r2_score of RandomForestRegressor() is  0.9828697221998504\n",
      "Testing r2_score of RandomForestRegressor() is  0.8940431290455969\n",
      "Training r2_score of RandomForestRegressor() is  0.9806958350284449\n",
      "Testing r2_score of RandomForestRegressor() is  0.8310783015151496\n",
      "Training r2_score of RandomForestRegressor() is  0.9840361588628855\n",
      "Testing r2_score of RandomForestRegressor() is  0.8422166539269742\n",
      "Training r2_score of RandomForestRegressor() is  0.981235514936234\n",
      "Testing r2_score of RandomForestRegressor() is  0.8312201561064734\n",
      "Training r2_score of RandomForestRegressor() is  0.9840620299408795\n",
      "Testing r2_score of RandomForestRegressor() is  0.8550284739071183\n",
      "Training r2_score of RandomForestRegressor() is  0.9815319736999742\n",
      "Testing r2_score of RandomForestRegressor() is  0.9156020119478879\n",
      "Training r2_score of RandomForestRegressor() is  0.9815642270009373\n",
      "Testing r2_score of RandomForestRegressor() is  0.8896839238156264\n",
      "Training r2_score of RandomForestRegressor() is  0.98258477718454\n",
      "Testing r2_score of RandomForestRegressor() is  0.8594033221190285\n",
      "Training r2_score of RandomForestRegressor() is  0.9823957582047159\n",
      "Testing r2_score of RandomForestRegressor() is  0.8509765854766983\n",
      "Training r2_score of RandomForestRegressor() is  0.9824046324971915\n",
      "Testing r2_score of RandomForestRegressor() is  0.8651228918043853\n",
      "Training r2_score of RandomForestRegressor() is  0.9805471362049546\n",
      "Testing r2_score of RandomForestRegressor() is  0.8631404897651215\n",
      "Training r2_score of RandomForestRegressor() is  0.9804704946159244\n",
      "Testing r2_score of RandomForestRegressor() is  0.8529361666717209\n",
      "Training r2_score of RandomForestRegressor() is  0.9827027665359976\n",
      "Testing r2_score of RandomForestRegressor() is  0.8218120398861137\n",
      "Training r2_score of RandomForestRegressor() is  0.982808734460122\n",
      "Testing r2_score of RandomForestRegressor() is  0.8440841340689818\n",
      "Training r2_score of RandomForestRegressor() is  0.9803352298921636\n",
      "Testing r2_score of RandomForestRegressor() is  0.8327127210651973\n",
      "Training r2_score of RandomForestRegressor() is  0.9825079082178494\n",
      "Testing r2_score of RandomForestRegressor() is  0.8920096986116652\n",
      "Training r2_score of RandomForestRegressor() is  0.9815821478962027\n",
      "Testing r2_score of RandomForestRegressor() is  0.8352270591695815\n",
      "Training r2_score of RandomForestRegressor() is  0.9831436571731907\n",
      "Testing r2_score of RandomForestRegressor() is  0.8562238165924216\n",
      "Training r2_score of RandomForestRegressor() is  0.9829415587447043\n",
      "Testing r2_score of RandomForestRegressor() is  0.8813922653607954\n",
      "Training r2_score of RandomForestRegressor() is  0.9816043560206882\n",
      "Testing r2_score of RandomForestRegressor() is  0.8686997469574264\n",
      "Training r2_score of RandomForestRegressor() is  0.9803802256633248\n",
      "Testing r2_score of RandomForestRegressor() is  0.8842361655568172\n",
      "Training r2_score of RandomForestRegressor() is  0.9810619537345718\n",
      "Testing r2_score of RandomForestRegressor() is  0.8538162598547946\n",
      "Training r2_score of RandomForestRegressor() is  0.9829543884629361\n",
      "Testing r2_score of RandomForestRegressor() is  0.8926632000744944\n",
      "Training r2_score of RandomForestRegressor() is  0.9825743155982052\n",
      "Testing r2_score of RandomForestRegressor() is  0.900731153640327\n",
      "Training r2_score of RandomForestRegressor() is  0.9812440117135346\n",
      "Testing r2_score of RandomForestRegressor() is  0.887971747940995\n",
      "Training r2_score of RandomForestRegressor() is  0.9815134234782973\n",
      "Testing r2_score of RandomForestRegressor() is  0.8576460426114858\n",
      "Training r2_score of RandomForestRegressor() is  0.9831357265062532\n",
      "Testing r2_score of RandomForestRegressor() is  0.895702040846474\n",
      "Training r2_score of RandomForestRegressor() is  0.9814190217968676\n",
      "Testing r2_score of RandomForestRegressor() is  0.9125433832723319\n",
      "Training r2_score of RandomForestRegressor() is  0.9795203986296931\n",
      "Testing r2_score of RandomForestRegressor() is  0.8519333159185012\n",
      "Training r2_score of RandomForestRegressor() is  0.9814790767107818\n",
      "Testing r2_score of RandomForestRegressor() is  0.8473063189184962\n",
      "Training r2_score of RandomForestRegressor() is  0.9833733553610465\n",
      "Testing r2_score of RandomForestRegressor() is  0.8676862059558992\n",
      "Training r2_score of RandomForestRegressor() is  0.9806539428042477\n",
      "Testing r2_score of RandomForestRegressor() is  0.883246998144204\n",
      "Training r2_score of RandomForestRegressor() is  0.9822009467789572\n",
      "Testing r2_score of RandomForestRegressor() is  0.8308228091087206\n",
      "Training r2_score of RandomForestRegressor() is  0.9833681731635542\n",
      "Testing r2_score of RandomForestRegressor() is  0.8050687984952039\n",
      "Training r2_score of RandomForestRegressor() is  0.9843059758988038\n",
      "Testing r2_score of RandomForestRegressor() is  0.8392111128561686\n",
      "Training r2_score of RandomForestRegressor() is  0.9831082998411964\n",
      "Testing r2_score of SVR() is  -0.01124028516875808\n",
      "Training r2_score of SVR() is  -0.007805032694256031\n",
      "Testing r2_score of SVR() is  -0.034990499241534634\n",
      "Training r2_score of SVR() is  -0.007291032421193666\n",
      "Testing r2_score of SVR() is  -0.013119015935324496\n",
      "Training r2_score of SVR() is  -0.013496545882845323\n",
      "Testing r2_score of SVR() is  -0.0012235015714505693\n",
      "Training r2_score of SVR() is  -0.009473507082505384\n",
      "Testing r2_score of SVR() is  -0.003946173059173219\n",
      "Training r2_score of SVR() is  -0.009624940882150712\n",
      "Testing r2_score of SVR() is  -0.003656655821819843\n",
      "Training r2_score of SVR() is  -0.008098715587735894\n",
      "Testing r2_score of SVR() is  -0.0024762150475059475\n",
      "Training r2_score of SVR() is  -0.010210888228167736\n",
      "Testing r2_score of SVR() is  -0.060964949452552375\n",
      "Training r2_score of SVR() is  -0.005648812276314308\n",
      "Testing r2_score of SVR() is  -0.030385198004832636\n",
      "Training r2_score of SVR() is  -0.009060623753633701\n",
      "Testing r2_score of SVR() is  -0.007639647232791313\n",
      "Training r2_score of SVR() is  -0.008649100738676196\n",
      "Testing r2_score of SVR() is  -0.031389694072310625\n",
      "Training r2_score of SVR() is  -0.004783662876184813\n",
      "Testing r2_score of SVR() is  -0.06941544759951124\n",
      "Training r2_score of SVR() is  -0.006744774296185474\n",
      "Testing r2_score of SVR() is  0.0004330971976277409\n",
      "Training r2_score of SVR() is  -0.012040969335061158\n",
      "Testing r2_score of SVR() is  0.0005025116939700869\n",
      "Training r2_score of SVR() is  -0.01216563426562911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of SVR() is  -0.0004895244590898962\n",
      "Training r2_score of SVR() is  -0.008752166592171928\n",
      "Testing r2_score of SVR() is  -0.004917435214374599\n",
      "Training r2_score of SVR() is  -0.008997005332301189\n",
      "Testing r2_score of SVR() is  -0.006606670566495554\n",
      "Training r2_score of SVR() is  -0.008889398140030869\n",
      "Testing r2_score of SVR() is  -0.0014030116086389821\n",
      "Training r2_score of SVR() is  -0.012229073802211943\n",
      "Testing r2_score of SVR() is  -0.014621572809854433\n",
      "Training r2_score of SVR() is  -0.007274785690992713\n",
      "Testing r2_score of SVR() is  -0.010982277679532748\n",
      "Training r2_score of SVR() is  -0.006975348663819991\n",
      "Testing r2_score of SVR() is  0.00046508022712821173\n",
      "Training r2_score of SVR() is  -0.012098248545216794\n",
      "Testing r2_score of SVR() is  -0.004685795034176987\n",
      "Training r2_score of SVR() is  -0.004363129514113773\n",
      "Testing r2_score of SVR() is  -0.003928623742005755\n",
      "Training r2_score of SVR() is  -0.00883935684779602\n",
      "Testing r2_score of SVR() is  -0.023926385908193515\n",
      "Training r2_score of SVR() is  -0.009309963360241813\n",
      "Testing r2_score of SVR() is  -0.001817776543983518\n",
      "Training r2_score of SVR() is  -0.009703054168227476\n",
      "Testing r2_score of SVR() is  -0.0157526804640562\n",
      "Training r2_score of SVR() is  -0.0059616934375035235\n",
      "Testing r2_score of SVR() is  -0.00017200503066239214\n",
      "Training r2_score of SVR() is  -0.008613535783374315\n",
      "Testing r2_score of SVR() is  -0.012981418133070521\n",
      "Training r2_score of SVR() is  -0.010178681462146066\n",
      "Testing r2_score of SVR() is  -0.013745857084050295\n",
      "Training r2_score of SVR() is  -0.007194998761712368\n",
      "Testing r2_score of SVR() is  -0.04256491287177555\n",
      "Training r2_score of SVR() is  -0.00529861447643154\n",
      "Testing r2_score of SVR() is  0.0004873637541136233\n",
      "Training r2_score of SVR() is  -0.0054712671015646475\n",
      "Testing r2_score of SVR() is  -0.0066685854743204764\n",
      "Training r2_score of SVR() is  -0.008891490412199499\n",
      "Testing r2_score of SVR() is  -0.001984165268055449\n",
      "Training r2_score of SVR() is  -0.009184294682146765\n",
      "Testing r2_score of SVR() is  -0.00024472132394248725\n",
      "Training r2_score of SVR() is  -0.014452295522836334\n",
      "Testing r2_score of SVR() is  -0.04341630484045367\n",
      "Training r2_score of SVR() is  -0.009980650997289064\n",
      "Testing r2_score of SVR() is  -0.02487013197428034\n",
      "Training r2_score of SVR() is  -0.012325567180597519\n",
      "Testing r2_score of SVR() is  -0.014854564877675003\n",
      "Training r2_score of SVR() is  -0.007282677203025445\n",
      "Testing r2_score of SVR() is  -0.0006696259038934116\n",
      "Training r2_score of SVR() is  -0.004454746644621643\n",
      "Testing r2_score of SVR() is  -0.009072757804169607\n",
      "Training r2_score of SVR() is  -0.00816676020585505\n",
      "Testing r2_score of SVR() is  -0.00011453083195034353\n",
      "Training r2_score of SVR() is  -0.0098478392188186\n",
      "Testing r2_score of SVR() is  -0.012129959573808469\n",
      "Training r2_score of SVR() is  -0.006740470219293915\n",
      "Testing r2_score of SVR() is  -0.006805855421191165\n",
      "Training r2_score of SVR() is  -0.008959304299717141\n",
      "Testing r2_score of SVR() is  -0.009537782758957114\n",
      "Training r2_score of SVR() is  -0.006604054932610515\n",
      "Testing r2_score of SVR() is  -0.0026180299947276\n",
      "Training r2_score of SVR() is  -0.010120274383674355\n",
      "Testing r2_score of SVR() is  -0.04997822174206834\n",
      "Training r2_score of SVR() is  -0.01392787453645683\n",
      "Testing r2_score of SVR() is  -0.03422101619414808\n",
      "Training r2_score of SVR() is  -0.011662645365646762\n",
      "Testing r2_score of SVR() is  -0.033981442957456975\n",
      "Training r2_score of SVR() is  -0.008710457242579794\n",
      "Testing r2_score of SVR() is  -0.04348728242715838\n",
      "Training r2_score of SVR() is  -0.009659179001985763\n",
      "Testing r2_score of SVR() is  -0.011350093057269417\n",
      "Training r2_score of SVR() is  -0.010023319205634706\n",
      "Testing r2_score of SVR() is  -0.009134874873719223\n",
      "Training r2_score of SVR() is  -0.009931331901650298\n",
      "Testing r2_score of KNeighborsRegressor() is  0.7120497099073733\n",
      "Training r2_score of KNeighborsRegressor() is  0.8411844002385147\n",
      "Testing r2_score of KNeighborsRegressor() is  0.6953326818621595\n",
      "Training r2_score of KNeighborsRegressor() is  0.8507489950191158\n",
      "Testing r2_score of KNeighborsRegressor() is  0.7523199912503111\n",
      "Training r2_score of KNeighborsRegressor() is  0.8426643884283384\n",
      "Testing r2_score of KNeighborsRegressor() is  0.7491078111291904\n",
      "Training r2_score of KNeighborsRegressor() is  0.8376376767518644\n",
      "Testing r2_score of KNeighborsRegressor() is  0.7202792760019192\n",
      "Training r2_score of KNeighborsRegressor() is  0.8444454841294929\n",
      "Testing r2_score of KNeighborsRegressor() is  0.7623940501736817\n",
      "Training r2_score of KNeighborsRegressor() is  0.8378172877585655\n",
      "Testing r2_score of KNeighborsRegressor() is  0.707244651625663\n",
      "Training r2_score of KNeighborsRegressor() is  0.84257248902989\n",
      "Testing r2_score of KNeighborsRegressor() is  0.8061529318372586\n",
      "Training r2_score of KNeighborsRegressor() is  0.8200235081614543\n",
      "Testing r2_score of KNeighborsRegressor() is  0.7521738389786614\n",
      "Training r2_score of KNeighborsRegressor() is  0.8460032792737411\n",
      "Testing r2_score of KNeighborsRegressor() is  0.6417137516365097\n",
      "Training r2_score of KNeighborsRegressor() is  0.8589450789901201\n",
      "Testing r2_score of KNeighborsRegressor() is  0.750932812261327\n",
      "Training r2_score of KNeighborsRegressor() is  0.8480115530306256\n",
      "Testing r2_score of KNeighborsRegressor() is  0.6644735070533367\n",
      "Training r2_score of KNeighborsRegressor() is  0.8580206182885849\n",
      "Testing r2_score of KNeighborsRegressor() is  0.7016354149565169\n",
      "Training r2_score of KNeighborsRegressor() is  0.8373395436203479\n",
      "Testing r2_score of KNeighborsRegressor() is  0.8210339295412961\n",
      "Training r2_score of KNeighborsRegressor() is  0.8197278302752115\n",
      "Testing r2_score of KNeighborsRegressor() is  0.7586545564905504\n",
      "Training r2_score of KNeighborsRegressor() is  0.8387369544307653\n",
      "Testing r2_score of KNeighborsRegressor() is  0.8264163345712671\n",
      "Training r2_score of KNeighborsRegressor() is  0.8306813802997861\n",
      "Testing r2_score of KNeighborsRegressor() is  0.8202810963694953\n",
      "Training r2_score of KNeighborsRegressor() is  0.8246280144570297\n",
      "Testing r2_score of KNeighborsRegressor() is  0.6974527275445316\n",
      "Training r2_score of KNeighborsRegressor() is  0.8425339101420084\n",
      "Testing r2_score of KNeighborsRegressor() is  0.6413526392168227\n",
      "Training r2_score of KNeighborsRegressor() is  0.8593170161130433\n",
      "Testing r2_score of KNeighborsRegressor() is  0.7723420968104874\n",
      "Training r2_score of KNeighborsRegressor() is  0.846921023812249\n",
      "Testing r2_score of KNeighborsRegressor() is  0.8146528360911391\n",
      "Training r2_score of KNeighborsRegressor() is  0.830781066317918\n",
      "Testing r2_score of KNeighborsRegressor() is  0.781626527080632\n",
      "Training r2_score of KNeighborsRegressor() is  0.835034783630847\n",
      "Testing r2_score of KNeighborsRegressor() is  0.7698397542834194\n",
      "Training r2_score of KNeighborsRegressor() is  0.8381128753366895\n",
      "Testing r2_score of KNeighborsRegressor() is  0.7070673595347086\n",
      "Training r2_score of KNeighborsRegressor() is  0.8508009617498461\n",
      "Testing r2_score of KNeighborsRegressor() is  0.8028784617470697\n",
      "Training r2_score of KNeighborsRegressor() is  0.8161415796124769\n",
      "Testing r2_score of KNeighborsRegressor() is  0.6781198343812562\n",
      "Training r2_score of KNeighborsRegressor() is  0.8505567357030538\n",
      "Testing r2_score of KNeighborsRegressor() is  0.7677273069220196\n",
      "Training r2_score of KNeighborsRegressor() is  0.8368880107180138\n",
      "Testing r2_score of KNeighborsRegressor() is  0.7633201673012657\n",
      "Training r2_score of KNeighborsRegressor() is  0.8418675129834028\n",
      "Testing r2_score of KNeighborsRegressor() is  0.6721152020914269\n",
      "Training r2_score of KNeighborsRegressor() is  0.8438255196042161\n",
      "Testing r2_score of KNeighborsRegressor() is  0.6988910095535542\n",
      "Training r2_score of KNeighborsRegressor() is  0.8466436187054672\n",
      "Testing r2_score of KNeighborsRegressor() is  0.7652228629026896\n",
      "Training r2_score of KNeighborsRegressor() is  0.8274127584931517\n",
      "Testing r2_score of KNeighborsRegressor() is  0.6964527368215581\n",
      "Training r2_score of KNeighborsRegressor() is  0.8337046721031509\n",
      "Testing r2_score of KNeighborsRegressor() is  0.7000910933841602\n",
      "Training r2_score of KNeighborsRegressor() is  0.8321550629472088\n",
      "Testing r2_score of KNeighborsRegressor() is  0.7077661445962494\n",
      "Training r2_score of KNeighborsRegressor() is  0.845055733905836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of KNeighborsRegressor() is  0.7447075944156745\n",
      "Training r2_score of KNeighborsRegressor() is  0.8374507943124603\n",
      "Testing r2_score of KNeighborsRegressor() is  0.7542811326968355\n",
      "Training r2_score of KNeighborsRegressor() is  0.8394463990484244\n",
      "Testing r2_score of KNeighborsRegressor() is  0.7507014458605412\n",
      "Training r2_score of KNeighborsRegressor() is  0.8372662996773144\n",
      "Testing r2_score of KNeighborsRegressor() is  0.8327314769529588\n",
      "Training r2_score of KNeighborsRegressor() is  0.8334249202095246\n",
      "Testing r2_score of KNeighborsRegressor() is  0.5964406987555158\n",
      "Training r2_score of KNeighborsRegressor() is  0.8520887290964638\n",
      "Testing r2_score of KNeighborsRegressor() is  0.770009223971084\n",
      "Training r2_score of KNeighborsRegressor() is  0.8488229167022658\n",
      "Testing r2_score of KNeighborsRegressor() is  0.807145219694532\n",
      "Training r2_score of KNeighborsRegressor() is  0.8359133519259015\n",
      "Testing r2_score of KNeighborsRegressor() is  0.7171910818898803\n",
      "Training r2_score of KNeighborsRegressor() is  0.8389291007264954\n",
      "Testing r2_score of KNeighborsRegressor() is  0.7885574467757731\n",
      "Training r2_score of KNeighborsRegressor() is  0.8386679776168117\n",
      "Testing r2_score of KNeighborsRegressor() is  0.7329712372641448\n",
      "Training r2_score of KNeighborsRegressor() is  0.8369098107461583\n",
      "Testing r2_score of KNeighborsRegressor() is  0.7467967991049229\n",
      "Training r2_score of KNeighborsRegressor() is  0.8445571964352776\n",
      "Testing r2_score of KNeighborsRegressor() is  0.8179801427098228\n",
      "Training r2_score of KNeighborsRegressor() is  0.8183388241490883\n",
      "Testing r2_score of KNeighborsRegressor() is  0.7321638895154523\n",
      "Training r2_score of KNeighborsRegressor() is  0.8367386488963763\n",
      "Testing r2_score of KNeighborsRegressor() is  0.6716467630446135\n",
      "Training r2_score of KNeighborsRegressor() is  0.843089362817137\n",
      "Testing r2_score of KNeighborsRegressor() is  0.7903778400679639\n",
      "Training r2_score of KNeighborsRegressor() is  0.8242994147065584\n",
      "Testing r2_score of KNeighborsRegressor() is  0.7181311113936948\n",
      "Training r2_score of KNeighborsRegressor() is  0.8512241477510382\n",
      "Testing r2_score of SGDRegressor() is  0.8821794414001971\n",
      "Training r2_score of SGDRegressor() is  0.9368224388625606\n",
      "Testing r2_score of SGDRegressor() is  0.9104795445663284\n",
      "Training r2_score of SGDRegressor() is  0.9374649038979909\n",
      "Testing r2_score of SGDRegressor() is  0.8807382412973325\n",
      "Training r2_score of SGDRegressor() is  0.9452438539637424\n",
      "Testing r2_score of SGDRegressor() is  0.9068204663859678\n",
      "Training r2_score of SGDRegressor() is  0.9388208822696541\n",
      "Testing r2_score of SGDRegressor() is  0.935397569643038\n",
      "Training r2_score of SGDRegressor() is  0.9293021151876213\n",
      "Testing r2_score of SGDRegressor() is  0.8994487846548253\n",
      "Training r2_score of SGDRegressor() is  0.9388322841397011\n",
      "Testing r2_score of SGDRegressor() is  0.9164062208035922\n",
      "Training r2_score of SGDRegressor() is  0.9352434506376284\n",
      "Testing r2_score of SGDRegressor() is  0.9126228421124946\n",
      "Training r2_score of SGDRegressor() is  0.941786969530853\n",
      "Testing r2_score of SGDRegressor() is  0.8709440043546325\n",
      "Training r2_score of SGDRegressor() is  0.9377619341609053\n",
      "Testing r2_score of SGDRegressor() is  0.8935668314330595\n",
      "Training r2_score of SGDRegressor() is  0.9380738342388708\n",
      "Testing r2_score of SGDRegressor() is  0.9134105173126058\n",
      "Training r2_score of SGDRegressor() is  0.9421006589562709\n",
      "Testing r2_score of SGDRegressor() is  0.8881971426535478\n",
      "Training r2_score of SGDRegressor() is  0.9425301853265241\n",
      "Testing r2_score of SGDRegressor() is  0.8397770764514245\n",
      "Training r2_score of SGDRegressor() is  0.9426027512867965\n",
      "Testing r2_score of SGDRegressor() is  0.898929598086908\n",
      "Training r2_score of SGDRegressor() is  0.9441689052615192\n",
      "Testing r2_score of SGDRegressor() is  0.8837554795112079\n",
      "Training r2_score of SGDRegressor() is  0.9448206367481707\n",
      "Testing r2_score of SGDRegressor() is  0.9040807237069227\n",
      "Training r2_score of SGDRegressor() is  0.9333287464869678\n",
      "Testing r2_score of SGDRegressor() is  0.9007098737707514\n",
      "Training r2_score of SGDRegressor() is  0.9462889972853741\n",
      "Testing r2_score of SGDRegressor() is  0.9058446174263849\n",
      "Training r2_score of SGDRegressor() is  0.9331200145399994\n",
      "Testing r2_score of SGDRegressor() is  0.8859935777282588\n",
      "Training r2_score of SGDRegressor() is  0.9310593318584311\n",
      "Testing r2_score of SGDRegressor() is  0.9097635934467438\n",
      "Training r2_score of SGDRegressor() is  0.9306082752094231\n",
      "Testing r2_score of SGDRegressor() is  0.9050031493146014\n",
      "Training r2_score of SGDRegressor() is  0.9328166548348058\n",
      "Testing r2_score of SGDRegressor() is  0.8833172174920901\n",
      "Training r2_score of SGDRegressor() is  0.9374530434827993\n",
      "Testing r2_score of SGDRegressor() is  0.8978133640731667\n",
      "Training r2_score of SGDRegressor() is  0.9345300361776698\n",
      "Testing r2_score of SGDRegressor() is  0.8873367916769308\n",
      "Training r2_score of SGDRegressor() is  0.9410804469624049\n",
      "Testing r2_score of SGDRegressor() is  0.9156806996596409\n",
      "Training r2_score of SGDRegressor() is  0.9291132882288294\n",
      "Testing r2_score of SGDRegressor() is  0.8971197557279657\n",
      "Training r2_score of SGDRegressor() is  0.9401385796748114\n",
      "Testing r2_score of SGDRegressor() is  0.8928590653701727\n",
      "Training r2_score of SGDRegressor() is  0.9400777982270482\n",
      "Testing r2_score of SGDRegressor() is  0.9210148522323327\n",
      "Training r2_score of SGDRegressor() is  0.9303962749055644\n",
      "Testing r2_score of SGDRegressor() is  0.8400436377556686\n",
      "Training r2_score of SGDRegressor() is  0.9387585751130846\n",
      "Testing r2_score of SGDRegressor() is  0.8799641910372689\n",
      "Training r2_score of SGDRegressor() is  0.9321947060446558\n",
      "Testing r2_score of SGDRegressor() is  0.8927421159301953\n",
      "Training r2_score of SGDRegressor() is  0.9376504694771446\n",
      "Testing r2_score of SGDRegressor() is  0.9064836908526309\n",
      "Training r2_score of SGDRegressor() is  0.9341813141130448\n",
      "Testing r2_score of SGDRegressor() is  0.8832335520389148\n",
      "Training r2_score of SGDRegressor() is  0.9440230202730396\n",
      "Testing r2_score of SGDRegressor() is  0.9099401221589475\n",
      "Training r2_score of SGDRegressor() is  0.9322190864977513\n",
      "Testing r2_score of SGDRegressor() is  0.9009294928392463\n",
      "Training r2_score of SGDRegressor() is  0.9363212434184011\n",
      "Testing r2_score of SGDRegressor() is  0.8857698388158419\n",
      "Training r2_score of SGDRegressor() is  0.9450722179861697\n",
      "Testing r2_score of SGDRegressor() is  0.9122941559495219\n",
      "Training r2_score of SGDRegressor() is  0.9338905817878815\n",
      "Testing r2_score of SGDRegressor() is  0.8376766803953319\n",
      "Training r2_score of SGDRegressor() is  0.9425210075298929\n",
      "Testing r2_score of SGDRegressor() is  0.883220654306707\n",
      "Training r2_score of SGDRegressor() is  0.9422623630959345\n",
      "Testing r2_score of SGDRegressor() is  0.8923748042671003\n",
      "Training r2_score of SGDRegressor() is  0.9431545941990308\n",
      "Testing r2_score of SGDRegressor() is  0.8532472016052342\n",
      "Training r2_score of SGDRegressor() is  0.9450998106526252\n",
      "Testing r2_score of SGDRegressor() is  0.9010800372936338\n",
      "Training r2_score of SGDRegressor() is  0.9373832230821002\n",
      "Testing r2_score of SGDRegressor() is  0.9035041033455543\n",
      "Training r2_score of SGDRegressor() is  0.9338819085854682\n",
      "Testing r2_score of SGDRegressor() is  0.895837162124309\n",
      "Training r2_score of SGDRegressor() is  0.9401249678599212\n",
      "Testing r2_score of SGDRegressor() is  0.9236205373790701\n",
      "Training r2_score of SGDRegressor() is  0.9355528623529225\n",
      "Testing r2_score of SGDRegressor() is  0.88499732246708\n",
      "Training r2_score of SGDRegressor() is  0.920262870692092\n",
      "Testing r2_score of SGDRegressor() is  0.9202323997920714\n",
      "Training r2_score of SGDRegressor() is  0.9325597256814891\n",
      "Testing r2_score of SGDRegressor() is  0.9185593139339748\n",
      "Training r2_score of SGDRegressor() is  0.9297158389403876\n",
      "Testing r2_score of SGDRegressor() is  0.8892410441790402\n",
      "Training r2_score of SGDRegressor() is  0.9351372099761519\n",
      "Testing r2_score of SGDRegressor() is  0.8734672603404753\n",
      "Training r2_score of SGDRegressor() is  0.9402911923474977\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.7659040646857961\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.750915882567166\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.7711725435198371\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of DecisionTreeRegressor() is  0.7844827908801184\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.7684372552024681\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.7719535105623094\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.6295635260270445\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.7326735466687969\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.6954797321891725\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.6715896787129634\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.765870741320323\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.7917757918458914\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.6585169088592489\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.6292396447952056\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.7941250892550953\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.8098933247939875\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.4955730256125528\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.6872897400021822\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.7010031726485491\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.7179477443140276\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.6877182073067027\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.7127436594905008\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.8041156733615856\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.83161366714345\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.7685247772996596\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.6280423581028107\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.8175435153359706\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.7177361962497284\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.760062899352773\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.6853502710068053\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.5175603496904446\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.7466402848475153\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.7475455236986517\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.6675603628092259\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.7092496689286365\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.581298594271297\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.569153045101302\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.6531419094258819\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.5826151226903518\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.7583311396446697\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.6536544084865274\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.7198541964023035\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.6941163445925783\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.7057540404874092\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.5554606004889304\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.7550509372838192\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.7789570908521094\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.7602275015280431\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.6515068714762202\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.7418625143583821\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of ElasticNet() is  0.7155847568950019\n",
      "Training r2_score of ElasticNet() is  0.7393754313530039\n",
      "Testing r2_score of ElasticNet() is  0.7268866275669891\n",
      "Training r2_score of ElasticNet() is  0.7217931874538188\n",
      "Testing r2_score of ElasticNet() is  0.7311471201766147\n",
      "Training r2_score of ElasticNet() is  0.7315020917626294\n",
      "Testing r2_score of ElasticNet() is  0.7345509004533719\n",
      "Training r2_score of ElasticNet() is  0.7343161243916847\n",
      "Testing r2_score of ElasticNet() is  0.7535912556999518\n",
      "Training r2_score of ElasticNet() is  0.7288098056925958\n",
      "Testing r2_score of ElasticNet() is  0.7239960751239927\n",
      "Training r2_score of ElasticNet() is  0.7445786884078256\n",
      "Testing r2_score of ElasticNet() is  0.6582020982787142\n",
      "Training r2_score of ElasticNet() is  0.7496256196430544\n",
      "Testing r2_score of ElasticNet() is  0.65651372488071\n",
      "Training r2_score of ElasticNet() is  0.7394480427059551\n",
      "Testing r2_score of ElasticNet() is  0.7312058349429367\n",
      "Training r2_score of ElasticNet() is  0.7328117456055139\n",
      "Testing r2_score of ElasticNet() is  0.744567562041188\n",
      "Training r2_score of ElasticNet() is  0.7339261115714633\n",
      "Testing r2_score of ElasticNet() is  0.6777278995026683\n",
      "Training r2_score of ElasticNet() is  0.7438392679994024\n",
      "Testing r2_score of ElasticNet() is  0.6715147824995746\n",
      "Training r2_score of ElasticNet() is  0.7435120317269319\n",
      "Testing r2_score of ElasticNet() is  0.7259102567702351\n",
      "Training r2_score of ElasticNet() is  0.7238991388193668\n",
      "Testing r2_score of ElasticNet() is  0.763153630940699\n",
      "Training r2_score of ElasticNet() is  0.7288892594161996\n",
      "Testing r2_score of ElasticNet() is  0.7248044562615117\n",
      "Training r2_score of ElasticNet() is  0.7365998920219232\n",
      "Testing r2_score of ElasticNet() is  0.7029860623379931\n",
      "Training r2_score of ElasticNet() is  0.7287703657629563\n",
      "Testing r2_score of ElasticNet() is  0.70309096884121\n",
      "Training r2_score of ElasticNet() is  0.7369493754864613\n",
      "Testing r2_score of ElasticNet() is  0.6859094885547604\n",
      "Training r2_score of ElasticNet() is  0.7500744691176846\n",
      "Testing r2_score of ElasticNet() is  0.7282240188471978\n",
      "Training r2_score of ElasticNet() is  0.724206430902192\n",
      "Testing r2_score of ElasticNet() is  0.6918970433456579\n",
      "Training r2_score of ElasticNet() is  0.7248759024637271\n",
      "Testing r2_score of ElasticNet() is  0.6898438780956002\n",
      "Training r2_score of ElasticNet() is  0.7469412135200706\n",
      "Testing r2_score of ElasticNet() is  0.7160980562683645\n",
      "Training r2_score of ElasticNet() is  0.7334800709181446\n",
      "Testing r2_score of ElasticNet() is  0.6767299852819781\n",
      "Training r2_score of ElasticNet() is  0.7311774528148551\n",
      "Testing r2_score of ElasticNet() is  0.7489922774565796\n",
      "Training r2_score of ElasticNet() is  0.7246477547166863\n",
      "Testing r2_score of ElasticNet() is  0.6902313691103783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training r2_score of ElasticNet() is  0.7325851767620919\n",
      "Testing r2_score of ElasticNet() is  0.7238365006091736\n",
      "Training r2_score of ElasticNet() is  0.7309486918707722\n",
      "Testing r2_score of ElasticNet() is  0.6329815268411652\n",
      "Training r2_score of ElasticNet() is  0.75947399706109\n",
      "Testing r2_score of ElasticNet() is  0.7445514083744595\n",
      "Training r2_score of ElasticNet() is  0.7323923576340672\n",
      "Testing r2_score of ElasticNet() is  0.7163750884545297\n",
      "Training r2_score of ElasticNet() is  0.7354474499469107\n",
      "Testing r2_score of ElasticNet() is  0.7297279779106778\n",
      "Training r2_score of ElasticNet() is  0.7463548824057946\n",
      "Testing r2_score of ElasticNet() is  0.6979821083002687\n",
      "Training r2_score of ElasticNet() is  0.740876265748395\n",
      "Testing r2_score of ElasticNet() is  0.733566187243116\n",
      "Training r2_score of ElasticNet() is  0.7305040419987517\n",
      "Testing r2_score of ElasticNet() is  0.7012185084078773\n",
      "Training r2_score of ElasticNet() is  0.7310151738346424\n",
      "Testing r2_score of ElasticNet() is  0.7091416697789834\n",
      "Training r2_score of ElasticNet() is  0.7305681301882636\n",
      "Testing r2_score of ElasticNet() is  0.7430856986720007\n",
      "Training r2_score of ElasticNet() is  0.7317252719348648\n",
      "Testing r2_score of ElasticNet() is  0.733522483359726\n",
      "Training r2_score of ElasticNet() is  0.736415315095829\n",
      "Testing r2_score of ElasticNet() is  0.7403674914108032\n",
      "Training r2_score of ElasticNet() is  0.7401757824219952\n",
      "Testing r2_score of ElasticNet() is  0.7545012130424028\n",
      "Training r2_score of ElasticNet() is  0.7188312883912376\n",
      "Testing r2_score of ElasticNet() is  0.6361835851160011\n",
      "Training r2_score of ElasticNet() is  0.7498509419138104\n",
      "Testing r2_score of ElasticNet() is  0.6967479583898095\n",
      "Training r2_score of ElasticNet() is  0.7489873206875817\n",
      "Testing r2_score of ElasticNet() is  0.7329531718418105\n",
      "Training r2_score of ElasticNet() is  0.7330738187096235\n",
      "Testing r2_score of ElasticNet() is  0.713684957585795\n",
      "Training r2_score of ElasticNet() is  0.7283588219924548\n",
      "Testing r2_score of ElasticNet() is  0.7733999635919844\n",
      "Training r2_score of ElasticNet() is  0.7254792765112119\n",
      "Testing r2_score of ElasticNet() is  0.7655714864316671\n",
      "Training r2_score of ElasticNet() is  0.7371620802365625\n",
      "Testing r2_score of ElasticNet() is  0.767010021109109\n",
      "Training r2_score of ElasticNet() is  0.7294552394219065\n",
      "Testing r2_score of ElasticNet() is  0.7211938938683771\n",
      "Training r2_score of ElasticNet() is  0.7385753491574989\n",
      "Testing r2_score of ElasticNet() is  0.7411947030477053\n",
      "Training r2_score of ElasticNet() is  0.7276616295716853\n",
      "Testing r2_score of ElasticNet() is  0.6599895785783134\n",
      "Training r2_score of ElasticNet() is  0.7429216535939488\n",
      "Testing r2_score of ElasticNet() is  0.7679239538584468\n",
      "Training r2_score of ElasticNet() is  0.7355351408861039\n",
      "Testing r2_score of ElasticNet() is  0.7359017203946623\n",
      "Training r2_score of ElasticNet() is  0.7315420974648309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.764e+09, tolerance: 1.830e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.818e+09, tolerance: 1.824e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.8427755826419702\n",
      "Training r2_score of Lasso() is  0.9659882458776151\n",
      "Testing r2_score of Lasso() is  0.8898116843882443\n",
      "Training r2_score of Lasso() is  0.9619732815339512\n",
      "Testing r2_score of Lasso() is  0.8530411838692963\n",
      "Training r2_score of Lasso() is  0.9673058050185204\n",
      "Testing r2_score of Lasso() is  0.9185343762594038\n",
      "Training r2_score of Lasso() is  0.9587071686349302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.130e+09, tolerance: 1.825e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.185e+09, tolerance: 1.861e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.065e+10, tolerance: 1.863e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.9061574291606821\n",
      "Training r2_score of Lasso() is  0.9597370803171579\n",
      "Testing r2_score of Lasso() is  0.8908520260484948\n",
      "Training r2_score of Lasso() is  0.9627454145486622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.011e+09, tolerance: 1.766e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.627e+09, tolerance: 1.789e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.8937109735422619\n",
      "Training r2_score of Lasso() is  0.9602994713529839\n",
      "Testing r2_score of Lasso() is  0.9028192621094304\n",
      "Training r2_score of Lasso() is  0.9658042306394841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.716e+09, tolerance: 1.734e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.483e+09, tolerance: 1.795e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.957e+09, tolerance: 1.837e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.8866677200635118\n",
      "Training r2_score of Lasso() is  0.9618487466640274\n",
      "Testing r2_score of Lasso() is  0.8864899789134288\n",
      "Training r2_score of Lasso() is  0.9577262003679994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.824e+09, tolerance: 1.896e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.096e+10, tolerance: 1.827e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.8984100577298711\n",
      "Training r2_score of Lasso() is  0.9628142907958122\n",
      "Testing r2_score of Lasso() is  0.8948289777006438\n",
      "Training r2_score of Lasso() is  0.9617957725511395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.156e+09, tolerance: 1.862e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.233e+08, tolerance: 1.932e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.8493567689846742\n",
      "Training r2_score of Lasso() is  0.9608356568841045\n",
      "Testing r2_score of Lasso() is  0.8803472425651304\n",
      "Training r2_score of Lasso() is  0.9618440823850759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.877e+09, tolerance: 1.855e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.906e+09, tolerance: 1.797e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.902689986146442\n",
      "Training r2_score of Lasso() is  0.9582689437733855\n",
      "Testing r2_score of Lasso() is  0.9246241541359049\n",
      "Training r2_score of Lasso() is  0.957633331525011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.965e+09, tolerance: 1.775e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.174e+08, tolerance: 1.754e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.8927420299756414\n",
      "Training r2_score of Lasso() is  0.9636861879550968\n",
      "Testing r2_score of Lasso() is  0.8485444081746655\n",
      "Training r2_score of Lasso() is  0.9659855450962106\n",
      "Testing r2_score of Lasso() is  0.9172497184419761\n",
      "Training r2_score of Lasso() is  0.9581019851834387\n",
      "Testing r2_score of Lasso() is  0.8461374240852684\n",
      "Training r2_score of Lasso() is  0.9638616599827932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.093e+09, tolerance: 1.924e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.833e+09, tolerance: 1.851e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.8926640365228993\n",
      "Training r2_score of Lasso() is  0.9596844905700137\n",
      "Testing r2_score of Lasso() is  0.9120682379224699\n",
      "Training r2_score of Lasso() is  0.9582202329372692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.433e+09, tolerance: 1.907e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.398e+09, tolerance: 1.848e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.8921917589000227\n",
      "Training r2_score of Lasso() is  0.9607188797843799\n",
      "Testing r2_score of Lasso() is  0.8956328423964893\n",
      "Training r2_score of Lasso() is  0.9577314857957251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.668e+09, tolerance: 1.955e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.931e+09, tolerance: 1.881e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.8728329136088533\n",
      "Training r2_score of Lasso() is  0.9609446987717732\n",
      "Testing r2_score of Lasso() is  0.9062658511283405\n",
      "Training r2_score of Lasso() is  0.9590449987819974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.989e+09, tolerance: 1.886e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.982e+09, tolerance: 1.883e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.8583400019047065\n",
      "Training r2_score of Lasso() is  0.9653627132889417\n",
      "Testing r2_score of Lasso() is  0.9088204329943688\n",
      "Training r2_score of Lasso() is  0.9598506156148265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.670e+09, tolerance: 1.970e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.569e+09, tolerance: 1.833e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.8648888909083876\n",
      "Training r2_score of Lasso() is  0.9624360209181642\n",
      "Testing r2_score of Lasso() is  0.8869063478300411\n",
      "Training r2_score of Lasso() is  0.9611862932262051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.901e+09, tolerance: 1.885e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.079e+09, tolerance: 1.950e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.8385088429281369\n",
      "Training r2_score of Lasso() is  0.9660040035578457\n",
      "Testing r2_score of Lasso() is  0.9020186302401656\n",
      "Training r2_score of Lasso() is  0.9610651513618356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.003e+09, tolerance: 1.786e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.654e+09, tolerance: 1.840e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.9086299263359159\n",
      "Training r2_score of Lasso() is  0.9589851842188393\n",
      "Testing r2_score of Lasso() is  0.9081493332873559\n",
      "Training r2_score of Lasso() is  0.9608871252877149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.189e+09, tolerance: 1.922e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.997e+09, tolerance: 1.829e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.8551409282259943\n",
      "Training r2_score of Lasso() is  0.9647854185955964\n",
      "Testing r2_score of Lasso() is  0.8998331146845915\n",
      "Training r2_score of Lasso() is  0.9612740086594931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.836e+09, tolerance: 1.897e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.061e+10, tolerance: 1.841e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.8683606172430927\n",
      "Training r2_score of Lasso() is  0.9633403940756888\n",
      "Testing r2_score of Lasso() is  0.868827293585282\n",
      "Training r2_score of Lasso() is  0.9648172639466909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.451e+09, tolerance: 1.777e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.603e+09, tolerance: 1.804e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.9142991096790243\n",
      "Training r2_score of Lasso() is  0.9568587871745444\n",
      "Testing r2_score of Lasso() is  0.8997901089416089\n",
      "Training r2_score of Lasso() is  0.9651011524201218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.103e+10, tolerance: 1.863e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.422e+09, tolerance: 1.819e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.9004257019339483\n",
      "Training r2_score of Lasso() is  0.9591754401473424\n",
      "Testing r2_score of Lasso() is  0.9049200882402483\n",
      "Training r2_score of Lasso() is  0.9594190221610334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.335e+09, tolerance: 1.790e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.336e+09, tolerance: 1.847e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.8849186427371101\n",
      "Training r2_score of Lasso() is  0.9631496542453886\n",
      "Testing r2_score of Lasso() is  0.9065669842965194\n",
      "Training r2_score of Lasso() is  0.9613809525433268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.874e+09, tolerance: 1.869e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.561e+08, tolerance: 1.807e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.926e+09, tolerance: 1.883e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.8666500063153949\n",
      "Training r2_score of Lasso() is  0.9655817581999081\n",
      "Testing r2_score of Lasso() is  0.9002485732498972\n",
      "Training r2_score of Lasso() is  0.9615887406862469\n",
      "Testing r2_score of Lasso() is  0.8715571300351856\n",
      "Training r2_score of Lasso() is  0.964793469793384\n",
      "Testing r2_score of Lasso() is  0.8738546467000228\n",
      "Training r2_score of Lasso() is  0.9644861486066846\n",
      "Testing r2_score of Lasso() is  0.8959552306056547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.580e+09, tolerance: 1.771e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.510e+10, tolerance: 1.860e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.534e+09, tolerance: 1.765e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training r2_score of Lasso() is  0.961603825103987\n",
      "Testing r2_score of Lasso() is  0.8877314605484592\n",
      "Training r2_score of Lasso() is  0.9640596628493256\n",
      "Testing r2_score of Ridge() is  0.8978743010589605\n",
      "Training r2_score of Ridge() is  0.9567744288590871\n",
      "Testing r2_score of Ridge() is  0.9165617248613641\n",
      "Training r2_score of Ridge() is  0.9534284792709963\n",
      "Testing r2_score of Ridge() is  0.8925083173894102\n",
      "Training r2_score of Ridge() is  0.9551257862955846\n",
      "Testing r2_score of Ridge() is  0.886725574199873\n",
      "Training r2_score of Ridge() is  0.9600312590022109\n",
      "Testing r2_score of Ridge() is  0.8924682761581537\n",
      "Training r2_score of Ridge() is  0.9590796801726158\n",
      "Testing r2_score of Ridge() is  0.8861689403970496\n",
      "Training r2_score of Ridge() is  0.9595273924285311\n",
      "Testing r2_score of Ridge() is  0.8954364548265736\n",
      "Training r2_score of Ridge() is  0.9540611903407784\n",
      "Testing r2_score of Ridge() is  0.9037122345158695\n",
      "Training r2_score of Ridge() is  0.954025511100891\n",
      "Testing r2_score of Ridge() is  0.8861918664612678\n",
      "Training r2_score of Ridge() is  0.9581801344947766\n",
      "Testing r2_score of Ridge() is  0.8885592116824749\n",
      "Training r2_score of Ridge() is  0.9560256317744259\n",
      "Testing r2_score of Ridge() is  0.9373400283708938\n",
      "Training r2_score of Ridge() is  0.9499013059485987\n",
      "Testing r2_score of Ridge() is  0.8901203285966723\n",
      "Training r2_score of Ridge() is  0.9583109200768062\n",
      "Testing r2_score of Ridge() is  0.8580314858526152\n",
      "Training r2_score of Ridge() is  0.9632670717647638\n",
      "Testing r2_score of Ridge() is  0.9060933408735451\n",
      "Training r2_score of Ridge() is  0.9562430977711219\n",
      "Testing r2_score of Ridge() is  0.8945706206137987\n",
      "Training r2_score of Ridge() is  0.9573363225834685\n",
      "Testing r2_score of Ridge() is  0.9051924448126486\n",
      "Training r2_score of Ridge() is  0.9536276534347763\n",
      "Testing r2_score of Ridge() is  0.9181519175645196\n",
      "Training r2_score of Ridge() is  0.9527043205410832\n",
      "Testing r2_score of Ridge() is  0.9239342934645802\n",
      "Training r2_score of Ridge() is  0.952687263311244\n",
      "Testing r2_score of Ridge() is  0.9077831607406075\n",
      "Training r2_score of Ridge() is  0.9544688411630401\n",
      "Testing r2_score of Ridge() is  0.9167104542194628\n",
      "Training r2_score of Ridge() is  0.9530680756862223\n",
      "Testing r2_score of Ridge() is  0.8900910007673116\n",
      "Training r2_score of Ridge() is  0.9599786158831968\n",
      "Testing r2_score of Ridge() is  0.9034544188629375\n",
      "Training r2_score of Ridge() is  0.9564910330103156\n",
      "Testing r2_score of Ridge() is  0.8884331415437534\n",
      "Training r2_score of Ridge() is  0.9583589145653202\n",
      "Testing r2_score of Ridge() is  0.9108337963690013\n",
      "Training r2_score of Ridge() is  0.9562931935095167\n",
      "Testing r2_score of Ridge() is  0.9476369041296083\n",
      "Training r2_score of Ridge() is  0.9495156906357282\n",
      "Testing r2_score of Ridge() is  0.9418228245201851\n",
      "Training r2_score of Ridge() is  0.9512833755357989\n",
      "Testing r2_score of Ridge() is  0.9016527136914363\n",
      "Training r2_score of Ridge() is  0.9530527813036761\n",
      "Testing r2_score of Ridge() is  0.8989191003133977\n",
      "Training r2_score of Ridge() is  0.9595559543110826\n",
      "Testing r2_score of Ridge() is  0.8962884857655997\n",
      "Training r2_score of Ridge() is  0.9572237418239482\n",
      "Testing r2_score of Ridge() is  0.922936938000996\n",
      "Training r2_score of Ridge() is  0.954029920874449\n",
      "Testing r2_score of Ridge() is  0.9018514226531129\n",
      "Training r2_score of Ridge() is  0.9563931302984723\n",
      "Testing r2_score of Ridge() is  0.9297496127596441\n",
      "Training r2_score of Ridge() is  0.9526013100733844\n",
      "Testing r2_score of Ridge() is  0.9138808198144179\n",
      "Training r2_score of Ridge() is  0.9558112767705662\n",
      "Testing r2_score of Ridge() is  0.9081299830072057\n",
      "Training r2_score of Ridge() is  0.9550763841734796\n",
      "Testing r2_score of Ridge() is  0.918743255925284\n",
      "Training r2_score of Ridge() is  0.9541120438655378\n",
      "Testing r2_score of Ridge() is  0.9188446478427716\n",
      "Training r2_score of Ridge() is  0.953837362051433\n",
      "Testing r2_score of Ridge() is  0.916707853690897\n",
      "Training r2_score of Ridge() is  0.952797814077774\n",
      "Testing r2_score of Ridge() is  0.8912265951668763\n",
      "Training r2_score of Ridge() is  0.9576185558609475\n",
      "Testing r2_score of Ridge() is  0.8964195895450878\n",
      "Training r2_score of Ridge() is  0.9585896890431119\n",
      "Testing r2_score of Ridge() is  0.8761415605011099\n",
      "Training r2_score of Ridge() is  0.9599388489420708\n",
      "Testing r2_score of Ridge() is  0.9277009403302214\n",
      "Training r2_score of Ridge() is  0.9516668351514689\n",
      "Testing r2_score of Ridge() is  0.9054097015673318\n",
      "Training r2_score of Ridge() is  0.9565353060314373\n",
      "Testing r2_score of Ridge() is  0.9223241269932918\n",
      "Training r2_score of Ridge() is  0.952966091411864\n",
      "Testing r2_score of Ridge() is  0.9188622457954478\n",
      "Training r2_score of Ridge() is  0.9520765553796547\n",
      "Testing r2_score of Ridge() is  0.8943733533419714\n",
      "Training r2_score of Ridge() is  0.9563944953063304\n",
      "Testing r2_score of Ridge() is  0.9024285278343515\n",
      "Training r2_score of Ridge() is  0.9568040324155955\n",
      "Testing r2_score of Ridge() is  0.8869331687621703\n",
      "Training r2_score of Ridge() is  0.9616044670748698\n",
      "Testing r2_score of Ridge() is  0.9274520524183515\n",
      "Training r2_score of Ridge() is  0.9524409081092426\n",
      "Testing r2_score of Ridge() is  0.9070258226568714\n",
      "Training r2_score of Ridge() is  0.9569750218913965\n",
      "Testing r2_score of Ridge() is  0.9299181216450048\n",
      "Training r2_score of Ridge() is  0.9531074666701419\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(50):\n",
    "    algo_testing(algo=\"RandomForestRegressor()\",test_size=0.2,X=X,Y=Y,evaluation_metric=\"r2_score\",random_state=None,shuffle=True)\n",
    "avg_accuracies[\"RandomForestRegressor()\"]/=50\n",
    "\n",
    "for i in range(50):\n",
    "\n",
    "    algo_testing(algo=\"SVR()\",test_size=0.2,X=X,Y=Y,evaluation_metric=\"r2_score\",random_state=None,shuffle=True)\n",
    "avg_accuracies[\"SVR()\"]/=50\n",
    "\n",
    "for i in range(50):\n",
    "\n",
    "    algo_testing(algo=\"KNeighborsRegressor()\",test_size=0.2,X=X,Y=Y,evaluation_metric=\"r2_score\",random_state=None,shuffle=True)\n",
    "avg_accuracies[\"KNeighborsRegressor()\"]/=50\n",
    "\n",
    "for i in range(50):\n",
    "\n",
    "    algo_testing(algo=\"SGDRegressor()\",test_size=0.2,X=X,Y=Y,evaluation_metric=\"r2_score\",random_state=None,shuffle=True)\n",
    "avg_accuracies[\"SGDRegressor()\"]/=50\n",
    "\n",
    "for i in range(50):\n",
    "\n",
    "    algo_testing(algo=\"DecisionTreeRegressor()\",test_size=0.2,X=X,Y=Y,evaluation_metric=\"r2_score\",random_state=None,shuffle=True)\n",
    "avg_accuracies[\"DecisionTreeRegressor()\"]/=50\n",
    "\n",
    "for i in range(50):\n",
    "\n",
    "    algo_testing(algo=\"ElasticNet()\",test_size=0.2,X=X,Y=Y,evaluation_metric=\"r2_score\",random_state=None,shuffle=True)\n",
    "avg_accuracies[\"ElasticNet()\"]/=50\n",
    "\n",
    "for i in range(50):\n",
    "\n",
    "    algo_testing(algo=\"Lasso()\",test_size=0.2,X=X,Y=Y,evaluation_metric=\"r2_score\",random_state=None,shuffle=True)\n",
    "avg_accuracies[\"Lasso()\"]/=50\n",
    "\n",
    "for i in range(50):\n",
    "\n",
    "    algo_testing(algo=\"Ridge()\",test_size=0.2,X=X,Y=Y,evaluation_metric=\"r2_score\",random_state=None,shuffle=True)\n",
    "avg_accuracies[\"Ridge()\"]/=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c37b7d7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LinearRegression()': -1.0095714549029022e+21,\n",
       " 'RandomForestRegressor()': 0.8620294805144093,\n",
       " 'SVR()': -0.014845902475678636,\n",
       " 'KNeighborsRegressor()': 0.7410189642004583,\n",
       " 'SGDRegressor()': 0.8945534072220188,\n",
       " 'DecisionTreeRegressor()': 0.7071279889235405,\n",
       " 'ElasticNet()': 0.7169194597278549,\n",
       " 'Lasso()': 0.8874557733773425,\n",
       " 'Ridge()': 0.9060065540575196}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "747af2fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LinearRegression()': -2.1470695203404444e+16,\n",
       " 'RandomForestRegressor()': 0.9156020119478879,\n",
       " 'SVR()': 0.0005025116939700869,\n",
       " 'KNeighborsRegressor()': 0.8327314769529588,\n",
       " 'SGDRegressor()': 0.935397569643038,\n",
       " 'DecisionTreeRegressor()': 0.83161366714345,\n",
       " 'ElasticNet()': 0.7733999635919844,\n",
       " 'Lasso()': 0.9246241541359049,\n",
       " 'Ridge()': 0.9476369041296083}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highest_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb230526",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5117ba29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9e565b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c0f657",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a64d9c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee71221-46cd-4f6d-8a8a-09eb9b64aa2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fab150-ef23-4110-bc56-7921a694d747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc108aa7-a72f-42c8-8fbd-5d78130f8e25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
