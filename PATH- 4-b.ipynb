{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "addeba46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler,minmax_scale,StandardScaler\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression,ElasticNet,Lasso,Ridge\n",
    "from sklearn.linear_model import SGDRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "298c7238",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.read_csv(\"house_price_train.csv\")\n",
    "df_train.drop(\"Id\",axis=1,inplace=True) ## reduntatnt\n",
    "output_col=df_train['SalePrice']\n",
    "df_train=df_train.drop('SalePrice',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0a57d23f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>...</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>13175</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9042</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GdPrv</td>\n",
       "      <td>Shed</td>\n",
       "      <td>2500</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0             60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1             20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2             60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3             70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4             60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "...          ...      ...          ...      ...    ...   ...      ...   \n",
       "1455          60       RL         62.0     7917   Pave   NaN      Reg   \n",
       "1456          20       RL         85.0    13175   Pave   NaN      Reg   \n",
       "1457          70       RL         66.0     9042   Pave   NaN      Reg   \n",
       "1458          20       RL         68.0     9717   Pave   NaN      Reg   \n",
       "1459          20       RL         75.0     9937   Pave   NaN      Reg   \n",
       "\n",
       "     LandContour Utilities LotConfig  ... ScreenPorch PoolArea PoolQC  Fence  \\\n",
       "0            Lvl    AllPub    Inside  ...           0        0    NaN    NaN   \n",
       "1            Lvl    AllPub       FR2  ...           0        0    NaN    NaN   \n",
       "2            Lvl    AllPub    Inside  ...           0        0    NaN    NaN   \n",
       "3            Lvl    AllPub    Corner  ...           0        0    NaN    NaN   \n",
       "4            Lvl    AllPub       FR2  ...           0        0    NaN    NaN   \n",
       "...          ...       ...       ...  ...         ...      ...    ...    ...   \n",
       "1455         Lvl    AllPub    Inside  ...           0        0    NaN    NaN   \n",
       "1456         Lvl    AllPub    Inside  ...           0        0    NaN  MnPrv   \n",
       "1457         Lvl    AllPub    Inside  ...           0        0    NaN  GdPrv   \n",
       "1458         Lvl    AllPub    Inside  ...           0        0    NaN    NaN   \n",
       "1459         Lvl    AllPub    Inside  ...           0        0    NaN    NaN   \n",
       "\n",
       "     MiscFeature MiscVal  MoSold  YrSold  SaleType  SaleCondition  \n",
       "0            NaN       0       2    2008        WD         Normal  \n",
       "1            NaN       0       5    2007        WD         Normal  \n",
       "2            NaN       0       9    2008        WD         Normal  \n",
       "3            NaN       0       2    2006        WD        Abnorml  \n",
       "4            NaN       0      12    2008        WD         Normal  \n",
       "...          ...     ...     ...     ...       ...            ...  \n",
       "1455         NaN       0       8    2007        WD         Normal  \n",
       "1456         NaN       0       2    2010        WD         Normal  \n",
       "1457        Shed    2500       5    2010        WD         Normal  \n",
       "1458         NaN       0       4    2010        WD         Normal  \n",
       "1459         NaN       0       6    2008        WD         Normal  \n",
       "\n",
       "[1460 rows x 79 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5c0c131a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSSubClass         int64\n",
       "MSZoning          object\n",
       "LotFrontage      float64\n",
       "LotArea            int64\n",
       "Street            object\n",
       "                  ...   \n",
       "MiscVal            int64\n",
       "MoSold             int64\n",
       "YrSold             int64\n",
       "SaleType          object\n",
       "SaleCondition     object\n",
       "Length: 79, dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3c48be5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>...</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>13175</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9042</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GdPrv</td>\n",
       "      <td>Shed</td>\n",
       "      <td>2500</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0             60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1             20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2             60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3             70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4             60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "...          ...      ...          ...      ...    ...   ...      ...   \n",
       "1455          60       RL         62.0     7917   Pave   NaN      Reg   \n",
       "1456          20       RL         85.0    13175   Pave   NaN      Reg   \n",
       "1457          70       RL         66.0     9042   Pave   NaN      Reg   \n",
       "1458          20       RL         68.0     9717   Pave   NaN      Reg   \n",
       "1459          20       RL         75.0     9937   Pave   NaN      Reg   \n",
       "\n",
       "     LandContour Utilities LotConfig  ... ScreenPorch PoolArea PoolQC  Fence  \\\n",
       "0            Lvl    AllPub    Inside  ...           0        0    NaN    NaN   \n",
       "1            Lvl    AllPub       FR2  ...           0        0    NaN    NaN   \n",
       "2            Lvl    AllPub    Inside  ...           0        0    NaN    NaN   \n",
       "3            Lvl    AllPub    Corner  ...           0        0    NaN    NaN   \n",
       "4            Lvl    AllPub       FR2  ...           0        0    NaN    NaN   \n",
       "...          ...       ...       ...  ...         ...      ...    ...    ...   \n",
       "1455         Lvl    AllPub    Inside  ...           0        0    NaN    NaN   \n",
       "1456         Lvl    AllPub    Inside  ...           0        0    NaN  MnPrv   \n",
       "1457         Lvl    AllPub    Inside  ...           0        0    NaN  GdPrv   \n",
       "1458         Lvl    AllPub    Inside  ...           0        0    NaN    NaN   \n",
       "1459         Lvl    AllPub    Inside  ...           0        0    NaN    NaN   \n",
       "\n",
       "     MiscFeature MiscVal  MoSold  YrSold  SaleType  SaleCondition  \n",
       "0            NaN       0       2    2008        WD         Normal  \n",
       "1            NaN       0       5    2007        WD         Normal  \n",
       "2            NaN       0       9    2008        WD         Normal  \n",
       "3            NaN       0       2    2006        WD        Abnorml  \n",
       "4            NaN       0      12    2008        WD         Normal  \n",
       "...          ...     ...     ...     ...       ...            ...  \n",
       "1455         NaN       0       8    2007        WD         Normal  \n",
       "1456         NaN       0       2    2010        WD         Normal  \n",
       "1457        Shed    2500       5    2010        WD         Normal  \n",
       "1458         NaN       0       4    2010        WD         Normal  \n",
       "1459         NaN       0       6    2008        WD         Normal  \n",
       "\n",
       "[1460 rows x 79 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb1810d",
   "metadata": {},
   "source": [
    "## PREPROCESSING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2362e143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.columns[df_train.isnull().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c24bff98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.heatmap(df_train.isnull(),yticklabels=False,cbar=False,cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bf96993b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(30,30))\n",
    "# sns.heatmap(pd.concat([df_train,output_col],axis=1).loc[:,list(pd.concat([df_train,output_col],axis=1).select_dtypes(include= np.number).columns)].corr(method='spearman'),annot=True,cmap=\"RdYlGn\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5e1da23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(nrows = 12, ncols = 3)    # axes is 2d array (3x3)\n",
    "# axes = axes.flatten()         # Convert axes to 1d array of length 9\n",
    "# fig.set_size_inches(30,30)\n",
    "# cols=list(df_train.select_dtypes(include= np.number).columns)\n",
    "# for ax, col in zip(axes, cols):\n",
    "#     print()\n",
    "#     sns.boxplot(df_train[col], ax = ax)\n",
    "#     ax.set_title(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dbc808bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(nrows = 12, ncols = 3)    # axes is 2d array (3x3)\n",
    "# axes = axes.flatten()         # Convert axes to 1d array of length 9\n",
    "# fig.set_size_inches(30,30)\n",
    "# cols=list(df_train.select_dtypes(include= np.number).columns)\n",
    "# for ax, col in zip(axes, cols):\n",
    "#     print()\n",
    "#     sns.distplot(df_train[col], ax = ax)\n",
    "#     ax.set_title(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "24b291d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def column_with_most_reduntant_null_values(threshold,df_train:pd.DataFrame):\n",
    "    null_cols=[]\n",
    "    for col in df_train.columns:\n",
    "        if df_train[col].isnull().sum()>=(threshold*len(df_train)):\n",
    "            null_cols.append(col)\n",
    "    df_train.drop(null_cols,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6db73cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_with_most_reduntant_null_values(threshold=0.5,df_train=df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1ed65a14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>...</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>35</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>13175</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9042</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2500</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass MSZoning  LotFrontage  LotArea Street LotShape LandContour  \\\n",
       "0             60       RL         65.0     8450   Pave      Reg         Lvl   \n",
       "1             20       RL         80.0     9600   Pave      Reg         Lvl   \n",
       "2             60       RL         68.0    11250   Pave      IR1         Lvl   \n",
       "3             70       RL         60.0     9550   Pave      IR1         Lvl   \n",
       "4             60       RL         84.0    14260   Pave      IR1         Lvl   \n",
       "...          ...      ...          ...      ...    ...      ...         ...   \n",
       "1455          60       RL         62.0     7917   Pave      Reg         Lvl   \n",
       "1456          20       RL         85.0    13175   Pave      Reg         Lvl   \n",
       "1457          70       RL         66.0     9042   Pave      Reg         Lvl   \n",
       "1458          20       RL         68.0     9717   Pave      Reg         Lvl   \n",
       "1459          20       RL         75.0     9937   Pave      Reg         Lvl   \n",
       "\n",
       "     Utilities LotConfig LandSlope  ... OpenPorchSF EnclosedPorch 3SsnPorch  \\\n",
       "0       AllPub    Inside       Gtl  ...          61             0         0   \n",
       "1       AllPub       FR2       Gtl  ...           0             0         0   \n",
       "2       AllPub    Inside       Gtl  ...          42             0         0   \n",
       "3       AllPub    Corner       Gtl  ...          35           272         0   \n",
       "4       AllPub       FR2       Gtl  ...          84             0         0   \n",
       "...        ...       ...       ...  ...         ...           ...       ...   \n",
       "1455    AllPub    Inside       Gtl  ...          40             0         0   \n",
       "1456    AllPub    Inside       Gtl  ...           0             0         0   \n",
       "1457    AllPub    Inside       Gtl  ...          60             0         0   \n",
       "1458    AllPub    Inside       Gtl  ...           0           112         0   \n",
       "1459    AllPub    Inside       Gtl  ...          68             0         0   \n",
       "\n",
       "     ScreenPorch PoolArea  MiscVal  MoSold  YrSold  SaleType SaleCondition  \n",
       "0              0        0        0       2    2008        WD        Normal  \n",
       "1              0        0        0       5    2007        WD        Normal  \n",
       "2              0        0        0       9    2008        WD        Normal  \n",
       "3              0        0        0       2    2006        WD       Abnorml  \n",
       "4              0        0        0      12    2008        WD        Normal  \n",
       "...          ...      ...      ...     ...     ...       ...           ...  \n",
       "1455           0        0        0       8    2007        WD        Normal  \n",
       "1456           0        0        0       2    2010        WD        Normal  \n",
       "1457           0        0     2500       5    2010        WD        Normal  \n",
       "1458           0        0        0       4    2010        WD        Normal  \n",
       "1459           0        0        0       6    2008        WD        Normal  \n",
       "\n",
       "[1460 rows x 75 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7db7fe1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_cols=list(df_train.select_dtypes(include= np.number).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "45120957",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols=list(df_train.select_dtypes(exclude= np.number).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4308bada",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_correlated=dict()\n",
    "for col1 in continuous_cols:\n",
    "    for col2 in continuous_cols:\n",
    "        if col1!=col2 and abs(df_train[col1].corr(df_train[col2],method='spearman'))>=0.80:\n",
    "            if (col1 not in most_correlated) and (col2 not in most_correlated):\n",
    "                most_correlated[col1]=col2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5007bc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop(columns=list(most_correlated),axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f8e886ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_null_values(for_numerical_cols:str,for_categorical_cols:str,df_train):\n",
    "    for cols in df_train.columns:\n",
    "        if df_train[cols].dtype==\"int64\" or df_train[cols].dtype==\"float64\":\n",
    "            if for_numerical_cols==\"median\":\n",
    "                median_=df_train[cols].median()\n",
    "                df_train[cols].fillna(median_,inplace=True)\n",
    "        elif df_train[cols].dtype==\"object\":\n",
    "            if for_categorical_cols==\"most_frequent\":\n",
    "                d=list(df_train[cols].value_counts().index) # most frequent\n",
    "                df_train[cols].fillna(d[0],inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c650d76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_null_values(for_numerical_cols=\"median\",for_categorical_cols=\"most_frequent\",df_train=df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "13f5495b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_train.columns:\n",
    "    if df_train[col].isnull().sum()>(0):\n",
    "\n",
    "        print(col,df_train[col].isnull().sum(),df_train[col].dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fcb707f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_cols=list(df_train.select_dtypes(include= np.number).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5db0ff8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols=list(df_train.select_dtypes(exclude= np.number).columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0facfb-207b-4c0f-bba5-8b2137ef8aa4",
   "metadata": {},
   "source": [
    "Deleting Outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6087a833-21ba-4408-838e-245ddae5285c",
   "metadata": {},
   "source": [
    "Here we are deleting outliers using Inter Quartile Range Strategy. Since for a column ouliers are in a specifc row and for different columns the oulier contained rows are different and if we delete those specific row then that row in output label should also be deleted thats why we are first adding label into our features after that we will separate the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "250a9d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.concat([output_col,df_train],axis=1) # since rows will be deleted here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b2bed2cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>...</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>208500</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>181500</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>223500</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>140000</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>...</td>\n",
       "      <td>35</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>250000</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>175000</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>210000</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>13175</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>266500</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9042</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2500</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>142125</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>147500</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      SalePrice  MSSubClass MSZoning  LotFrontage  LotArea Street LotShape  \\\n",
       "0        208500          60       RL         65.0     8450   Pave      Reg   \n",
       "1        181500          20       RL         80.0     9600   Pave      Reg   \n",
       "2        223500          60       RL         68.0    11250   Pave      IR1   \n",
       "3        140000          70       RL         60.0     9550   Pave      IR1   \n",
       "4        250000          60       RL         84.0    14260   Pave      IR1   \n",
       "...         ...         ...      ...          ...      ...    ...      ...   \n",
       "1455     175000          60       RL         62.0     7917   Pave      Reg   \n",
       "1456     210000          20       RL         85.0    13175   Pave      Reg   \n",
       "1457     266500          70       RL         66.0     9042   Pave      Reg   \n",
       "1458     142125          20       RL         68.0     9717   Pave      Reg   \n",
       "1459     147500          20       RL         75.0     9937   Pave      Reg   \n",
       "\n",
       "     LandContour Utilities LotConfig  ... OpenPorchSF EnclosedPorch 3SsnPorch  \\\n",
       "0            Lvl    AllPub    Inside  ...          61             0         0   \n",
       "1            Lvl    AllPub       FR2  ...           0             0         0   \n",
       "2            Lvl    AllPub    Inside  ...          42             0         0   \n",
       "3            Lvl    AllPub    Corner  ...          35           272         0   \n",
       "4            Lvl    AllPub       FR2  ...          84             0         0   \n",
       "...          ...       ...       ...  ...         ...           ...       ...   \n",
       "1455         Lvl    AllPub    Inside  ...          40             0         0   \n",
       "1456         Lvl    AllPub    Inside  ...           0             0         0   \n",
       "1457         Lvl    AllPub    Inside  ...          60             0         0   \n",
       "1458         Lvl    AllPub    Inside  ...           0           112         0   \n",
       "1459         Lvl    AllPub    Inside  ...          68             0         0   \n",
       "\n",
       "     ScreenPorch PoolArea MiscVal  MoSold  YrSold  SaleType SaleCondition  \n",
       "0              0        0       0       2    2008        WD        Normal  \n",
       "1              0        0       0       5    2007        WD        Normal  \n",
       "2              0        0       0       9    2008        WD        Normal  \n",
       "3              0        0       0       2    2006        WD       Abnorml  \n",
       "4              0        0       0      12    2008        WD        Normal  \n",
       "...          ...      ...     ...     ...     ...       ...           ...  \n",
       "1455           0        0       0       8    2007        WD        Normal  \n",
       "1456           0        0       0       2    2010        WD        Normal  \n",
       "1457           0        0    2500       5    2010        WD        Normal  \n",
       "1458           0        0       0       4    2010        WD        Normal  \n",
       "1459           0        0       0       6    2008        WD        Normal  \n",
       "\n",
       "[1460 rows x 72 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f4870b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -55.0 , 145.0 ]\n",
      "[ 30.0 , 110.0 ]\n",
      "[ 2440.0 , 16936.0 ]\n",
      "[ 2.0 , 10.0 ]\n",
      "[ 3.5 , 7.5 ]\n",
      "[ 1909.0 , 2061.0 ]\n",
      "[ -255.75 , 426.25 ]\n",
      "[ -1060.5 , 1767.5 ]\n",
      "[ 0.0 , 0.0 ]\n",
      "[ -579.875 , 1725.125 ]\n",
      "[ 199.0 , 2037.0 ]\n",
      "[ -1092.375 , 1820.625 ]\n",
      "[ 0.0 , 0.0 ]\n",
      "[ -1.5 , 2.5 ]\n",
      "[ 0.0 , 0.0 ]\n",
      "[ -0.5 , 3.5 ]\n",
      "[ -1.5 , 2.5 ]\n",
      "[ 0.5 , 4.5 ]\n",
      "[ 1.0 , 1.0 ]\n",
      "[ 2.0 , 10.0 ]\n",
      "[ -1.5 , 2.5 ]\n",
      "[ 1903.0 , 2063.0 ]\n",
      "[ -19.0 , 933.0 ]\n",
      "[ -239.625 , 399.375 ]\n",
      "[ -97.5 , 162.5 ]\n",
      "[ 0.0 , 0.0 ]\n",
      "[ 0.0 , 0.0 ]\n",
      "[ 0.0 , 0.0 ]\n",
      "[ 0.0 , 0.0 ]\n",
      "[ 0.0 , 0.0 ]\n",
      "[ 0.5 , 12.5 ]\n",
      "[ 2004.0 , 2012.0 ]\n"
     ]
    }
   ],
   "source": [
    "for col in continuous_cols:\n",
    "    q1=df_train[col].quantile(0.25)\n",
    "    q3=df_train[col].quantile(0.75)\n",
    "    iqr=q3-q1\n",
    "    l=q1-1.5*iqr\n",
    "    h=q3+1.5*iqr\n",
    "    print(\"[\",l,\",\",h,\"]\")\n",
    "    df_train = df_train[(df_train[col] <= h)] \n",
    "    df_train = df_train[(df_train[col] >=l)] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "853ad8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output_col=df_train['SalePrice']\n",
    "df_train.drop(\"SalePrice\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037fd6a6-16b3-4231-9a17-f0168da59a19",
   "metadata": {},
   "source": [
    "Here we are encoding our categorical columns using 'one_hot_encoding' as a strategy. We will be experimenting other strategies later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2a741245",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def encoding_categorical_cols(df_train:pd.DataFrame,categorical_columns:list,strategy:str):\n",
    "    df_categorical=pd.DataFrame(df_train.loc[:,categorical_columns])\n",
    "    if strategy==\"labelencoder\":\n",
    "        for col in list(df_categorical.columns):\n",
    "            cat=[]\n",
    "            d={}\n",
    "\n",
    "            cat.append([df_categorical[col].value_counts().index,len(df_categorical[col].value_counts().index)])\n",
    "\n",
    "            for j in range(int(cat[0][1])):\n",
    "                d[str(cat[0][0][j])]=j\n",
    "            df_categorical[col]=df_categorical[col].map(d)\n",
    "        df_train.drop(categorical_columns,axis=1,inplace=True)\n",
    "        \n",
    "        df_train=pd.concat([df_train,df_categorical],axis=1)\n",
    "        \n",
    "    if strategy==\"onehotencoder\":\n",
    "        one_hot_encoded=pd.get_dummies(df_categorical)\n",
    "        # print(one_hot_encoded)\n",
    "        df_train.drop(categorical_columns,axis=1,inplace=True)\n",
    "        df_train=pd.concat([df_train,one_hot_encoded],axis=1)\n",
    "    return df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bb34ffe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=encoding_categorical_cols(df_train=df_train,categorical_columns=categorical_cols,strategy=\"onehotencoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "adc20103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>...</th>\n",
       "      <th>SaleType_ConLw</th>\n",
       "      <th>SaleType_New</th>\n",
       "      <th>SaleType_Oth</th>\n",
       "      <th>SaleType_WD</th>\n",
       "      <th>SaleCondition_Abnorml</th>\n",
       "      <th>SaleCondition_AdjLand</th>\n",
       "      <th>SaleCondition_Alloca</th>\n",
       "      <th>SaleCondition_Family</th>\n",
       "      <th>SaleCondition_Normal</th>\n",
       "      <th>SaleCondition_Partial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>196.0</td>\n",
       "      <td>706</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2002</td>\n",
       "      <td>162.0</td>\n",
       "      <td>486</td>\n",
       "      <td>0</td>\n",
       "      <td>434</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>350.0</td>\n",
       "      <td>655</td>\n",
       "      <td>0</td>\n",
       "      <td>490</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20</td>\n",
       "      <td>75.0</td>\n",
       "      <td>10084</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2005</td>\n",
       "      <td>186.0</td>\n",
       "      <td>1369</td>\n",
       "      <td>0</td>\n",
       "      <td>317</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20</td>\n",
       "      <td>70.0</td>\n",
       "      <td>11200</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>906</td>\n",
       "      <td>0</td>\n",
       "      <td>134</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444</th>\n",
       "      <td>20</td>\n",
       "      <td>63.0</td>\n",
       "      <td>8500</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2004</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1422</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1448</th>\n",
       "      <td>50</td>\n",
       "      <td>70.0</td>\n",
       "      <td>11767</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>560</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451</th>\n",
       "      <td>20</td>\n",
       "      <td>78.0</td>\n",
       "      <td>9262</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2009</td>\n",
       "      <td>194.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1573</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>20</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7500</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>410</td>\n",
       "      <td>0</td>\n",
       "      <td>811</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>60</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>953</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>576 rows × 217 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  \\\n",
       "0             60         65.0     8450            7            5   \n",
       "2             60         68.0    11250            7            5   \n",
       "4             60         84.0    14260            8            5   \n",
       "6             20         75.0    10084            8            5   \n",
       "10            20         70.0    11200            5            5   \n",
       "...          ...          ...      ...          ...          ...   \n",
       "1444          20         63.0     8500            7            5   \n",
       "1448          50         70.0    11767            4            7   \n",
       "1451          20         78.0     9262            8            5   \n",
       "1454          20         62.0     7500            7            5   \n",
       "1455          60         62.0     7917            6            5   \n",
       "\n",
       "      YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  BsmtUnfSF  ...  \\\n",
       "0             2003       196.0         706           0        150  ...   \n",
       "2             2002       162.0         486           0        434  ...   \n",
       "4             2000       350.0         655           0        490  ...   \n",
       "6             2005       186.0        1369           0        317  ...   \n",
       "10            1965         0.0         906           0        134  ...   \n",
       "...            ...         ...         ...         ...        ...  ...   \n",
       "1444          2004       106.0           0           0       1422  ...   \n",
       "1448          2000         0.0           0           0        560  ...   \n",
       "1451          2009       194.0           0           0       1573  ...   \n",
       "1454          2005         0.0         410           0        811  ...   \n",
       "1455          2000         0.0           0           0        953  ...   \n",
       "\n",
       "      SaleType_ConLw  SaleType_New  SaleType_Oth  SaleType_WD  \\\n",
       "0                  0             0             0            1   \n",
       "2                  0             0             0            1   \n",
       "4                  0             0             0            1   \n",
       "6                  0             0             0            1   \n",
       "10                 0             0             0            1   \n",
       "...              ...           ...           ...          ...   \n",
       "1444               0             0             0            1   \n",
       "1448               0             0             0            1   \n",
       "1451               0             1             0            0   \n",
       "1454               0             0             0            1   \n",
       "1455               0             0             0            1   \n",
       "\n",
       "      SaleCondition_Abnorml  SaleCondition_AdjLand  SaleCondition_Alloca  \\\n",
       "0                         0                      0                     0   \n",
       "2                         0                      0                     0   \n",
       "4                         0                      0                     0   \n",
       "6                         0                      0                     0   \n",
       "10                        0                      0                     0   \n",
       "...                     ...                    ...                   ...   \n",
       "1444                      0                      0                     0   \n",
       "1448                      0                      0                     0   \n",
       "1451                      0                      0                     0   \n",
       "1454                      0                      0                     0   \n",
       "1455                      0                      0                     0   \n",
       "\n",
       "      SaleCondition_Family  SaleCondition_Normal  SaleCondition_Partial  \n",
       "0                        0                     1                      0  \n",
       "2                        0                     1                      0  \n",
       "4                        0                     1                      0  \n",
       "6                        0                     1                      0  \n",
       "10                       0                     1                      0  \n",
       "...                    ...                   ...                    ...  \n",
       "1444                     0                     1                      0  \n",
       "1448                     0                     1                      0  \n",
       "1451                     0                     0                      1  \n",
       "1454                     0                     1                      0  \n",
       "1455                     0                     1                      0  \n",
       "\n",
       "[576 rows x 217 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e63bcfff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>...</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>576.000000</td>\n",
       "      <td>576.000000</td>\n",
       "      <td>576.000000</td>\n",
       "      <td>576.000000</td>\n",
       "      <td>576.000000</td>\n",
       "      <td>576.000000</td>\n",
       "      <td>576.000000</td>\n",
       "      <td>576.000000</td>\n",
       "      <td>576.0</td>\n",
       "      <td>576.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>576.000000</td>\n",
       "      <td>576.000000</td>\n",
       "      <td>576.000000</td>\n",
       "      <td>576.0</td>\n",
       "      <td>576.0</td>\n",
       "      <td>576.0</td>\n",
       "      <td>576.0</td>\n",
       "      <td>576.0</td>\n",
       "      <td>576.000000</td>\n",
       "      <td>576.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>48.315972</td>\n",
       "      <td>68.781250</td>\n",
       "      <td>9167.371528</td>\n",
       "      <td>6.263889</td>\n",
       "      <td>5.366319</td>\n",
       "      <td>1989.269097</td>\n",
       "      <td>77.281250</td>\n",
       "      <td>441.932292</td>\n",
       "      <td>0.0</td>\n",
       "      <td>614.366319</td>\n",
       "      <td>...</td>\n",
       "      <td>482.994792</td>\n",
       "      <td>90.241319</td>\n",
       "      <td>40.446181</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.348958</td>\n",
       "      <td>2007.789931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>31.355368</td>\n",
       "      <td>13.663944</td>\n",
       "      <td>2609.625982</td>\n",
       "      <td>1.316047</td>\n",
       "      <td>0.704898</td>\n",
       "      <td>19.823626</td>\n",
       "      <td>108.909316</td>\n",
       "      <td>416.412209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>428.094824</td>\n",
       "      <td>...</td>\n",
       "      <td>190.219283</td>\n",
       "      <td>97.639848</td>\n",
       "      <td>44.083011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.635827</td>\n",
       "      <td>1.321120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>2887.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2006.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>7717.250000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1972.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>390.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2007.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>9017.500000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1999.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>428.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>97.500000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2008.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>10800.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2005.000000</td>\n",
       "      <td>147.250000</td>\n",
       "      <td>743.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>879.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>583.750000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2009.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>120.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>16770.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>423.000000</td>\n",
       "      <td>1619.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1709.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>928.000000</td>\n",
       "      <td>379.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MSSubClass  LotFrontage       LotArea  OverallQual  OverallCond  \\\n",
       "count  576.000000   576.000000    576.000000   576.000000   576.000000   \n",
       "mean    48.315972    68.781250   9167.371528     6.263889     5.366319   \n",
       "std     31.355368    13.663944   2609.625982     1.316047     0.704898   \n",
       "min     20.000000    30.000000   2887.000000     2.000000     4.000000   \n",
       "25%     20.000000    60.000000   7717.250000     5.000000     5.000000   \n",
       "50%     50.000000    69.000000   9017.500000     6.000000     5.000000   \n",
       "75%     60.000000    75.000000  10800.000000     7.000000     6.000000   \n",
       "max    120.000000   110.000000  16770.000000    10.000000     7.000000   \n",
       "\n",
       "       YearRemodAdd  MasVnrArea   BsmtFinSF1  BsmtFinSF2    BsmtUnfSF  ...  \\\n",
       "count    576.000000  576.000000   576.000000       576.0   576.000000  ...   \n",
       "mean    1989.269097   77.281250   441.932292         0.0   614.366319  ...   \n",
       "std       19.823626  108.909316   416.412209         0.0   428.094824  ...   \n",
       "min     1950.000000    0.000000     0.000000         0.0     0.000000  ...   \n",
       "25%     1972.000000    0.000000     0.000000         0.0   280.000000  ...   \n",
       "50%     1999.000000    0.000000   428.000000         0.0   517.000000  ...   \n",
       "75%     2005.000000  147.250000   743.000000         0.0   879.250000  ...   \n",
       "max     2010.000000  423.000000  1619.000000         0.0  1709.000000  ...   \n",
       "\n",
       "       GarageArea  WoodDeckSF  OpenPorchSF  EnclosedPorch  3SsnPorch  \\\n",
       "count  576.000000  576.000000   576.000000          576.0      576.0   \n",
       "mean   482.994792   90.241319    40.446181            0.0        0.0   \n",
       "std    190.219283   97.639848    44.083011            0.0        0.0   \n",
       "min      0.000000    0.000000     0.000000            0.0        0.0   \n",
       "25%    390.000000    0.000000     0.000000            0.0        0.0   \n",
       "50%    480.000000   97.500000    33.000000            0.0        0.0   \n",
       "75%    583.750000  168.000000    63.000000            0.0        0.0   \n",
       "max    928.000000  379.000000   162.000000            0.0        0.0   \n",
       "\n",
       "       ScreenPorch  PoolArea  MiscVal      MoSold       YrSold  \n",
       "count        576.0     576.0    576.0  576.000000   576.000000  \n",
       "mean           0.0       0.0      0.0    6.348958  2007.789931  \n",
       "std            0.0       0.0      0.0    2.635827     1.321120  \n",
       "min            0.0       0.0      0.0    1.000000  2006.000000  \n",
       "25%            0.0       0.0      0.0    5.000000  2007.000000  \n",
       "50%            0.0       0.0      0.0    6.000000  2008.000000  \n",
       "75%            0.0       0.0      0.0    8.000000  2009.000000  \n",
       "max            0.0       0.0      0.0   12.000000  2010.000000  \n",
       "\n",
       "[8 rows x 32 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.loc[:,continuous_cols].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f1709177",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_train.columns:\n",
    "    if df_train[col].isnull().sum()>0:\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf599849-f69c-4693-9e61-9db515d6ab51",
   "metadata": {},
   "source": [
    "Since in previous model we tried min max scaler here we will try Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "589aafd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df_train\n",
    "Y=output_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "00b848d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       576.000000\n",
       "mean     181988.453125\n",
       "std       63196.732692\n",
       "min       37900.000000\n",
       "25%      135907.500000\n",
       "50%      176000.000000\n",
       "75%      215000.000000\n",
       "max      440000.000000\n",
       "Name: SalePrice, dtype: float64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8fd67785",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_accuracies={}\n",
    "highest_accuracies={}\n",
    "algorithms_tested=[\"LinearRegression()\",\"RandomForestRegressor()\",\"SVR()\",\"KNeighborsRegressor()\",\"SGDRegressor()\",\"DecisionTreeRegressor()\",\"ElasticNet()\",\"Lasso()\",\"Ridge()\"]\n",
    "for al in algorithms_tested:\n",
    "    avg_accuracies[al]=0\n",
    "    highest_accuracies[al]=float('-inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9bda032f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def algo_testing(algo:str,test_size:float,X,Y,evaluation_metric:str,random_state,shuffle):\n",
    "    model=eval(algo)\n",
    "    evaluation_metric=eval(evaluation_metric)\n",
    "    X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=random_state,shuffle=shuffle)\n",
    "   \n",
    "    model.fit(X_train,Y_train)\n",
    "    predicted=model.predict(X_test)\n",
    "    \n",
    "    r2=evaluation_metric(Y_test, predicted)\n",
    "    print(f\"Testing r2_score of {model} is \",r2)\n",
    "    print(f\"Training r2_score of {model} is \", model.score(X_train,Y_train))\n",
    "    if highest_accuracies[algo]<r2:\n",
    "        \n",
    "        highest_accuracies[algo]=r2\n",
    "    avg_accuracies[algo]+=r2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "125579fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of LinearRegression() is  0.8945342133972922\n",
      "Training r2_score of LinearRegression() is  0.9603210560117585\n",
      "Testing r2_score of LinearRegression() is  0.8354425895410761\n",
      "Training r2_score of LinearRegression() is  0.9632184049758667\n",
      "Testing r2_score of LinearRegression() is  0.8610378766721654\n",
      "Training r2_score of LinearRegression() is  0.9639937973523943\n",
      "Testing r2_score of LinearRegression() is  0.9174166840395739\n",
      "Training r2_score of LinearRegression() is  0.958847484962838\n",
      "Testing r2_score of LinearRegression() is  0.9011777516429356\n",
      "Training r2_score of LinearRegression() is  0.9605563967591335\n",
      "Testing r2_score of LinearRegression() is  0.8836998361309826\n",
      "Training r2_score of LinearRegression() is  0.9633873511196\n",
      "Testing r2_score of LinearRegression() is  0.8554938339246234\n",
      "Training r2_score of LinearRegression() is  0.9683303693924848\n",
      "Testing r2_score of LinearRegression() is  0.8996282063053265\n",
      "Training r2_score of LinearRegression() is  0.9617433677383874\n",
      "Testing r2_score of LinearRegression() is  0.884702627393208\n",
      "Training r2_score of LinearRegression() is  0.9606563630764844\n",
      "Testing r2_score of LinearRegression() is  0.8304279430361934\n",
      "Training r2_score of LinearRegression() is  0.9638501620867247\n",
      "Testing r2_score of LinearRegression() is  0.9267065428846499\n",
      "Training r2_score of LinearRegression() is  0.9585789830817047\n",
      "Testing r2_score of LinearRegression() is  0.8563618440355283\n",
      "Training r2_score of LinearRegression() is  0.9615373275068161\n",
      "Testing r2_score of LinearRegression() is  0.9054371075890454\n",
      "Training r2_score of LinearRegression() is  0.9603246657997895\n",
      "Testing r2_score of LinearRegression() is  0.9209746141105946\n",
      "Training r2_score of LinearRegression() is  0.9574228379617735\n",
      "Testing r2_score of LinearRegression() is  0.8452161775842404\n",
      "Training r2_score of LinearRegression() is  0.9641890903470801\n",
      "Testing r2_score of LinearRegression() is  0.8694623686605378\n",
      "Training r2_score of LinearRegression() is  0.9620902592483404\n",
      "Testing r2_score of LinearRegression() is  0.8898226291736696\n",
      "Training r2_score of LinearRegression() is  0.9626416050183295\n",
      "Testing r2_score of LinearRegression() is  0.9213114866674759\n",
      "Training r2_score of LinearRegression() is  0.9558361290906838\n",
      "Testing r2_score of LinearRegression() is  0.9146769802076885\n",
      "Training r2_score of LinearRegression() is  0.9568637493201623\n",
      "Testing r2_score of LinearRegression() is  0.8956650439089908\n",
      "Training r2_score of LinearRegression() is  0.9623975548361535\n",
      "Testing r2_score of LinearRegression() is  0.9047090966373744\n",
      "Training r2_score of LinearRegression() is  0.9607454679569395\n",
      "Testing r2_score of LinearRegression() is  0.9101603657261689\n",
      "Training r2_score of LinearRegression() is  0.9596127159653246\n",
      "Testing r2_score of LinearRegression() is  0.8540344282336113\n",
      "Training r2_score of LinearRegression() is  0.9657911888138387\n",
      "Testing r2_score of LinearRegression() is  0.867049795881859\n",
      "Training r2_score of LinearRegression() is  0.9651022599173875\n",
      "Testing r2_score of LinearRegression() is  0.8925238139410918\n",
      "Training r2_score of LinearRegression() is  0.9599084120812821\n",
      "Testing r2_score of LinearRegression() is  0.9126424588475168\n",
      "Training r2_score of LinearRegression() is  0.9599385119598128\n",
      "Testing r2_score of LinearRegression() is  0.8859966453996646\n",
      "Training r2_score of LinearRegression() is  0.9620518870876188\n",
      "Testing r2_score of LinearRegression() is  0.8200321909912038\n",
      "Training r2_score of LinearRegression() is  0.9605475423368347\n",
      "Testing r2_score of LinearRegression() is  0.8648532602602239\n",
      "Training r2_score of LinearRegression() is  0.9608507624882394\n",
      "Testing r2_score of LinearRegression() is  0.8525249542406546\n",
      "Training r2_score of LinearRegression() is  0.9631209968667808\n",
      "Testing r2_score of LinearRegression() is  0.9188881665486145\n",
      "Training r2_score of LinearRegression() is  0.9571974038475763\n",
      "Testing r2_score of LinearRegression() is  0.8800263540218939\n",
      "Training r2_score of LinearRegression() is  0.9621352180865352\n",
      "Testing r2_score of LinearRegression() is  0.8426288476837759\n",
      "Training r2_score of LinearRegression() is  0.958663869983631\n",
      "Testing r2_score of LinearRegression() is  0.9126289648040765\n",
      "Training r2_score of LinearRegression() is  0.9609457240377808\n",
      "Testing r2_score of LinearRegression() is  0.8815908740266883\n",
      "Training r2_score of LinearRegression() is  0.9645325440433461\n",
      "Testing r2_score of LinearRegression() is  0.8739270213703417\n",
      "Training r2_score of LinearRegression() is  0.9607039069311059\n",
      "Testing r2_score of LinearRegression() is  0.8483954203255051\n",
      "Training r2_score of LinearRegression() is  0.9638564291559251\n",
      "Testing r2_score of LinearRegression() is  0.8737265344410017\n",
      "Training r2_score of LinearRegression() is  0.9633598499134794\n",
      "Testing r2_score of LinearRegression() is  0.8825502713536533\n",
      "Training r2_score of LinearRegression() is  0.9610879868650686\n",
      "Testing r2_score of LinearRegression() is  0.8677386264966496\n",
      "Training r2_score of LinearRegression() is  0.9608122277903135\n",
      "Testing r2_score of LinearRegression() is  0.9065770314613171\n",
      "Training r2_score of LinearRegression() is  0.9602160784355898\n",
      "Testing r2_score of LinearRegression() is  0.9122902526824737\n",
      "Training r2_score of LinearRegression() is  0.9566423450829193\n",
      "Testing r2_score of LinearRegression() is  0.8606281763782497\n",
      "Training r2_score of LinearRegression() is  0.963742539061159\n",
      "Testing r2_score of LinearRegression() is  0.9161711964876671\n",
      "Training r2_score of LinearRegression() is  0.9590598364746015\n",
      "Testing r2_score of LinearRegression() is  0.8653064175036008\n",
      "Training r2_score of LinearRegression() is  0.9668146349725453\n",
      "Testing r2_score of LinearRegression() is  0.8771706058129147\n",
      "Training r2_score of LinearRegression() is  0.9644746060661523\n",
      "Testing r2_score of LinearRegression() is  0.9060475045913238\n",
      "Training r2_score of LinearRegression() is  0.9615720081005117\n",
      "Testing r2_score of LinearRegression() is  0.8965402460271092\n",
      "Training r2_score of LinearRegression() is  0.9601558489370183\n",
      "Testing r2_score of LinearRegression() is  0.8859088168345776\n",
      "Training r2_score of LinearRegression() is  0.9627065045362617\n",
      "Testing r2_score of LinearRegression() is  0.8765111854292709\n",
      "Training r2_score of LinearRegression() is  0.9610667860132256\n"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    algo_testing(algo=\"LinearRegression()\",test_size=0.2,X=X,Y=Y,evaluation_metric=\"r2_score\",random_state=None,shuffle=True)\n",
    "avg_accuracies[\"LinearRegression()\"]/=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ff78a7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of RandomForestRegressor() is  0.9122032395484649\n",
      "Training r2_score of RandomForestRegressor() is  0.980307254699355\n",
      "Testing r2_score of RandomForestRegressor() is  0.8242286814262525\n",
      "Training r2_score of RandomForestRegressor() is  0.9833888466954425\n",
      "Testing r2_score of RandomForestRegressor() is  0.9204297824518164\n",
      "Training r2_score of RandomForestRegressor() is  0.9809536148801556\n",
      "Testing r2_score of RandomForestRegressor() is  0.8688508181169713\n",
      "Training r2_score of RandomForestRegressor() is  0.98276397089336\n",
      "Testing r2_score of RandomForestRegressor() is  0.8949157002041616\n",
      "Training r2_score of RandomForestRegressor() is  0.9798996808837669\n",
      "Testing r2_score of RandomForestRegressor() is  0.8729318209326815\n",
      "Training r2_score of RandomForestRegressor() is  0.9805874938677923\n",
      "Testing r2_score of RandomForestRegressor() is  0.8932477035275331\n",
      "Training r2_score of RandomForestRegressor() is  0.9812753830966519\n",
      "Testing r2_score of RandomForestRegressor() is  0.8532344707028423\n",
      "Training r2_score of RandomForestRegressor() is  0.9848163365291214\n",
      "Testing r2_score of RandomForestRegressor() is  0.8766853898175562\n",
      "Training r2_score of RandomForestRegressor() is  0.9827558416152208\n",
      "Testing r2_score of RandomForestRegressor() is  0.8646326388886254\n",
      "Training r2_score of RandomForestRegressor() is  0.9812067109360864\n",
      "Testing r2_score of RandomForestRegressor() is  0.8497405940707455\n",
      "Training r2_score of RandomForestRegressor() is  0.9822503347442141\n",
      "Testing r2_score of RandomForestRegressor() is  0.8036185808958061\n",
      "Training r2_score of RandomForestRegressor() is  0.9826879482453585\n",
      "Testing r2_score of RandomForestRegressor() is  0.9197204244657636\n",
      "Training r2_score of RandomForestRegressor() is  0.9806526338502731\n",
      "Testing r2_score of RandomForestRegressor() is  0.8543554063659102\n",
      "Training r2_score of RandomForestRegressor() is  0.982662650376017\n",
      "Testing r2_score of RandomForestRegressor() is  0.8814874613344396\n",
      "Training r2_score of RandomForestRegressor() is  0.9822378207150816\n",
      "Testing r2_score of RandomForestRegressor() is  0.8022979555379927\n",
      "Training r2_score of RandomForestRegressor() is  0.9843064559879627\n",
      "Testing r2_score of RandomForestRegressor() is  0.8766758591730796\n",
      "Training r2_score of RandomForestRegressor() is  0.9795691814416195\n",
      "Testing r2_score of RandomForestRegressor() is  0.8653503815696661\n",
      "Training r2_score of RandomForestRegressor() is  0.9823104156887624\n",
      "Testing r2_score of RandomForestRegressor() is  0.9168678655964713\n",
      "Training r2_score of RandomForestRegressor() is  0.9794660723433513\n",
      "Testing r2_score of RandomForestRegressor() is  0.8927934805890434\n",
      "Training r2_score of RandomForestRegressor() is  0.9816468020273434\n",
      "Testing r2_score of RandomForestRegressor() is  0.8489192893680834\n",
      "Training r2_score of RandomForestRegressor() is  0.9831927270933591\n",
      "Testing r2_score of RandomForestRegressor() is  0.851883169210022\n",
      "Training r2_score of RandomForestRegressor() is  0.9811705436264236\n",
      "Testing r2_score of RandomForestRegressor() is  0.9020660730738898\n",
      "Training r2_score of RandomForestRegressor() is  0.9810380391794399\n",
      "Testing r2_score of RandomForestRegressor() is  0.9049920943503477\n",
      "Training r2_score of RandomForestRegressor() is  0.9816566467897383\n",
      "Testing r2_score of RandomForestRegressor() is  0.8730746604611811\n",
      "Training r2_score of RandomForestRegressor() is  0.9789701900157375\n",
      "Testing r2_score of RandomForestRegressor() is  0.8673018728522928\n",
      "Training r2_score of RandomForestRegressor() is  0.9820101551505279\n",
      "Testing r2_score of RandomForestRegressor() is  0.8060582561564928\n",
      "Training r2_score of RandomForestRegressor() is  0.9828400162320298\n",
      "Testing r2_score of RandomForestRegressor() is  0.9203501333863576\n",
      "Training r2_score of RandomForestRegressor() is  0.9812168345035822\n",
      "Testing r2_score of RandomForestRegressor() is  0.8656802398803708\n",
      "Training r2_score of RandomForestRegressor() is  0.9826050614547994\n",
      "Testing r2_score of RandomForestRegressor() is  0.8338446374954633\n",
      "Training r2_score of RandomForestRegressor() is  0.9830660243038056\n",
      "Testing r2_score of RandomForestRegressor() is  0.813988254829629\n",
      "Training r2_score of RandomForestRegressor() is  0.9847520900532232\n",
      "Testing r2_score of RandomForestRegressor() is  0.9397878103943064\n",
      "Training r2_score of RandomForestRegressor() is  0.9795776455547017\n",
      "Testing r2_score of RandomForestRegressor() is  0.8888774413344032\n",
      "Training r2_score of RandomForestRegressor() is  0.9803993569608205\n",
      "Testing r2_score of RandomForestRegressor() is  0.8826163748289506\n",
      "Training r2_score of RandomForestRegressor() is  0.9823221572762414\n",
      "Testing r2_score of RandomForestRegressor() is  0.9231128636386207\n",
      "Training r2_score of RandomForestRegressor() is  0.9801521393063269\n",
      "Testing r2_score of RandomForestRegressor() is  0.9115001424079565\n",
      "Training r2_score of RandomForestRegressor() is  0.9817204631848029\n",
      "Testing r2_score of RandomForestRegressor() is  0.834513912121416\n",
      "Training r2_score of RandomForestRegressor() is  0.9836778386670608\n",
      "Testing r2_score of RandomForestRegressor() is  0.8410918556699631\n",
      "Training r2_score of RandomForestRegressor() is  0.9807178938952733\n",
      "Testing r2_score of RandomForestRegressor() is  0.8873239901475102\n",
      "Training r2_score of RandomForestRegressor() is  0.9796282038657284\n",
      "Testing r2_score of RandomForestRegressor() is  0.8261428643605881\n",
      "Training r2_score of RandomForestRegressor() is  0.9801124011239507\n",
      "Testing r2_score of RandomForestRegressor() is  0.8637371227081214\n",
      "Training r2_score of RandomForestRegressor() is  0.9812504440625152\n",
      "Testing r2_score of RandomForestRegressor() is  0.7820556614983342\n",
      "Training r2_score of RandomForestRegressor() is  0.9839595189632772\n",
      "Testing r2_score of RandomForestRegressor() is  0.8738668922662262\n",
      "Training r2_score of RandomForestRegressor() is  0.9817964846581984\n",
      "Testing r2_score of RandomForestRegressor() is  0.9020364347367844\n",
      "Training r2_score of RandomForestRegressor() is  0.9808192049968187\n",
      "Testing r2_score of RandomForestRegressor() is  0.8628050422677349\n",
      "Training r2_score of RandomForestRegressor() is  0.9828503359970236\n",
      "Testing r2_score of RandomForestRegressor() is  0.8987431357286157\n",
      "Training r2_score of RandomForestRegressor() is  0.9814336291217333\n",
      "Testing r2_score of RandomForestRegressor() is  0.7904755084701456\n",
      "Training r2_score of RandomForestRegressor() is  0.9828834582883419\n",
      "Testing r2_score of RandomForestRegressor() is  0.8102149123640286\n",
      "Training r2_score of RandomForestRegressor() is  0.9822180378604479\n",
      "Testing r2_score of RandomForestRegressor() is  0.8768231553831227\n",
      "Training r2_score of RandomForestRegressor() is  0.9813404898295478\n",
      "Testing r2_score of RandomForestRegressor() is  0.9044564458200216\n",
      "Training r2_score of RandomForestRegressor() is  0.9807997069531962\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(50):\n",
    "    algo_testing(algo=\"RandomForestRegressor()\",test_size=0.2,X=X,Y=Y,evaluation_metric=\"r2_score\",random_state=None,shuffle=True)\n",
    "avg_accuracies[\"RandomForestRegressor()\"]/=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8737ed20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of SVR() is  -0.015698231074787516\n",
      "Training r2_score of SVR() is  -0.006463141406070072\n",
      "Testing r2_score of SVR() is  -0.00034838262689573796\n",
      "Training r2_score of SVR() is  -0.010188130889947189\n",
      "Testing r2_score of SVR() is  -0.014636293671962175\n",
      "Training r2_score of SVR() is  -0.009760614369892506\n",
      "Testing r2_score of SVR() is  -0.04157340351864924\n",
      "Training r2_score of SVR() is  -0.005649245669939518\n",
      "Testing r2_score of SVR() is  -0.042910958613108674\n",
      "Training r2_score of SVR() is  -0.007978558987619344\n",
      "Testing r2_score of SVR() is  -0.01572050946587078\n",
      "Training r2_score of SVR() is  -0.007293724854481987\n",
      "Testing r2_score of SVR() is  -0.014296955500274544\n",
      "Training r2_score of SVR() is  -0.008924205885561642\n",
      "Testing r2_score of SVR() is  -0.026559538117253423\n",
      "Training r2_score of SVR() is  -0.008464035121267477\n",
      "Testing r2_score of SVR() is  -0.02497655330174231\n",
      "Training r2_score of SVR() is  -0.006707078386346099\n",
      "Testing r2_score of SVR() is  -0.00039957669714141275\n",
      "Training r2_score of SVR() is  -0.0095948596015063\n",
      "Testing r2_score of SVR() is  -6.710900426964983e-05\n",
      "Training r2_score of SVR() is  -0.010907128337707572\n",
      "Testing r2_score of SVR() is  -0.009211971651796658\n",
      "Training r2_score of SVR() is  -0.010986900423448631\n",
      "Testing r2_score of SVR() is  -0.051895359791444884\n",
      "Training r2_score of SVR() is  -0.007060589233757408\n",
      "Testing r2_score of SVR() is  -0.004777267813465436\n",
      "Training r2_score of SVR() is  -0.009224254045400837\n",
      "Testing r2_score of SVR() is  -0.00033835799779224907\n",
      "Training r2_score of SVR() is  -0.013861044012103418\n",
      "Testing r2_score of SVR() is  -0.017988720028742744\n",
      "Training r2_score of SVR() is  -0.0071310739579482085\n",
      "Testing r2_score of SVR() is  -0.008649393233265856\n",
      "Training r2_score of SVR() is  -0.008920974967112638\n",
      "Testing r2_score of SVR() is  -5.891261648738322e-05\n",
      "Training r2_score of SVR() is  -0.008418279939839346\n",
      "Testing r2_score of SVR() is  -0.00012519401793253948\n",
      "Training r2_score of SVR() is  -0.012673799623645898\n",
      "Testing r2_score of SVR() is  -0.015406084496734529\n",
      "Training r2_score of SVR() is  -0.0077704281473154335\n",
      "Testing r2_score of SVR() is  -0.027299906482308067\n",
      "Training r2_score of SVR() is  -0.008923989210055883\n",
      "Testing r2_score of SVR() is  -5.993095462564213e-05\n",
      "Training r2_score of SVR() is  -0.012496507016718228\n",
      "Testing r2_score of SVR() is  -0.009115267997357845\n",
      "Training r2_score of SVR() is  -0.008782766460330382\n",
      "Testing r2_score of SVR() is  -0.07316989831471732\n",
      "Training r2_score of SVR() is  -0.007762417578531133\n",
      "Testing r2_score of SVR() is  -0.0148947634736738\n",
      "Training r2_score of SVR() is  -0.008665836549653916\n",
      "Testing r2_score of SVR() is  -0.001957026718223842\n",
      "Training r2_score of SVR() is  -0.011035731178326902\n",
      "Testing r2_score of SVR() is  -0.011761716359445895\n",
      "Training r2_score of SVR() is  -0.00657784315601484\n",
      "Testing r2_score of SVR() is  -0.007746104301888934\n",
      "Training r2_score of SVR() is  -0.00835094287641569\n",
      "Testing r2_score of SVR() is  -0.005236217147666977\n",
      "Training r2_score of SVR() is  -0.0066231996138603755\n",
      "Testing r2_score of SVR() is  -0.044740765243736824\n",
      "Training r2_score of SVR() is  -0.005961138893813667\n",
      "Testing r2_score of SVR() is  -0.0038016645082952216\n",
      "Training r2_score of SVR() is  -0.013247659563970338\n",
      "Testing r2_score of SVR() is  -0.0071029617154039215\n",
      "Training r2_score of SVR() is  -0.007537707424577933\n",
      "Testing r2_score of SVR() is  -0.008046171310314376\n",
      "Training r2_score of SVR() is  -0.009112228904559982\n",
      "Testing r2_score of SVR() is  -0.0367821909031818\n",
      "Training r2_score of SVR() is  -0.007781672247438642\n",
      "Testing r2_score of SVR() is  -0.025496646455803518\n",
      "Training r2_score of SVR() is  -0.0058232486270641814\n",
      "Testing r2_score of SVR() is  -0.0627003567333666\n",
      "Training r2_score of SVR() is  -0.01115595177579487\n",
      "Testing r2_score of SVR() is  -0.015222858653874738\n",
      "Training r2_score of SVR() is  -0.01037171098797196\n",
      "Testing r2_score of SVR() is  -9.249293014290672e-05\n",
      "Training r2_score of SVR() is  -0.011134005330935226\n",
      "Testing r2_score of SVR() is  -0.011052384425187967\n",
      "Training r2_score of SVR() is  -0.008329612771106776\n",
      "Testing r2_score of SVR() is  -0.009319729238039809\n",
      "Training r2_score of SVR() is  -0.008741348227526924\n",
      "Testing r2_score of SVR() is  -0.002878388463156689\n",
      "Training r2_score of SVR() is  -0.0126888682855546\n",
      "Testing r2_score of SVR() is  -0.004986797314290081\n",
      "Training r2_score of SVR() is  -0.008169085119930086\n",
      "Testing r2_score of SVR() is  -0.035966200355954214\n",
      "Training r2_score of SVR() is  -0.007855899627051466\n",
      "Testing r2_score of SVR() is  -0.005817587807507518\n",
      "Training r2_score of SVR() is  -0.008794092734611958\n",
      "Testing r2_score of SVR() is  -0.00911302559138183\n",
      "Training r2_score of SVR() is  -0.008798303244784922\n",
      "Testing r2_score of SVR() is  -0.012685941050333938\n",
      "Training r2_score of SVR() is  -0.011134967773023696\n",
      "Testing r2_score of SVR() is  -0.009392861201279468\n",
      "Training r2_score of SVR() is  -0.011765170432323835\n",
      "Testing r2_score of SVR() is  3.2180146942173415e-05\n",
      "Training r2_score of SVR() is  -0.01190815477791296\n",
      "Testing r2_score of SVR() is  -0.003610208984949681\n",
      "Training r2_score of SVR() is  -0.0053069067836606365\n",
      "Testing r2_score of SVR() is  -0.0010554365918662434\n",
      "Training r2_score of SVR() is  -0.00973366162394651\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(50):\n",
    "\n",
    "    algo_testing(algo=\"SVR()\",test_size=0.2,X=X,Y=Y,evaluation_metric=\"r2_score\",random_state=None,shuffle=True)\n",
    "avg_accuracies[\"SVR()\"]/=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d5b05673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of KNeighborsRegressor() is  0.6287540661412218\n",
      "Training r2_score of KNeighborsRegressor() is  0.766500278970432\n",
      "Testing r2_score of KNeighborsRegressor() is  0.59168126539728\n",
      "Training r2_score of KNeighborsRegressor() is  0.7917088779991784\n",
      "Testing r2_score of KNeighborsRegressor() is  0.5850523096193295\n",
      "Training r2_score of KNeighborsRegressor() is  0.7837352797495996\n",
      "Testing r2_score of KNeighborsRegressor() is  0.6387533917407054\n",
      "Training r2_score of KNeighborsRegressor() is  0.7846789556743519\n",
      "Testing r2_score of KNeighborsRegressor() is  0.5907985141109913\n",
      "Training r2_score of KNeighborsRegressor() is  0.7760190122046315\n",
      "Testing r2_score of KNeighborsRegressor() is  0.6809688803990231\n",
      "Training r2_score of KNeighborsRegressor() is  0.7669561997125814\n",
      "Testing r2_score of KNeighborsRegressor() is  0.618280273486201\n",
      "Training r2_score of KNeighborsRegressor() is  0.7664707192017984\n",
      "Testing r2_score of KNeighborsRegressor() is  0.6124194776026348\n",
      "Training r2_score of KNeighborsRegressor() is  0.7730480845459574\n",
      "Testing r2_score of KNeighborsRegressor() is  0.6714276016081673\n",
      "Training r2_score of KNeighborsRegressor() is  0.7611142029787591\n",
      "Testing r2_score of KNeighborsRegressor() is  0.7114377075966414\n",
      "Training r2_score of KNeighborsRegressor() is  0.7667049906831719\n",
      "Testing r2_score of KNeighborsRegressor() is  0.6227034929444748\n",
      "Training r2_score of KNeighborsRegressor() is  0.7835173212238471\n",
      "Testing r2_score of KNeighborsRegressor() is  0.7269926603598094\n",
      "Training r2_score of KNeighborsRegressor() is  0.7597792484240803\n",
      "Testing r2_score of KNeighborsRegressor() is  0.6910207371176067\n",
      "Training r2_score of KNeighborsRegressor() is  0.7773578439014377\n",
      "Testing r2_score of KNeighborsRegressor() is  0.6821413616601686\n",
      "Training r2_score of KNeighborsRegressor() is  0.7741381422742332\n",
      "Testing r2_score of KNeighborsRegressor() is  0.6448478271881052\n",
      "Training r2_score of KNeighborsRegressor() is  0.7870410244600752\n",
      "Testing r2_score of KNeighborsRegressor() is  0.6829592950729138\n",
      "Training r2_score of KNeighborsRegressor() is  0.751574252158519\n",
      "Testing r2_score of KNeighborsRegressor() is  0.6948290048973175\n",
      "Training r2_score of KNeighborsRegressor() is  0.7712284823937108\n",
      "Testing r2_score of KNeighborsRegressor() is  0.6654523662058518\n",
      "Training r2_score of KNeighborsRegressor() is  0.7732967546020811\n",
      "Testing r2_score of KNeighborsRegressor() is  0.6934174253632692\n",
      "Training r2_score of KNeighborsRegressor() is  0.7472243879867455\n",
      "Testing r2_score of KNeighborsRegressor() is  0.5919689557625121\n",
      "Training r2_score of KNeighborsRegressor() is  0.784465254110245\n",
      "Testing r2_score of KNeighborsRegressor() is  0.700888666762401\n",
      "Training r2_score of KNeighborsRegressor() is  0.7630504675845056\n",
      "Testing r2_score of KNeighborsRegressor() is  0.7146131244502452\n",
      "Training r2_score of KNeighborsRegressor() is  0.7688620120753096\n",
      "Testing r2_score of KNeighborsRegressor() is  0.5521997717386764\n",
      "Training r2_score of KNeighborsRegressor() is  0.811196735550267\n",
      "Testing r2_score of KNeighborsRegressor() is  0.7367998533067621\n",
      "Training r2_score of KNeighborsRegressor() is  0.7449413621622663\n",
      "Testing r2_score of KNeighborsRegressor() is  0.5973060171007916\n",
      "Training r2_score of KNeighborsRegressor() is  0.79782447239045\n",
      "Testing r2_score of KNeighborsRegressor() is  0.6141197713999357\n",
      "Training r2_score of KNeighborsRegressor() is  0.7760639780593952\n",
      "Testing r2_score of KNeighborsRegressor() is  0.6433492317374122\n",
      "Training r2_score of KNeighborsRegressor() is  0.7843696040581203\n",
      "Testing r2_score of KNeighborsRegressor() is  0.5747163899057979\n",
      "Training r2_score of KNeighborsRegressor() is  0.795455671901847\n",
      "Testing r2_score of KNeighborsRegressor() is  0.6900108124490496\n",
      "Training r2_score of KNeighborsRegressor() is  0.7679759089371668\n",
      "Testing r2_score of KNeighborsRegressor() is  0.6405412956048985\n",
      "Training r2_score of KNeighborsRegressor() is  0.7777551337002933\n",
      "Testing r2_score of KNeighborsRegressor() is  0.5744791930810089\n",
      "Training r2_score of KNeighborsRegressor() is  0.8000885645190113\n",
      "Testing r2_score of KNeighborsRegressor() is  0.7032553910966457\n",
      "Training r2_score of KNeighborsRegressor() is  0.7583353217874166\n",
      "Testing r2_score of KNeighborsRegressor() is  0.6678894073001407\n",
      "Training r2_score of KNeighborsRegressor() is  0.7720796056612858\n",
      "Testing r2_score of KNeighborsRegressor() is  0.520423836628118\n",
      "Training r2_score of KNeighborsRegressor() is  0.7915363829640927\n",
      "Testing r2_score of KNeighborsRegressor() is  0.621609681620175\n",
      "Training r2_score of KNeighborsRegressor() is  0.7818698860548232\n",
      "Testing r2_score of KNeighborsRegressor() is  0.6140232314152747\n",
      "Training r2_score of KNeighborsRegressor() is  0.7842321766856173\n",
      "Testing r2_score of KNeighborsRegressor() is  0.6523186498467741\n",
      "Training r2_score of KNeighborsRegressor() is  0.7684492537220003\n",
      "Testing r2_score of KNeighborsRegressor() is  0.592671451760592\n",
      "Training r2_score of KNeighborsRegressor() is  0.7855274968816033\n",
      "Testing r2_score of KNeighborsRegressor() is  0.5953728883301823\n",
      "Training r2_score of KNeighborsRegressor() is  0.7865419514846206\n",
      "Testing r2_score of KNeighborsRegressor() is  0.6581123001952598\n",
      "Training r2_score of KNeighborsRegressor() is  0.7598432191682403\n",
      "Testing r2_score of KNeighborsRegressor() is  0.7173013884854873\n",
      "Training r2_score of KNeighborsRegressor() is  0.7673804475262174\n",
      "Testing r2_score of KNeighborsRegressor() is  0.6315834829845051\n",
      "Training r2_score of KNeighborsRegressor() is  0.7739071080691241\n",
      "Testing r2_score of KNeighborsRegressor() is  0.6260704621326018\n",
      "Training r2_score of KNeighborsRegressor() is  0.7811634906487444\n",
      "Testing r2_score of KNeighborsRegressor() is  0.6600640438767315\n",
      "Training r2_score of KNeighborsRegressor() is  0.7631227196800251\n",
      "Testing r2_score of KNeighborsRegressor() is  0.7093445548708244\n",
      "Training r2_score of KNeighborsRegressor() is  0.7729627928075757\n",
      "Testing r2_score of KNeighborsRegressor() is  0.6286548301025701\n",
      "Training r2_score of KNeighborsRegressor() is  0.7936522991222902\n",
      "Testing r2_score of KNeighborsRegressor() is  0.706207127333154\n",
      "Training r2_score of KNeighborsRegressor() is  0.7710491389441845\n",
      "Testing r2_score of KNeighborsRegressor() is  0.7401351304066244\n",
      "Training r2_score of KNeighborsRegressor() is  0.7670877832917424\n",
      "Testing r2_score of KNeighborsRegressor() is  0.6911909344594553\n",
      "Training r2_score of KNeighborsRegressor() is  0.7540095264961685\n",
      "Testing r2_score of KNeighborsRegressor() is  0.6706209982304312\n",
      "Training r2_score of KNeighborsRegressor() is  0.7836728446244666\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(50):\n",
    "\n",
    "    algo_testing(algo=\"KNeighborsRegressor()\",test_size=0.2,X=X,Y=Y,evaluation_metric=\"r2_score\",random_state=None,shuffle=True)\n",
    "avg_accuracies[\"KNeighborsRegressor()\"]/=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8d553002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of SGDRegressor() is  -1.1432785032618579e+23\n",
      "Training r2_score of SGDRegressor() is  -6.830163600901873e+22\n",
      "Testing r2_score of SGDRegressor() is  -7.796645058791021e+23\n",
      "Training r2_score of SGDRegressor() is  -7.618922377445879e+23\n",
      "Testing r2_score of SGDRegressor() is  -4.733359230034105e+23\n",
      "Training r2_score of SGDRegressor() is  -4.492814667309254e+23\n",
      "Testing r2_score of SGDRegressor() is  -8.101436055885949e+21\n",
      "Training r2_score of SGDRegressor() is  -1.100618642842771e+22\n",
      "Testing r2_score of SGDRegressor() is  -8.604066490780491e+23\n",
      "Training r2_score of SGDRegressor() is  -6.599060044322396e+23\n",
      "Testing r2_score of SGDRegressor() is  -2.5698078218066634e+23\n",
      "Training r2_score of SGDRegressor() is  -3.058286534980844e+23\n",
      "Testing r2_score of SGDRegressor() is  -6.971875947417275e+23\n",
      "Training r2_score of SGDRegressor() is  -7.428370414257587e+23\n",
      "Testing r2_score of SGDRegressor() is  -2.5796483275823587e+23\n",
      "Training r2_score of SGDRegressor() is  -2.3939252907873285e+23\n",
      "Testing r2_score of SGDRegressor() is  -3.049243843647698e+22\n",
      "Training r2_score of SGDRegressor() is  -2.6226622299766595e+22\n",
      "Testing r2_score of SGDRegressor() is  -9.63041057368109e+23\n",
      "Training r2_score of SGDRegressor() is  -9.094482343245086e+23\n",
      "Testing r2_score of SGDRegressor() is  -1.5709335824862913e+24\n",
      "Training r2_score of SGDRegressor() is  -1.495192387229432e+24\n",
      "Testing r2_score of SGDRegressor() is  -7.589565659888994e+21\n",
      "Training r2_score of SGDRegressor() is  -5.585673708652166e+21\n",
      "Testing r2_score of SGDRegressor() is  -6.375234160071986e+23\n",
      "Training r2_score of SGDRegressor() is  -5.494814126479331e+23\n",
      "Testing r2_score of SGDRegressor() is  -1.1101253551672592e+24\n",
      "Training r2_score of SGDRegressor() is  -1.2659465988768085e+24\n",
      "Testing r2_score of SGDRegressor() is  -8.306710778128745e+22\n",
      "Training r2_score of SGDRegressor() is  -9.968885390774505e+22\n",
      "Testing r2_score of SGDRegressor() is  -1.363268096251151e+24\n",
      "Training r2_score of SGDRegressor() is  -1.3267851346926728e+24\n",
      "Testing r2_score of SGDRegressor() is  -5.066061815410709e+23\n",
      "Training r2_score of SGDRegressor() is  -5.726773340608013e+23\n",
      "Testing r2_score of SGDRegressor() is  -1.710079714433164e+24\n",
      "Training r2_score of SGDRegressor() is  -1.6919647105661108e+24\n",
      "Testing r2_score of SGDRegressor() is  -5.251814807348581e+23\n",
      "Training r2_score of SGDRegressor() is  -5.8644182960083196e+23\n",
      "Testing r2_score of SGDRegressor() is  -1.7080650235660498e+24\n",
      "Training r2_score of SGDRegressor() is  -1.4611101925900986e+24\n",
      "Testing r2_score of SGDRegressor() is  -3.5568171892752386e+23\n",
      "Training r2_score of SGDRegressor() is  -3.7372181221949945e+23\n",
      "Testing r2_score of SGDRegressor() is  -3.4264400626835255e+22\n",
      "Training r2_score of SGDRegressor() is  -3.1441619696080533e+22\n",
      "Testing r2_score of SGDRegressor() is  -1.2792229910525032e+24\n",
      "Training r2_score of SGDRegressor() is  -1.0148647788286072e+24\n",
      "Testing r2_score of SGDRegressor() is  -1.2734261288668778e+24\n",
      "Training r2_score of SGDRegressor() is  -1.699870201187885e+24\n",
      "Testing r2_score of SGDRegressor() is  -1.303675897144817e+24\n",
      "Training r2_score of SGDRegressor() is  -1.4401943038351638e+24\n",
      "Testing r2_score of SGDRegressor() is  -5.053085573932571e+23\n",
      "Training r2_score of SGDRegressor() is  -4.1299354337483016e+23\n",
      "Testing r2_score of SGDRegressor() is  -2.3631940073910553e+23\n",
      "Training r2_score of SGDRegressor() is  -2.405576802908574e+23\n",
      "Testing r2_score of SGDRegressor() is  -8.544736356756607e+22\n",
      "Training r2_score of SGDRegressor() is  -8.205611635211031e+22\n",
      "Testing r2_score of SGDRegressor() is  -1.0542573148809313e+22\n",
      "Training r2_score of SGDRegressor() is  -8.503181184669688e+21\n",
      "Testing r2_score of SGDRegressor() is  -2.983080338545493e+24\n",
      "Training r2_score of SGDRegressor() is  -2.3779836089698183e+24\n",
      "Testing r2_score of SGDRegressor() is  -1.0610127575619215e+24\n",
      "Training r2_score of SGDRegressor() is  -8.165864872037934e+23\n",
      "Testing r2_score of SGDRegressor() is  -1.2677046493792942e+24\n",
      "Training r2_score of SGDRegressor() is  -1.3214458080725822e+24\n",
      "Testing r2_score of SGDRegressor() is  -1.896888928718185e+24\n",
      "Training r2_score of SGDRegressor() is  -1.405870031351019e+24\n",
      "Testing r2_score of SGDRegressor() is  -4.591897331300299e+23\n",
      "Training r2_score of SGDRegressor() is  -4.239048818882736e+23\n",
      "Testing r2_score of SGDRegressor() is  -3.503512525294132e+22\n",
      "Training r2_score of SGDRegressor() is  -2.7797869728998133e+22\n",
      "Testing r2_score of SGDRegressor() is  -1.1112109903231633e+22\n",
      "Training r2_score of SGDRegressor() is  -8.698641689398226e+21\n",
      "Testing r2_score of SGDRegressor() is  -1.2326564546974929e+24\n",
      "Training r2_score of SGDRegressor() is  -1.29066837324058e+24\n",
      "Testing r2_score of SGDRegressor() is  -9.827351552556911e+21\n",
      "Training r2_score of SGDRegressor() is  -9.158420036591622e+21\n",
      "Testing r2_score of SGDRegressor() is  -1.0169791273830123e+23\n",
      "Training r2_score of SGDRegressor() is  -7.568975294747608e+22\n",
      "Testing r2_score of SGDRegressor() is  -1.3260492469728493e+24\n",
      "Training r2_score of SGDRegressor() is  -1.5127699936797954e+24\n",
      "Testing r2_score of SGDRegressor() is  -1.2850985332909218e+23\n",
      "Training r2_score of SGDRegressor() is  -1.5547966192142494e+23\n",
      "Testing r2_score of SGDRegressor() is  -2.747196396217915e+24\n",
      "Training r2_score of SGDRegressor() is  -2.0354100157585165e+24\n",
      "Testing r2_score of SGDRegressor() is  -5.479947936741635e+23\n",
      "Training r2_score of SGDRegressor() is  -5.1485822021676235e+23\n",
      "Testing r2_score of SGDRegressor() is  -1.9533906896716248e+23\n",
      "Training r2_score of SGDRegressor() is  -2.0313725340736433e+23\n",
      "Testing r2_score of SGDRegressor() is  -3.2106397699029314e+23\n",
      "Training r2_score of SGDRegressor() is  -3.444512153676151e+23\n",
      "Testing r2_score of SGDRegressor() is  -1.154841080924203e+24\n",
      "Training r2_score of SGDRegressor() is  -1.1856090949923169e+24\n",
      "Testing r2_score of SGDRegressor() is  -1.1904984297056224e+24\n",
      "Training r2_score of SGDRegressor() is  -9.95178387642464e+23\n",
      "Testing r2_score of SGDRegressor() is  -2.8369891003234192e+23\n",
      "Training r2_score of SGDRegressor() is  -2.7696981935371332e+23\n",
      "Testing r2_score of SGDRegressor() is  -1.310250424835588e+24\n",
      "Training r2_score of SGDRegressor() is  -1.0757027876953597e+24\n",
      "Testing r2_score of SGDRegressor() is  -3.925027826772242e+22\n",
      "Training r2_score of SGDRegressor() is  -4.419092224739084e+22\n"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "\n",
    "    algo_testing(algo=\"SGDRegressor()\",test_size=0.2,X=X,Y=Y,evaluation_metric=\"r2_score\",random_state=None,shuffle=True)\n",
    "avg_accuracies[\"SGDRegressor()\"]/=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8d6dbd8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of DecisionTreeRegressor() is  0.8217982672390272\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.7446211152606028\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.6358362533817655\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.8586403339740046\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.6742545325024936\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.6736989836089264\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.7585874042482379\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.7507480440684036\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.809632274878254\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.7993448973101056\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.4650010608327164\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.7638551980583976\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.6438580636426903\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.6791385977824148\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.6636738245819815\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.6974608123873725\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.783067178242079\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.6963305216095734\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.614673351212365\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.77436335981106\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.7590252081120766\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.7511294999333227\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.8160633867162885\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.6179289194313901\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.6651610518364225\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.6179482357394049\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.7378788790207822\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.747322905004904\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.6046689085273462\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.812212080405686\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.7118329241610812\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.8142111059905435\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.7202639336013434\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.7200291560790348\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.7558641179428638\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.6490168180827799\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.7466246711142588\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.754566663052788\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.5472706200051106\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.6301484459652698\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.7964197996605344\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.7271831057751437\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.7042109799727247\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.7072963462428001\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.6105729412035727\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.8649829327286551\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.7287791050785972\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.7601674919192917\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.7217568374320849\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n",
      "Testing r2_score of DecisionTreeRegressor() is  0.7273561499688685\n",
      "Training r2_score of DecisionTreeRegressor() is  1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(50):\n",
    "\n",
    "    algo_testing(algo=\"DecisionTreeRegressor()\",test_size=0.2,X=X,Y=Y,evaluation_metric=\"r2_score\",random_state=None,shuffle=True)\n",
    "avg_accuracies[\"DecisionTreeRegressor()\"]/=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "56473577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of ElasticNet() is  0.8550766051338873\n",
      "Training r2_score of ElasticNet() is  0.9070705642705083\n",
      "Testing r2_score of ElasticNet() is  0.8764770777914614\n",
      "Training r2_score of ElasticNet() is  0.9020581281083084\n",
      "Testing r2_score of ElasticNet() is  0.8652373216587851\n",
      "Training r2_score of ElasticNet() is  0.9080727591733236\n",
      "Testing r2_score of ElasticNet() is  0.8782881888515294\n",
      "Training r2_score of ElasticNet() is  0.9032799542042093\n",
      "Testing r2_score of ElasticNet() is  0.8637168462017042\n",
      "Training r2_score of ElasticNet() is  0.9062856313603285\n",
      "Testing r2_score of ElasticNet() is  0.8944405790489117\n",
      "Training r2_score of ElasticNet() is  0.8995860835255131\n",
      "Testing r2_score of ElasticNet() is  0.8797562796716101\n",
      "Training r2_score of ElasticNet() is  0.9020102050334353\n",
      "Testing r2_score of ElasticNet() is  0.9051989976841335\n",
      "Training r2_score of ElasticNet() is  0.8954251122532528\n",
      "Testing r2_score of ElasticNet() is  0.9043843471163128\n",
      "Training r2_score of ElasticNet() is  0.8976080005281707\n",
      "Testing r2_score of ElasticNet() is  0.9202274517718272\n",
      "Training r2_score of ElasticNet() is  0.8940483422939616\n",
      "Testing r2_score of ElasticNet() is  0.8751944884146029\n",
      "Training r2_score of ElasticNet() is  0.9028626128111519\n",
      "Testing r2_score of ElasticNet() is  0.8881456145207719\n",
      "Training r2_score of ElasticNet() is  0.9007268487950427\n",
      "Testing r2_score of ElasticNet() is  0.9105540624120289\n",
      "Training r2_score of ElasticNet() is  0.8951966036445598\n",
      "Testing r2_score of ElasticNet() is  0.895609829888923\n",
      "Training r2_score of ElasticNet() is  0.8988904227974991\n",
      "Testing r2_score of ElasticNet() is  0.8973223047302319\n",
      "Training r2_score of ElasticNet() is  0.89765830523816\n",
      "Testing r2_score of ElasticNet() is  0.8884966538906314\n",
      "Training r2_score of ElasticNet() is  0.9019870216873429\n",
      "Testing r2_score of ElasticNet() is  0.9166781384702022\n",
      "Training r2_score of ElasticNet() is  0.8957021254310555\n",
      "Testing r2_score of ElasticNet() is  0.8854695114584848\n",
      "Training r2_score of ElasticNet() is  0.9008031620463824\n",
      "Testing r2_score of ElasticNet() is  0.863638703719143\n",
      "Training r2_score of ElasticNet() is  0.9056405962782222\n",
      "Testing r2_score of ElasticNet() is  0.9017268219338568\n",
      "Training r2_score of ElasticNet() is  0.897922314636164\n",
      "Testing r2_score of ElasticNet() is  0.8969509353581271\n",
      "Training r2_score of ElasticNet() is  0.899953447712204\n",
      "Testing r2_score of ElasticNet() is  0.8948503514662464\n",
      "Training r2_score of ElasticNet() is  0.8977234151202566\n",
      "Testing r2_score of ElasticNet() is  0.8377994042441765\n",
      "Training r2_score of ElasticNet() is  0.9103473064518651\n",
      "Testing r2_score of ElasticNet() is  0.8976232943248741\n",
      "Training r2_score of ElasticNet() is  0.899142537565448\n",
      "Testing r2_score of ElasticNet() is  0.9041400049056632\n",
      "Training r2_score of ElasticNet() is  0.8964713332889033\n",
      "Testing r2_score of ElasticNet() is  0.8431743790562601\n",
      "Training r2_score of ElasticNet() is  0.9101958994632514\n",
      "Testing r2_score of ElasticNet() is  0.8493839093913115\n",
      "Training r2_score of ElasticNet() is  0.9065053494065102\n",
      "Testing r2_score of ElasticNet() is  0.9047112350196838\n",
      "Training r2_score of ElasticNet() is  0.8967003499315925\n",
      "Testing r2_score of ElasticNet() is  0.8293886407096811\n",
      "Training r2_score of ElasticNet() is  0.9113215356218367\n",
      "Testing r2_score of ElasticNet() is  0.9167608502206989\n",
      "Training r2_score of ElasticNet() is  0.8949452613618883\n",
      "Testing r2_score of ElasticNet() is  0.884685656701773\n",
      "Training r2_score of ElasticNet() is  0.9000761757534992\n",
      "Testing r2_score of ElasticNet() is  0.8926017101568475\n",
      "Training r2_score of ElasticNet() is  0.8998604313407098\n",
      "Testing r2_score of ElasticNet() is  0.8486672903103112\n",
      "Training r2_score of ElasticNet() is  0.9069561664303474\n",
      "Testing r2_score of ElasticNet() is  0.8930699360358978\n",
      "Training r2_score of ElasticNet() is  0.8951132868916505\n",
      "Testing r2_score of ElasticNet() is  0.856307752022435\n",
      "Training r2_score of ElasticNet() is  0.9063026179541569\n",
      "Testing r2_score of ElasticNet() is  0.893680343320116\n",
      "Training r2_score of ElasticNet() is  0.900100527393668\n",
      "Testing r2_score of ElasticNet() is  0.8357533442624242\n",
      "Training r2_score of ElasticNet() is  0.9093662246298554\n",
      "Testing r2_score of ElasticNet() is  0.9146727708955702\n",
      "Training r2_score of ElasticNet() is  0.8967157650329043\n",
      "Testing r2_score of ElasticNet() is  0.8659853704821059\n",
      "Training r2_score of ElasticNet() is  0.9030330633332265\n",
      "Testing r2_score of ElasticNet() is  0.8710726294475793\n",
      "Training r2_score of ElasticNet() is  0.9026233176603482\n",
      "Testing r2_score of ElasticNet() is  0.8215030573057206\n",
      "Training r2_score of ElasticNet() is  0.9125245338961316\n",
      "Testing r2_score of ElasticNet() is  0.9007936249453965\n",
      "Training r2_score of ElasticNet() is  0.8956571394707844\n",
      "Testing r2_score of ElasticNet() is  0.8662598034572322\n",
      "Training r2_score of ElasticNet() is  0.9069689218429093\n",
      "Testing r2_score of ElasticNet() is  0.8788024652563603\n",
      "Training r2_score of ElasticNet() is  0.9038975675023875\n",
      "Testing r2_score of ElasticNet() is  0.8587482529532382\n",
      "Training r2_score of ElasticNet() is  0.9056846173142283\n",
      "Testing r2_score of ElasticNet() is  0.8962752748860445\n",
      "Training r2_score of ElasticNet() is  0.8969928367022003\n",
      "Testing r2_score of ElasticNet() is  0.8571188550963008\n",
      "Training r2_score of ElasticNet() is  0.9055237007785519\n",
      "Testing r2_score of ElasticNet() is  0.8332246522277001\n",
      "Training r2_score of ElasticNet() is  0.9074996882040373\n",
      "Testing r2_score of ElasticNet() is  0.88742219658238\n",
      "Training r2_score of ElasticNet() is  0.8996361513589612\n",
      "Testing r2_score of ElasticNet() is  0.9046704096643245\n",
      "Training r2_score of ElasticNet() is  0.8979450582763252\n"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "\n",
    "    algo_testing(algo=\"ElasticNet()\",test_size=0.2,X=X,Y=Y,evaluation_metric=\"r2_score\",random_state=None,shuffle=True)\n",
    "avg_accuracies[\"ElasticNet()\"]/=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ccd7d989",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.375e+10, tolerance: 1.879e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.715e+10, tolerance: 1.845e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.8705732199953429\n",
      "Training r2_score of Lasso() is  0.9647062230705158\n",
      "Testing r2_score of Lasso() is  0.9052702001813115\n",
      "Training r2_score of Lasso() is  0.9603540454393246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.609e+10, tolerance: 1.841e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.979e+10, tolerance: 1.980e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.9001958765064495\n",
      "Training r2_score of Lasso() is  0.9614632478687541\n",
      "Testing r2_score of Lasso() is  0.8451258426326401\n",
      "Training r2_score of Lasso() is  0.9604291370132947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.299e+10, tolerance: 1.872e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.422e+10, tolerance: 1.932e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.664e+10, tolerance: 1.888e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.8887958255174158\n",
      "Training r2_score of Lasso() is  0.9601941772755638\n",
      "Testing r2_score of Lasso() is  0.8812826984619773\n",
      "Training r2_score of Lasso() is  0.9630828457302603\n",
      "Testing r2_score of Lasso() is  0.8983493177230469\n",
      "Training r2_score of Lasso() is  0.9618148169404638\n",
      "Testing r2_score of Lasso() is  0.8691027864039171\n",
      "Training r2_score of Lasso() is  0.9640879217830832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.432e+10, tolerance: 1.868e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.438e+10, tolerance: 1.802e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.8863093337550558\n",
      "Training r2_score of Lasso() is  0.9607058593519399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.781e+10, tolerance: 1.998e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.673e+10, tolerance: 1.764e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.8502754794922369\n",
      "Training r2_score of Lasso() is  0.9602868272356799\n",
      "Testing r2_score of Lasso() is  0.9201573178343774\n",
      "Training r2_score of Lasso() is  0.9567590866482932\n",
      "Testing r2_score of Lasso() is  0.8935808302966356\n",
      "Training r2_score of Lasso() is  0.9586408375468234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.868e+10, tolerance: 1.839e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.381e+10, tolerance: 1.796e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.8940324481618948\n",
      "Training r2_score of Lasso() is  0.9621613877011911\n",
      "Testing r2_score of Lasso() is  0.8715268947081878\n",
      "Training r2_score of Lasso() is  0.9634629156712687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.509e+10, tolerance: 1.886e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.297e+10, tolerance: 1.763e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.8849261175523563\n",
      "Training r2_score of Lasso() is  0.9624366212755003\n",
      "Testing r2_score of Lasso() is  0.8795939989772305\n",
      "Training r2_score of Lasso() is  0.9610625444387543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.522e+10, tolerance: 1.880e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.228e+10, tolerance: 1.821e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.9057850451484122\n",
      "Training r2_score of Lasso() is  0.9624036629145036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.929e+10, tolerance: 1.914e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.277e+10, tolerance: 1.965e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.8767665645190816\n",
      "Training r2_score of Lasso() is  0.9596405240090387\n",
      "Testing r2_score of Lasso() is  0.8725965165451097\n",
      "Training r2_score of Lasso() is  0.9618492485486887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.585e+10, tolerance: 1.831e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.334e+10, tolerance: 1.752e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.449e+10, tolerance: 1.795e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.9029254783153757\n",
      "Training r2_score of Lasso() is  0.9583199650636799\n",
      "Testing r2_score of Lasso() is  0.8999781171384243\n",
      "Training r2_score of Lasso() is  0.962250303952986\n",
      "Testing r2_score of Lasso() is  0.8976260158255466\n",
      "Training r2_score of Lasso() is  0.961308610601481\n",
      "Testing r2_score of Lasso() is  0.9152631455737318\n",
      "Training r2_score of Lasso() is  0.9613409712204875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.295e+10, tolerance: 1.788e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.551e+10, tolerance: 1.879e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.024e+10, tolerance: 1.711e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.8662258385912107\n",
      "Training r2_score of Lasso() is  0.9614219394788572\n",
      "Testing r2_score of Lasso() is  0.9006138349864302\n",
      "Training r2_score of Lasso() is  0.9641567394361994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.297e+10, tolerance: 1.706e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.9134236888431957\n",
      "Training r2_score of Lasso() is  0.9610342358946693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.940e+10, tolerance: 1.830e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.9283625989193982\n",
      "Training r2_score of Lasso() is  0.9562613467759601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.441e+10, tolerance: 1.815e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.9259177581847337\n",
      "Training r2_score of Lasso() is  0.9584445831920143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.619e+10, tolerance: 1.909e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.8842880242685068\n",
      "Training r2_score of Lasso() is  0.9617729299819003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.023e+10, tolerance: 1.836e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.8708208063592574\n",
      "Training r2_score of Lasso() is  0.9627079669913061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.486e+10, tolerance: 1.851e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.8633443118090126\n",
      "Training r2_score of Lasso() is  0.9629785002305679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.797e+10, tolerance: 1.809e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.214e+10, tolerance: 1.818e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.9253168902880243\n",
      "Training r2_score of Lasso() is  0.9581207474001237\n",
      "Testing r2_score of Lasso() is  0.8683958590647101\n",
      "Training r2_score of Lasso() is  0.9640162234095649\n",
      "Testing r2_score of Lasso() is  0.8473216937334649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.174e+10, tolerance: 1.926e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training r2_score of Lasso() is  0.9658389055484181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.507e+10, tolerance: 1.911e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.8821748985081469\n",
      "Training r2_score of Lasso() is  0.9607217266798679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.698e+10, tolerance: 1.661e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.8726712755844258\n",
      "Training r2_score of Lasso() is  0.9634289370096927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.403e+10, tolerance: 1.969e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.8633679391213336\n",
      "Training r2_score of Lasso() is  0.9629646148685456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.585e+09, tolerance: 1.807e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.8646953980622879\n",
      "Training r2_score of Lasso() is  0.9670389868419051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.598e+10, tolerance: 1.894e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.8771966610051641\n",
      "Training r2_score of Lasso() is  0.9625773726559255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.608e+10, tolerance: 1.834e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.104e+10, tolerance: 1.887e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.9104526814839939\n",
      "Training r2_score of Lasso() is  0.9597366213349099\n",
      "Testing r2_score of Lasso() is  0.8957416891378833\n",
      "Training r2_score of Lasso() is  0.9572718298961512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.000e+10, tolerance: 1.789e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.9114241418837686\n",
      "Training r2_score of Lasso() is  0.9576223531645288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.320e+10, tolerance: 1.810e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.608e+10, tolerance: 1.795e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.9142772669328092\n",
      "Training r2_score of Lasso() is  0.9598362426783975\n",
      "Testing r2_score of Lasso() is  0.9251894626314929\n",
      "Training r2_score of Lasso() is  0.9576756546305908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.648e+09, tolerance: 1.790e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.623e+10, tolerance: 1.816e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.009e+10, tolerance: 1.942e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.9222297118322199\n",
      "Training r2_score of Lasso() is  0.9578715778608358\n",
      "Testing r2_score of Lasso() is  0.9023474743822594\n",
      "Training r2_score of Lasso() is  0.9598551381773097\n",
      "Testing r2_score of Lasso() is  0.8902424465350015\n",
      "Training r2_score of Lasso() is  0.9583587753143553\n",
      "Testing r2_score of Lasso() is  0.9018686276554965\n",
      "Training r2_score of Lasso() is  0.960817995875563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.721e+10, tolerance: 1.906e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.776e+10, tolerance: 1.836e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Lasso() is  0.8726005963628075\n",
      "Training r2_score of Lasso() is  0.9668085730914977\n",
      "Testing r2_score of Lasso() is  0.912335162917931\n",
      "Training r2_score of Lasso() is  0.9597900766236862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mritu\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.578e+10, tolerance: 1.798e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "\n",
    "    algo_testing(algo=\"Lasso()\",test_size=0.2,X=X,Y=Y,evaluation_metric=\"r2_score\",random_state=None,shuffle=True)\n",
    "avg_accuracies[\"Lasso()\"]/=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ec55c398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing r2_score of Ridge() is  0.9090182820743694\n",
      "Training r2_score of Ridge() is  0.958811360794388\n",
      "Testing r2_score of Ridge() is  0.9197007465713153\n",
      "Training r2_score of Ridge() is  0.9569696316526047\n",
      "Testing r2_score of Ridge() is  0.8894166148851658\n",
      "Training r2_score of Ridge() is  0.9598705543713906\n",
      "Testing r2_score of Ridge() is  0.8708878798738996\n",
      "Training r2_score of Ridge() is  0.9620259563063851\n",
      "Testing r2_score of Ridge() is  0.9272472853295637\n",
      "Training r2_score of Ridge() is  0.9568095632582565\n",
      "Testing r2_score of Ridge() is  0.8926853728631571\n",
      "Training r2_score of Ridge() is  0.9618377625753556\n",
      "Testing r2_score of Ridge() is  0.9355431907022025\n",
      "Training r2_score of Ridge() is  0.9553137143879507\n",
      "Testing r2_score of Ridge() is  0.8931112414866402\n",
      "Training r2_score of Ridge() is  0.9607680179530218\n",
      "Testing r2_score of Ridge() is  0.903850575128673\n",
      "Training r2_score of Ridge() is  0.957294038702025\n",
      "Testing r2_score of Ridge() is  0.8943142784906812\n",
      "Training r2_score of Ridge() is  0.9615858213406677\n",
      "Testing r2_score of Ridge() is  0.9050178074421367\n",
      "Training r2_score of Ridge() is  0.9589740938561215\n",
      "Testing r2_score of Ridge() is  0.9347366813257558\n",
      "Training r2_score of Ridge() is  0.9548090499253852\n",
      "Testing r2_score of Ridge() is  0.9360876155721487\n",
      "Training r2_score of Ridge() is  0.9540177728127148\n",
      "Testing r2_score of Ridge() is  0.8955437798542593\n",
      "Training r2_score of Ridge() is  0.9588200387901539\n",
      "Testing r2_score of Ridge() is  0.8977120306456495\n",
      "Training r2_score of Ridge() is  0.9604412385130682\n",
      "Testing r2_score of Ridge() is  0.9208701971084762\n",
      "Training r2_score of Ridge() is  0.9567206466790329\n",
      "Testing r2_score of Ridge() is  0.897194399749863\n",
      "Training r2_score of Ridge() is  0.9599386470373272\n",
      "Testing r2_score of Ridge() is  0.8983199717626527\n",
      "Training r2_score of Ridge() is  0.9582582805441232\n",
      "Testing r2_score of Ridge() is  0.8801692717852948\n",
      "Training r2_score of Ridge() is  0.9624151633664509\n",
      "Testing r2_score of Ridge() is  0.9147941773423917\n",
      "Training r2_score of Ridge() is  0.9576019271711036\n",
      "Testing r2_score of Ridge() is  0.8846791451933369\n",
      "Training r2_score of Ridge() is  0.9616738609544675\n",
      "Testing r2_score of Ridge() is  0.9335723464475627\n",
      "Training r2_score of Ridge() is  0.9555453698875461\n",
      "Testing r2_score of Ridge() is  0.9251370183830657\n",
      "Training r2_score of Ridge() is  0.9582097843141326\n",
      "Testing r2_score of Ridge() is  0.9179737111956933\n",
      "Training r2_score of Ridge() is  0.9572957261284158\n",
      "Testing r2_score of Ridge() is  0.8739078436745418\n",
      "Training r2_score of Ridge() is  0.9645648775075982\n",
      "Testing r2_score of Ridge() is  0.9145308926462854\n",
      "Training r2_score of Ridge() is  0.957960680083225\n",
      "Testing r2_score of Ridge() is  0.901347250109555\n",
      "Training r2_score of Ridge() is  0.9609431513566148\n",
      "Testing r2_score of Ridge() is  0.9146501910442636\n",
      "Training r2_score of Ridge() is  0.9589268600412606\n",
      "Testing r2_score of Ridge() is  0.9247007169708776\n",
      "Training r2_score of Ridge() is  0.9571056272634771\n",
      "Testing r2_score of Ridge() is  0.900440628067628\n",
      "Training r2_score of Ridge() is  0.9617990641765339\n",
      "Testing r2_score of Ridge() is  0.9343456768174296\n",
      "Training r2_score of Ridge() is  0.9541812574532873\n",
      "Testing r2_score of Ridge() is  0.8924493858123859\n",
      "Training r2_score of Ridge() is  0.9600094257633508\n",
      "Testing r2_score of Ridge() is  0.9354676952804793\n",
      "Training r2_score of Ridge() is  0.9539073435237442\n",
      "Testing r2_score of Ridge() is  0.9258735656721139\n",
      "Training r2_score of Ridge() is  0.9569226866370012\n",
      "Testing r2_score of Ridge() is  0.9063482125786441\n",
      "Training r2_score of Ridge() is  0.9565936050803273\n",
      "Testing r2_score of Ridge() is  0.8776144775953587\n",
      "Training r2_score of Ridge() is  0.9625415326641072\n",
      "Testing r2_score of Ridge() is  0.9238775528730875\n",
      "Training r2_score of Ridge() is  0.954920078584072\n",
      "Testing r2_score of Ridge() is  0.9322755131270218\n",
      "Training r2_score of Ridge() is  0.9546121743833965\n",
      "Testing r2_score of Ridge() is  0.9105323465000652\n",
      "Training r2_score of Ridge() is  0.9568494337175882\n",
      "Testing r2_score of Ridge() is  0.8683673585103078\n",
      "Training r2_score of Ridge() is  0.9634816873997912\n",
      "Testing r2_score of Ridge() is  0.9105758692828446\n",
      "Training r2_score of Ridge() is  0.957905391008958\n",
      "Testing r2_score of Ridge() is  0.9166010750114968\n",
      "Training r2_score of Ridge() is  0.9550823349894361\n",
      "Testing r2_score of Ridge() is  0.910286559027848\n",
      "Training r2_score of Ridge() is  0.9570560181854321\n",
      "Testing r2_score of Ridge() is  0.9066299634202263\n",
      "Training r2_score of Ridge() is  0.9572026974276452\n",
      "Testing r2_score of Ridge() is  0.9006340104929937\n",
      "Training r2_score of Ridge() is  0.9612039202751531\n",
      "Testing r2_score of Ridge() is  0.9290690240575208\n",
      "Training r2_score of Ridge() is  0.95436220381184\n",
      "Testing r2_score of Ridge() is  0.9048776491317395\n",
      "Training r2_score of Ridge() is  0.95875601484197\n",
      "Testing r2_score of Ridge() is  0.8980901955092904\n",
      "Training r2_score of Ridge() is  0.959961740431767\n",
      "Testing r2_score of Ridge() is  0.8880214819270689\n",
      "Training r2_score of Ridge() is  0.9608532151716643\n",
      "Testing r2_score of Ridge() is  0.8927490170762707\n",
      "Training r2_score of Ridge() is  0.9609412810891861\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(50):\n",
    "\n",
    "    algo_testing(algo=\"Ridge()\",test_size=0.2,X=X,Y=Y,evaluation_metric=\"r2_score\",random_state=None,shuffle=True)\n",
    "avg_accuracies[\"Ridge()\"]/=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a9aed687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LinearRegression()': 0.8831795176269176,\n",
       " 'RandomForestRegressor()': 0.8686521700485363,\n",
       " 'SVR()': -0.015334241886413025,\n",
       " 'KNeighborsRegressor()': 0.6494356106577349,\n",
       " 'SGDRegressor()': -7.410145889263951e+23,\n",
       " 'DecisionTreeRegressor()': 0.7167295459067489,\n",
       " 'ElasticNet()': 0.8800347645015103,\n",
       " 'Lasso()': 0.8904577162070147,\n",
       " 'Ridge()': 0.907436955468626}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "80b71c05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LinearRegression()': 0.9267065428846499,\n",
       " 'RandomForestRegressor()': 0.9397878103943064,\n",
       " 'SVR()': 3.2180146942173415e-05,\n",
       " 'KNeighborsRegressor()': 0.7401351304066244,\n",
       " 'SGDRegressor()': -7.589565659888994e+21,\n",
       " 'DecisionTreeRegressor()': 0.8649829327286551,\n",
       " 'ElasticNet()': 0.9202274517718272,\n",
       " 'Lasso()': 0.9283625989193982,\n",
       " 'Ridge()': 0.9360876155721487}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highest_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfaf0fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f121ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c8e6fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c321e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a64d9c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee71221-46cd-4f6d-8a8a-09eb9b64aa2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fab150-ef23-4110-bc56-7921a694d747",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
